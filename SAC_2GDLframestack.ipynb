{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XCEQ6e08PQYe"
      },
      "outputs": [],
      "source": [
        "from gymnasium import Env\n",
        "from gymnasium.spaces.box import Box\n",
        "import numpy as np\n",
        "import random\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, StopTrainingOnRewardThreshold, EvalCallback\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pickle\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rFCb5ECGR1Lt"
      },
      "outputs": [],
      "source": [
        "class BobinaEnvTest(Env):\n",
        "  \"\"\"\n",
        "  Custom Gym Environment for the Hybrid Electromagnetic Suspension, considering just two degrees of freedom.\n",
        "  \"\"\"\n",
        "  def __init__(self, alive = 20, masa_pod = 250, airgap = 16.3, duration = 10, dist_cm = 0.7, inercia= 70, min_distance = 9, max_distance = 22.5):\n",
        "    # Actions: Voltage applied to the coil\n",
        "    self.action_space = Box(low=np.array([-100, -100]), high = np.array([100, 100]), dtype=np.float32)\n",
        "    # Observations: Airgap to the ceiling, velocity, distance to the objective, current of the coil\n",
        "    self.observation_space = Box(low=np.array([-10, -10, -np.inf, -np.inf, -45, -45]), high = np.array([10, 10, np.inf, np.inf, 45, 45]), dtype=np.float32)\n",
        "    # Initial parameters\n",
        "    airgap = random.uniform(15.3, 17.3)\n",
        "    self.state = np.array([airgap - 16.3, airgap - 16.3, 0, 0, 0, 0])\n",
        "    self.airgapinicial = airgap\n",
        "    self.duration = duration\n",
        "    self.timeleft = duration\n",
        "    self.crash = False\n",
        "    self.masa_pod = masa_pod\n",
        "    self.sistema = TwoGDL(masa_pod = self.masa_pod, airgap = self.airgapinicial, dist_cm = dist_cm, inercia= inercia, min_distance = min_distance, max_distance = max_distance)\n",
        "    self.steps = []\n",
        "    self.airgap1 = airgap\n",
        "    self.airgap2 = airgap\n",
        "    self.distancia1 = 0\n",
        "    self.distancia2 = 0\n",
        "    self.velocidad = 0\n",
        "    self.current1 = 0\n",
        "    self.current2 = 0\n",
        "    self.alive = alive\n",
        "    self.vel = 0\n",
        "    self.velangular = 0\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    # Apply action\n",
        "    self.state, self.crash, angulo, error = self.sistema.step(action[0],action[1])\n",
        "    self.distancia1, self.distancia2, self.vel, self.velangular, self.current1, self.current2 = self.state\n",
        "\n",
        "    # Reduce the time of the experiment\n",
        "    self.timeleft -= 0.001\n",
        "\n",
        "    # Calculate reward\n",
        "    reward = -abs(self.distancia1) -abs(self.distancia2) - 10000*self.crash\n",
        "\n",
        "    \"\"\"if self.airgap >= 23: reward = -500\n",
        "    elif self.airgap <= 10: reward = -500\n",
        "    else: reward = -abs(self.current)\"\"\"\n",
        "\n",
        "    # Check if experiment is done\n",
        "    if self.timeleft <= 0:\n",
        "      truncated = True\n",
        "    else: truncated = False\n",
        "    # Set placeholder for info\n",
        "    info = {}\n",
        "    # Only if we implemented the crash\n",
        "    \"\"\"if self.crash:\n",
        "      reward = - 100000\n",
        "      terminated = True\n",
        "    else:\n",
        "      terminated = False\"\"\"\n",
        "    terminated = False\n",
        "    self.steps.append(self.state)\n",
        "    return self.state, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "  def render(self, yes = \"yes\", normalize = True, seed = 0):\n",
        "    # create data\n",
        "    x = list(range(0,len(self.steps)))\n",
        "    y1 = [16.3+step[0] for step in self.steps]\n",
        "    y2 = [16.3+step[1] for step in self.steps]\n",
        "    objective = [16.3]*len(self.steps)\n",
        "\n",
        "    # plot lines\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    #ax.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red\n",
        "    #ax.tick_params(axis='y', colors='white')  #setting up Y-axis tick color to black\n",
        "    if normalize: ax.set_ylim(bottom=8, top=23)\n",
        "    plt.xlabel(\"Time (s)\") #, color='white')\n",
        "    plt.ylabel(\"Airgap (mm)\") #, color='white')\n",
        "    plt.title(\"Airgap evolution\") #, color='white')\n",
        "\n",
        "    plt.plot(x, y1, label = \"Airgap 1\")\n",
        "    plt.plot(x, y2, label = \"Airgap 2\")\n",
        "    plt.plot(x, objective, label = \"Objective\")\n",
        "    plt.legend()\n",
        "    #if self.steps[0][0] < 0: plt.savefig(\"images/top-2gdl8x8nocrash.png\")\n",
        "    #else: plt.savefig(\"images/bottom-2gdl8x8nocrash.png\")\n",
        "    plt.savefig(f\"images/2gdl8x8nocrashsituation{seed}.png\")\n",
        "    plt.show()\n",
        "\n",
        "  def reset(self, seed = 0):\n",
        "    # Reset experiment choosing randomly the start (ceiling or floor)\n",
        "    airgap = random.uniform(9.5, 22)\n",
        "    #self.state = np.array([airgap - 16.3, airgap - 16.3, 0, 0, 0, 0])\n",
        "    self.sistema = TwoGDL(masa_pod = self.masa_pod, airgap = airgap, dist_cm = 0.7, inercia= 70, min_distance = 9, max_distance = 22.5)\n",
        "    angulo = random.uniform(-0.008, 0.008)\n",
        "    self.vel = random.uniform(-0.2, 0.2)\n",
        "    self.velangular = random.uniform(-0.3, 0.3)\n",
        "    self.current1 = 0\n",
        "    self.current2 = 0\n",
        "    airgap1, airgap2 = self.sistema.pos2airgap(pos = airgap, theta = angulo)\n",
        "    self.distancia1, self.distancia2 = airgap1-16.3, airgap2-16.3\n",
        "    self.state= self.distancia1, self.distancia2, self.vel, self.velangular, self.current1, self.current2\n",
        "    self.sistema.integral_aceleracion = self.vel\n",
        "    self.sistema.integral_alpha = self.velangular\n",
        "    self.sistema.integral_omega = angulo\n",
        "    self.state, self.crash = self.sistema.step(0,0)\n",
        "    self.distancia11, self.distancia12, self.distancia21, self.distancia22, self.current1, self.current2 = self.state\n",
        "    \n",
        "    # Reset time\n",
        "    self.timeleft = self.duration\n",
        "    self.crash = False\n",
        "    self.steps = []\n",
        "    return self.state, seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BobinaEnv(Env):\n",
        "  \"\"\"\n",
        "  Custom Gym Environment for the Hybrid Electromagnetic Suspension, considering just two degrees of freedom.\n",
        "  \"\"\"\n",
        "  def __init__(self, alive = 20, masa_pod = 250, airgap = 16.3, duration = 10, dist_cm = 0.7, inercia= 70, min_distance = 9, max_distance = 22.5):\n",
        "    # Actions: Voltage applied to the coil\n",
        "    self.action_space = Box(low=np.array([-100, -100]), high = np.array([100, 100]), dtype=np.float32)\n",
        "    # Observations: Airgap to the ceiling, velocity, distance to the objective, current of the coil\n",
        "    self.observation_space = Box(low=np.array([-10, -10, -10, -10, -45, -45]), high = np.array([10, 10, 10, 10, 45, 45]), dtype=np.float32)\n",
        "    # Initial parameters\n",
        "    airgap = random.choice([11.5, 21])\n",
        "    self.state = np.array([airgap - 16.3, airgap - 16.3, airgap - 16.3, airgap - 16.3, 0, 0])\n",
        "    self.airgapinicial = airgap\n",
        "    self.duration = duration\n",
        "    self.timeleft = duration\n",
        "    self.crash = False\n",
        "    self.masa_pod = masa_pod\n",
        "    self.sistema = TwoGDL(masa_pod = self.masa_pod, airgap = self.airgapinicial, dist_cm = dist_cm, inercia= inercia, min_distance = min_distance, max_distance = max_distance)\n",
        "    self.steps = []\n",
        "    self.airgap1 = airgap\n",
        "    self.airgap2 = airgap\n",
        "    self.distancia1 = 0\n",
        "    self.distancia2 = 0\n",
        "    self.velocidad = 0\n",
        "    self.current1 = 0\n",
        "    self.current2 = 0\n",
        "    self.alive = alive\n",
        "    self.vel = 0\n",
        "    self.velangular = 0\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    # Apply action\n",
        "    self.state, self.crash = self.sistema.step(action[0],action[1])\n",
        "    self.distancia11, self.distancia12, self.distancia21, self.distancia22, self.current1, self.current2 = self.state\n",
        "\n",
        "    # Reduce the time of the experiment\n",
        "    self.timeleft -= 0.001\n",
        "\n",
        "    # Calculate reward\n",
        "    reward = -abs(self.distancia12) -abs(self.distancia22) - 50*self.crash\n",
        "\n",
        "    \"\"\"if self.airgap >= 23: reward = -500\n",
        "    elif self.airgap <= 10: reward = -500\n",
        "    else: reward = -abs(self.current)\"\"\"\n",
        "\n",
        "    # Check if experiment is done\n",
        "    if self.timeleft <= 0:\n",
        "      truncated = True\n",
        "    else: truncated = False\n",
        "    # Set placeholder for info\n",
        "    info = {}\n",
        "    # Only if we implemented the crash\n",
        "    \"\"\"if self.crash:\n",
        "      reward = - 100000\n",
        "      terminated = True\n",
        "    else:\n",
        "      terminated = False\"\"\"\n",
        "    terminated = False\n",
        "    self.steps.append(self.state)\n",
        "    return self.state, reward, terminated, truncated, info\n",
        "\n",
        "\n",
        "  def render(self, yes = \"yes\", normalize = True, seed = 0):\n",
        "    # create data\n",
        "    x = list(range(0,len(self.steps)))\n",
        "    y1 = [16.3+step[0] for step in self.steps]\n",
        "    y2 = [16.3+step[2] for step in self.steps]\n",
        "    objective = [16.3]*len(self.steps)\n",
        "\n",
        "    # plot lines\n",
        "    fig = plt.figure(figsize=(10,5))\n",
        "    ax = fig.add_subplot(111)\n",
        "    #ax.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red\n",
        "    #ax.tick_params(axis='y', colors='white')  #setting up Y-axis tick color to black\n",
        "    if normalize: ax.set_ylim(bottom=8, top=23)\n",
        "    plt.xlabel(\"Time (s)\") #, color='white')\n",
        "    plt.ylabel(\"Airgap (mm)\") #, color='white')\n",
        "    plt.title(\"Airgap evolution\") #, color='white')\n",
        "\n",
        "    plt.plot(x, y1, label = \"Airgap 1\")\n",
        "    plt.plot(x, y2, label = \"Airgap 2\")\n",
        "    plt.plot(x, objective, label = \"Objective\")\n",
        "    plt.legend()\n",
        "    #if self.steps[0][0] < 0: plt.savefig(\"images/top-2gdl8x8nocrash.png\")\n",
        "    #else: plt.savefig(\"images/bottom-2gdl8x8nocrash.png\")\n",
        "    plt.savefig(f\"images/2gdl8x8nocrashsituation{seed}.png\")\n",
        "    plt.show()\n",
        "\n",
        "  def reset(self, seed = 0):\n",
        "    # Reset experiment choosing randomly the start (ceiling or floor)\n",
        "    airgap = random.choice([11.5, 21])\n",
        "    self.state = np.array([airgap - 16.3, airgap - 16.3, airgap - 16.3, airgap - 16.3, 0, 0])\n",
        "    self.sistema = TwoGDL(masa_pod = self.masa_pod, airgap = airgap, dist_cm = 0.7, inercia= 70, min_distance = 9, max_distance = 22.5)\n",
        "    \n",
        "    # Reset time\n",
        "    self.timeleft = self.duration\n",
        "    self.crash = False\n",
        "    self.steps = []\n",
        "    return self.state, seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9SgMX9wfPZEl"
      },
      "outputs": [],
      "source": [
        "class Bobina():\n",
        "  \"\"\" \n",
        "  Coil model for the Hybrid Electromagnetic Suspension\n",
        "  \"\"\"\n",
        "  def __init__(self, masa_pod = 250, airgap = 22.5, min_distance = 9, max_distance = 22.5):\n",
        "    self.masa_pod = masa_pod\n",
        "    self.airgap = airgap\n",
        "    self.aceleracion = []\n",
        "    self.velocidad = []\n",
        "    mat = scipy.io.loadmat('./coil/hems.mat')\n",
        "    self.hems = mat[\"hems\"][0][0]\n",
        "    self.airgaps = self.hems[0][0]\n",
        "    self.currents = self.hems[1][0]\n",
        "    self.force_vertical = pickle.load(open(\"./coil/mlp_vertical.pkl\", 'rb'))\n",
        "    self.flux = self.hems[3]\n",
        "    self.force_horizontal = self.hems[4]\n",
        "    self.inductance = pickle.load(open(\"./coil/rf_inductance.pkl\", 'rb'))\n",
        "    self.resistance = self.hems[6][0][0]\n",
        "    self.min_distance = min_distance\n",
        "    self.max_distance = max_distance\n",
        "    self.airgapinicial = airgap\n",
        "    self.crash = False\n",
        "    self.current = 0\n",
        "    self.steps_RL = []\n",
        "\n",
        "  def integral(self, lista, h = 1):\n",
        "    return sum(h*(lista[i]+lista[i+1])/2 for i in range(len(lista)-1))\n",
        "\n",
        "  def RL(self, airgap, target_voltage, temperature):\n",
        "    # Resistance-Inductance circuit\n",
        "\n",
        "    # Get resistance of the coil\n",
        "    R = self.R(current = self.current, temperature = temperature)   \n",
        "    V = target_voltage\n",
        "    I = self.current\n",
        "    L = self.L(airgap = airgap, current = self.current)\n",
        "    dIdt = ((V/R) - I)/(L/R)                                      \n",
        "    self.steps_RL.append(dIdt)                                   \n",
        "    current = self.integral(self.steps_RL, h = 0.001)                          \n",
        "    return current                                                  \n",
        "\n",
        "  def R(self, current, temperature):\n",
        "    return self.resistance                                         \n",
        "\n",
        "  def L(self, airgap, current):\n",
        "    # Return predicted inductance\n",
        "    return float(self.inductance.predict(np.array([[airgap, current]]))[0])\n",
        "\n",
        "  def vertical_force(self, airgap, target_voltage, temperature):\n",
        "    # Get current from RL circuit\n",
        "    I = self.RL(airgap = airgap, target_voltage = target_voltage, temperature = temperature) \n",
        "    \n",
        "    # Clip result\n",
        "    if I > 45:\n",
        "      I = 45\n",
        "    elif I < -45:\n",
        "      I = -45\n",
        "    self.current = I\n",
        "    # Get vertical force from \n",
        "    FI = self.FI_vertical(airgap = airgap, current = I)                    \n",
        "    return FI, I\n",
        "\n",
        "\n",
        "  def FI_vertical(self, airgap, current):\n",
        "    # Return predicted vertical force\n",
        "    return float(self.force_vertical.predict(np.array([[airgap, current]])))    \n",
        "\n",
        "\n",
        "  def next_airgap(self, masa_pod, vertical_force, verbose = False):\n",
        "    # Devide the mass of the pod by 4 coils\n",
        "    masa = masa_pod/4  \n",
        "    # Calculate weight\n",
        "    peso = masa * 9.8    \n",
        "    # Get total force                                                       \n",
        "    fuerza = peso - vertical_force\n",
        "    if verbose: print(\"Fuerza resultante: \", fuerza)   \n",
        "    # Calculate acceleration                                     \n",
        "    aceleracion = fuerza/masa\n",
        "    if verbose: print(\"Aceleración: \", aceleracion)                                         \n",
        "    self.aceleracion.append(aceleracion)       \n",
        "    # Calculate velocity                                \n",
        "    velocidad = self.integral(self.aceleracion, 0.001)\n",
        "    if verbose: print(\"Integral primera (velocidad): \", velocidad)                          \n",
        "    self.velocidad.append(velocidad)               \n",
        "    # Calculate position (x1000 as to transform from m to mm)                            \n",
        "    posicion = self.airgapinicial + self.integral(self.velocidad, 0.001)*1000 \n",
        "    if verbose: print(\"Integral segunda (posición): \", posicion)\n",
        "\n",
        "    # Clip position\n",
        "    if posicion > self.max_distance:\n",
        "      airgap = self.max_distance\n",
        "      self.aceleracion = [0]\n",
        "      self.velocidad = [0]  \n",
        "      #self.crash = True     \n",
        "      self.airgapinicial = self.max_distance                                               \n",
        "    elif posicion < self.min_distance:\n",
        "      airgap = self.min_distance\n",
        "      self.aceleracion = [0]\n",
        "      self.velocidad = [0]\n",
        "      #self.crash = True\n",
        "      self.airgapinicial = self.min_distance\n",
        "    else: airgap = posicion\n",
        "    return airgap, velocidad\n",
        "\n",
        "  def step(self, target_voltage, verbose = False):\n",
        "    # Calculate vertical force and current\n",
        "    vertical_force, self.current = self.vertical_force(airgap = self.airgap, target_voltage = target_voltage, temperature = 40)\n",
        "    if verbose: print(\"Fuerza vertical: \", vertical_force)\n",
        "    # Calculate next airgap and velocity\n",
        "    self.airgap, velocidad = self.next_airgap(self.masa_pod, vertical_force, verbose = verbose)\n",
        "    #noise = np.random.normal(0,0.5)\n",
        "    #self.airgap = self.airgap + noise     \n",
        "    return (np.float32(self.airgap), np.float32(velocidad), np.float32(self.airgap - 16.3), np.float32(self.current)), self.crash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TwoGDL():\n",
        "    def __init__(self, masa_pod = 250, airgap = 22.5, dist_cm = 0.7, inercia= 70, min_distance = 9, max_distance = 22.5):\n",
        "        self.masa_pod = masa_pod\n",
        "        self.airgap1 = airgap\n",
        "        self.airgap1_list = [airgap, airgap]\n",
        "        self.airgap2 = airgap\n",
        "        self.airgap2_list = [airgap, airgap]\n",
        "        self.dist_cm = dist_cm\n",
        "        self.inercia = inercia\n",
        "        self.airgapinicial = airgap\n",
        "        self.min_distance = min_distance\n",
        "        self.max_distance = max_distance\n",
        "        self.b1 = Bobina(masa_pod = self.masa_pod, airgap = self.airgap1, min_distance = self.min_distance, max_distance = self.max_distance)\n",
        "        self.b2 = Bobina(masa_pod = self.masa_pod, airgap = self.airgap2, min_distance = self.min_distance, max_distance = self.max_distance)\n",
        "        self.crash = False\n",
        "        self.angulo = [0]\n",
        "        self.alpha = [0]\n",
        "        self.integral_alpha = 0\n",
        "        self.omega = [0]\n",
        "        self.integral_omega = 0\n",
        "        self.altura = [0]\n",
        "        self.aceleracion = [0]\n",
        "        self.integral_aceleracion = 0\n",
        "        self.velocidad = [0]\n",
        "        self.integral_velocidad = 0\n",
        "    \n",
        "    def integral(self, lista, h = 1):\n",
        "        return sum(h*(lista[i]+lista[i+1])/2 for i in range(len(lista)-1))\n",
        "    \n",
        "    def fast_integral(self, last, lista, h = 0.001):\n",
        "        return last + h*(lista[-1]+lista[-2])/2\n",
        "    \n",
        "    def get_angulo(self, f1, f2):\n",
        "        F1 = f1*self.dist_cm\n",
        "        F2 = -f2*self.dist_cm\n",
        "        M = F1+F2\n",
        "        alpha = M/self.inercia\n",
        "        self.alpha.append(alpha)\n",
        "        omega = self.fast_integral(self.integral_alpha, self.alpha, 0.001)\n",
        "        self.integral_alpha = omega\n",
        "        self.omega.append(omega)\n",
        "        angulo = self.fast_integral(self.integral_omega, self.omega, 0.001)\n",
        "        self.integral_omega = angulo\n",
        "        self.angulo.append(angulo)\n",
        "        return angulo\n",
        "    \n",
        "    def get_altura(self, f1, f2):\n",
        "        F = (self.masa_pod/2)*9.8 - f1 - f2\n",
        "        a = F/(self.masa_pod/2)\n",
        "        self.aceleracion.append(a)\n",
        "        v = self.fast_integral(self.integral_aceleracion, self.aceleracion, 0.001)\n",
        "        self.integral_aceleracion = v\n",
        "        self.velocidad.append(v)\n",
        "        zpos = self.fast_integral(self.integral_velocidad,self.velocidad, 0.001)\n",
        "        self.integral_velocidad = zpos\n",
        "        zpos = self.airgapinicial + zpos*1000\n",
        "        self.altura.append(zpos)\n",
        "        return zpos\n",
        "    \n",
        "    def pos2airgap(self, pos, theta):\n",
        "        airgap1 = pos + self.dist_cm*math.sin(theta)*1000\n",
        "        airgap2 = pos - self.dist_cm*math.sin(theta)*1000\n",
        "        return airgap1, airgap2\n",
        "    \n",
        "    def step(self, target_voltage1, target_voltage2, verbose = False):\n",
        "        # Calculate vertical force and current\n",
        "        self.crash = False\n",
        "        vertical_force1, current1 = self.b1.vertical_force(airgap = self.airgap1, target_voltage = target_voltage1, temperature = 40)\n",
        "        vertical_force2, current2 = self.b2.vertical_force(airgap = self.airgap2, target_voltage = target_voltage2, temperature = 40)\n",
        "        if verbose: print(\"Fuerza vertical 1: \", vertical_force1)\n",
        "        if verbose: print(\"Fuerza vertical 2: \", vertical_force2)\n",
        "        angulo = self.get_angulo(f1 = vertical_force1, f2 = vertical_force2)\n",
        "        zpos = self.get_altura(f1 = vertical_force1, f2 = vertical_force2)\n",
        "        self.airgap1, self.airgap2 = self.pos2airgap(pos = zpos, theta = angulo)\n",
        "        self.airgap1_list.append(self.airgap1)\n",
        "        self.airgap2_list.append(self.airgap2)\n",
        "        if verbose: print(\"Airgap 1: \", self.airgap1)\n",
        "        if verbose: print(\"Airgap 2: \", self.airgap2)\n",
        "        if self.airgap1 > self.max_distance or self.airgap2 > self.max_distance:\n",
        "            self.airgap1 = self.max_distance\n",
        "            self.airgap2 = self.max_distance\n",
        "            self.crash = True\n",
        "            self.angulo = [0]\n",
        "            self.alpha = [0]\n",
        "            self.integral_alpha = 0\n",
        "            self.omega = [0]\n",
        "            self.integral_omega = 0\n",
        "            self.altura = [0]\n",
        "            self.aceleracion = [0]\n",
        "            self.integral_aceleracion = 0\n",
        "            self.velocidad = [0]\n",
        "            self.integral_velocidad = 0\n",
        "            self.airgapinicial = self.max_distance\n",
        "        elif self.airgap1 < self.min_distance or self.airgap2 < self.min_distance:\n",
        "            self.airgap1 = self.min_distance\n",
        "            self.airgap2 = self.min_distance\n",
        "            self.crash = True\n",
        "            self.angulo = [0]\n",
        "            self.alpha = [0]\n",
        "            self.integral_alpha = 0\n",
        "            self.omega = [0]\n",
        "            self.integral_omega = 0\n",
        "            self.altura = [0]\n",
        "            self.aceleracion = [0]\n",
        "            self.integral_aceleracion = 0\n",
        "            self.velocidad = [0]\n",
        "            self.integral_velocidad = 0\n",
        "            self.airgapinicial = self.min_distance\n",
        "        #return (np.float32(self.airgap1 -16.3), np.float32(self.airgap2-16.3), np.float32(current1), np.float32(current2)), self.crash\n",
        "        #return (np.float32(self.airgap1 -16.3), np.float32(self.airgap2-16.3), np.float32(self.integral_aceleracion), np.float32(self.integral_alpha), np.float32(current1), np.float32(current2)), self.crash, angulo, zpos - 16.3\n",
        "        return (np.float32(self.airgap1_list[-2] -16.3), np.float32(self.airgap1_list[-1] -16.3), np.float32(self.airgap2_list[-2] -16.3), np.float32(self.airgap2_list[-1] -16.3), np.float32(current1), np.float32(current2)), self.crash\n",
        "        #añadir una que returnee los 2 errores y las 2 velocidades\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "aNE6VBJdTFDL",
        "outputId": "be5ffab5-4f53-48bc-9fcc-fd387eb09d56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuguito\u001b[0m (\u001b[33mhyperloopupv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.16.2 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\hugoa\\H9\\RL\\GitHub Vrain\\rl_levitation_control\\rl_levitation_control\\wandb\\run-20240129_134958-va5muxcj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hyperloopupv/2gdl/runs/va5muxcj' target=\"_blank\">warm-dust-38</a></strong> to <a href='https://wandb.ai/hyperloopupv/2gdl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/hyperloopupv/2gdl' target=\"_blank\">https://wandb.ai/hyperloopupv/2gdl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/hyperloopupv/2gdl/runs/va5muxcj' target=\"_blank\">https://wandb.ai/hyperloopupv/2gdl/runs/va5muxcj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    project=\"2gdl\",\n",
        "    sync_tensorboard=True,\n",
        "    monitor_gym=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oinA6TP-TL36"
      },
      "outputs": [],
      "source": [
        "# Create log dir\n",
        "log_dir = \"2gdl/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = BobinaEnv( duration = 5 )\n",
        "env = Monitor(env, log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22oTxNkmTfCd",
        "outputId": "7872ccfd-4bbe-4c07-9740-0ddcc3fb26bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable\n",
        "\n",
        "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
        "    \"\"\"\n",
        "    Linear learning rate schedule.\n",
        "\n",
        "    :param initial_value: Initial learning rate.\n",
        "    :return: schedule that computes\n",
        "      current learning rate depending on remaining progress\n",
        "    \"\"\"\n",
        "    def func(progress_remaining: float) -> float:\n",
        "        \"\"\"\n",
        "        Progress will decrease from 1 (beginning) to 0.\n",
        "\n",
        "        :param progress_remaining:\n",
        "        :return: current learning rate\n",
        "        \"\"\"\n",
        "        return progress_remaining * initial_value\n",
        "\n",
        "    return func\n",
        "\n",
        "# para el critic , qf=[400, 300], para el actor pi=[300, 200]\n",
        "policy_kwargs = dict(net_arch=dict(pi=[8, 8], qf=[256, 256]))\n",
        "model = SAC(\"MlpPolicy\", env,learning_rate = linear_schedule(0.001), policy_kwargs=policy_kwargs, verbose=1, tensorboard_log=log_dir, device=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "MODEL_PATH = f\"models/2gdl8x8framestack-success16/model.zip\"\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = BobinaEnv(duration = 5)\n",
        "\n",
        "# Load the trained agent\n",
        "model = SAC.load(MODEL_PATH, env=env, learning_rate = linear_schedule(0.00001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NVwBakWxTf2c"
      },
      "outputs": [],
      "source": [
        "# Create checkpoint callback\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=10000, save_path=log_dir, name_prefix=\"2gdl\"\n",
        ")\n",
        "\n",
        "\n",
        "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=-350, verbose=1)\n",
        "eval_callback = EvalCallback(env, callback_on_new_best=callback_on_best, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d75OTj_9TxDJ",
        "outputId": "f5860707-4220-4914-9a00-b3da3cf62a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to 2gdl/SAC_52\n",
            "Eval num_timesteps=10000, episode_reward=-320332.29 +/- 2954.59\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.19e+03 |\n",
            "|    critic_loss     | 148      |\n",
            "|    ent_coef        | 0.00964  |\n",
            "|    ent_coef_loss   | 89.8     |\n",
            "|    learning_rate   | 9.99e-06 |\n",
            "|    n_updates       | 3689798  |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=20000, episode_reward=-317531.14 +/- 3452.47\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 20000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.32e+03  |\n",
            "|    critic_loss     | 274       |\n",
            "|    ent_coef        | 0.0106    |\n",
            "|    ent_coef_loss   | 65        |\n",
            "|    learning_rate   | 9.98e-06  |\n",
            "|    n_updates       | 3699798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 1286      |\n",
            "|    total_timesteps | 20000     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-225217.44 +/- 118131.34\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.25e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 30000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.33e+03  |\n",
            "|    critic_loss     | 68        |\n",
            "|    ent_coef        | 0.0117    |\n",
            "|    ent_coef_loss   | 87.1      |\n",
            "|    learning_rate   | 9.97e-06  |\n",
            "|    n_updates       | 3709798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=40000, episode_reward=-310647.48 +/- 5511.19\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 40000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.4e+03   |\n",
            "|    critic_loss     | 5.09e+03  |\n",
            "|    ent_coef        | 0.0129    |\n",
            "|    ent_coef_loss   | 64.2      |\n",
            "|    learning_rate   | 9.96e-06  |\n",
            "|    n_updates       | 3719798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.86e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 2512      |\n",
            "|    total_timesteps | 40000     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-319825.86 +/- 3688.30\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.04e+03 |\n",
            "|    critic_loss     | 158      |\n",
            "|    ent_coef        | 0.0142   |\n",
            "|    ent_coef_loss   | 47.4     |\n",
            "|    learning_rate   | 9.95e-06 |\n",
            "|    n_updates       | 3729798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=-319664.46 +/- 3709.98\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.38e+03 |\n",
            "|    critic_loss     | 197      |\n",
            "|    ent_coef        | 0.0157   |\n",
            "|    ent_coef_loss   | 34.1     |\n",
            "|    learning_rate   | 9.94e-06 |\n",
            "|    n_updates       | 3739798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.95e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 3735      |\n",
            "|    total_timesteps | 60000     |\n",
            "----------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=-319784.21 +/- 3452.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.57e+03 |\n",
            "|    critic_loss     | 131      |\n",
            "|    ent_coef        | 0.0173   |\n",
            "|    ent_coef_loss   | 34.3     |\n",
            "|    learning_rate   | 9.93e-06 |\n",
            "|    n_updates       | 3749798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=-318446.98 +/- 3753.24\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 80000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.75e+03  |\n",
            "|    critic_loss     | 127       |\n",
            "|    ent_coef        | 0.0191    |\n",
            "|    ent_coef_loss   | 25.6      |\n",
            "|    learning_rate   | 9.92e-06  |\n",
            "|    n_updates       | 3759798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -3e+05   |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 16       |\n",
            "|    time_elapsed    | 4963     |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=-318560.28 +/- 3676.29\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.19e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 90000     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.92e+03  |\n",
            "|    critic_loss     | 54.8      |\n",
            "|    ent_coef        | 0.021     |\n",
            "|    ent_coef_loss   | 26.5      |\n",
            "|    learning_rate   | 9.91e-06  |\n",
            "|    n_updates       | 3769798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=-318469.47 +/- 3787.72\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 100000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.06e+03  |\n",
            "|    critic_loss     | 39.8      |\n",
            "|    ent_coef        | 0.0232    |\n",
            "|    ent_coef_loss   | 19.1      |\n",
            "|    learning_rate   | 9.9e-06   |\n",
            "|    n_updates       | 3779798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.04e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 6213      |\n",
            "|    total_timesteps | 100000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=110000, episode_reward=-316478.43 +/- 4151.16\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 110000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.03e+03  |\n",
            "|    critic_loss     | 1.86e+03  |\n",
            "|    ent_coef        | 0.0256    |\n",
            "|    ent_coef_loss   | 20.5      |\n",
            "|    learning_rate   | 9.89e-06  |\n",
            "|    n_updates       | 3789798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=-318040.19 +/- 4314.88\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 120000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.18e+03  |\n",
            "|    critic_loss     | 78.7      |\n",
            "|    ent_coef        | 0.0282    |\n",
            "|    ent_coef_loss   | 16.1      |\n",
            "|    learning_rate   | 9.88e-06  |\n",
            "|    n_updates       | 3799798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.06e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 24        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 7450      |\n",
            "|    total_timesteps | 120000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=130000, episode_reward=-316345.26 +/- 4219.10\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 130000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.07e+03  |\n",
            "|    critic_loss     | 22.5      |\n",
            "|    ent_coef        | 0.031     |\n",
            "|    ent_coef_loss   | 9.94      |\n",
            "|    learning_rate   | 9.87e-06  |\n",
            "|    n_updates       | 3809798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=140000, episode_reward=-315800.21 +/- 4706.06\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 140000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.15e+03  |\n",
            "|    critic_loss     | 48.4      |\n",
            "|    ent_coef        | 0.0342    |\n",
            "|    ent_coef_loss   | 16        |\n",
            "|    learning_rate   | 9.86e-06  |\n",
            "|    n_updates       | 3819798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.08e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 28        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 8682      |\n",
            "|    total_timesteps | 140000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=150000, episode_reward=-313427.45 +/- 4068.15\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 150000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.34e+03  |\n",
            "|    critic_loss     | 57.8      |\n",
            "|    ent_coef        | 0.0377    |\n",
            "|    ent_coef_loss   | 12.9      |\n",
            "|    learning_rate   | 9.85e-06  |\n",
            "|    n_updates       | 3829798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=-319672.40 +/- 3781.91\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 160000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.22e+03 |\n",
            "|    critic_loss     | 326      |\n",
            "|    ent_coef        | 0.0414   |\n",
            "|    ent_coef_loss   | 7.59     |\n",
            "|    learning_rate   | 9.84e-06 |\n",
            "|    n_updates       | 3839798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.09e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 32        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 9923      |\n",
            "|    total_timesteps | 160000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=170000, episode_reward=-318013.43 +/- 4347.29\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 170000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.25e+03  |\n",
            "|    critic_loss     | 921       |\n",
            "|    ent_coef        | 0.0456    |\n",
            "|    ent_coef_loss   | 7.85      |\n",
            "|    learning_rate   | 9.83e-06  |\n",
            "|    n_updates       | 3849798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=180000, episode_reward=-316503.09 +/- 4131.24\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 180000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.19e+03  |\n",
            "|    critic_loss     | 89        |\n",
            "|    ent_coef        | 0.0503    |\n",
            "|    ent_coef_loss   | 7.68      |\n",
            "|    learning_rate   | 9.82e-06  |\n",
            "|    n_updates       | 3859798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -3.1e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 16       |\n",
            "|    time_elapsed    | 11137    |\n",
            "|    total_timesteps | 180000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=190000, episode_reward=-318119.30 +/- 4217.66\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 190000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.27e+03  |\n",
            "|    critic_loss     | 79.8      |\n",
            "|    ent_coef        | 0.0555    |\n",
            "|    ent_coef_loss   | 6.85      |\n",
            "|    learning_rate   | 9.81e-06  |\n",
            "|    n_updates       | 3869798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=-314553.40 +/- 3504.75\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.15e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 200000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.25e+03  |\n",
            "|    critic_loss     | 63.2      |\n",
            "|    ent_coef        | 0.0611    |\n",
            "|    ent_coef_loss   | 6.3       |\n",
            "|    learning_rate   | 9.8e-06   |\n",
            "|    n_updates       | 3879798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -3.1e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 16       |\n",
            "|    time_elapsed    | 12352    |\n",
            "|    total_timesteps | 200000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=210000, episode_reward=-318058.62 +/- 4291.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 210000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.36e+03  |\n",
            "|    critic_loss     | 30.4      |\n",
            "|    ent_coef        | 0.0674    |\n",
            "|    ent_coef_loss   | 5.85      |\n",
            "|    learning_rate   | 9.79e-06  |\n",
            "|    n_updates       | 3889798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=220000, episode_reward=-319777.86 +/- 3570.86\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 220000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.37e+03 |\n",
            "|    critic_loss     | 25.7     |\n",
            "|    ent_coef        | 0.0741   |\n",
            "|    ent_coef_loss   | 5.23     |\n",
            "|    learning_rate   | 9.78e-06 |\n",
            "|    n_updates       | 3899798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.11e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 44        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 13562     |\n",
            "|    total_timesteps | 220000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=230000, episode_reward=-314332.42 +/- 3615.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.14e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 230000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.35e+03  |\n",
            "|    critic_loss     | 19        |\n",
            "|    ent_coef        | 0.0814    |\n",
            "|    ent_coef_loss   | 3.47      |\n",
            "|    learning_rate   | 9.77e-06  |\n",
            "|    n_updates       | 3909798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=-312966.18 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 240000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.14e+03  |\n",
            "|    critic_loss     | 391       |\n",
            "|    ent_coef        | 0.0903    |\n",
            "|    ent_coef_loss   | 7.89      |\n",
            "|    learning_rate   | 9.76e-06  |\n",
            "|    n_updates       | 3919798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.11e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 48        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 14812     |\n",
            "|    total_timesteps | 240000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=250000, episode_reward=-316197.66 +/- 4424.87\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 250000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.2e+03   |\n",
            "|    critic_loss     | 18.1      |\n",
            "|    ent_coef        | 0.0997    |\n",
            "|    ent_coef_loss   | 8.32      |\n",
            "|    learning_rate   | 9.75e-06  |\n",
            "|    n_updates       | 3929798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=260000, episode_reward=-315697.97 +/- 4832.93\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 260000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.15e+03  |\n",
            "|    critic_loss     | 178       |\n",
            "|    ent_coef        | 0.11      |\n",
            "|    ent_coef_loss   | 8.01      |\n",
            "|    learning_rate   | 9.74e-06  |\n",
            "|    n_updates       | 3939798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.12e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 52        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 16028     |\n",
            "|    total_timesteps | 260000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=270000, episode_reward=-317432.92 +/- 5121.45\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 270000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.18e+03  |\n",
            "|    critic_loss     | 108       |\n",
            "|    ent_coef        | 0.12      |\n",
            "|    ent_coef_loss   | 3.01      |\n",
            "|    learning_rate   | 9.73e-06  |\n",
            "|    n_updates       | 3949798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=-317174.78 +/- 5438.56\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 280000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.23e+03  |\n",
            "|    critic_loss     | 112       |\n",
            "|    ent_coef        | 0.132     |\n",
            "|    ent_coef_loss   | 3.36      |\n",
            "|    learning_rate   | 9.72e-06  |\n",
            "|    n_updates       | 3959798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.12e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 56        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 17245     |\n",
            "|    total_timesteps | 280000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=290000, episode_reward=-311892.80 +/- 4860.68\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.12e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 290000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.37e+03  |\n",
            "|    critic_loss     | 87.3      |\n",
            "|    ent_coef        | 0.145     |\n",
            "|    ent_coef_loss   | 2.37      |\n",
            "|    learning_rate   | 9.71e-06  |\n",
            "|    n_updates       | 3969798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=300000, episode_reward=-308094.28 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.08e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 300000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.22e+03  |\n",
            "|    critic_loss     | 612       |\n",
            "|    ent_coef        | 0.158     |\n",
            "|    ent_coef_loss   | 1.39      |\n",
            "|    learning_rate   | 9.7e-06   |\n",
            "|    n_updates       | 3979798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.12e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 60        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 18511     |\n",
            "|    total_timesteps | 300000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=310000, episode_reward=-310307.86 +/- 5653.53\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 310000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 6.34e+03 |\n",
            "|    critic_loss     | 16.5     |\n",
            "|    ent_coef        | 0.171    |\n",
            "|    ent_coef_loss   | 0.564    |\n",
            "|    learning_rate   | 9.69e-06 |\n",
            "|    n_updates       | 3989798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=320000, episode_reward=-312780.10 +/- 7213.26\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 320000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.29e+03  |\n",
            "|    critic_loss     | 130       |\n",
            "|    ent_coef        | 0.175     |\n",
            "|    ent_coef_loss   | -0.0354   |\n",
            "|    learning_rate   | 9.68e-06  |\n",
            "|    n_updates       | 3999798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 64        |\n",
            "|    fps             | 16        |\n",
            "|    time_elapsed    | 19913     |\n",
            "|    total_timesteps | 320000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=330000, episode_reward=-310619.63 +/- 13466.26\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 330000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.28e+03  |\n",
            "|    critic_loss     | 57.6      |\n",
            "|    ent_coef        | 0.17      |\n",
            "|    ent_coef_loss   | 0.157     |\n",
            "|    learning_rate   | 9.67e-06  |\n",
            "|    n_updates       | 4009798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=340000, episode_reward=-159118.60 +/- 132677.78\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.59e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 340000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.08e+03  |\n",
            "|    critic_loss     | 140       |\n",
            "|    ent_coef        | 0.173     |\n",
            "|    ent_coef_loss   | 0.646     |\n",
            "|    learning_rate   | 9.66e-06  |\n",
            "|    n_updates       | 4019798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.09e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 68        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 21305     |\n",
            "|    total_timesteps | 340000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=350000, episode_reward=-162734.57 +/- 129726.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.63e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 350000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.17e+03  |\n",
            "|    critic_loss     | 75.7      |\n",
            "|    ent_coef        | 0.177     |\n",
            "|    ent_coef_loss   | 0.387     |\n",
            "|    learning_rate   | 9.65e-06  |\n",
            "|    n_updates       | 4029798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=360000, episode_reward=-161761.04 +/- 130520.90\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.62e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 360000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.25e+03  |\n",
            "|    critic_loss     | 67        |\n",
            "|    ent_coef        | 0.17      |\n",
            "|    ent_coef_loss   | -0.276    |\n",
            "|    learning_rate   | 9.64e-06  |\n",
            "|    n_updates       | 4039798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -3.1e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 22661    |\n",
            "|    total_timesteps | 360000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=370000, episode_reward=-117974.66 +/- 101820.65\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 370000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.21e+03  |\n",
            "|    critic_loss     | 241       |\n",
            "|    ent_coef        | 0.157     |\n",
            "|    ent_coef_loss   | -0.596    |\n",
            "|    learning_rate   | 9.63e-06  |\n",
            "|    n_updates       | 4049798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=380000, episode_reward=-316617.75 +/- 6121.35\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 380000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.22e+03  |\n",
            "|    critic_loss     | 768       |\n",
            "|    ent_coef        | 0.143     |\n",
            "|    ent_coef_loss   | -1.46     |\n",
            "|    learning_rate   | 9.62e-06  |\n",
            "|    n_updates       | 4059798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.04e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 76        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 23996     |\n",
            "|    total_timesteps | 380000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=390000, episode_reward=-316745.97 +/- 5965.84\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 390000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.16e+03  |\n",
            "|    critic_loss     | 45.5      |\n",
            "|    ent_coef        | 0.134     |\n",
            "|    ent_coef_loss   | 0.346     |\n",
            "|    learning_rate   | 9.61e-06  |\n",
            "|    n_updates       | 4069798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=400000, episode_reward=-316807.78 +/- 5889.55\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 400000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.13e+03  |\n",
            "|    critic_loss     | 104       |\n",
            "|    ent_coef        | 0.127     |\n",
            "|    ent_coef_loss   | -0.57     |\n",
            "|    learning_rate   | 9.6e-06   |\n",
            "|    n_updates       | 4079798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.05e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 80        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 25322     |\n",
            "|    total_timesteps | 400000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=410000, episode_reward=-152636.28 +/- 137971.39\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.53e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 410000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.98e+03  |\n",
            "|    critic_loss     | 388       |\n",
            "|    ent_coef        | 0.117     |\n",
            "|    ent_coef_loss   | -0.0353   |\n",
            "|    learning_rate   | 9.59e-06  |\n",
            "|    n_updates       | 4089798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=420000, episode_reward=-208033.41 +/- 139048.63\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.08e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 420000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.84e+03  |\n",
            "|    critic_loss     | 269       |\n",
            "|    ent_coef        | 0.116     |\n",
            "|    ent_coef_loss   | 1.27      |\n",
            "|    learning_rate   | 9.58e-06  |\n",
            "|    n_updates       | 4099798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.96e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 84        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 26644     |\n",
            "|    total_timesteps | 420000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=430000, episode_reward=-316406.82 +/- 6320.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 430000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.07e+03  |\n",
            "|    critic_loss     | 82.6      |\n",
            "|    ent_coef        | 0.127     |\n",
            "|    ent_coef_loss   | 1.37      |\n",
            "|    learning_rate   | 9.57e-06  |\n",
            "|    n_updates       | 4109798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=440000, episode_reward=-317903.70 +/- 4487.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.18e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 440000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.77e+03  |\n",
            "|    critic_loss     | 808       |\n",
            "|    ent_coef        | 0.138     |\n",
            "|    ent_coef_loss   | 2.01      |\n",
            "|    learning_rate   | 9.56e-06  |\n",
            "|    n_updates       | 4119798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.96e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 88        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 27965     |\n",
            "|    total_timesteps | 440000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=450000, episode_reward=-319834.80 +/- 3465.96\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 450000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.88e+03 |\n",
            "|    critic_loss     | 191      |\n",
            "|    ent_coef        | 0.151    |\n",
            "|    ent_coef_loss   | 1.05     |\n",
            "|    learning_rate   | 9.55e-06 |\n",
            "|    n_updates       | 4129798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=460000, episode_reward=-319737.84 +/- 3660.81\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -3.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 460000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.96e+03 |\n",
            "|    critic_loss     | 125      |\n",
            "|    ent_coef        | 0.164    |\n",
            "|    ent_coef_loss   | 0.913    |\n",
            "|    learning_rate   | 9.54e-06 |\n",
            "|    n_updates       | 4139798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.97e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 92        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 29293     |\n",
            "|    total_timesteps | 460000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=470000, episode_reward=-313629.64 +/- 3969.29\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.14e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 470000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.96e+03  |\n",
            "|    critic_loss     | 116       |\n",
            "|    ent_coef        | 0.176     |\n",
            "|    ent_coef_loss   | -0.296    |\n",
            "|    learning_rate   | 9.53e-06  |\n",
            "|    n_updates       | 4149798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=480000, episode_reward=-319430.13 +/- 4274.36\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.19e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 480000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.93e+03  |\n",
            "|    critic_loss     | 97.2      |\n",
            "|    ent_coef        | 0.175     |\n",
            "|    ent_coef_loss   | -0.947    |\n",
            "|    learning_rate   | 9.52e-06  |\n",
            "|    n_updates       | 4159798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 96        |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 30629     |\n",
            "|    total_timesteps | 480000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=490000, episode_reward=-317249.19 +/- 5288.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 490000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.96e+03  |\n",
            "|    critic_loss     | 135       |\n",
            "|    ent_coef        | 0.165     |\n",
            "|    ent_coef_loss   | -0.756    |\n",
            "|    learning_rate   | 9.51e-06  |\n",
            "|    n_updates       | 4169798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=500000, episode_reward=-316941.20 +/- 5666.48\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.17e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 500000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.83e+03  |\n",
            "|    critic_loss     | 212       |\n",
            "|    ent_coef        | 0.16      |\n",
            "|    ent_coef_loss   | 0.154     |\n",
            "|    learning_rate   | 9.5e-06   |\n",
            "|    n_updates       | 4179798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.99e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 100       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 31986     |\n",
            "|    total_timesteps | 500000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=510000, episode_reward=-276077.92 +/- 37141.88\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.76e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 510000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.03e+03  |\n",
            "|    critic_loss     | 117       |\n",
            "|    ent_coef        | 0.163     |\n",
            "|    ent_coef_loss   | -0.263    |\n",
            "|    learning_rate   | 9.49e-06  |\n",
            "|    n_updates       | 4189798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=520000, episode_reward=-286123.71 +/- 70887.36\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.86e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 520000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.94e+03  |\n",
            "|    critic_loss     | 359       |\n",
            "|    ent_coef        | 0.153     |\n",
            "|    ent_coef_loss   | -0.375    |\n",
            "|    learning_rate   | 9.48e-06  |\n",
            "|    n_updates       | 4199798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.99e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 104       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 33388     |\n",
            "|    total_timesteps | 520000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=530000, episode_reward=-143299.09 +/- 145555.44\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.43e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 530000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.03e+03  |\n",
            "|    critic_loss     | 87.3      |\n",
            "|    ent_coef        | 0.142     |\n",
            "|    ent_coef_loss   | -1.03     |\n",
            "|    learning_rate   | 9.47e-06  |\n",
            "|    n_updates       | 4209798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=540000, episode_reward=-262631.27 +/- 117871.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.63e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 540000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 6.09e+03  |\n",
            "|    critic_loss     | 26.9      |\n",
            "|    ent_coef        | 0.131     |\n",
            "|    ent_coef_loss   | -1.52     |\n",
            "|    learning_rate   | 9.46e-06  |\n",
            "|    n_updates       | 4219798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -3.01e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 108       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 34735     |\n",
            "|    total_timesteps | 540000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=550000, episode_reward=-207659.88 +/- 139507.31\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.08e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 550000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.82e+03  |\n",
            "|    critic_loss     | 580       |\n",
            "|    ent_coef        | 0.123     |\n",
            "|    ent_coef_loss   | 0.521     |\n",
            "|    learning_rate   | 9.45e-06  |\n",
            "|    n_updates       | 4229798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=560000, episode_reward=-152769.35 +/- 137823.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.53e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 560000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.96e+03  |\n",
            "|    critic_loss     | 70.5      |\n",
            "|    ent_coef        | 0.121     |\n",
            "|    ent_coef_loss   | 0.158     |\n",
            "|    learning_rate   | 9.44e-06  |\n",
            "|    n_updates       | 4239798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.99e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 112       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 36085     |\n",
            "|    total_timesteps | 560000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=570000, episode_reward=-265864.40 +/- 111512.98\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 570000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.63e+03  |\n",
            "|    critic_loss     | 370       |\n",
            "|    ent_coef        | 0.133     |\n",
            "|    ent_coef_loss   | 3.85      |\n",
            "|    learning_rate   | 9.43e-06  |\n",
            "|    n_updates       | 4249798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=580000, episode_reward=-41805.05 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.18e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 580000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.71e+03  |\n",
            "|    critic_loss     | 297       |\n",
            "|    ent_coef        | 0.145     |\n",
            "|    ent_coef_loss   | 1.43      |\n",
            "|    learning_rate   | 9.42e-06  |\n",
            "|    n_updates       | 4259798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.93e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 116       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 37428     |\n",
            "|    total_timesteps | 580000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=590000, episode_reward=-149674.26 +/- 140351.24\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 590000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.81e+03 |\n",
            "|    critic_loss     | 67.5     |\n",
            "|    ent_coef        | 0.148    |\n",
            "|    ent_coef_loss   | -0.988   |\n",
            "|    learning_rate   | 9.41e-06 |\n",
            "|    n_updates       | 4269798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=600000, episode_reward=-148384.66 +/- 141403.20\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.48e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 600000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.61e+03  |\n",
            "|    critic_loss     | 107       |\n",
            "|    ent_coef        | 0.137     |\n",
            "|    ent_coef_loss   | -0.751    |\n",
            "|    learning_rate   | 9.4e-06   |\n",
            "|    n_updates       | 4279798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.82e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 120       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 38759     |\n",
            "|    total_timesteps | 600000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=610000, episode_reward=-206196.49 +/- 141299.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.06e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 610000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.91e+03  |\n",
            "|    critic_loss     | 58.4      |\n",
            "|    ent_coef        | 0.126     |\n",
            "|    ent_coef_loss   | -1.56     |\n",
            "|    learning_rate   | 9.39e-06  |\n",
            "|    n_updates       | 4289798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=620000, episode_reward=-92090.32 +/- 114738.30\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.21e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 620000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.68e+03  |\n",
            "|    critic_loss     | 55.1      |\n",
            "|    ent_coef        | 0.116     |\n",
            "|    ent_coef_loss   | -2.14     |\n",
            "|    learning_rate   | 9.38e-06  |\n",
            "|    n_updates       | 4299798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.74e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 124       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 40082     |\n",
            "|    total_timesteps | 620000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=630000, episode_reward=-149629.76 +/- 140386.04\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 630000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.61e+03 |\n",
            "|    critic_loss     | 74.5     |\n",
            "|    ent_coef        | 0.106    |\n",
            "|    ent_coef_loss   | -1.55    |\n",
            "|    learning_rate   | 9.37e-06 |\n",
            "|    n_updates       | 4309798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=640000, episode_reward=-91771.18 +/- 114897.90\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.18e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 640000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.61e+03  |\n",
            "|    critic_loss     | 30.5      |\n",
            "|    ent_coef        | 0.098     |\n",
            "|    ent_coef_loss   | -2.09     |\n",
            "|    learning_rate   | 9.36e-06  |\n",
            "|    n_updates       | 4319798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.68e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 128       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 41406     |\n",
            "|    total_timesteps | 640000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=650000, episode_reward=-148575.02 +/- 141246.73\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 650000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.61e+03  |\n",
            "|    critic_loss     | 34.4      |\n",
            "|    ent_coef        | 0.0908    |\n",
            "|    ent_coef_loss   | -1.3      |\n",
            "|    learning_rate   | 9.35e-06  |\n",
            "|    n_updates       | 4329798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=660000, episode_reward=-148182.74 +/- 141567.05\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.48e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 660000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.52e+03  |\n",
            "|    critic_loss     | 27.7      |\n",
            "|    ent_coef        | 0.0859    |\n",
            "|    ent_coef_loss   | 0.0929    |\n",
            "|    learning_rate   | 9.34e-06  |\n",
            "|    n_updates       | 4339798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.65e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 132       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 42733     |\n",
            "|    total_timesteps | 660000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=670000, episode_reward=-263561.78 +/- 116009.06\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 670000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.57e+03  |\n",
            "|    critic_loss     | 86.8      |\n",
            "|    ent_coef        | 0.0828    |\n",
            "|    ent_coef_loss   | -0.912    |\n",
            "|    learning_rate   | 9.33e-06  |\n",
            "|    n_updates       | 4349798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=680000, episode_reward=-147913.81 +/- 141786.48\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.48e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 680000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.37e+03  |\n",
            "|    critic_loss     | 142       |\n",
            "|    ent_coef        | 0.0818    |\n",
            "|    ent_coef_loss   | 0.0537    |\n",
            "|    learning_rate   | 9.32e-06  |\n",
            "|    n_updates       | 4359798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.63e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 136       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 44070     |\n",
            "|    total_timesteps | 680000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=690000, episode_reward=-205975.82 +/- 141569.31\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.06e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 690000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.56e+03  |\n",
            "|    critic_loss     | 45.5      |\n",
            "|    ent_coef        | 0.0792    |\n",
            "|    ent_coef_loss   | -0.638    |\n",
            "|    learning_rate   | 9.31e-06  |\n",
            "|    n_updates       | 4369798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=700000, episode_reward=-149039.54 +/- 140868.19\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 700000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.51e+03  |\n",
            "|    critic_loss     | 83.2      |\n",
            "|    ent_coef        | 0.0767    |\n",
            "|    ent_coef_loss   | 0.662     |\n",
            "|    learning_rate   | 9.3e-06   |\n",
            "|    n_updates       | 4379798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -2.6e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 45411    |\n",
            "|    total_timesteps | 700000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=710000, episode_reward=-206964.50 +/- 140358.77\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 710000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.64e+03  |\n",
            "|    critic_loss     | 99.4      |\n",
            "|    ent_coef        | 0.0768    |\n",
            "|    ent_coef_loss   | -0.0942   |\n",
            "|    learning_rate   | 9.29e-06  |\n",
            "|    n_updates       | 4389798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=720000, episode_reward=-149850.34 +/- 140206.53\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 720000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.58e+03 |\n",
            "|    critic_loss     | 103      |\n",
            "|    ent_coef        | 0.0745   |\n",
            "|    ent_coef_loss   | 0.749    |\n",
            "|    learning_rate   | 9.28e-06 |\n",
            "|    n_updates       | 4399798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.54e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 144       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 46763     |\n",
            "|    total_timesteps | 720000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=730000, episode_reward=-92929.33 +/- 114318.90\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.29e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 730000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.5e+03   |\n",
            "|    critic_loss     | 48.7      |\n",
            "|    ent_coef        | 0.0752    |\n",
            "|    ent_coef_loss   | -1.05     |\n",
            "|    learning_rate   | 9.27e-06  |\n",
            "|    n_updates       | 4409798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=740000, episode_reward=-150680.10 +/- 139529.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.51e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 740000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.21e+03  |\n",
            "|    critic_loss     | 48.6      |\n",
            "|    ent_coef        | 0.0726    |\n",
            "|    ent_coef_loss   | -0.851    |\n",
            "|    learning_rate   | 9.26e-06  |\n",
            "|    n_updates       | 4419798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.49e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 148       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 48146     |\n",
            "|    total_timesteps | 740000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=750000, episode_reward=-150878.32 +/- 139367.76\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.51e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 750000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.56e+03  |\n",
            "|    critic_loss     | 20.1      |\n",
            "|    ent_coef        | 0.0667    |\n",
            "|    ent_coef_loss   | -1.1      |\n",
            "|    learning_rate   | 9.25e-06  |\n",
            "|    n_updates       | 4429798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=760000, episode_reward=-207454.62 +/- 139760.75\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 760000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.45e+03  |\n",
            "|    critic_loss     | 61.7      |\n",
            "|    ent_coef        | 0.0623    |\n",
            "|    ent_coef_loss   | -0.496    |\n",
            "|    learning_rate   | 9.24e-06  |\n",
            "|    n_updates       | 4439798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.41e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 152       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 49499     |\n",
            "|    total_timesteps | 760000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=770000, episode_reward=-321569.10 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.22e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 770000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.33e+03  |\n",
            "|    critic_loss     | 48.6      |\n",
            "|    ent_coef        | 0.0594    |\n",
            "|    ent_coef_loss   | -0.707    |\n",
            "|    learning_rate   | 9.23e-06  |\n",
            "|    n_updates       | 4449798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=780000, episode_reward=-206922.85 +/- 140412.89\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 780000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.32e+03  |\n",
            "|    critic_loss     | 121       |\n",
            "|    ent_coef        | 0.057     |\n",
            "|    ent_coef_loss   | -0.943    |\n",
            "|    learning_rate   | 9.22e-06  |\n",
            "|    n_updates       | 4459798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.41e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 156       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 50830     |\n",
            "|    total_timesteps | 780000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=790000, episode_reward=-207233.41 +/- 140094.85\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 790000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.26e+03  |\n",
            "|    critic_loss     | 49.7      |\n",
            "|    ent_coef        | 0.0556    |\n",
            "|    ent_coef_loss   | -0.0632   |\n",
            "|    learning_rate   | 9.21e-06  |\n",
            "|    n_updates       | 4469798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=800000, episode_reward=-207034.43 +/- 140338.22\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 800000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.42e+03  |\n",
            "|    critic_loss     | 15.6      |\n",
            "|    ent_coef        | 0.0553    |\n",
            "|    ent_coef_loss   | -2.1      |\n",
            "|    learning_rate   | 9.2e-06   |\n",
            "|    n_updates       | 4479798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.35e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 160       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 52177     |\n",
            "|    total_timesteps | 800000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=810000, episode_reward=-149355.08 +/- 140653.73\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 810000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.26e+03  |\n",
            "|    critic_loss     | 63.7      |\n",
            "|    ent_coef        | 0.055     |\n",
            "|    ent_coef_loss   | -0.748    |\n",
            "|    learning_rate   | 9.19e-06  |\n",
            "|    n_updates       | 4489798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=820000, episode_reward=-206666.36 +/- 140788.89\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 820000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.2e+03   |\n",
            "|    critic_loss     | 78        |\n",
            "|    ent_coef        | 0.0566    |\n",
            "|    ent_coef_loss   | -0.598    |\n",
            "|    learning_rate   | 9.18e-06  |\n",
            "|    n_updates       | 4499798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -2.3e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 53503    |\n",
            "|    total_timesteps | 820000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=830000, episode_reward=-264196.45 +/- 114849.13\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 830000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.22e+03  |\n",
            "|    critic_loss     | 43.6      |\n",
            "|    ent_coef        | 0.0562    |\n",
            "|    ent_coef_loss   | 0.763     |\n",
            "|    learning_rate   | 9.17e-06  |\n",
            "|    n_updates       | 4509798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=840000, episode_reward=-149230.87 +/- 140756.02\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 840000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.31e+03  |\n",
            "|    critic_loss     | 121       |\n",
            "|    ent_coef        | 0.0609    |\n",
            "|    ent_coef_loss   | 2.62      |\n",
            "|    learning_rate   | 9.16e-06  |\n",
            "|    n_updates       | 4519798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -2.3e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 54829    |\n",
            "|    total_timesteps | 840000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=850000, episode_reward=-149178.91 +/- 140799.13\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 850000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.48e+03  |\n",
            "|    critic_loss     | 64.4      |\n",
            "|    ent_coef        | 0.0656    |\n",
            "|    ent_coef_loss   | 1.17      |\n",
            "|    learning_rate   | 9.15e-06  |\n",
            "|    n_updates       | 4529798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=860000, episode_reward=-206719.98 +/- 140726.43\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 860000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.35e+03  |\n",
            "|    critic_loss     | 26.3      |\n",
            "|    ent_coef        | 0.0687    |\n",
            "|    ent_coef_loss   | 0.738     |\n",
            "|    learning_rate   | 9.14e-06  |\n",
            "|    n_updates       | 4539798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.24e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 172       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 56160     |\n",
            "|    total_timesteps | 860000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=870000, episode_reward=-92219.48 +/- 114701.43\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.22e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 870000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.03e+03  |\n",
            "|    critic_loss     | 15.8      |\n",
            "|    ent_coef        | 0.0731    |\n",
            "|    ent_coef_loss   | 0.525     |\n",
            "|    learning_rate   | 9.13e-06  |\n",
            "|    n_updates       | 4549798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=880000, episode_reward=-34767.90 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.48e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 880000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.51e+03  |\n",
            "|    critic_loss     | 24        |\n",
            "|    ent_coef        | 0.0739    |\n",
            "|    ent_coef_loss   | -0.828    |\n",
            "|    learning_rate   | 9.12e-06  |\n",
            "|    n_updates       | 4559798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.29e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 176       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 57498     |\n",
            "|    total_timesteps | 880000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=890000, episode_reward=-149310.83 +/- 140690.89\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 890000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.27e+03  |\n",
            "|    critic_loss     | 44.5      |\n",
            "|    ent_coef        | 0.0711    |\n",
            "|    ent_coef_loss   | -0.0796   |\n",
            "|    learning_rate   | 9.11e-06  |\n",
            "|    n_updates       | 4569798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=900000, episode_reward=-264191.24 +/- 114860.55\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 900000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5e+03     |\n",
            "|    critic_loss     | 40.7      |\n",
            "|    ent_coef        | 0.0654    |\n",
            "|    ent_coef_loss   | -2.25     |\n",
            "|    learning_rate   | 9.1e-06   |\n",
            "|    n_updates       | 4579798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -2.2e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 58848    |\n",
            "|    total_timesteps | 900000   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=910000, episode_reward=-149036.34 +/- 140915.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 910000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.24e+03  |\n",
            "|    critic_loss     | 19.6      |\n",
            "|    ent_coef        | 0.0602    |\n",
            "|    ent_coef_loss   | -2.02     |\n",
            "|    learning_rate   | 9.09e-06  |\n",
            "|    n_updates       | 4589798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=920000, episode_reward=-91467.50 +/- 115076.26\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.15e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 920000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.04e+03  |\n",
            "|    critic_loss     | 171       |\n",
            "|    ent_coef        | 0.0552    |\n",
            "|    ent_coef_loss   | -1.66     |\n",
            "|    learning_rate   | 9.08e-06  |\n",
            "|    n_updates       | 4599798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.17e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 184       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 60206     |\n",
            "|    total_timesteps | 920000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=930000, episode_reward=-206647.40 +/- 140812.36\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 930000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.92e+03  |\n",
            "|    critic_loss     | 24        |\n",
            "|    ent_coef        | 0.0525    |\n",
            "|    ent_coef_loss   | 0.087     |\n",
            "|    learning_rate   | 9.07e-06  |\n",
            "|    n_updates       | 4609798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=940000, episode_reward=-149607.67 +/- 140447.42\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 940000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.06e+03 |\n",
            "|    critic_loss     | 63.9     |\n",
            "|    ent_coef        | 0.048    |\n",
            "|    ent_coef_loss   | -1.65    |\n",
            "|    learning_rate   | 9.06e-06 |\n",
            "|    n_updates       | 4619798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.12e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 188       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 61565     |\n",
            "|    total_timesteps | 940000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=950000, episode_reward=-150261.46 +/- 139913.13\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 950000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.12e+03 |\n",
            "|    critic_loss     | 103      |\n",
            "|    ent_coef        | 0.0439   |\n",
            "|    ent_coef_loss   | -2.1     |\n",
            "|    learning_rate   | 9.05e-06 |\n",
            "|    n_updates       | 4629798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=960000, episode_reward=-93346.14 +/- 114110.60\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.33e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 960000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.96e+03  |\n",
            "|    critic_loss     | 43.4      |\n",
            "|    ent_coef        | 0.0403    |\n",
            "|    ent_coef_loss   | -1.63     |\n",
            "|    learning_rate   | 9.04e-06  |\n",
            "|    n_updates       | 4639798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.12e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 192       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 62924     |\n",
            "|    total_timesteps | 960000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=970000, episode_reward=-207312.55 +/- 139933.87\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 970000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.94e+03  |\n",
            "|    critic_loss     | 21.8      |\n",
            "|    ent_coef        | 0.037     |\n",
            "|    ent_coef_loss   | -1.02     |\n",
            "|    learning_rate   | 9.03e-06  |\n",
            "|    n_updates       | 4649798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=980000, episode_reward=-149603.70 +/- 140408.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 980000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.18e+03 |\n",
            "|    critic_loss     | 94.2     |\n",
            "|    ent_coef        | 0.034    |\n",
            "|    ent_coef_loss   | -2.73    |\n",
            "|    learning_rate   | 9.02e-06 |\n",
            "|    n_updates       | 4659798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -2.01e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 196       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 64277     |\n",
            "|    total_timesteps | 980000    |\n",
            "----------------------------------\n",
            "Eval num_timesteps=990000, episode_reward=-92363.54 +/- 114601.98\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.24e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 990000    |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.03e+03  |\n",
            "|    critic_loss     | 88.6      |\n",
            "|    ent_coef        | 0.0315    |\n",
            "|    ent_coef_loss   | -0.664    |\n",
            "|    learning_rate   | 9.01e-06  |\n",
            "|    n_updates       | 4669798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1000000, episode_reward=-91995.85 +/- 114786.88\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -9.2e+04 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 5.18e+03 |\n",
            "|    critic_loss     | 23.4     |\n",
            "|    ent_coef        | 0.0308   |\n",
            "|    ent_coef_loss   | -0.205   |\n",
            "|    learning_rate   | 9e-06    |\n",
            "|    n_updates       | 4679798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.89e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 200       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 65625     |\n",
            "|    total_timesteps | 1000000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1010000, episode_reward=-206836.11 +/- 140516.37\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1010000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.05e+03  |\n",
            "|    critic_loss     | 10.5      |\n",
            "|    ent_coef        | 0.0285    |\n",
            "|    ent_coef_loss   | -2.28     |\n",
            "|    learning_rate   | 8.99e-06  |\n",
            "|    n_updates       | 4689798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1020000, episode_reward=-92363.92 +/- 114627.54\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.24e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1020000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.52e+03  |\n",
            "|    critic_loss     | 90.1      |\n",
            "|    ent_coef        | 0.027     |\n",
            "|    ent_coef_loss   | 1.57      |\n",
            "|    learning_rate   | 8.98e-06  |\n",
            "|    n_updates       | 4699798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.87e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 204       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 66966     |\n",
            "|    total_timesteps | 1020000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1030000, episode_reward=-264223.48 +/- 114791.39\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1030000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.73e+03  |\n",
            "|    critic_loss     | 34.6      |\n",
            "|    ent_coef        | 0.0292    |\n",
            "|    ent_coef_loss   | 3.71      |\n",
            "|    learning_rate   | 8.97e-06  |\n",
            "|    n_updates       | 4709798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1040000, episode_reward=-209278.77 +/- 137524.72\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.09e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1040000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 5.15e+03  |\n",
            "|    critic_loss     | 77.9      |\n",
            "|    ent_coef        | 0.0281    |\n",
            "|    ent_coef_loss   | -2.31     |\n",
            "|    learning_rate   | 8.96e-06  |\n",
            "|    n_updates       | 4719798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 208       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 68307     |\n",
            "|    total_timesteps | 1040000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1050000, episode_reward=-207071.89 +/- 140226.98\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1050000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.83e+03  |\n",
            "|    critic_loss     | 82.3      |\n",
            "|    ent_coef        | 0.0261    |\n",
            "|    ent_coef_loss   | -0.797    |\n",
            "|    learning_rate   | 8.95e-06  |\n",
            "|    n_updates       | 4729798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1060000, episode_reward=-149493.90 +/- 140496.85\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1060000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.91e+03  |\n",
            "|    critic_loss     | 2.94e+04  |\n",
            "|    ent_coef        | 0.0241    |\n",
            "|    ent_coef_loss   | 0.974     |\n",
            "|    learning_rate   | 8.94e-06  |\n",
            "|    n_updates       | 4739798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 212       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 69590     |\n",
            "|    total_timesteps | 1060000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1070000, episode_reward=-149730.18 +/- 140303.97\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1070000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.66e+03 |\n",
            "|    critic_loss     | 10.2     |\n",
            "|    ent_coef        | 0.0241   |\n",
            "|    ent_coef_loss   | 0.0594   |\n",
            "|    learning_rate   | 8.93e-06 |\n",
            "|    n_updates       | 4749798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1080000, episode_reward=-264469.95 +/- 114296.01\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1080000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.83e+03  |\n",
            "|    critic_loss     | 58.1      |\n",
            "|    ent_coef        | 0.0244    |\n",
            "|    ent_coef_loss   | -0.258    |\n",
            "|    learning_rate   | 8.92e-06  |\n",
            "|    n_updates       | 4759798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 216       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 70872     |\n",
            "|    total_timesteps | 1080000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1090000, episode_reward=-150489.03 +/- 139726.07\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1090000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.97e+03 |\n",
            "|    critic_loss     | 149      |\n",
            "|    ent_coef        | 0.0254   |\n",
            "|    ent_coef_loss   | 0.629    |\n",
            "|    learning_rate   | 8.91e-06 |\n",
            "|    n_updates       | 4769798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1100000, episode_reward=-150640.46 +/- 139602.89\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.51e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1100000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.63e+03  |\n",
            "|    critic_loss     | 31.3      |\n",
            "|    ent_coef        | 0.0258    |\n",
            "|    ent_coef_loss   | 0.724     |\n",
            "|    learning_rate   | 8.9e-06   |\n",
            "|    n_updates       | 4779798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.93e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 220       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 72163     |\n",
            "|    total_timesteps | 1100000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1110000, episode_reward=-264563.41 +/- 114109.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.65e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1110000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.55e+03  |\n",
            "|    critic_loss     | 7.18      |\n",
            "|    ent_coef        | 0.0242    |\n",
            "|    ent_coef_loss   | -0.368    |\n",
            "|    learning_rate   | 8.89e-06  |\n",
            "|    n_updates       | 4789798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1120000, episode_reward=-207199.98 +/- 140134.75\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1120000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.45e+03  |\n",
            "|    critic_loss     | 45.7      |\n",
            "|    ent_coef        | 0.0227    |\n",
            "|    ent_coef_loss   | -0.511    |\n",
            "|    learning_rate   | 8.88e-06  |\n",
            "|    n_updates       | 4799798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 224       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 73463     |\n",
            "|    total_timesteps | 1120000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1130000, episode_reward=-149140.15 +/- 140787.06\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1130000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.81e+03  |\n",
            "|    critic_loss     | 152       |\n",
            "|    ent_coef        | 0.021     |\n",
            "|    ent_coef_loss   | -0.00738  |\n",
            "|    learning_rate   | 8.87e-06  |\n",
            "|    n_updates       | 4809798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1140000, episode_reward=-264133.81 +/- 114970.27\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1140000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.46e+03  |\n",
            "|    critic_loss     | 61.1      |\n",
            "|    ent_coef        | 0.0205    |\n",
            "|    ent_coef_loss   | 0.868     |\n",
            "|    learning_rate   | 8.86e-06  |\n",
            "|    n_updates       | 4819798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 228       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 74769     |\n",
            "|    total_timesteps | 1140000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1150000, episode_reward=-263937.37 +/- 115362.22\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1150000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.63e+03  |\n",
            "|    critic_loss     | 11.3      |\n",
            "|    ent_coef        | 0.0213    |\n",
            "|    ent_coef_loss   | 0.0472    |\n",
            "|    learning_rate   | 8.85e-06  |\n",
            "|    n_updates       | 4829798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1160000, episode_reward=-263954.33 +/- 115227.11\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1160000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.51e+03  |\n",
            "|    critic_loss     | 16.2      |\n",
            "|    ent_coef        | 0.0224    |\n",
            "|    ent_coef_loss   | 0.764     |\n",
            "|    learning_rate   | 8.84e-06  |\n",
            "|    n_updates       | 4839798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.93e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 232       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 76078     |\n",
            "|    total_timesteps | 1160000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1170000, episode_reward=-91227.06 +/- 115170.39\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.12e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1170000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.34e+03  |\n",
            "|    critic_loss     | 48.4      |\n",
            "|    ent_coef        | 0.024     |\n",
            "|    ent_coef_loss   | 1.28      |\n",
            "|    learning_rate   | 8.83e-06  |\n",
            "|    n_updates       | 4849798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1180000, episode_reward=-148973.79 +/- 140922.32\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1180000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.5e+03   |\n",
            "|    critic_loss     | 59.2      |\n",
            "|    ent_coef        | 0.0259    |\n",
            "|    ent_coef_loss   | 0.793     |\n",
            "|    learning_rate   | 8.82e-06  |\n",
            "|    n_updates       | 4859798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.87e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 236       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 77383     |\n",
            "|    total_timesteps | 1180000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1190000, episode_reward=-149730.12 +/- 140305.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1190000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.36e+03 |\n",
            "|    critic_loss     | 166      |\n",
            "|    ent_coef        | 0.0281   |\n",
            "|    ent_coef_loss   | 1.72     |\n",
            "|    learning_rate   | 8.81e-06 |\n",
            "|    n_updates       | 4869798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1200000, episode_reward=-149828.01 +/- 140225.17\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1200000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.46e+03 |\n",
            "|    critic_loss     | 15.6     |\n",
            "|    ent_coef        | 0.0304   |\n",
            "|    ent_coef_loss   | 0.548    |\n",
            "|    learning_rate   | 8.8e-06  |\n",
            "|    n_updates       | 4879798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 240       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 78679     |\n",
            "|    total_timesteps | 1200000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1210000, episode_reward=-149945.98 +/- 140129.05\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1210000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.38e+03 |\n",
            "|    critic_loss     | 25.7     |\n",
            "|    ent_coef        | 0.0329   |\n",
            "|    ent_coef_loss   | 0.571    |\n",
            "|    learning_rate   | 8.79e-06 |\n",
            "|    n_updates       | 4889798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1220000, episode_reward=-207233.39 +/- 140030.29\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1220000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.23e+03  |\n",
            "|    critic_loss     | 31.9      |\n",
            "|    ent_coef        | 0.0355    |\n",
            "|    ent_coef_loss   | 1.09      |\n",
            "|    learning_rate   | 8.78e-06  |\n",
            "|    n_updates       | 4899798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 244       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 79969     |\n",
            "|    total_timesteps | 1220000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1230000, episode_reward=-92570.43 +/- 114498.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.26e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1230000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.16e+03  |\n",
            "|    critic_loss     | 261       |\n",
            "|    ent_coef        | 0.0381    |\n",
            "|    ent_coef_loss   | 0.717     |\n",
            "|    learning_rate   | 8.77e-06  |\n",
            "|    n_updates       | 4909798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1240000, episode_reward=-206983.66 +/- 140336.76\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1240000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.41e+03  |\n",
            "|    critic_loss     | 104       |\n",
            "|    ent_coef        | 0.0405    |\n",
            "|    ent_coef_loss   | -0.103    |\n",
            "|    learning_rate   | 8.76e-06  |\n",
            "|    n_updates       | 4919798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.87e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 248       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 81251     |\n",
            "|    total_timesteps | 1240000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1250000, episode_reward=-206704.26 +/- 140740.56\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1250000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.34e+03  |\n",
            "|    critic_loss     | 12.5      |\n",
            "|    ent_coef        | 0.0432    |\n",
            "|    ent_coef_loss   | 1.51      |\n",
            "|    learning_rate   | 8.75e-06  |\n",
            "|    n_updates       | 4929798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1260000, episode_reward=-89868.09 +/- 115875.38\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -8.99e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1260000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.38e+03  |\n",
            "|    critic_loss     | 14.6      |\n",
            "|    ent_coef        | 0.0473    |\n",
            "|    ent_coef_loss   | 1.17      |\n",
            "|    learning_rate   | 8.74e-06  |\n",
            "|    n_updates       | 4939798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 252      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 82524    |\n",
            "|    total_timesteps | 1260000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1270000, episode_reward=-38594.21 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.86e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1270000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.32e+03  |\n",
            "|    critic_loss     | 21.2      |\n",
            "|    ent_coef        | 0.0513    |\n",
            "|    ent_coef_loss   | 2         |\n",
            "|    learning_rate   | 8.73e-06  |\n",
            "|    n_updates       | 4949798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1280000, episode_reward=-154071.56 +/- 136801.80\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1280000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.31e+03  |\n",
            "|    critic_loss     | 17.8      |\n",
            "|    ent_coef        | 0.0543    |\n",
            "|    ent_coef_loss   | -0.348    |\n",
            "|    learning_rate   | 8.72e-06  |\n",
            "|    n_updates       | 4959798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 256       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 83819     |\n",
            "|    total_timesteps | 1280000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1290000, episode_reward=-156173.29 +/- 135044.65\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1290000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.22e+03  |\n",
            "|    critic_loss     | 34.7      |\n",
            "|    ent_coef        | 0.0503    |\n",
            "|    ent_coef_loss   | -0.42     |\n",
            "|    learning_rate   | 8.71e-06  |\n",
            "|    n_updates       | 4969798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1300000, episode_reward=-99611.53 +/- 110978.27\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.96e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1300000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.22e+03  |\n",
            "|    critic_loss     | 36.9      |\n",
            "|    ent_coef        | 0.0469    |\n",
            "|    ent_coef_loss   | -0.305    |\n",
            "|    learning_rate   | 8.7e-06   |\n",
            "|    n_updates       | 4979798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 260       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 85121     |\n",
            "|    total_timesteps | 1300000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1310000, episode_reward=-35346.27 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.53e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1310000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.34e+03  |\n",
            "|    critic_loss     | 213       |\n",
            "|    ent_coef        | 0.0443    |\n",
            "|    ent_coef_loss   | -0.565    |\n",
            "|    learning_rate   | 8.69e-06  |\n",
            "|    n_updates       | 4989798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1320000, episode_reward=-206810.75 +/- 140548.35\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1320000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.15e+03  |\n",
            "|    critic_loss     | 14.8      |\n",
            "|    ent_coef        | 0.0423    |\n",
            "|    ent_coef_loss   | -0.362    |\n",
            "|    learning_rate   | 8.68e-06  |\n",
            "|    n_updates       | 4999798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 264       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 86414     |\n",
            "|    total_timesteps | 1320000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1330000, episode_reward=-264411.48 +/- 114415.01\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1330000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.12e+03  |\n",
            "|    critic_loss     | 488       |\n",
            "|    ent_coef        | 0.0408    |\n",
            "|    ent_coef_loss   | 0.206     |\n",
            "|    learning_rate   | 8.67e-06  |\n",
            "|    n_updates       | 5009798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1340000, episode_reward=-150277.89 +/- 139899.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1340000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.58e+03 |\n",
            "|    critic_loss     | 13.7     |\n",
            "|    ent_coef        | 0.0422   |\n",
            "|    ent_coef_loss   | -0.495   |\n",
            "|    learning_rate   | 8.66e-06 |\n",
            "|    n_updates       | 5019798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 268       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 87711     |\n",
            "|    total_timesteps | 1340000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1350000, episode_reward=-321618.47 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.22e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1350000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.36e+03  |\n",
            "|    critic_loss     | 21.1      |\n",
            "|    ent_coef        | 0.0413    |\n",
            "|    ent_coef_loss   | -0.749    |\n",
            "|    learning_rate   | 8.65e-06  |\n",
            "|    n_updates       | 5029798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1360000, episode_reward=-207142.71 +/- 140204.97\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1360000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.98e+03  |\n",
            "|    critic_loss     | 34.9      |\n",
            "|    ent_coef        | 0.0386    |\n",
            "|    ent_coef_loss   | -0.457    |\n",
            "|    learning_rate   | 8.64e-06  |\n",
            "|    n_updates       | 5039798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 272       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 89016     |\n",
            "|    total_timesteps | 1360000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1370000, episode_reward=-207443.06 +/- 139837.08\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1370000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.09e+03  |\n",
            "|    critic_loss     | 568       |\n",
            "|    ent_coef        | 0.0376    |\n",
            "|    ent_coef_loss   | -0.33     |\n",
            "|    learning_rate   | 8.63e-06  |\n",
            "|    n_updates       | 5049798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1380000, episode_reward=-149860.53 +/- 140241.09\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1380000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.11e+03 |\n",
            "|    critic_loss     | 10.4     |\n",
            "|    ent_coef        | 0.0376   |\n",
            "|    ent_coef_loss   | -0.456   |\n",
            "|    learning_rate   | 8.62e-06 |\n",
            "|    n_updates       | 5059798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.76e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 276       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 90322     |\n",
            "|    total_timesteps | 1380000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1390000, episode_reward=-149880.61 +/- 140223.56\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1390000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.05e+03 |\n",
            "|    critic_loss     | 24.2     |\n",
            "|    ent_coef        | 0.0396   |\n",
            "|    ent_coef_loss   | 1.72     |\n",
            "|    learning_rate   | 8.61e-06 |\n",
            "|    n_updates       | 5069798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1400000, episode_reward=-35434.03 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.54e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1400000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.15e+03  |\n",
            "|    critic_loss     | 32.1      |\n",
            "|    ent_coef        | 0.0434    |\n",
            "|    ent_coef_loss   | 9.25      |\n",
            "|    learning_rate   | 8.6e-06   |\n",
            "|    n_updates       | 5079798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.79e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 280       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 91620     |\n",
            "|    total_timesteps | 1400000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1410000, episode_reward=-207002.65 +/- 140373.63\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1410000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.84e+03  |\n",
            "|    critic_loss     | 24.2      |\n",
            "|    ent_coef        | 0.0473    |\n",
            "|    ent_coef_loss   | 7.2       |\n",
            "|    learning_rate   | 8.59e-06  |\n",
            "|    n_updates       | 5089798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1420000, episode_reward=-206902.97 +/- 140495.04\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1420000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.74e+03  |\n",
            "|    critic_loss     | 9.14      |\n",
            "|    ent_coef        | 0.0512    |\n",
            "|    ent_coef_loss   | 3.1       |\n",
            "|    learning_rate   | 8.58e-06  |\n",
            "|    n_updates       | 5099798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.82e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 284       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 92918     |\n",
            "|    total_timesteps | 1420000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1430000, episode_reward=-206814.44 +/- 140606.79\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1430000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.88e+03  |\n",
            "|    critic_loss     | 11.3      |\n",
            "|    ent_coef        | 0.0515    |\n",
            "|    ent_coef_loss   | 0.51      |\n",
            "|    learning_rate   | 8.57e-06  |\n",
            "|    n_updates       | 5109798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1440000, episode_reward=-264310.51 +/- 114620.51\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1440000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.97e+03  |\n",
            "|    critic_loss     | 2.69e+04  |\n",
            "|    ent_coef        | 0.0509    |\n",
            "|    ent_coef_loss   | -0.322    |\n",
            "|    learning_rate   | 8.56e-06  |\n",
            "|    n_updates       | 5119798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.82e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 288       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 94195     |\n",
            "|    total_timesteps | 1440000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1450000, episode_reward=-91883.90 +/- 114867.33\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.19e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1450000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.97e+03  |\n",
            "|    critic_loss     | 5.14      |\n",
            "|    ent_coef        | 0.0489    |\n",
            "|    ent_coef_loss   | 3.18      |\n",
            "|    learning_rate   | 8.55e-06  |\n",
            "|    n_updates       | 5129798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1460000, episode_reward=-149540.29 +/- 140501.37\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.5e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1460000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.77e+03 |\n",
            "|    critic_loss     | 51.3     |\n",
            "|    ent_coef        | 0.0527   |\n",
            "|    ent_coef_loss   | 1.61     |\n",
            "|    learning_rate   | 8.54e-06 |\n",
            "|    n_updates       | 5139798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.76e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 292       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 95469     |\n",
            "|    total_timesteps | 1460000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1470000, episode_reward=-149493.17 +/- 140541.56\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1470000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.44e+03  |\n",
            "|    critic_loss     | 15.8      |\n",
            "|    ent_coef        | 0.0504    |\n",
            "|    ent_coef_loss   | -0.466    |\n",
            "|    learning_rate   | 8.53e-06  |\n",
            "|    n_updates       | 5149798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1480000, episode_reward=-264459.99 +/- 114322.15\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.64e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1480000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.93e+03  |\n",
            "|    critic_loss     | 8.14      |\n",
            "|    ent_coef        | 0.0466    |\n",
            "|    ent_coef_loss   | -0.965    |\n",
            "|    learning_rate   | 8.52e-06  |\n",
            "|    n_updates       | 5159798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 296       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 96751     |\n",
            "|    total_timesteps | 1480000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1490000, episode_reward=-91965.48 +/- 114826.74\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -9.2e+04 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1490000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.7e+03  |\n",
            "|    critic_loss     | 15.4     |\n",
            "|    ent_coef        | 0.044    |\n",
            "|    ent_coef_loss   | 2.86     |\n",
            "|    learning_rate   | 8.51e-06 |\n",
            "|    n_updates       | 5169798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1500000, episode_reward=-148220.16 +/- 141581.06\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.48e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1500000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.65e+03  |\n",
            "|    critic_loss     | 5.47      |\n",
            "|    ent_coef        | 0.0429    |\n",
            "|    ent_coef_loss   | -0.594    |\n",
            "|    learning_rate   | 8.5e-06   |\n",
            "|    n_updates       | 5179798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 98024    |\n",
            "|    total_timesteps | 1500000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1510000, episode_reward=-206409.63 +/- 141102.54\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.06e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1510000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.61e+03  |\n",
            "|    critic_loss     | 9.88      |\n",
            "|    ent_coef        | 0.0458    |\n",
            "|    ent_coef_loss   | 0.088     |\n",
            "|    learning_rate   | 8.49e-06  |\n",
            "|    n_updates       | 5189798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1520000, episode_reward=-148046.44 +/- 141722.33\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.48e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1520000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.99e+03  |\n",
            "|    critic_loss     | 14.3      |\n",
            "|    ent_coef        | 0.0429    |\n",
            "|    ent_coef_loss   | -1.21     |\n",
            "|    learning_rate   | 8.48e-06  |\n",
            "|    n_updates       | 5199798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 304       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 99298     |\n",
            "|    total_timesteps | 1520000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1530000, episode_reward=-206319.66 +/- 141213.18\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.06e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1530000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.91e+03  |\n",
            "|    critic_loss     | 4.58      |\n",
            "|    ent_coef        | 0.0402    |\n",
            "|    ent_coef_loss   | -0.533    |\n",
            "|    learning_rate   | 8.47e-06  |\n",
            "|    n_updates       | 5209798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1540000, episode_reward=-152403.46 +/- 138164.47\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.52e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1540000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.84e+03  |\n",
            "|    critic_loss     | 580       |\n",
            "|    ent_coef        | 0.0374    |\n",
            "|    ent_coef_loss   | -0.618    |\n",
            "|    learning_rate   | 8.46e-06  |\n",
            "|    n_updates       | 5219798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 308       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 100602    |\n",
            "|    total_timesteps | 1540000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1550000, episode_reward=-207495.27 +/- 139773.17\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.07e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1550000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.89e+03  |\n",
            "|    critic_loss     | 19.6      |\n",
            "|    ent_coef        | 0.0352    |\n",
            "|    ent_coef_loss   | -0.774    |\n",
            "|    learning_rate   | 8.45e-06  |\n",
            "|    n_updates       | 5229798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1560000, episode_reward=-205628.20 +/- 142061.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.06e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1560000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.78e+03  |\n",
            "|    critic_loss     | 7.44      |\n",
            "|    ent_coef        | 0.0341    |\n",
            "|    ent_coef_loss   | 0.254     |\n",
            "|    learning_rate   | 8.44e-06  |\n",
            "|    n_updates       | 5239798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 312       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 101902    |\n",
            "|    total_timesteps | 1560000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1570000, episode_reward=-158433.65 +/- 133241.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.58e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1570000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.41e+03  |\n",
            "|    critic_loss     | 17.2      |\n",
            "|    ent_coef        | 0.0365    |\n",
            "|    ent_coef_loss   | 1.01      |\n",
            "|    learning_rate   | 8.43e-06  |\n",
            "|    n_updates       | 5249798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1580000, episode_reward=-213235.19 +/- 132742.32\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1580000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.89e+03  |\n",
            "|    critic_loss     | 5.31      |\n",
            "|    ent_coef        | 0.04      |\n",
            "|    ent_coef_loss   | 3.35      |\n",
            "|    learning_rate   | 8.42e-06  |\n",
            "|    n_updates       | 5259798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.79e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 316       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 103215    |\n",
            "|    total_timesteps | 1580000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1590000, episode_reward=-154307.39 +/- 136610.83\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1590000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.6e+03   |\n",
            "|    critic_loss     | 13.5      |\n",
            "|    ent_coef        | 0.0402    |\n",
            "|    ent_coef_loss   | -1.01     |\n",
            "|    learning_rate   | 8.41e-06  |\n",
            "|    n_updates       | 5269798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1600000, episode_reward=-156101.80 +/- 135144.61\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1600000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.82e+03  |\n",
            "|    critic_loss     | 14.3      |\n",
            "|    ent_coef        | 0.0411    |\n",
            "|    ent_coef_loss   | 1.78      |\n",
            "|    learning_rate   | 8.4e-06   |\n",
            "|    n_updates       | 5279798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.74e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 320       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 104604    |\n",
            "|    total_timesteps | 1600000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1610000, episode_reward=-266817.76 +/- 109606.76\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.67e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1610000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.89e+03  |\n",
            "|    critic_loss     | 7.98      |\n",
            "|    ent_coef        | 0.0404    |\n",
            "|    ent_coef_loss   | -1.29     |\n",
            "|    learning_rate   | 8.39e-06  |\n",
            "|    n_updates       | 5289798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1620000, episode_reward=-212912.36 +/- 133137.85\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1620000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.55e+03  |\n",
            "|    critic_loss     | 198       |\n",
            "|    ent_coef        | 0.0394    |\n",
            "|    ent_coef_loss   | 1.06      |\n",
            "|    learning_rate   | 8.38e-06  |\n",
            "|    n_updates       | 5299798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.66e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 324       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 105957    |\n",
            "|    total_timesteps | 1620000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1630000, episode_reward=-158728.78 +/- 132999.19\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.59e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1630000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.63e+03  |\n",
            "|    critic_loss     | 4.51      |\n",
            "|    ent_coef        | 0.0398    |\n",
            "|    ent_coef_loss   | 1.71      |\n",
            "|    learning_rate   | 8.37e-06  |\n",
            "|    n_updates       | 5309798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1640000, episode_reward=-156400.53 +/- 134900.53\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1640000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.68e+03  |\n",
            "|    critic_loss     | 22.1      |\n",
            "|    ent_coef        | 0.0383    |\n",
            "|    ent_coef_loss   | 0.422     |\n",
            "|    learning_rate   | 8.36e-06  |\n",
            "|    n_updates       | 5319798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.66e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 328       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 107321    |\n",
            "|    total_timesteps | 1640000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1650000, episode_reward=-46470.65 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.65e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1650000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.46e+03  |\n",
            "|    critic_loss     | 4.06      |\n",
            "|    ent_coef        | 0.0392    |\n",
            "|    ent_coef_loss   | 3.29      |\n",
            "|    learning_rate   | 8.35e-06  |\n",
            "|    n_updates       | 5329798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1660000, episode_reward=-156576.04 +/- 134756.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1660000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.57e+03  |\n",
            "|    critic_loss     | 845       |\n",
            "|    ent_coef        | 0.0423    |\n",
            "|    ent_coef_loss   | 1.52      |\n",
            "|    learning_rate   | 8.34e-06  |\n",
            "|    n_updates       | 5339798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.66e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 332       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 108693    |\n",
            "|    total_timesteps | 1660000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1670000, episode_reward=-158403.13 +/- 133266.78\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.58e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1670000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.7e+03   |\n",
            "|    critic_loss     | 759       |\n",
            "|    ent_coef        | 0.0429    |\n",
            "|    ent_coef_loss   | -0.655    |\n",
            "|    learning_rate   | 8.33e-06  |\n",
            "|    n_updates       | 5349798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1680000, episode_reward=-170875.84 +/- 123080.72\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.71e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1680000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.26e+03  |\n",
            "|    critic_loss     | 6.29      |\n",
            "|    ent_coef        | 0.0401    |\n",
            "|    ent_coef_loss   | -0.611    |\n",
            "|    learning_rate   | 8.32e-06  |\n",
            "|    n_updates       | 5359798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.69e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 336       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 110047    |\n",
            "|    total_timesteps | 1680000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1690000, episode_reward=-307505.45 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.08e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1690000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.6e+03   |\n",
            "|    critic_loss     | 27.8      |\n",
            "|    ent_coef        | 0.0371    |\n",
            "|    ent_coef_loss   | -0.602    |\n",
            "|    learning_rate   | 8.31e-06  |\n",
            "|    n_updates       | 5369798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1700000, episode_reward=-313671.95 +/- 6488.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.14e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1700000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.55e+03  |\n",
            "|    critic_loss     | 60.2      |\n",
            "|    ent_coef        | 0.0342    |\n",
            "|    ent_coef_loss   | -1.35     |\n",
            "|    learning_rate   | 8.3e-06   |\n",
            "|    n_updates       | 5379798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.78e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 340       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 111391    |\n",
            "|    total_timesteps | 1700000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1710000, episode_reward=-308917.44 +/- 6350.28\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.09e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1710000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.38e+03  |\n",
            "|    critic_loss     | 871       |\n",
            "|    ent_coef        | 0.0342    |\n",
            "|    ent_coef_loss   | 1.02      |\n",
            "|    learning_rate   | 8.29e-06  |\n",
            "|    n_updates       | 5389798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1720000, episode_reward=-312627.49 +/- 7340.55\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1720000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.44e+03  |\n",
            "|    critic_loss     | 23.2      |\n",
            "|    ent_coef        | 0.0372    |\n",
            "|    ent_coef_loss   | 2         |\n",
            "|    learning_rate   | 8.28e-06  |\n",
            "|    n_updates       | 5399798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 344       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 112738    |\n",
            "|    total_timesteps | 1720000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1730000, episode_reward=-312702.08 +/- 7235.34\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1730000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.73e+03  |\n",
            "|    critic_loss     | 23.4      |\n",
            "|    ent_coef        | 0.0405    |\n",
            "|    ent_coef_loss   | 2.58      |\n",
            "|    learning_rate   | 8.27e-06  |\n",
            "|    n_updates       | 5409798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1740000, episode_reward=-182527.12 +/- 113521.75\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1740000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.43e+03  |\n",
            "|    critic_loss     | 18.2      |\n",
            "|    ent_coef        | 0.044     |\n",
            "|    ent_coef_loss   | 3.41      |\n",
            "|    learning_rate   | 8.26e-06  |\n",
            "|    n_updates       | 5419798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 348       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 114085    |\n",
            "|    total_timesteps | 1740000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1750000, episode_reward=-316066.64 +/- 10996.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.16e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1750000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.73e+03  |\n",
            "|    critic_loss     | 41.4      |\n",
            "|    ent_coef        | 0.0476    |\n",
            "|    ent_coef_loss   | 3         |\n",
            "|    learning_rate   | 8.25e-06  |\n",
            "|    n_updates       | 5429798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1760000, episode_reward=-312732.83 +/- 7210.43\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1760000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.58e+03  |\n",
            "|    critic_loss     | 96.7      |\n",
            "|    ent_coef        | 0.0519    |\n",
            "|    ent_coef_loss   | 5.67      |\n",
            "|    learning_rate   | 8.24e-06  |\n",
            "|    n_updates       | 5439798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.84e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 352       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 115433    |\n",
            "|    total_timesteps | 1760000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1770000, episode_reward=-312692.19 +/- 7245.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.13e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1770000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.53e+03  |\n",
            "|    critic_loss     | 48.3      |\n",
            "|    ent_coef        | 0.0565    |\n",
            "|    ent_coef_loss   | 6.31      |\n",
            "|    learning_rate   | 8.23e-06  |\n",
            "|    n_updates       | 5449798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1780000, episode_reward=-313913.52 +/- 15410.24\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.14e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1780000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.24e+03  |\n",
            "|    critic_loss     | 67.8      |\n",
            "|    ent_coef        | 0.0611    |\n",
            "|    ent_coef_loss   | 4.67      |\n",
            "|    learning_rate   | 8.22e-06  |\n",
            "|    n_updates       | 5459798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.87e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 356       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 116780    |\n",
            "|    total_timesteps | 1780000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1790000, episode_reward=-263053.32 +/- 117127.99\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.63e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1790000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.7e+03   |\n",
            "|    critic_loss     | 88.2      |\n",
            "|    ent_coef        | 0.0664    |\n",
            "|    ent_coef_loss   | 5.23      |\n",
            "|    learning_rate   | 8.21e-06  |\n",
            "|    n_updates       | 5469798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1800000, episode_reward=-318955.90 +/- 5113.92\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.19e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1800000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.78e+03  |\n",
            "|    critic_loss     | 317       |\n",
            "|    ent_coef        | 0.0721    |\n",
            "|    ent_coef_loss   | 4.42      |\n",
            "|    learning_rate   | 8.2e-06   |\n",
            "|    n_updates       | 5479798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 118174   |\n",
            "|    total_timesteps | 1800000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1810000, episode_reward=-307613.53 +/- 7031.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.08e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1810000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.48e+03  |\n",
            "|    critic_loss     | 1.83e+03  |\n",
            "|    ent_coef        | 0.0782    |\n",
            "|    ent_coef_loss   | 6.25      |\n",
            "|    learning_rate   | 8.19e-06  |\n",
            "|    n_updates       | 5489798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1820000, episode_reward=-265989.98 +/- 111371.10\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1820000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.29e+03  |\n",
            "|    critic_loss     | 75.2      |\n",
            "|    ent_coef        | 0.0849    |\n",
            "|    ent_coef_loss   | 6.54      |\n",
            "|    learning_rate   | 8.18e-06  |\n",
            "|    n_updates       | 5499798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.95e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 364       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 119555    |\n",
            "|    total_timesteps | 1820000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1830000, episode_reward=-96171.85 +/- 112751.50\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.62e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1830000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.82e+03  |\n",
            "|    critic_loss     | 66.6      |\n",
            "|    ent_coef        | 0.0922    |\n",
            "|    ent_coef_loss   | 7.06      |\n",
            "|    learning_rate   | 8.17e-06  |\n",
            "|    n_updates       | 5509798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1840000, episode_reward=-148798.50 +/- 141064.91\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.49e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1840000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.84e+03  |\n",
            "|    critic_loss     | 89.3      |\n",
            "|    ent_coef        | 0.0997    |\n",
            "|    ent_coef_loss   | 0.481     |\n",
            "|    learning_rate   | 8.16e-06  |\n",
            "|    n_updates       | 5519798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 368       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 120906    |\n",
            "|    total_timesteps | 1840000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1850000, episode_reward=-287403.66 +/- 41905.87\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.87e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1850000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.93e+03  |\n",
            "|    critic_loss     | 59.1      |\n",
            "|    ent_coef        | 0.107     |\n",
            "|    ent_coef_loss   | 2.06      |\n",
            "|    learning_rate   | 8.15e-06  |\n",
            "|    n_updates       | 5529798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1860000, episode_reward=-94310.32 +/- 113654.65\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.43e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1860000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.11e+03  |\n",
            "|    critic_loss     | 197       |\n",
            "|    ent_coef        | 0.115     |\n",
            "|    ent_coef_loss   | 2.33      |\n",
            "|    learning_rate   | 8.14e-06  |\n",
            "|    n_updates       | 5539798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 372       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 122242    |\n",
            "|    total_timesteps | 1860000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1870000, episode_reward=-260977.14 +/- 121287.11\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.61e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1870000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.79e+03  |\n",
            "|    critic_loss     | 92.4      |\n",
            "|    ent_coef        | 0.124     |\n",
            "|    ent_coef_loss   | 1.12      |\n",
            "|    learning_rate   | 8.13e-06  |\n",
            "|    n_updates       | 5549798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1880000, episode_reward=-139732.92 +/- 148510.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.4e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1880000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.04e+03 |\n",
            "|    critic_loss     | 102      |\n",
            "|    ent_coef        | 0.132    |\n",
            "|    ent_coef_loss   | 0.719    |\n",
            "|    learning_rate   | 8.12e-06 |\n",
            "|    n_updates       | 5559798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.98e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 376       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 123580    |\n",
            "|    total_timesteps | 1880000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1890000, episode_reward=-18810.83 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.88e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1890000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.19e+03  |\n",
            "|    critic_loss     | 3.87e+03  |\n",
            "|    ent_coef        | 0.139     |\n",
            "|    ent_coef_loss   | 0.626     |\n",
            "|    learning_rate   | 8.11e-06  |\n",
            "|    n_updates       | 5569798   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=1900000, episode_reward=-204741.35 +/- 143146.08\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.05e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1900000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.71e+03  |\n",
            "|    critic_loss     | 48.2      |\n",
            "|    ent_coef        | 0.15      |\n",
            "|    ent_coef_loss   | 0.608     |\n",
            "|    learning_rate   | 8.1e-06   |\n",
            "|    n_updates       | 5579798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.94e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 380       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 124966    |\n",
            "|    total_timesteps | 1900000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1910000, episode_reward=-264723.98 +/- 113791.63\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.65e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1910000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.06e+03  |\n",
            "|    critic_loss     | 54.3      |\n",
            "|    ent_coef        | 0.157     |\n",
            "|    ent_coef_loss   | -0.419    |\n",
            "|    learning_rate   | 8.09e-06  |\n",
            "|    n_updates       | 5589798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1920000, episode_reward=-210742.41 +/- 135796.24\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1920000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.92e+03  |\n",
            "|    critic_loss     | 397       |\n",
            "|    ent_coef        | 0.159     |\n",
            "|    ent_coef_loss   | -0.549    |\n",
            "|    learning_rate   | 8.08e-06  |\n",
            "|    n_updates       | 5599798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.97e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 384       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 126304    |\n",
            "|    total_timesteps | 1920000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1930000, episode_reward=-211643.07 +/- 134691.33\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.12e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1930000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.02e+03  |\n",
            "|    critic_loss     | 29.4      |\n",
            "|    ent_coef        | 0.151     |\n",
            "|    ent_coef_loss   | -0.854    |\n",
            "|    learning_rate   | 8.07e-06  |\n",
            "|    n_updates       | 5609798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1940000, episode_reward=-266890.56 +/- 109453.16\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.67e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1940000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.66e+03  |\n",
            "|    critic_loss     | 93.6      |\n",
            "|    ent_coef        | 0.156     |\n",
            "|    ent_coef_loss   | -0.133    |\n",
            "|    learning_rate   | 8.06e-06  |\n",
            "|    n_updates       | 5619798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.92e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 388       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 127616    |\n",
            "|    total_timesteps | 1940000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1950000, episode_reward=-157444.16 +/- 134004.71\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1950000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.66e+03  |\n",
            "|    critic_loss     | 39.9      |\n",
            "|    ent_coef        | 0.162     |\n",
            "|    ent_coef_loss   | 0.539     |\n",
            "|    learning_rate   | 8.05e-06  |\n",
            "|    n_updates       | 5629798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1960000, episode_reward=-265990.34 +/- 111150.69\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1960000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.61e+03  |\n",
            "|    critic_loss     | 33.1      |\n",
            "|    ent_coef        | 0.166     |\n",
            "|    ent_coef_loss   | 0.0147    |\n",
            "|    learning_rate   | 8.04e-06  |\n",
            "|    n_updates       | 5639798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.92e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 392       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 128935    |\n",
            "|    total_timesteps | 1960000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1970000, episode_reward=-156559.45 +/- 134726.90\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1970000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.13e+03  |\n",
            "|    critic_loss     | 230       |\n",
            "|    ent_coef        | 0.167     |\n",
            "|    ent_coef_loss   | -0.0316   |\n",
            "|    learning_rate   | 8.03e-06  |\n",
            "|    n_updates       | 5649798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1980000, episode_reward=-157057.45 +/- 134320.08\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1980000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.67e+03  |\n",
            "|    critic_loss     | 25.7      |\n",
            "|    ent_coef        | 0.174     |\n",
            "|    ent_coef_loss   | 0.462     |\n",
            "|    learning_rate   | 8.02e-06  |\n",
            "|    n_updates       | 5659798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 396      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 130256   |\n",
            "|    total_timesteps | 1980000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=1990000, episode_reward=-157139.83 +/- 134252.77\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 1990000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.82e+03  |\n",
            "|    critic_loss     | 47.3      |\n",
            "|    ent_coef        | 0.182     |\n",
            "|    ent_coef_loss   | 0.904     |\n",
            "|    learning_rate   | 8.01e-06  |\n",
            "|    n_updates       | 5669798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2000000, episode_reward=-156898.24 +/- 134449.88\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2000000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.79e+03  |\n",
            "|    critic_loss     | 83.7      |\n",
            "|    ent_coef        | 0.193     |\n",
            "|    ent_coef_loss   | 0.36      |\n",
            "|    learning_rate   | 8e-06     |\n",
            "|    n_updates       | 5679798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.87e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 400       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 131582    |\n",
            "|    total_timesteps | 2000000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2010000, episode_reward=-266791.48 +/- 109547.05\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.67e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2010000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.51e+03  |\n",
            "|    critic_loss     | 58.3      |\n",
            "|    ent_coef        | 0.199     |\n",
            "|    ent_coef_loss   | 0.15      |\n",
            "|    learning_rate   | 7.99e-06  |\n",
            "|    n_updates       | 5689798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2020000, episode_reward=-266456.54 +/- 110215.83\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2020000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4e+03     |\n",
            "|    critic_loss     | 1.24e+03  |\n",
            "|    ent_coef        | 0.204     |\n",
            "|    ent_coef_loss   | -0.151    |\n",
            "|    learning_rate   | 7.98e-06  |\n",
            "|    n_updates       | 5699798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.88e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 404       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 132903    |\n",
            "|    total_timesteps | 2020000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2030000, episode_reward=-100035.96 +/- 110764.44\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1e+05   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2030000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.83e+03 |\n",
            "|    critic_loss     | 57.5     |\n",
            "|    ent_coef        | 0.209    |\n",
            "|    ent_coef_loss   | -0.214   |\n",
            "|    learning_rate   | 7.97e-06 |\n",
            "|    n_updates       | 5709798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2040000, episode_reward=-210828.17 +/- 135623.97\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2040000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.68e+03  |\n",
            "|    critic_loss     | 168       |\n",
            "|    ent_coef        | 0.215     |\n",
            "|    ent_coef_loss   | -0.347    |\n",
            "|    learning_rate   | 7.96e-06  |\n",
            "|    n_updates       | 5719798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.85e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 408       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 134224    |\n",
            "|    total_timesteps | 2040000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2050000, episode_reward=-99268.94 +/- 111148.23\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.93e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2050000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.88e+03  |\n",
            "|    critic_loss     | 87.9      |\n",
            "|    ent_coef        | 0.206     |\n",
            "|    ent_coef_loss   | -0.27     |\n",
            "|    learning_rate   | 7.95e-06  |\n",
            "|    n_updates       | 5729798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2060000, episode_reward=-154462.49 +/- 136439.54\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2060000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.86e+03  |\n",
            "|    critic_loss     | 31.4      |\n",
            "|    ent_coef        | 0.192     |\n",
            "|    ent_coef_loss   | -0.825    |\n",
            "|    learning_rate   | 7.94e-06  |\n",
            "|    n_updates       | 5739798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.88e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 412       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 135540    |\n",
            "|    total_timesteps | 2060000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2070000, episode_reward=-155045.53 +/- 135963.13\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2070000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.62e+03  |\n",
            "|    critic_loss     | 1.53e+03  |\n",
            "|    ent_coef        | 0.18      |\n",
            "|    ent_coef_loss   | -0.504    |\n",
            "|    learning_rate   | 7.93e-06  |\n",
            "|    n_updates       | 5749798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2080000, episode_reward=-210901.01 +/- 135536.02\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2080000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.73e+03  |\n",
            "|    critic_loss     | 53.8      |\n",
            "|    ent_coef        | 0.174     |\n",
            "|    ent_coef_loss   | -0.27     |\n",
            "|    learning_rate   | 7.92e-06  |\n",
            "|    n_updates       | 5759798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.85e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 416       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 136879    |\n",
            "|    total_timesteps | 2080000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2090000, episode_reward=-100039.02 +/- 110763.34\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1e+05   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2090000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.68e+03 |\n",
            "|    critic_loss     | 621      |\n",
            "|    ent_coef        | 0.163    |\n",
            "|    ent_coef_loss   | -0.607   |\n",
            "|    learning_rate   | 7.91e-06 |\n",
            "|    n_updates       | 5769798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2100000, episode_reward=-154741.42 +/- 136211.12\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2100000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.36e+03  |\n",
            "|    critic_loss     | 57.3      |\n",
            "|    ent_coef        | 0.163     |\n",
            "|    ent_coef_loss   | -0.0409   |\n",
            "|    learning_rate   | 7.9e-06   |\n",
            "|    n_updates       | 5779798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.85e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 420       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 138190    |\n",
            "|    total_timesteps | 2100000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2110000, episode_reward=-209897.87 +/- 136828.66\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2110000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.59e+03 |\n",
            "|    critic_loss     | 18.6     |\n",
            "|    ent_coef        | 0.153    |\n",
            "|    ent_coef_loss   | -1.04    |\n",
            "|    learning_rate   | 7.89e-06 |\n",
            "|    n_updates       | 5789798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2120000, episode_reward=-153885.51 +/- 136953.37\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2120000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.33e+03  |\n",
            "|    critic_loss     | 36.6      |\n",
            "|    ent_coef        | 0.142     |\n",
            "|    ent_coef_loss   | -0.613    |\n",
            "|    learning_rate   | 7.88e-06  |\n",
            "|    n_updates       | 5799798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 424      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 139505   |\n",
            "|    total_timesteps | 2120000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2130000, episode_reward=-154027.93 +/- 136837.59\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2130000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.64e+03  |\n",
            "|    critic_loss     | 145       |\n",
            "|    ent_coef        | 0.132     |\n",
            "|    ent_coef_loss   | -0.73     |\n",
            "|    learning_rate   | 7.87e-06  |\n",
            "|    n_updates       | 5809798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2140000, episode_reward=-210292.09 +/- 136349.14\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2140000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.75e+03 |\n",
            "|    critic_loss     | 35.3     |\n",
            "|    ent_coef        | 0.123    |\n",
            "|    ent_coef_loss   | -0.683   |\n",
            "|    learning_rate   | 7.86e-06 |\n",
            "|    n_updates       | 5819798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.93e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 428       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 140818    |\n",
            "|    total_timesteps | 2140000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2150000, episode_reward=-210071.52 +/- 136620.60\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2150000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.49e+03 |\n",
            "|    critic_loss     | 53.1     |\n",
            "|    ent_coef        | 0.119    |\n",
            "|    ent_coef_loss   | 0.146    |\n",
            "|    learning_rate   | 7.85e-06 |\n",
            "|    n_updates       | 5829798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2160000, episode_reward=-100286.59 +/- 110667.85\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1e+05   |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2160000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.76e+03 |\n",
            "|    critic_loss     | 23.3     |\n",
            "|    ent_coef        | 0.122    |\n",
            "|    ent_coef_loss   | 0.124    |\n",
            "|    learning_rate   | 7.84e-06 |\n",
            "|    n_updates       | 5839798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.96e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 432       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 142135    |\n",
            "|    total_timesteps | 2160000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2170000, episode_reward=-211147.18 +/- 135304.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2170000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.86e+03  |\n",
            "|    critic_loss     | 17.4      |\n",
            "|    ent_coef        | 0.129     |\n",
            "|    ent_coef_loss   | 0.0825    |\n",
            "|    learning_rate   | 7.83e-06  |\n",
            "|    n_updates       | 5849798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2180000, episode_reward=-100893.65 +/- 110364.93\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.01e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2180000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.68e+03  |\n",
            "|    critic_loss     | 1.64e+03  |\n",
            "|    ent_coef        | 0.136     |\n",
            "|    ent_coef_loss   | 0.453     |\n",
            "|    learning_rate   | 7.82e-06  |\n",
            "|    n_updates       | 5859798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.96e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 436       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 143463    |\n",
            "|    total_timesteps | 2180000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2190000, episode_reward=-45296.43 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.53e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2190000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.83e+03  |\n",
            "|    critic_loss     | 30.7      |\n",
            "|    ent_coef        | 0.145     |\n",
            "|    ent_coef_loss   | 0.0122    |\n",
            "|    learning_rate   | 7.81e-06  |\n",
            "|    n_updates       | 5869798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2200000, episode_reward=-210793.14 +/- 135738.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2200000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.59e+03  |\n",
            "|    critic_loss     | 38.9      |\n",
            "|    ent_coef        | 0.154     |\n",
            "|    ent_coef_loss   | 0.39      |\n",
            "|    learning_rate   | 7.8e-06   |\n",
            "|    n_updates       | 5879798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.9e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 144797   |\n",
            "|    total_timesteps | 2200000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2210000, episode_reward=-209898.52 +/- 136833.02\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2210000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 4.02e+03 |\n",
            "|    critic_loss     | 142      |\n",
            "|    ent_coef        | 0.158    |\n",
            "|    ent_coef_loss   | 0.162    |\n",
            "|    learning_rate   | 7.79e-06 |\n",
            "|    n_updates       | 5889798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2220000, episode_reward=-39762.69 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.98e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2220000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.74e+03  |\n",
            "|    critic_loss     | 41.9      |\n",
            "|    ent_coef        | 0.162     |\n",
            "|    ent_coef_loss   | 0.11      |\n",
            "|    learning_rate   | 7.78e-06  |\n",
            "|    n_updates       | 5899798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.82e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 444       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 146130    |\n",
            "|    total_timesteps | 2220000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2230000, episode_reward=-208989.84 +/- 137944.95\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.09e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2230000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.72e+03  |\n",
            "|    critic_loss     | 26.3      |\n",
            "|    ent_coef        | 0.158     |\n",
            "|    ent_coef_loss   | -0.0349   |\n",
            "|    learning_rate   | 7.77e-06  |\n",
            "|    n_updates       | 5909798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2240000, episode_reward=-265382.49 +/- 112477.49\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.65e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2240000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4e+03     |\n",
            "|    critic_loss     | 507       |\n",
            "|    ent_coef        | 0.15      |\n",
            "|    ent_coef_loss   | -0.363    |\n",
            "|    learning_rate   | 7.76e-06  |\n",
            "|    n_updates       | 5919798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 448       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 147454    |\n",
            "|    total_timesteps | 2240000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2250000, episode_reward=-265484.62 +/- 112272.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.65e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2250000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.77e+03  |\n",
            "|    critic_loss     | 1.61e+03  |\n",
            "|    ent_coef        | 0.145     |\n",
            "|    ent_coef_loss   | 0.315     |\n",
            "|    learning_rate   | 7.75e-06  |\n",
            "|    n_updates       | 5929798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2260000, episode_reward=-97359.29 +/- 112130.57\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.74e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2260000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.69e+03  |\n",
            "|    critic_loss     | 1.64e+03  |\n",
            "|    ent_coef        | 0.148     |\n",
            "|    ent_coef_loss   | 0.542     |\n",
            "|    learning_rate   | 7.74e-06  |\n",
            "|    n_updates       | 5939798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.81e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 452       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 148774    |\n",
            "|    total_timesteps | 2260000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2270000, episode_reward=-209753.84 +/- 137007.84\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2270000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.59e+03 |\n",
            "|    critic_loss     | 14.3     |\n",
            "|    ent_coef        | 0.154    |\n",
            "|    ent_coef_loss   | -0.252   |\n",
            "|    learning_rate   | 7.73e-06 |\n",
            "|    n_updates       | 5949798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2280000, episode_reward=-210264.88 +/- 136381.64\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2280000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.71e+03 |\n",
            "|    critic_loss     | 20.6     |\n",
            "|    ent_coef        | 0.157    |\n",
            "|    ent_coef_loss   | 0.0208   |\n",
            "|    learning_rate   | 7.72e-06 |\n",
            "|    n_updates       | 5959798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.76e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 456       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 150094    |\n",
            "|    total_timesteps | 2280000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2290000, episode_reward=-99667.54 +/- 110975.99\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.97e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2290000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.81e+03  |\n",
            "|    critic_loss     | 13.9      |\n",
            "|    ent_coef        | 0.162     |\n",
            "|    ent_coef_loss   | 0.15      |\n",
            "|    learning_rate   | 7.71e-06  |\n",
            "|    n_updates       | 5969798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2300000, episode_reward=-154770.63 +/- 136231.27\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2300000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.66e+03  |\n",
            "|    critic_loss     | 41.4      |\n",
            "|    ent_coef        | 0.169     |\n",
            "|    ent_coef_loss   | 0.00354   |\n",
            "|    learning_rate   | 7.7e-06   |\n",
            "|    n_updates       | 5979798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.76e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 460       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 151403    |\n",
            "|    total_timesteps | 2300000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2310000, episode_reward=-210269.64 +/- 136374.49\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2310000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.93e+03 |\n",
            "|    critic_loss     | 60.3     |\n",
            "|    ent_coef        | 0.17     |\n",
            "|    ent_coef_loss   | -0.19    |\n",
            "|    learning_rate   | 7.69e-06 |\n",
            "|    n_updates       | 5989798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2320000, episode_reward=-154226.39 +/- 136675.45\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.54e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2320000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.7e+03   |\n",
            "|    critic_loss     | 17.1      |\n",
            "|    ent_coef        | 0.168     |\n",
            "|    ent_coef_loss   | -0.399    |\n",
            "|    learning_rate   | 7.68e-06  |\n",
            "|    n_updates       | 5999798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.7e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 464      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 152722   |\n",
            "|    total_timesteps | 2320000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2330000, episode_reward=-98155.52 +/- 111731.81\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.82e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2330000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.84e+03  |\n",
            "|    critic_loss     | 69.1      |\n",
            "|    ent_coef        | 0.166     |\n",
            "|    ent_coef_loss   | 0.087     |\n",
            "|    learning_rate   | 7.67e-06  |\n",
            "|    n_updates       | 6009798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2340000, episode_reward=-209823.49 +/- 136920.74\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2340000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.82e+03 |\n",
            "|    critic_loss     | 13.5     |\n",
            "|    ent_coef        | 0.158    |\n",
            "|    ent_coef_loss   | -0.469   |\n",
            "|    learning_rate   | 7.66e-06 |\n",
            "|    n_updates       | 6019798  |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.7e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 468      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 154054   |\n",
            "|    total_timesteps | 2340000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2350000, episode_reward=-98696.78 +/- 111460.80\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.87e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2350000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.67e+03  |\n",
            "|    critic_loss     | 14.6      |\n",
            "|    ent_coef        | 0.148     |\n",
            "|    ent_coef_loss   | -0.48     |\n",
            "|    learning_rate   | 7.65e-06  |\n",
            "|    n_updates       | 6029798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2360000, episode_reward=-210447.90 +/- 136156.15\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2360000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.67e+03 |\n",
            "|    critic_loss     | 52       |\n",
            "|    ent_coef        | 0.139    |\n",
            "|    ent_coef_loss   | -0.762   |\n",
            "|    learning_rate   | 7.64e-06 |\n",
            "|    n_updates       | 6039798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.68e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 472       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 155318    |\n",
            "|    total_timesteps | 2360000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2370000, episode_reward=-155001.24 +/- 136000.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2370000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.71e+03  |\n",
            "|    critic_loss     | 73.4      |\n",
            "|    ent_coef        | 0.129     |\n",
            "|    ent_coef_loss   | -0.666    |\n",
            "|    learning_rate   | 7.63e-06  |\n",
            "|    n_updates       | 6049798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2380000, episode_reward=-210457.69 +/- 136080.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2380000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.59e+03 |\n",
            "|    critic_loss     | 15.7     |\n",
            "|    ent_coef        | 0.12     |\n",
            "|    ent_coef_loss   | -0.502   |\n",
            "|    learning_rate   | 7.62e-06 |\n",
            "|    n_updates       | 6059798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.71e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 476       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 156568    |\n",
            "|    total_timesteps | 2380000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2390000, episode_reward=-210680.78 +/- 135807.39\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2390000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.58e+03  |\n",
            "|    critic_loss     | 21.3      |\n",
            "|    ent_coef        | 0.113     |\n",
            "|    ent_coef_loss   | -0.107    |\n",
            "|    learning_rate   | 7.61e-06  |\n",
            "|    n_updates       | 6069798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2400000, episode_reward=-265996.29 +/- 111141.19\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2400000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.88e+03  |\n",
            "|    critic_loss     | 19.5      |\n",
            "|    ent_coef        | 0.106     |\n",
            "|    ent_coef_loss   | -0.256    |\n",
            "|    learning_rate   | 7.6e-06   |\n",
            "|    n_updates       | 6079798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.78e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 480       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 157810    |\n",
            "|    total_timesteps | 2400000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2410000, episode_reward=-210480.38 +/- 136052.07\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2410000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.65e+03 |\n",
            "|    critic_loss     | 11       |\n",
            "|    ent_coef        | 0.0991   |\n",
            "|    ent_coef_loss   | -0.0174  |\n",
            "|    learning_rate   | 7.59e-06 |\n",
            "|    n_updates       | 6089798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2420000, episode_reward=-210556.56 +/- 135959.19\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2420000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.62e+03  |\n",
            "|    critic_loss     | 46.4      |\n",
            "|    ent_coef        | 0.0932    |\n",
            "|    ent_coef_loss   | -0.938    |\n",
            "|    learning_rate   | 7.58e-06  |\n",
            "|    n_updates       | 6099798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.75e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 484       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 159053    |\n",
            "|    total_timesteps | 2420000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2430000, episode_reward=-266100.39 +/- 110933.63\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2430000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.52e+03  |\n",
            "|    critic_loss     | 20.9      |\n",
            "|    ent_coef        | 0.0878    |\n",
            "|    ent_coef_loss   | -0.295    |\n",
            "|    learning_rate   | 7.57e-06  |\n",
            "|    n_updates       | 6109798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2440000, episode_reward=-155066.09 +/- 135989.09\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2440000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.93e+03  |\n",
            "|    critic_loss     | 14        |\n",
            "|    ent_coef        | 0.0827    |\n",
            "|    ent_coef_loss   | -0.502    |\n",
            "|    learning_rate   | 7.56e-06  |\n",
            "|    n_updates       | 6119798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 488       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 160286    |\n",
            "|    total_timesteps | 2440000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2450000, episode_reward=-210713.36 +/- 135698.45\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2450000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.07e+03  |\n",
            "|    critic_loss     | 10.6      |\n",
            "|    ent_coef        | 0.0849    |\n",
            "|    ent_coef_loss   | 0.883     |\n",
            "|    learning_rate   | 7.55e-06  |\n",
            "|    n_updates       | 6129798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2460000, episode_reward=-321511.65 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.22e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2460000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.73e+03  |\n",
            "|    critic_loss     | 14.7      |\n",
            "|    ent_coef        | 0.0914    |\n",
            "|    ent_coef_loss   | 1.47      |\n",
            "|    learning_rate   | 7.54e-06  |\n",
            "|    n_updates       | 6139798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 492       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 161512    |\n",
            "|    total_timesteps | 2460000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2470000, episode_reward=-99717.83 +/- 110949.04\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -9.97e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2470000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.82e+03  |\n",
            "|    critic_loss     | 16.5      |\n",
            "|    ent_coef        | 0.0986    |\n",
            "|    ent_coef_loss   | 1.56      |\n",
            "|    learning_rate   | 7.53e-06  |\n",
            "|    n_updates       | 6149798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2480000, episode_reward=-156642.06 +/- 134615.77\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.57e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2480000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.61e+03  |\n",
            "|    critic_loss     | 20.8      |\n",
            "|    ent_coef        | 0.106     |\n",
            "|    ent_coef_loss   | 0.658     |\n",
            "|    learning_rate   | 7.52e-06  |\n",
            "|    n_updates       | 6159798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 496       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 162749    |\n",
            "|    total_timesteps | 2480000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2490000, episode_reward=-156302.73 +/- 134892.74\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2490000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.93e+03  |\n",
            "|    critic_loss     | 25.1      |\n",
            "|    ent_coef        | 0.114     |\n",
            "|    ent_coef_loss   | 1.37      |\n",
            "|    learning_rate   | 7.51e-06  |\n",
            "|    n_updates       | 6169798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2500000, episode_reward=-210690.52 +/- 135728.41\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2500000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.72e+03  |\n",
            "|    critic_loss     | 82        |\n",
            "|    ent_coef        | 0.122     |\n",
            "|    ent_coef_loss   | 1.83      |\n",
            "|    learning_rate   | 7.5e-06   |\n",
            "|    n_updates       | 6179798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 163992   |\n",
            "|    total_timesteps | 2500000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2510000, episode_reward=-154616.39 +/- 136270.47\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2510000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.49e+03  |\n",
            "|    critic_loss     | 180       |\n",
            "|    ent_coef        | 0.13      |\n",
            "|    ent_coef_loss   | 0.354     |\n",
            "|    learning_rate   | 7.49e-06  |\n",
            "|    n_updates       | 6189798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2520000, episode_reward=-210225.33 +/- 136298.93\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2520000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.45e+03 |\n",
            "|    critic_loss     | 17.3     |\n",
            "|    ent_coef        | 0.134    |\n",
            "|    ent_coef_loss   | -0.00933 |\n",
            "|    learning_rate   | 7.48e-06 |\n",
            "|    n_updates       | 6199798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.86e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 504       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 165238    |\n",
            "|    total_timesteps | 2520000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2530000, episode_reward=-321512.39 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.22e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2530000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.53e+03  |\n",
            "|    critic_loss     | 48.6      |\n",
            "|    ent_coef        | 0.134     |\n",
            "|    ent_coef_loss   | -0.0706   |\n",
            "|    learning_rate   | 7.47e-06  |\n",
            "|    n_updates       | 6209798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2540000, episode_reward=-154543.31 +/- 136144.27\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2540000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.64e+03  |\n",
            "|    critic_loss     | 153       |\n",
            "|    ent_coef        | 0.144     |\n",
            "|    ent_coef_loss   | 8.75      |\n",
            "|    learning_rate   | 7.46e-06  |\n",
            "|    n_updates       | 6219798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.94e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 508       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 166476    |\n",
            "|    total_timesteps | 2540000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2550000, episode_reward=-210422.74 +/- 135649.91\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -2.1e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2550000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.21e+03 |\n",
            "|    critic_loss     | 70.7     |\n",
            "|    ent_coef        | 0.155    |\n",
            "|    ent_coef_loss   | 7.19     |\n",
            "|    learning_rate   | 7.45e-06 |\n",
            "|    n_updates       | 6229798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2560000, episode_reward=-46694.00 +/- 1152.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.67e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2560000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.23e+03  |\n",
            "|    critic_loss     | 58.2      |\n",
            "|    ent_coef        | 0.167     |\n",
            "|    ent_coef_loss   | 10.3      |\n",
            "|    learning_rate   | 7.44e-06  |\n",
            "|    n_updates       | 6239798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.88e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 512       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 167716    |\n",
            "|    total_timesteps | 2560000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2570000, episode_reward=-45972.31 +/- 474.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -4.6e+04 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2570000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.52e+03 |\n",
            "|    critic_loss     | 197      |\n",
            "|    ent_coef        | 0.18     |\n",
            "|    ent_coef_loss   | 11.8     |\n",
            "|    learning_rate   | 7.43e-06 |\n",
            "|    n_updates       | 6249798  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2580000, episode_reward=-120192.77 +/- 61740.70\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 5e+03    |\n",
            "|    mean_reward     | -1.2e+05 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 2580000  |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 3.77e+03 |\n",
            "|    critic_loss     | 189      |\n",
            "|    ent_coef        | 0.193    |\n",
            "|    ent_coef_loss   | 7.41     |\n",
            "|    learning_rate   | 7.42e-06 |\n",
            "|    n_updates       | 6259798  |\n",
            "---------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.85e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 516       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 168947    |\n",
            "|    total_timesteps | 2580000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2590000, episode_reward=-210969.89 +/- 135321.79\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2590000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.46e+03  |\n",
            "|    critic_loss     | 33        |\n",
            "|    ent_coef        | 0.202     |\n",
            "|    ent_coef_loss   | 0.649     |\n",
            "|    learning_rate   | 7.41e-06  |\n",
            "|    n_updates       | 6269798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2600000, episode_reward=-156065.18 +/- 134999.59\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2600000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.62e+03  |\n",
            "|    critic_loss     | 39        |\n",
            "|    ent_coef        | 0.218     |\n",
            "|    ent_coef_loss   | 1.9       |\n",
            "|    learning_rate   | 7.4e-06   |\n",
            "|    n_updates       | 6279798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.85e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 520       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 170180    |\n",
            "|    total_timesteps | 2600000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2610000, episode_reward=-156187.76 +/- 134901.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2610000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.83e+03  |\n",
            "|    critic_loss     | 219       |\n",
            "|    ent_coef        | 0.235     |\n",
            "|    ent_coef_loss   | 1.2       |\n",
            "|    learning_rate   | 7.39e-06  |\n",
            "|    n_updates       | 6289798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2620000, episode_reward=-321459.24 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.21e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2620000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.46e+03  |\n",
            "|    critic_loss     | 61.3      |\n",
            "|    ent_coef        | 0.252     |\n",
            "|    ent_coef_loss   | 1.11      |\n",
            "|    learning_rate   | 7.38e-06  |\n",
            "|    n_updates       | 6299798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 524      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 171411   |\n",
            "|    total_timesteps | 2620000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2630000, episode_reward=-101127.72 +/- 110165.05\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.01e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2630000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.79e+03  |\n",
            "|    critic_loss     | 151       |\n",
            "|    ent_coef        | 0.272     |\n",
            "|    ent_coef_loss   | 1.5       |\n",
            "|    learning_rate   | 7.37e-06  |\n",
            "|    n_updates       | 6309798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2640000, episode_reward=-266449.50 +/- 110231.46\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2640000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.85e+03  |\n",
            "|    critic_loss     | 36.9      |\n",
            "|    ent_coef        | 0.275     |\n",
            "|    ent_coef_loss   | 0.146     |\n",
            "|    learning_rate   | 7.36e-06  |\n",
            "|    n_updates       | 6319798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 528      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 172637   |\n",
            "|    total_timesteps | 2640000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2650000, episode_reward=-211366.64 +/- 134963.82\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2650000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.77e+03  |\n",
            "|    critic_loss     | 93.1      |\n",
            "|    ent_coef        | 0.275     |\n",
            "|    ent_coef_loss   | 0.469     |\n",
            "|    learning_rate   | 7.35e-06  |\n",
            "|    n_updates       | 6329798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2660000, episode_reward=-156420.78 +/- 134839.02\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2660000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.92e+03  |\n",
            "|    critic_loss     | 113       |\n",
            "|    ent_coef        | 0.266     |\n",
            "|    ent_coef_loss   | -0.154    |\n",
            "|    learning_rate   | 7.34e-06  |\n",
            "|    n_updates       | 6339798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 532       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 173871    |\n",
            "|    total_timesteps | 2660000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2670000, episode_reward=-321563.93 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -3.22e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2670000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.77e+03  |\n",
            "|    critic_loss     | 25.8      |\n",
            "|    ent_coef        | 0.256     |\n",
            "|    ent_coef_loss   | 0.0439    |\n",
            "|    learning_rate   | 7.33e-06  |\n",
            "|    n_updates       | 6349798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2680000, episode_reward=-266413.03 +/- 110301.83\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2680000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.86e+03  |\n",
            "|    critic_loss     | 11.4      |\n",
            "|    ent_coef        | 0.248     |\n",
            "|    ent_coef_loss   | -0.37     |\n",
            "|    learning_rate   | 7.32e-06  |\n",
            "|    n_updates       | 6359798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 536      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 175102   |\n",
            "|    total_timesteps | 2680000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2690000, episode_reward=-100826.43 +/- 110369.68\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.01e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2690000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.71e+03  |\n",
            "|    critic_loss     | 63.8      |\n",
            "|    ent_coef        | 0.231     |\n",
            "|    ent_coef_loss   | -1.01     |\n",
            "|    learning_rate   | 7.31e-06  |\n",
            "|    n_updates       | 6369798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2700000, episode_reward=-211160.28 +/- 135215.67\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2700000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.07e+03  |\n",
            "|    critic_loss     | 3.48e+04  |\n",
            "|    ent_coef        | 0.216     |\n",
            "|    ent_coef_loss   | -0.122    |\n",
            "|    learning_rate   | 7.3e-06   |\n",
            "|    n_updates       | 6379798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.77e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 540       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 176341    |\n",
            "|    total_timesteps | 2700000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2710000, episode_reward=-155756.36 +/- 135379.72\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2710000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.65e+03  |\n",
            "|    critic_loss     | 30.4      |\n",
            "|    ent_coef        | 0.205     |\n",
            "|    ent_coef_loss   | -0.153    |\n",
            "|    learning_rate   | 7.29e-06  |\n",
            "|    n_updates       | 6389798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2720000, episode_reward=-44113.40 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.41e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2720000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.37e+03  |\n",
            "|    critic_loss     | 1.68e+03  |\n",
            "|    ent_coef        | 0.2       |\n",
            "|    ent_coef_loss   | -0.164    |\n",
            "|    learning_rate   | 7.28e-06  |\n",
            "|    n_updates       | 6399798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 544       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 177588    |\n",
            "|    total_timesteps | 2720000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2730000, episode_reward=-210594.93 +/- 135907.80\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2730000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.67e+03  |\n",
            "|    critic_loss     | 28.4      |\n",
            "|    ent_coef        | 0.187     |\n",
            "|    ent_coef_loss   | -0.175    |\n",
            "|    learning_rate   | 7.27e-06  |\n",
            "|    n_updates       | 6409798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2740000, episode_reward=-210642.59 +/- 135851.54\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2740000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 4.04e+03  |\n",
            "|    critic_loss     | 49.3      |\n",
            "|    ent_coef        | 0.178     |\n",
            "|    ent_coef_loss   | -0.569    |\n",
            "|    learning_rate   | 7.26e-06  |\n",
            "|    n_updates       | 6419798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 548      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 178831   |\n",
            "|    total_timesteps | 2740000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2750000, episode_reward=-266172.59 +/- 110777.09\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2750000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.41e+03  |\n",
            "|    critic_loss     | 21.9      |\n",
            "|    ent_coef        | 0.169     |\n",
            "|    ent_coef_loss   | -0.252    |\n",
            "|    learning_rate   | 7.25e-06  |\n",
            "|    n_updates       | 6429798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2760000, episode_reward=-155170.18 +/- 135811.83\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.55e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2760000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.7e+03   |\n",
            "|    critic_loss     | 41.2      |\n",
            "|    ent_coef        | 0.18      |\n",
            "|    ent_coef_loss   | 0.495     |\n",
            "|    learning_rate   | 7.24e-06  |\n",
            "|    n_updates       | 6439798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 552      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 180062   |\n",
            "|    total_timesteps | 2760000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2770000, episode_reward=-211295.62 +/- 135043.02\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2770000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.76e+03  |\n",
            "|    critic_loss     | 26.8      |\n",
            "|    ent_coef        | 0.193     |\n",
            "|    ent_coef_loss   | 0.829     |\n",
            "|    learning_rate   | 7.23e-06  |\n",
            "|    n_updates       | 6449798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2780000, episode_reward=-212282.17 +/- 133899.52\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.12e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2780000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.64e+03  |\n",
            "|    critic_loss     | 78.4      |\n",
            "|    ent_coef        | 0.209     |\n",
            "|    ent_coef_loss   | 3.08      |\n",
            "|    learning_rate   | 7.22e-06  |\n",
            "|    n_updates       | 6459798   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 5e+03     |\n",
            "|    ep_rew_mean     | -1.83e+05 |\n",
            "| time/              |           |\n",
            "|    episodes        | 556       |\n",
            "|    fps             | 15        |\n",
            "|    time_elapsed    | 181286    |\n",
            "|    total_timesteps | 2780000   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2790000, episode_reward=-155785.70 +/- 135399.12\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2790000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.41e+03  |\n",
            "|    critic_loss     | 71.6      |\n",
            "|    ent_coef        | 0.223     |\n",
            "|    ent_coef_loss   | 1.26      |\n",
            "|    learning_rate   | 7.21e-06  |\n",
            "|    n_updates       | 6469798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2800000, episode_reward=-155726.87 +/- 135404.88\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -1.56e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2800000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.56e+03  |\n",
            "|    critic_loss     | 36        |\n",
            "|    ent_coef        | 0.222     |\n",
            "|    ent_coef_loss   | -0.179    |\n",
            "|    learning_rate   | 7.2e-06   |\n",
            "|    n_updates       | 6479798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 182504   |\n",
            "|    total_timesteps | 2800000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2810000, episode_reward=-266296.66 +/- 110328.34\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.66e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2810000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.51e+03  |\n",
            "|    critic_loss     | 24.6      |\n",
            "|    ent_coef        | 0.208     |\n",
            "|    ent_coef_loss   | -0.738    |\n",
            "|    learning_rate   | 7.19e-06  |\n",
            "|    n_updates       | 6489798   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=2820000, episode_reward=-46101.65 +/- 0.00\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -4.61e+04 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2820000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.8e+03   |\n",
            "|    critic_loss     | 26.2      |\n",
            "|    ent_coef        | 0.195     |\n",
            "|    ent_coef_loss   | -0.324    |\n",
            "|    learning_rate   | 7.18e-06  |\n",
            "|    n_updates       | 6499798   |\n",
            "----------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5e+03    |\n",
            "|    ep_rew_mean     | -1.8e+05 |\n",
            "| time/              |          |\n",
            "|    episodes        | 564      |\n",
            "|    fps             | 15       |\n",
            "|    time_elapsed    | 183726   |\n",
            "|    total_timesteps | 2820000  |\n",
            "---------------------------------\n",
            "Eval num_timesteps=2830000, episode_reward=-211339.12 +/- 134870.15\n",
            "Episode length: 5000.00 +/- 0.00\n",
            "----------------------------------\n",
            "| eval/              |           |\n",
            "|    mean_ep_length  | 5e+03     |\n",
            "|    mean_reward     | -2.11e+05 |\n",
            "| time/              |           |\n",
            "|    total_timesteps | 2830000   |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 3.25e+03  |\n",
            "|    critic_loss     | 10        |\n",
            "|    ent_coef        | 0.186     |\n",
            "|    ent_coef_loss   | 0.0344    |\n",
            "|    learning_rate   | 7.17e-06  |\n",
            "|    n_updates       | 6509798   |\n",
            "----------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mWandbCallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgradient_save_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/2gdl8x8framestack.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_save_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    309\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 312\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:541\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mreset_noise(env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# Select action randomly or according to policy\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m    544\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:373\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._sample_action\u001b[1;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[0;32m    368\u001b[0m     unscaled_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_envs)])\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;66;03m# Note: when using continuous actions,\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m     unscaled_action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\base_class.py:555\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    537\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    540\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    541\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\policies.py:349\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    346\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 349\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m    351\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\sac\\policies.py:353\u001b[0m, in \u001b[0;36mSACPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: th\u001b[38;5;241m.\u001b[39mTensor, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\sac\\policies.py:170\u001b[0m, in \u001b[0;36mActor.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    168\u001b[0m mean_actions, log_std, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action_dist_params(obs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# Note: the action is squashed\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mactions_from_params(mean_actions, log_std, deterministic\u001b[38;5;241m=\u001b[39mdeterministic, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\distributions.py:190\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.actions_from_params\u001b[1;34m(self, mean_actions, log_std, deterministic)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactions_from_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean_actions: th\u001b[38;5;241m.\u001b[39mTensor, log_std: th\u001b[38;5;241m.\u001b[39mTensor, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# Update the proba distribution\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\distributions.py:224\u001b[0m, in \u001b[0;36mSquashedDiagGaussianDistribution.proba_distribution\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproba_distribution\u001b[39m(\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSquashedDiagGaussianDistribution, mean_actions: th\u001b[38;5;241m.\u001b[39mTensor, log_std: th\u001b[38;5;241m.\u001b[39mTensor\n\u001b[0;32m    223\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSquashedDiagGaussianDistribution:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\stable_baselines3\\common\\distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\distributions\\normal.py:56\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[1;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\distributions\\distribution.py:67\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     65\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[0;32m     66\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the agent\n",
        "model.learn(total_timesteps=10000000,\n",
        "    callback=[\n",
        "        checkpoint_callback,\n",
        "        eval_callback,\n",
        "        WandbCallback(\n",
        "            gradient_save_freq=10000,\n",
        "            model_save_path=f\"models/2gdl8x8framestack.2\",\n",
        "            model_save_freq=10000,\n",
        "            verbose=2,\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHXGbAZET2JT",
        "outputId": "b97fc6c4-ec5b-4df7-d0d1-33c8be525e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:1 Score:-57087.66697450366\n",
            "Episode:2 Score:-57169.60609087738\n",
            "Episode:3 Score:-57424.86711319699\n"
          ]
        }
      ],
      "source": [
        "episodes = 3\n",
        "state, seed = env.reset()\n",
        "for episode in range(1, episodes+1):\n",
        "    state, seed = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "b = Bobina()\n",
        "b.airgap = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20.00214, -0.10582279, 3.7021403, 45.0), False)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.step(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agkJzsGwT_Uc",
        "outputId": "53ab7a6a-04fc-4968-e6b5-f07eb32b5f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "[-4.8 -4.8 -4.8 -4.8  0.   0. ]\n",
            "Time predict 10.24867582321167\n",
            "Time model 72.01218795776367\n",
            "Episode reward -4038.0602211076766\n",
            "[(0.0, 0.0), (-3.2358797, -3.1195915), (-6.339973, -6.1121325), (-9.161808, -8.83256), (-11.694877, -11.274597), (-13.973344, -13.487273), (-16.070297, -15.535294), (-18.029266, -17.42969), (-19.833715, -19.166698), (-21.45158, -20.749697), (-22.81872, -22.167974), (-23.83326, -23.425379), (-24.396168, -24.52945), (-24.502956, -25.492422), (-24.270916, -26.347738), (-23.862999, -27.135586), (-23.410172, -27.88375), (-22.985645, -28.60928), (-22.617811, -29.320166), (-22.313604, -30.018927), (-22.069878, -30.70553), (-21.880281, -31.379324), (-21.739292, -32.040188), (-21.64239, -32.6878), (-21.607645, -33.305454), (-21.695353, -33.83614), (-21.927092, -34.23237), (-22.26238, -34.4832), (-22.664297, -34.584454), (-23.108282, -34.540073), (-23.577696, -34.36163), (-24.060762, -34.06593), (-24.550459, -33.67239), (-25.039404, -33.20045), (-25.519955, -32.66795), (-25.98641, -32.090923), (-26.433647, -31.483515), (-26.857037, -30.857592), (-27.251331, -30.223293), (-27.61162, -29.589382), (-27.93347, -28.963356), (-28.213432, -28.351635), (-28.448849, -27.759876), (-28.637236, -27.19335), (-28.776527, -26.656082), (-28.865496, -26.151598), (-28.904493, -25.683498), (-28.895521, -25.254625), (-28.842148, -24.86604), (-28.74867, -24.517763), (-28.619648, -24.209873), (-28.459564, -23.941216), (-28.272451, -23.71079), (-28.062212, -23.517887), (-27.83214, -23.360601), (-27.584614, -23.236301), (-27.32158, -23.142797), (-27.044844, -23.078398), (-26.756714, -23.041056), (-26.459152, -23.028704), (-26.153696, -23.039358), (-25.842896, -23.071157), (-25.529268, -23.122292), (-25.215042, -23.190958), (-24.901848, -23.275345), (-24.59132, -23.37361), (-24.285616, -23.484001), (-23.98565, -23.604816), (-23.692825, -23.73399), (-23.409515, -23.870012), (-23.136625, -24.011877), (-22.876072, -24.158243), (-22.629837, -24.307724), (-22.39897, -24.458826), (-22.184317, -24.610023), (-21.985788, -24.75953), (-21.80353, -24.906137), (-21.637585, -25.049215), (-21.487858, -25.187778), (-21.353846, -25.320997), (-21.23522, -25.448273), (-21.13177, -25.56906), (-21.04262, -25.682789), (-20.966637, -25.789156), (-20.9028, -25.888083), (-20.8502, -25.979448), (-20.808043, -26.063236), (-20.775509, -26.139433), (-20.751715, -26.20811), (-20.735836, -26.269382), (-20.727093, -26.323391), (-20.724798, -26.370337), (-20.728329, -26.410408), (-20.736992, -26.4438), (-20.750172, -26.470726), (-20.76735, -26.491434), (-20.787863, -26.506203), (-20.811176, -26.515303), (-20.836786, -26.51903), (-20.864176, -26.517742), (-20.892895, -26.511776), (-20.922468, -26.501446), (-20.952606, -26.487083), (-20.98283, -26.468992), (-21.012758, -26.447515), (-21.042177, -26.422995), (-21.070822, -26.39577), (-21.098486, -26.366156), (-21.124874, -26.334408), (-21.149828, -26.300817), (-21.17321, -26.265633), (-21.195023, -26.229074), (-21.21514, -26.191341), (-21.233389, -26.1526), (-21.249756, -26.11302), (-21.264174, -26.072765), (-21.276628, -26.031986), (-21.28715, -25.990866), (-21.295877, -25.949507), (-21.302717, -25.90799), (-21.307615, -25.86643), (-21.310638, -25.824942), (-21.311804, -25.783613), (-21.311172, -25.742514), (-21.308847, -25.701723), (-21.304861, -25.661297), (-21.29921, -25.62125), (-21.292046, -25.581642), (-21.283459, -25.542513), (-21.273438, -25.503883), (-21.262087, -25.465782), (-21.249441, -25.428164), (-21.235498, -25.391039), (-21.220394, -25.354483), (-21.204308, -25.318497), (-21.187302, -25.283047), (-21.169336, -25.24812), (-21.150402, -25.213709), (-21.130651, -25.17979), (-21.110226, -25.146353), (-21.08913, -25.113361), (-21.067411, -25.080805), (-21.04509, -25.048635), (-21.02229, -25.01684), (-20.99899, -24.98538), (-20.975231, -24.954182), (-20.951157, -24.923267), (-20.92672, -24.892607), (-20.902039, -24.862152), (-20.877125, -24.831884), (-20.8519, -24.801762), (-20.826515, -24.771746), (-20.800999, -24.74181), (-20.775326, -24.711939), (-20.749573, -24.682076), (-20.723734, -24.65221), (-20.697756, -24.62232), (-20.671618, -24.592403), (-20.645336, -24.562483), (-20.618977, -24.532532), (-20.592579, -24.502548), (-20.566038, -24.472523), (-20.539333, -24.442398), (-20.512606, -24.412163), (-20.485802, -24.381872), (-20.458714, -24.35153), (-20.43145, -24.321129), (-20.40422, -24.290682), (-20.377054, -24.26016), (-20.349869, -24.229485), (-20.322536, -24.198643), (-20.295216, -24.167643), (-20.267923, -24.13646), (-20.240564, -24.105066), (-20.213148, -24.073442), (-20.185663, -24.041574), (-20.15811, -24.009457), (-20.1305, -23.977089), (-20.102844, -23.944464), (-20.07513, -23.911566), (-20.047398, -23.878386), (-20.019611, -23.844902), (-19.991716, -23.811102), (-19.96369, -23.776978), (-19.935633, -23.74253), (-19.907486, -23.707767), (-19.8792, -23.67268), (-19.850847, -23.637249), (-19.822401, -23.601469), (-19.793797, -23.565334), (-19.765083, -23.528862), (-19.73628, -23.492027), (-19.70727, -23.454689), (-19.678095, -23.41691), (-19.648848, -23.378826), (-19.619469, -23.340422), (-19.589888, -23.30167), (-19.559837, -23.262527), (-19.529007, -23.22296), (-19.497194, -23.182983), (-19.46408, -23.142624), (-19.429678, -23.101965), (-19.394264, -23.061127), (-19.357824, -23.020142), (-19.320341, -22.979006), (-19.281849, -22.93763), (-19.242365, -22.896025), (-19.201996, -22.854338), (-19.16065, -22.812578), (-19.1184, -22.770712), (-19.075401, -22.728706), (-19.031557, -22.686556), (-18.986937, -22.644262), (-18.94158, -22.601753), (-18.895472, -22.559004), (-18.848648, -22.515991), (-18.801226, -22.47269), (-18.753231, -22.429073), (-18.704597, -22.385073), (-18.655409, -22.340694), (-18.605694, -22.295935), (-18.555517, -22.250778), (-18.504885, -22.205173), (-18.453747, -22.159088), (-18.401848, -22.112526), (-18.34915, -22.065506), (-18.296051, -22.018085), (-18.242542, -21.970278), (-18.188576, -21.922045), (-18.134195, -21.87338), (-18.079424, -21.824284), (-18.02481, -21.774813), (-17.971273, -21.72506), (-17.919401, -21.674995), (-17.869284, -21.624231), (-17.821032, -21.57259), (-17.774628, -21.520168), (-17.729767, -21.466848), (-17.686401, -21.412436), (-17.64432, -21.35683), (-17.60328, -21.300106), (-17.563253, -21.242292), (-17.52418, -21.183409), (-17.486032, -21.123505), (-17.448784, -21.062613), (-17.412472, -21.000772), (-17.377163, -20.938025), (-17.342844, -20.874306), (-17.309294, -20.809628), (-17.276386, -20.744097), (-17.243982, -20.67776), (-17.21191, -20.610643), (-17.180021, -20.542793), (-17.148174, -20.474277), (-17.116344, -20.404854), (-17.0845, -20.334654), (-17.05255, -20.264135), (-17.02042, -20.19335), (-16.988073, -20.12234), (-16.955341, -20.05113), (-16.92223, -19.979752), (-16.888735, -19.908237), (-16.854832, -19.836613), (-16.820688, -19.764935), (-16.786337, -19.69326), (-16.751842, -19.621584), (-16.717308, -19.54989), (-16.682844, -19.478113), (-16.648342, -19.405779), (-16.61402, -19.332708), (-16.580498, -19.259096), (-16.548004, -19.184767), (-16.516495, -19.109468), (-16.485971, -19.03299), (-16.456121, -18.955126), (-16.426744, -18.875734), (-16.39796, -18.794798), (-16.369684, -18.712307), (-16.341866, -18.628242), (-16.314375, -18.542599), (-16.287096, -18.455404), (-16.259918, -18.366243), (-16.232723, -18.275177), (-16.205517, -18.182783), (-16.178268, -18.089157), (-16.150753, -17.994385), (-16.122612, -17.898691), (-16.093468, -17.802525), (-16.062967, -17.706413), (-16.030825, -17.610775), (-15.997, -17.515966), (-15.961445, -17.42228), (-15.9241295, -17.329617), (-15.885086, -17.238314), (-15.844344, -17.14909), (-15.801953, -17.06223), (-15.757846, -16.977896), (-15.711998, -16.89625), (-15.664431, -16.817495), (-15.615251, -16.741812), (-15.564644, -16.66928), (-15.512737, -16.59988), (-15.459763, -16.533585), (-15.405787, -16.470306), (-15.351136, -16.409632), (-15.2964115, -16.351429), (-15.241901, -16.295761), (-15.187819, -16.242287), (-15.134382, -16.190695), (-15.081578, -16.1406), (-15.029288, -16.091877), (-14.977641, -16.044634), (-14.926713, -15.998786), (-14.876432, -15.954195), (-14.826806, -15.91073), (-14.777948, -15.868341), (-14.72986, -15.826948), (-14.682538, -15.786432), (-14.636062, -15.746689), (-14.590431, -15.707615), (-14.545649, -15.669123), (-14.5017185, -15.631129), (-14.458672, -15.593552), (-14.416258, -15.556308), (-14.374498, -15.519345), (-14.333732, -15.482644), (-14.29394, -15.445975), (-14.255068, -15.409269), (-14.217046, -15.372645), (-14.179823, -15.336069), (-14.143337, -15.299484), (-14.107477, -15.262832), (-14.072191, -15.226073), (-14.037477, -15.189199), (-14.003335, -15.152223), (-13.969734, -15.115122), (-13.936657, -15.077874), (-13.904087, -15.040477), (-13.871982, -15.002928), (-13.840288, -14.965211), (-13.808966, -14.927297), (-13.777992, -14.889205), (-13.747343, -14.850975), (-13.716976, -14.812594), (-13.686911, -14.774069), (-13.6571455, -14.735413), (-13.62761, -14.696614), (-13.59828, -14.657687), (-13.569117, -14.618643), (-13.540139, -14.57949), (-13.511298, -14.540244), (-13.482573, -14.500908), (-13.453895, -14.461501), (-13.425268, -14.42182), (-13.396839, -14.381913), (-13.368657, -14.342075), (-13.340671, -14.302312), (-13.312709, -14.262569), (-13.284821, -14.222837), (-13.25701, -14.183125), (-13.229211, -14.143411), (-13.2014065, -14.1037035), (-13.173404, -14.063989), (-13.144692, -14.024198), (-13.114596, -13.984297), (-13.082682, -13.944339), (-13.048771, -13.904475), (-13.01293, -13.864915), (-12.975269, -13.825799), (-12.935829, -13.787219), (-12.894681, -13.749241), (-12.851932, -13.711889), (-12.807697, -13.67517), (-12.762109, -13.639065), (-12.715248, -13.603539), (-12.667292, -13.568507), (-12.618322, -13.533911), (-12.568383, -13.49975), (-12.517478, -13.465773), (-12.464904, -13.431814), (-12.408942, -13.39785), (-12.348161, -13.3638115), (-12.282056, -13.329871), (-12.21024, -13.296344), (-12.132418, -13.263515), (-12.04837, -13.231617), (-11.95792, -13.200765), (-11.861033, -13.170911), (-11.757734, -13.1419), (-11.64799, -13.11353), (-11.531748, -13.085617), (-11.408896, -13.057997), (-11.278502, -13.030549), (-11.140599, -13.003239), (-10.996109, -12.976083), (-10.845959, -12.949151), (-10.69406, -12.92288), (-10.546553, -12.897751), (-10.408293, -12.873421), (-10.2805605, -12.848593), (-10.163747, -12.821599), (-10.058326, -12.790954), (-9.963377, -12.755492), (-9.877796, -12.714396), (-9.800633, -12.667162), (-9.731228, -12.613462), (-9.6691885, -12.552871), (-9.614275, -12.484882), (-9.566184, -12.408614), (-9.524537, -12.323653), (-9.488982, -12.230138), (-9.458899, -12.127766), (-9.433866, -12.016206), (-9.413761, -11.895193), (-9.398117, -11.764446), (-9.3864765, -11.623673), (-9.378488, -11.47263), (-9.373753, -11.31011), (-9.371965, -11.136006), (-9.372575, -10.951707), (-9.373942, -10.758514), (-9.373586, -10.558518), (-9.36932, -10.354079), (-9.359659, -10.146276), (-9.343726, -9.937222), (-9.321051, -9.729982), (-9.291322, -9.525924), (-9.254314, -9.325869), (-9.209985, -9.129185), (-9.158551, -8.936596), (-9.100325, -8.750141), (-9.035502, -8.570203), (-8.964123, -8.396978), (-8.886078, -8.230066), (-8.801297, -8.070246), (-8.709927, -7.9191837), (-8.61249, -7.7772737), (-8.510071, -7.644569), (-8.404324, -7.5209713), (-8.29636, -7.406155), (-8.187612, -7.2989917), (-8.079821, -7.198902), (-7.9736023, -7.1057906), (-7.8691072, -7.01873), (-7.766431, -6.936763), (-7.6657214, -6.859119), (-7.5671806, -6.7851863), (-7.47098, -6.7144523), (-7.376722, -6.646458), (-7.284657, -6.580841), (-7.19558, -6.5173044), (-7.109457, -6.455487), (-7.026021, -6.3946404), (-6.9450727, -6.334521), (-6.86649, -6.2753835), (-6.79013, -6.2170763), (-6.71586, -6.1593885), (-6.6435575, -6.102156), (-6.573084, -6.045242), (-6.504396, -5.988546), (-6.437448, -5.931983), (-6.3717346, -5.875458), (-6.3072896, -5.818941), (-6.244615, -5.7624297), (-6.1835837, -5.7058415), (-6.1239786, -5.649058), (-6.0656133, -5.59199), (-6.0083313, -5.534599), (-5.952048, -5.4768786), (-5.8965883, -5.4184556), (-5.8414507, -5.3599496), (-5.7858214, -5.302958), (-5.728931, -5.248537), (-5.670275, -5.197462), (-5.609711, -5.150301), (-5.5474086, -5.1074643), (-5.4761763, -5.0495934), (-5.3785386, -4.927812), (-5.265797, -4.746854), (-5.17822, -4.5713906), (-5.1321373, -4.42819), (-5.11216, -4.2940574), (-5.0982614, -4.1432104), (-5.084419, -3.9762995), (-5.0263524, -3.9243543), (-4.8655186, -4.1018534), (-4.630707, -4.3348284), (-4.3943524, -4.4206276), (-4.1899753, -4.4287043), (-4.0158257, -4.514014), (-3.8643637, -4.6490245), (-3.7318256, -4.7081413), (-3.6146758, -4.687951), (-3.541416, -4.588473), (-3.5420141, -4.3757997), (-3.5312939, -4.312987), (-3.5159614, -4.279964), (-3.6030476, -3.8420658), (-3.539783, -3.901408), (-3.3842137, -4.284463), (-3.660822, -3.264678), (-3.6632743, -3.068991), (-3.0219452, -4.81279), (-2.9286284, -4.505625), (-3.5246782, -2.0637553), (-3.495054, -2.0907362), (-2.7323651, -4.5393205), (-2.700457, -4.470161), (-3.4375844, -1.8661673), (-3.4024112, -1.7821451), (-2.5657806, -4.256456), (-2.5713701, -4.1543403), (-2.8869407, -1.452404), (-1.3144269, -1.3934419), (1.6425809, -4.045321), (4.334987, -4.311642), (6.3231254, -2.7370453), (7.944634, -3.550902), (8.290033, -6.0359764), (6.1959434, -6.289314), (3.4764776, -4.0859137), (2.8255596, -1.6738204), (4.318641, -1.3785796), (5.2933474, -3.3101518), (4.2522535, -3.856643), (2.4819925, -2.091584), (1.8005053, -0.16853362), (2.187422, -0.19137119), (2.3985085, -1.4499747), (1.8869504, -1.13153), (1.093342, 0.6295445), (0.7290943, 1.2028618), (0.5605924, 0.21487384), (0.2900549, 0.17219087), (0.0014952874, 1.6305114), (-0.4687378, 2.0894096), (-0.9053312, 1.1389298), (-0.947866, 1.2203964), (-1.2427915, 2.472399), (-2.4246504, 2.7948737), (-3.3465083, 2.724774), (-2.9969845, 3.7419906), (-2.6445563, 4.802052), (-3.6580338, 4.3025208), (-4.735561, 3.6741073), (-4.404283, 4.4968224), (-3.9537559, 5.1441884), (-4.5837293, 4.600397), (-5.293948, 3.8577552), (-4.899888, 4.0196037), (-4.042176, 4.596786), (-4.077728, 4.26125), (-4.563997, 3.4712012), (-4.1554084, 3.5548737), (-3.1821053, 4.1082563), (-2.9841604, 3.8062375), (-3.3186457, 2.9822893), (-2.877679, 2.9670339), (-1.8764547, 3.4964902), (-1.6312907, 3.2591262), (-1.9853898, 2.4532294), (-1.6295222, 2.367721), (-0.68744713, 2.8690686), (-0.48588508, 2.7008584), (-0.96334743, 1.9424076), (-0.7746852, 1.8216376), (0.058315214, 2.3057818), (0.1656075, 2.1978672), (-0.47244865, 1.489678), (-0.4692747, 1.3457919), (0.23920693, 1.8135225), (0.09645108, 1.0789357), (-0.59357226, -0.2697855), (-0.107850276, 0.4283556), (0.5523513, 1.2200248), (-0.3109213, -0.45640728), (-1.2084571, -1.9329768), (-0.7518668, -0.9664744), (-0.38067645, -0.30171934), (-1.0438166, -1.8816177), (-1.9123203, -3.368239), (-2.001067, -2.6513574), (-1.7189229, -1.6377552), (-2.012017, -2.741975), (-2.6865232, -4.560416), (-2.8532178, -4.318821), (-2.5696998, -2.8867767), (-2.6851263, -3.2243469), (-3.127251, -4.7181334), (-3.1562903, -4.624029), (-2.7894173, -3.205288), (-2.8162637, -3.2601461), (-3.2182052, -4.6866875), (-3.220605, -4.7571106), (-2.807788, -3.4310167), (-2.774663, -3.3849678), (-3.1444495, -4.717926), (-3.128539, -4.8190317), (-2.8256662, -3.4224517), (-2.798045, -3.281418), (-2.9176757, -4.705893), (-2.9378526, -4.80861), (-3.0001445, -3.2319415), (-2.8940175, -3.0513227), (-2.5132082, -4.6432743), (-2.483247, -4.934345), (-3.1136408, -3.2731874), (-3.216404, -2.8318803), (-2.322171, -4.3700213), (-1.8413937, -5.0885153), (-2.7292805, -3.7366018), (-3.3801303, -2.7911916), (-2.548768, -3.8417754), (-1.788402, -4.7767196), (-2.365348, -3.937384), (-3.1096344, -2.941417), (-2.7427752, -3.5570488), (-2.124313, -4.337634), (-2.1609337, -3.9182196), (-2.6578124, -3.1820304), (-2.8958595, -3.3422139), (-2.6826952, -3.727976), (-2.4211602, -3.4355075), (-2.553045, -3.0574036), (-2.910652, -3.2538393), (-2.9583395, -3.3461654), (-2.6892672, -2.8837104), (-2.646351, -2.7260978), (-2.9304216, -3.1578364), (-3.0161872, -3.1062503), (-2.7773578, -2.4200695), (-2.7263756, -2.3889182), (-2.9654346, -3.0466802), (-2.9742594, -2.8967164), (-2.7066584, -2.0238876), (-2.7135725, -2.1124246), (-2.97242, -2.955196), (-2.8831723, -2.695508), (-2.544492, -1.6687608), (-2.6187239, -1.8838412), (-2.9374447, -2.8863995), (-2.768988, -2.523574), (-2.347096, -1.3563842), (-2.4815586, -1.6881691), (-2.8798103, -2.8436468), (-2.6536012, -2.3879929), (-2.147167, -1.0697103), (-2.3295317, -1.4675528), (-2.8196316, -2.8031387), (-2.5641325, -2.3354578), (-1.9675477, -0.832063), (-2.1738448, -1.2049797), (-2.7734225, -2.7353237), (-2.5259738, -2.3384328), (-1.8278385, -0.6501565), (-2.0162656, -0.92837435), (-2.731258, -2.641645), (-2.5371702, -2.3685796), (-1.7423718, -0.5259317), (-1.876147, -0.68136877), (-2.6880546, -2.5277662), (-2.5692508, -2.3813896), (-1.7038163, -0.44962367), (-1.7640251, -0.5192881), (-2.6312714, -2.4391737), (-2.5903754, -2.351919), (-1.699949, -0.37301078), (-1.6992391, -0.39917675), (-2.5782835, -2.3781013), (-2.5862656, -2.3582866), (-1.6928846, -0.34544823), (-1.6551309, -0.31493658), (-2.5356426, -2.3067894), (-2.5768037, -2.3413572), (-1.6873486, -0.34354904), (-1.6204079, -0.2852731), (-2.4907498, -2.2680376), (-2.5492542, -2.3316467), (-1.6719595, -0.35642502), (-1.5975455, -0.28903246), (-2.4566212, -2.2597563), (-2.4860623, -2.2593453), (-1.5659401, -0.17986222), (-1.5537207, -0.20312631), (-2.5163393, -2.370887), (-2.5203538, -2.3311472), (-1.5276643, -0.08376594), (-1.4946158, -0.102829225), (-2.482157, -2.3943777), (-2.5152304, -2.4042592), (-1.5300357, -0.11301948), (-1.4874511, -0.10841716), (-2.4548275, -2.4186602), (-2.490453, -2.4459639), (-1.5227746, -0.16092466), (-1.4858027, -0.15887547), (-2.4506757, -2.4733522), (-2.4928656, -2.5146856), (-1.5406609, -0.26300696), (-1.5086651, -0.28071845), (-2.4581482, -2.5833728), (-2.5012038, -2.6364245), (-1.5852323, -0.40806544), (-1.5659186, -0.41263407), (-2.485561, -2.6803722), (-2.5080984, -2.7322512), (-1.6032085, -0.5418074), (-1.5963418, -0.5220899), (-2.5086303, -2.7076979), (-2.5202608, -2.7738369), (-1.6123781, -0.6827055), (-1.6111017, -0.68455136), (-2.5344121, -2.8080013), (-2.576348, -2.8926258), (-1.6828704, -0.879963), (-1.6427356, -0.8407386), (-2.5286415, -2.8560078), (-2.606008, -2.9842238), (-1.7641001, -1.0900685), (-1.6771377, -0.98524207), (-2.4916897, -2.8551755), (-2.5779, -2.9797084), (-1.787498, -1.1677326), (-1.7051061, -1.0762317), (-2.4820073, -2.8934283), (-2.5577297, -2.9951687), (-1.7913681, -1.2077205), (-1.7245793, -1.1334593), (-2.4891343, -2.9331636), (-2.5509214, -3.0131528), (-1.7914808, -1.2287211), (-1.740874, -1.1688802), (-2.5064478, -2.9649878), (-2.5616376, -3.0268095), (-1.8016019, -1.23485), (-1.754736, -1.1837945), (-2.522045, -2.9846628), (-2.5744667, -3.0375085), (-1.8143443, -1.236933), (-1.7720888, -1.1877587), (-2.5414915, -2.991611), (-2.5906272, -3.0399444), (-1.8284007, -1.233893), (-1.7886274, -1.185184), (-2.5601876, -2.9907835), (-2.6069674, -3.0360916), (-1.8414775, -1.225826), (-1.8019689, -1.1771984), (-2.5752099, -2.9846227), (-2.6204917, -3.0282156), (-1.8514147, -1.2143196), (-1.8107431, -1.1651629), (-2.5852113, -2.974463), (-2.6297228, -3.01756), (-1.8572036, -1.2006493), (-1.8146169, -1.1503662), (-2.5901175, -2.9613311), (-2.6345744, -3.0048003), (-1.8590047, -1.1854548), (-1.8141975, -1.1336269), (-2.590746, -2.9459825), (-2.6358333, -2.9903784), (-1.857693, -1.1688603), (-1.8106357, -1.1151545), (-2.5883594, -2.9289339), (-2.6346314, -2.9747682), (-1.8543627, -1.1515474), (-1.805127, -1.095756), (-2.584241, -2.910541), (-2.6322072, -2.958023), (-1.8501143, -1.1334832), (-1.7987107, -1.0756077), (-2.5793445, -2.89131), (-2.629355, -2.94065), (-1.8456464, -1.1150372), (-1.7920502, -1.0550828), (-2.5742326, -2.8716946), (-2.6264422, -2.9228587), (-1.8412707, -1.0963478), (-1.7855501, -1.0347831), (-2.5692227, -2.8524988), (-2.6235487, -2.905414), (-1.8368821, -1.0777835), (-1.7791526, -1.0148151), (-2.564329, -2.834205), (-2.6206114, -2.8890808), (-1.83242, -1.0603094), (-1.7727605, -0.995985), (-2.5593894, -2.8171449), (-2.617524, -2.8741162), (-1.8278533, -1.0444142), (-1.7663099, -0.97884494), (-2.5542526, -2.8017092), (-2.6141627, -2.860809), (-1.8231834, -1.0304277), (-1.7598425, -0.9637398), (-2.5488942, -2.7881584), (-2.610484, -2.8493545), (-1.8184557, -1.018561), (-1.7534782, -0.95088524), (-2.5434196, -2.7766395), (-2.6065688, -2.839826), (-1.8137887, -1.0088763), (-1.747396, -0.94035745), (-2.5380177, -2.7672026), (-2.6025746, -2.8322175), (-1.8093274, -1.0013435), (-1.7417697, -0.93214), (-2.5328896, -2.7598286), (-2.5986826, -2.826458), (-1.8052278, -0.9958415), (-1.7367722, -0.92612094), (-2.5282347, -2.7544324), (-2.595073, -2.822443), (-1.8016217, -0.99222004), (-1.7325177, -0.9221477), (-2.5241828, -2.75089), (-2.5918748, -2.8200438), (-1.798597, -0.9903142), (-1.7290654, -0.92003936), (-2.5208018, -2.7490413), (-2.5891519, -2.8191078), (-1.7961866, -0.98994595), (-1.726426, -0.91960377), (-2.518113, -2.7487128), (-2.5869272, -2.8194723), (-1.7943691, -0.99092615), (-1.7245463, -0.92063475), (-2.5160785, -2.7497234), (-2.5851803, -2.8209734), (-1.7931138, -0.9930695), (-1.7233733, -0.922926), (-2.514649, -2.7518735), (-2.5838687, -2.8234272), (-1.7923481, -0.9961839), (-1.7228155, -0.9262691), (-2.5137627, -2.7549715), (-2.5829544, -2.8266501), (-1.7920135, -1.0000587), (-1.7227962, -0.9304433), (-2.5133595, -2.7588181), (-2.5823958, -2.8304634), (-1.7920531, -1.0044996), (-1.7232305, -0.93523186), (-2.513368, -2.763214), (-2.5821476, -2.834692), (-1.7924118, -1.0093201), (-1.7240567, -0.94042724), (-2.51375, -2.7679644), (-2.5821912, -2.839157), (-1.7930483, -1.014328), (-1.7252018, -0.9458312), (-2.5144439, -2.7728956), (-2.5824857, -2.8437092), (-1.7939104, -1.0193657), (-1.7266016, -0.9512704), (-2.5154018, -2.7778456), (-2.582994, -2.8482046), (-1.7949501, -1.0242851), (-1.7281973, -0.9565893), (-2.516576, -2.782677), (-2.5836923, -2.852527), (-1.796127, -1.0289611), (-1.729919, -0.9616511), (-2.517908, -2.7872705), (-2.5845401, -2.8565822), (-1.7973921, -1.0332986), (-1.731702, -0.9663485), (-2.519335, -2.7915275), (-2.585488, -2.8602898), (-1.7987031, -1.0372224), (-1.7334994, -0.97060055), (-2.52081, -2.7953742), (-2.586496, -2.863596), (-1.8000056, -1.0406822), (-1.7352451, -0.97435564), (-2.5222855, -2.798766), (-2.5875335, -2.8664613), (-1.8012706, -1.0436375), (-1.7369022, -0.97756565), (-2.523715, -2.8016613), (-2.5885603, -2.8688664), (-1.8024684, -1.0460777), (-1.7384387, -0.98021835), (-2.5250688, -2.8040493), (-2.5895503, -2.8708045), (-1.8035641, -1.0480034), (-1.7398162, -0.98231745), (-2.5263143, -2.8059335), (-2.5904865, -2.8722837), (-1.8045547, -1.0494225), (-1.7410257, -0.98386467), (-2.5274274, -2.807318), (-2.5913358, -2.8733222), (-1.8054163, -1.0503721), (-1.7420619, -0.9849025), (-2.5284073, -2.8082333), (-2.592097, -2.8739436), (-1.8061457, -1.0508769), (-1.7429059, -0.9854643), (-2.5292306, -2.8087215), (-2.5927565, -2.8741908), (-1.8067387, -1.0509821), (-1.7435694, -0.9855906), (-2.5299084, -2.8088162), (-2.5933142, -2.8741035), (-1.8071952, -1.0507356), (-1.7440494, -0.98533386), (-2.5304363, -2.8085678), (-2.5937712, -2.8737254), (-1.807524, -1.0501902), (-1.7443621, -0.98475325), (-2.530822, -2.8080256), (-2.5941248, -2.873104), (-1.8077345, -1.0493977), (-1.7445207, -0.98390615), (-2.5310657, -2.8072467), (-2.5943744, -2.872292), (-1.8078369, -1.0484155), (-1.7445414, -0.9828469), (-2.5311794, -2.806273), (-2.5945277, -2.8713307), (-1.8078415, -1.0472964), (-1.7444448, -0.9816379), (-2.5311856, -2.8051624), (-2.594595, -2.8702643), (-1.8077499, -1.0460821), (-1.7442331, -0.9803298), (-2.531093, -2.803968), (-2.5945888, -2.8691406), (-1.8075885, -1.0448176), (-1.7439387, -0.9789643), (-2.5309122, -2.802728), (-2.5945122, -2.8680012), (-1.807369, -1.0435525), (-1.7435824, -0.9775942), (-2.5306652, -2.801481), (-2.5943768, -2.8668702), (-1.8071015, -1.0423144), (-1.7431755, -0.97625417), (-2.530363, -2.800264), (-2.5941975, -2.8657832), (-1.8068032, -1.0411397), (-1.7427374, -0.9749801), (-2.5300248, -2.799105), (-2.5939834, -2.8647592), (-1.8064833, -1.0400442), (-1.7422844, -0.9737936), (-2.5296607, -2.7980304), (-2.593744, -2.8638253), (-1.806156, -1.0390555), (-1.7418364, -0.97271734), (-2.5292935, -2.7970548), (-2.5934918, -2.8629878), (-1.8058298, -1.038182), (-1.7413981, -0.971771), (-2.5289235, -2.796198), (-2.5932336, -2.8622622), (-1.8055128, -1.0374342), (-1.7409807, -0.97095835), (-2.5285602, -2.7954643), (-2.5929737, -2.8616538), (-1.8052175, -1.036817), (-1.7405996, -0.9702856), (-2.5282187, -2.7948573), (-2.5927196, -2.8611627), (-1.804935, -1.036332), (-1.7402496, -0.96975917), (-2.527908, -2.7943838), (-2.5924857, -2.8607848), (-1.8046808, -1.0359666), (-1.7399429, -0.9693652), (-2.5276322, -2.7940347), (-2.5922737, -2.8605218), (-1.804462, -1.0357223), (-1.7396795, -0.9690994), (-2.5273843, -2.7938027), (-2.5920844, -2.8603647), (-1.8042798, -1.0355933), (-1.7394627, -0.9689555), (-2.5271695, -2.793679), (-2.591915, -2.8603027), (-1.8041341, -1.0355668), (-1.739301, -0.96892035), (-2.527, -2.79365), (-2.591772, -2.8603232), (-1.804017, -1.0356303), (-1.739179, -0.9689849), (-2.526865, -2.7937102), (-2.5916524, -2.8604164), (-1.8039308, -1.035767), (-1.7391008, -0.9691321), (-2.5267699, -2.7938473), (-2.5915627, -2.8605697), (-1.8038723, -1.035963), (-1.7390574, -0.9693467), (-2.5267088, -2.7940466), (-2.5914986, -2.8607748), (-1.8038449, -1.0362083), (-1.7390509, -0.96961), (-2.526681, -2.79429), (-2.591467, -2.8610172), (-1.8038491, -1.0364891), (-1.7390736, -0.96991277), (-2.526675, -2.7945704), (-2.5914454, -2.861287), (-1.8038689, -1.0367951), (-1.7391257, -0.97024167), (-2.5266993, -2.7948701), (-2.5914476, -2.8615696), (-1.8039083, -1.0371135), (-1.7391995, -0.9705852), (-2.5267482, -2.7951822), (-2.591471, -2.861857), (-1.8039671, -1.0374324), (-1.7392896, -0.9709299), (-2.526806, -2.7954962), (-2.5915048, -2.8621433), (-1.8040409, -1.0377452), (-1.7393957, -0.9712649), (-2.5268786, -2.7957995), (-2.5915449, -2.8624175), (-1.8041114, -1.0380455), (-1.7395034, -0.97159106), (-2.5269663, -2.7960927), (-2.591599, -2.8626723), (-1.8041885, -1.0383204), (-1.7396172, -0.9718931), (-2.5270607, -2.7963667), (-2.591662, -2.8629084), (-1.804269, -1.0385671), (-1.7397286, -0.9721631), (-2.527154, -2.7966158), (-2.5917246, -2.863122), (-1.8043537, -1.0387862), (-1.7398406, -0.97239953), (-2.5272462, -2.7968307), (-2.5917892, -2.8633065), (-1.8044295, -1.0389774), (-1.7399421, -0.9726055), (-2.527338, -2.7970161), (-2.5918562, -2.8634596), (-1.8045068, -1.0391327), (-1.740041, -0.97277623), (-2.5274239, -2.7971704), (-2.591918, -2.8635852), (-1.8045771, -1.0392569), (-1.7401303, -0.9729079), (-2.527504, -2.7972872), (-2.591979, -2.8636794), (-1.8046415, -1.0393497), (-1.7402065, -0.97300965), (-2.527574, -2.7973769), (-2.5920348, -2.8637455), (-1.8046974, -1.0394112), (-1.7402712, -0.9730778), (-2.5276349, -2.797437), (-2.5920813, -2.8637848), (-1.8047435, -1.0394429), (-1.7403251, -0.97311515), (-2.5276885, -2.7974708), (-2.5921304, -2.8638031), (-1.8047893, -1.0394485), (-1.7403694, -0.97311854), (-2.527727, -2.797474), (-2.5921595, -2.8638017), (-1.8048196, -1.0394411), (-1.7404044, -0.97310555), (-2.5277593, -2.7974555), (-2.592187, -2.8637757), (-1.8048391, -1.0394084), (-1.7404206, -0.9730705), (-2.5277824, -2.797421), (-2.5922089, -2.8637357), (-1.8048505, -1.0393585), (-1.7404308, -0.9730189), (-2.5277994, -2.7973733), (-2.5922258, -2.8636835), (-1.8048593, -1.0392946), (-1.7404351, -0.9729523), (-2.5278091, -2.7973123), (-2.592236, -2.863621), (-1.8048571, -1.039222), (-1.7404261, -0.97287583), (-2.5278113, -2.7972436), (-2.5922456, -2.8635552), (-1.8048537, -1.039145), (-1.7404139, -0.9727917), (-2.5278063, -2.7971683), (-2.592242, -2.8634858), (-1.8048407, -1.039065), (-1.7403964, -0.9727052), (-2.5277941, -2.7970896), (-2.5922358, -2.863412), (-1.8048288, -1.0389853), (-1.7403756, -0.9726193), (-2.5277815, -2.79701), (-2.5922291, -2.863339), (-1.8048066, -1.0389053), (-1.7403431, -0.97253495), (-2.5277605, -2.796936), (-2.5922174, -2.8632717), (-1.8047888, -1.0388288), (-1.7403193, -0.9724517), (-2.5277395, -2.7968616), (-2.592203, -2.8632066), (-1.8047704, -1.0387596), (-1.740292, -0.97237605), (-2.5277164, -2.796791), (-2.5921855, -2.8631463), (-1.8047475, -1.0386988), (-1.7402651, -0.9723089), (-2.527695, -2.7967277), (-2.592172, -2.8630915), (-1.8047314, -1.0386416), (-1.7402397, -0.97224706), (-2.5276709, -2.7966728), (-2.5921519, -2.8630455), (-1.8047069, -1.0385956), (-1.7402107, -0.97219867), (-2.5276465, -2.7966287), (-2.5921352, -2.8630068), (-1.8046869, -1.038554), (-1.7401863, -0.97215307), (-2.5276284, -2.7965887), (-2.5921228, -2.862975), (-1.8046675, -1.0385215), (-1.7401605, -0.9721185), (-2.527607, -2.79656), (-2.5921097, -2.8629513), (-1.8046572, -1.0384958), (-1.7401435, -0.9720902), (-2.527585, -2.796535), (-2.5920897, -2.8629367), (-1.8046418, -1.0384862), (-1.7401295, -0.9720743), (-2.5275698, -2.7965171), (-2.5920784, -2.862925), (-1.8046302, -1.0384787), (-1.740111, -0.9720662), (-2.5275557, -2.7965083), (-2.5920722, -2.8629193), (-1.8046213, -1.0384767), (-1.7400992, -0.97206515), (-2.5275462, -2.7965078), (-2.592066, -2.8629203), (-1.8046187, -1.0384786), (-1.7400948, -0.9720668), (-2.5275362, -2.7965107), (-2.5920548, -2.862927), (-1.8046099, -1.0384884), (-1.7400868, -0.97207737), (-2.527527, -2.7965202), (-2.5920491, -2.8629377), (-1.804608, -1.0385015), (-1.7400854, -0.97209007), (-2.5275252, -2.796531), (-2.5920436, -2.8629491), (-1.804603, -1.0385172), (-1.7400852, -0.9721089), (-2.5275242, -2.7965496), (-2.592039, -2.8629646), (-1.8045981, -1.0385321), (-1.7400848, -0.9721277), (-2.527528, -2.7965693), (-2.5920448, -2.8629816), (-1.8046051, -1.038549), (-1.7400887, -0.97214484), (-2.527524, -2.796586), (-2.5920396, -2.8630028), (-1.804608, -1.0385741), (-1.740096, -0.9721678), (-2.5275285, -2.7966037), (-2.5920403, -2.8630183), (-1.8046091, -1.0385942), (-1.7401028, -0.9721922), (-2.5275393, -2.7966247), (-2.5920453, -2.8630335), (-1.8046103, -1.0386106), (-1.7401062, -0.9722141), (-2.5275414, -2.7966483), (-2.5920484, -2.8630533), (-1.8046199, -1.0386279), (-1.7401159, -0.97223055), (-2.5275428, -2.7966635), (-2.5920482, -2.8630712), (-1.8046242, -1.0386504), (-1.7401226, -0.97225285), (-2.5275493, -2.7966802), (-2.5920508, -2.8630838), (-1.804625, -1.0386648), (-1.7401284, -0.9722719), (-2.527558, -2.7966993), (-2.5920584, -2.8630981), (-1.8046322, -1.0386772), (-1.7401358, -0.9722856), (-2.5275652, -2.7967124), (-2.592062, -2.8631096), (-1.8046346, -1.0386893), (-1.7401443, -0.9722993), (-2.5275738, -2.7967267), (-2.5920653, -2.8631196), (-1.8046386, -1.0386974), (-1.7401495, -0.9723111), (-2.5275776, -2.7967377), (-2.592068, -2.8631282), (-1.8046432, -1.0387049), (-1.7401558, -0.9723164), (-2.5275831, -2.7967417), (-2.5920742, -2.8631322), (-1.804647, -1.0387102), (-1.7401549, -0.9723246), (-2.527583, -2.7967508), (-2.5920799, -2.8631399), (-1.8046569, -1.0387156), (-1.7401626, -0.97232676), (-2.5275874, -2.7967508), (-2.5920823, -2.863142), (-1.8046582, -1.0387204), (-1.7401636, -0.97233063), (-2.5275881, -2.796754), (-2.5920844, -2.8631442), (-1.8046619, -1.0387213), (-1.7401677, -0.97233045), (-2.5275934, -2.7967527), (-2.592087, -2.863143), (-1.8046612, -1.03872), (-1.7401696, -0.97233003), (-2.5275974, -2.7967525), (-2.5920925, -2.8631408), (-1.8046665, -1.0387158), (-1.7401687, -0.9723251), (-2.5275934, -2.7967486), (-2.5920901, -2.8631403), (-1.8046676, -1.0387163), (-1.7401725, -0.972323), (-2.527596, -2.7967448), (-2.5920935, -2.863136), (-1.8046718, -1.0387121), (-1.7401738, -0.97231764), (-2.5275922, -2.796739), (-2.5920863, -2.8631334), (-1.8046671, -1.0387119), (-1.7401762, -0.9723169), (-2.5275993, -2.7967355), (-2.5920877, -2.8631248), (-1.8046633, -1.0387028), (-1.7401757, -0.9723135), (-2.5276017, -2.7967348), (-2.5920885, -2.8631194), (-1.8046594, -1.0386933), (-1.7401712, -0.9723064), (-2.5276022, -2.7967324), (-2.5920932, -2.8631177), (-1.8046587, -1.0386873), (-1.7401643, -0.9722991), (-2.5275981, -2.7967286), (-2.592092, -2.863115), (-1.8046597, -1.0386817), (-1.7401676, -0.9722908), (-2.5275996, -2.796721), (-2.5920908, -2.8631103), (-1.8046564, -1.0386782), (-1.7401632, -0.97228754), (-2.527599, -2.7967176), (-2.592094, -2.863105), (-1.8046579, -1.0386719), (-1.740162, -0.9722804), (-2.5275955, -2.7967114), (-2.592088, -2.863102), (-1.8046539, -1.0386711), (-1.7401605, -0.9722795), (-2.5275948, -2.7967079), (-2.592091, -2.863098), (-1.8046551, -1.0386662), (-1.7401572, -0.97227454), (-2.527592, -2.7967052), (-2.5920892, -2.8630955), (-1.8046544, -1.0386629), (-1.7401533, -0.9722694), (-2.5275857, -2.7967012), (-2.59209, -2.8630958), (-1.8046602, -1.0386628), (-1.7401558, -0.97226447), (-2.5275831, -2.7966943), (-2.5920854, -2.8630936), (-1.8046566, -1.0386658), (-1.7401538, -0.9722663), (-2.5275812, -2.796692), (-2.592083, -2.863089), (-1.8046561, -1.0386627), (-1.7401552, -0.972267), (-2.5275826, -2.7966936), (-2.592083, -2.8630872), (-1.8046547, -1.0386583), (-1.7401541, -0.97226286), (-2.5275834, -2.7966912), (-2.592084, -2.8630881), (-1.8046503, -1.0386609), (-1.7401466, -0.97226447), (-2.5275793, -2.796693), (-2.5920835, -2.8630886), (-1.8046552, -1.0386587), (-1.7401538, -0.97226197), (-2.5275784, -2.7966897), (-2.592077, -2.8630867), (-1.8046516, -1.0386603), (-1.7401521, -0.97226477), (-2.527579, -2.7966921), (-2.5920782, -2.8630872), (-1.8046513, -1.0386599), (-1.7401524, -0.9722649), (-2.527579, -2.7966921), (-2.5920787, -2.8630881), (-1.8046505, -1.0386611), (-1.74015, -0.9722662), (-2.5275786, -2.7966938), (-2.59208, -2.8630893), (-1.8046511, -1.0386622), (-1.7401495, -0.9722654), (-2.5275788, -2.7966924), (-2.5920804, -2.8630886), (-1.8046519, -1.0386626), (-1.7401506, -0.9722666), (-2.5275776, -2.796694), (-2.592078, -2.8630903), (-1.8046517, -1.0386637), (-1.7401513, -0.9722685), (-2.527579, -2.7966945), (-2.5920792, -2.8630908), (-1.8046502, -1.0386652), (-1.7401518, -0.97227067), (-2.5275817, -2.7966974), (-2.5920775, -2.8630927), (-1.8046465, -1.0386665), (-1.7401516, -0.97227323), (-2.5275846, -2.7967012), (-2.5920823, -2.8630936), (-1.804651, -1.0386648), (-1.7401519, -0.9722724), (-2.5275812, -2.7967021), (-2.592079, -2.863097), (-1.8046501, -1.0386695), (-1.7401531, -0.97227573), (-2.527582, -2.7967029), (-2.5920782, -2.8630965), (-1.8046528, -1.0386697), (-1.7401578, -0.9722749), (-2.5275815, -2.796701), (-2.5920746, -2.8630967), (-1.8046477, -1.0386727), (-1.7401527, -0.97227895), (-2.5275826, -2.796704), (-2.592082, -2.8630962), (-1.804653, -1.0386695), (-1.7401525, -0.9722772), (-2.5275786, -2.7967045), (-2.5920794, -2.8631), (-1.8046554, -1.0386745), (-1.7401552, -0.9722776), (-2.5275784, -2.7967017), (-2.592079, -2.8630986), (-1.804657, -1.038677), (-1.7401575, -0.9722815), (-2.527581, -2.7967026), (-2.5920804, -2.8630974), (-1.8046571, -1.0386757), (-1.740157, -0.9722809), (-2.5275795, -2.796704), (-2.5920775, -2.8630996), (-1.8046542, -1.0386771), (-1.7401584, -0.97228247), (-2.5275834, -2.7967052), (-2.5920775, -2.863098), (-1.8046508, -1.0386747), (-1.7401584, -0.97228265), (-2.5275867, -2.7967074), (-2.5920796, -2.8630989), (-1.8046511, -1.0386729), (-1.7401569, -0.9722815), (-2.5275855, -2.7967083), (-2.5920804, -2.8631008), (-1.8046494, -1.0386747), (-1.7401541, -0.9722825), (-2.5275862, -2.7967083), (-2.5920827, -2.8630996), (-1.8046516, -1.0386721), (-1.740155, -0.97227955), (-2.527587, -2.7967074), (-2.592084, -2.8631), (-1.8046533, -1.0386719), (-1.7401569, -0.9722784), (-2.5275855, -2.7967064), (-2.5920815, -2.8631), (-1.8046533, -1.038674), (-1.7401557, -0.97228086), (-2.5275853, -2.7967057), (-2.5920823, -2.8630996), (-1.8046523, -1.038674), (-1.7401552, -0.9722801), (-2.5275853, -2.7967055), (-2.592083, -2.8630993), (-1.8046533, -1.0386742), (-1.7401557, -0.97228026), (-2.5275853, -2.7967052), (-2.5920856, -2.863099), (-1.8046578, -1.0386726), (-1.7401547, -0.9722773), (-2.5275795, -2.796704), (-2.5920815, -2.8631012), (-1.8046572, -1.038675), (-1.740157, -0.97227645), (-2.5275812, -2.7967021), (-2.5920777, -2.8630998), (-1.804651, -1.0386766), (-1.7401576, -0.97228205), (-2.5275874, -2.7967052), (-2.5920804, -2.8630962), (-1.8046514, -1.0386701), (-1.7401571, -0.9722797), (-2.5275862, -2.796707), (-2.5920825, -2.8630981), (-1.8046534, -1.0386698), (-1.7401558, -0.97227687), (-2.5275822, -2.7967048), (-2.5920804, -2.8630989), (-1.8046556, -1.0386729), (-1.7401572, -0.972278), (-2.5275815, -2.7967021), (-2.5920775, -2.8630972), (-1.8046538, -1.0386745), (-1.7401611, -0.9722793), (-2.527588, -2.7967017), (-2.5920806, -2.8630955), (-1.8046501, -1.0386711), (-1.7401551, -0.97227764), (-2.5275843, -2.796704), (-2.5920823, -2.863097), (-1.804653, -1.0386695), (-1.7401513, -0.9722763), (-2.5275798, -2.7967033), (-2.5920813, -2.863098), (-1.8046559, -1.038672), (-1.7401565, -0.97227615), (-2.5275846, -2.7967005), (-2.5920851, -2.863096), (-1.8046558, -1.0386716), (-1.7401537, -0.97227603), (-2.527582, -2.7967014), (-2.5920844, -2.8630984), (-1.8046567, -1.0386729), (-1.7401532, -0.972276), (-2.5275772, -2.796702), (-2.5920784, -2.863099), (-1.8046572, -1.0386741), (-1.7401586, -0.97227615), (-2.5275793, -2.7966993), (-2.592077, -2.863096), (-1.8046565, -1.038674), (-1.7401608, -0.9722794), (-2.527585, -2.7967017), (-2.5920794, -2.863095), (-1.8046526, -1.0386717), (-1.7401571, -0.97227883), (-2.5275846, -2.7967033), (-2.5920815, -2.863096), (-1.8046515, -1.0386701), (-1.7401537, -0.9722777), (-2.5275848, -2.7967045), (-2.592083, -2.863098), (-1.8046515, -1.0386703), (-1.7401531, -0.97227585), (-2.5275836, -2.7967038), (-2.592083, -2.8630993), (-1.8046539, -1.0386726), (-1.7401525, -0.97227556), (-2.5275784, -2.7967014), (-2.5920784, -2.863099), (-1.8046552, -1.0386742), (-1.7401603, -0.9722768), (-2.5275853, -2.7966993), (-2.592078, -2.8630943), (-1.8046501, -1.0386722), (-1.7401565, -0.97227937), (-2.5275848, -2.7967036), (-2.5920792, -2.8630955), (-1.8046517, -1.0386704), (-1.740157, -0.972279), (-2.527584, -2.7967045), (-2.5920806, -2.8630958), (-1.8046528, -1.0386695), (-1.7401527, -0.97227746), (-2.5275815, -2.7967045), (-2.5920815, -2.8630989), (-1.8046538, -1.0386716), (-1.7401547, -0.9722755), (-2.5275817, -2.7967021), (-2.5920813, -2.8630981), (-1.8046551, -1.0386727), (-1.7401555, -0.97227716), (-2.5275824, -2.7967014), (-2.5920825, -2.8630955), (-1.8046553, -1.0386707), (-1.7401553, -0.97227705), (-2.5275822, -2.7967026), (-2.5920827, -2.8630981), (-1.8046571, -1.0386733), (-1.7401549, -0.9722759), (-2.5275784, -2.7967), (-2.5920806, -2.8630984), (-1.8046567, -1.0386751), (-1.7401565, -0.9722774), (-2.5275812, -2.7966993), (-2.5920806, -2.8630962), (-1.8046534, -1.0386745), (-1.7401553, -0.9722801), (-2.5275846, -2.7967033), (-2.5920813, -2.8630953), (-1.8046513, -1.0386693), (-1.7401544, -0.97227806), (-2.5275834, -2.7967055), (-2.5920794, -2.863098), (-1.8046523, -1.0386708), (-1.7401568, -0.9722769), (-2.5275846, -2.7967033), (-2.5920808, -2.8630984), (-1.8046527, -1.0386723), (-1.7401541, -0.97227675), (-2.5275817, -2.796703), (-2.5920835, -2.8630998), (-1.8046558, -1.0386739), (-1.7401525, -0.97227645), (-2.527578, -2.7967014), (-2.5920806, -2.8630996), (-1.8046582, -1.0386755), (-1.7401582, -0.9722775), (-2.5275803, -2.7966995), (-2.5920784, -2.8630955), (-1.8046547, -1.0386739), (-1.7401577, -0.9722794), (-2.5275817, -2.796702), (-2.5920763, -2.8630965), (-1.8046526, -1.038674), (-1.7401594, -0.97227955), (-2.5275874, -2.796702), (-2.5920832, -2.8630955), (-1.8046522, -1.0386711), (-1.7401526, -0.9722773), (-2.5275803, -2.7967038), (-2.5920794, -2.8630993), (-1.8046534, -1.0386738), (-1.740158, -0.9722786), (-2.5275857, -2.796702), (-2.5920804, -2.863094), (-1.8046497, -1.0386709), (-1.7401539, -0.9722802), (-2.5275843, -2.7967055), (-2.5920832, -2.8630974), (-1.8046541, -1.0386707), (-1.7401531, -0.9722776), (-2.5275822, -2.7967038), (-2.592084, -2.863098), (-1.8046565, -1.0386716), (-1.7401539, -0.97227573), (-2.5275788, -2.796702), (-2.5920806, -2.8630989), (-1.8046571, -1.0386746), (-1.7401576, -0.9722773), (-2.527582, -2.7966995), (-2.5920796, -2.8630953), (-1.8046542, -1.0386732), (-1.7401592, -0.97227985), (-2.527586, -2.7967026), (-2.5920804, -2.8630955), (-1.8046505, -1.038671), (-1.7401547, -0.97227794), (-2.527584, -2.7967036), (-2.592081, -2.8630974), (-1.8046533, -1.0386726), (-1.7401537, -0.9722784), (-2.5275793, -2.7967033), (-2.5920787, -2.8630977), (-1.8046536, -1.0386729), (-1.7401547, -0.9722787), (-2.5275822, -2.7967029), (-2.592083, -2.8630962), (-1.8046551, -1.0386715), (-1.7401549, -0.9722783), (-2.5275812, -2.7967036), (-2.59208, -2.863098), (-1.8046553, -1.0386724), (-1.7401574, -0.9722769), (-2.527583, -2.796702), (-2.5920808, -2.8630972), (-1.8046534, -1.0386724), (-1.7401543, -0.97227836), (-2.5275831, -2.7967043), (-2.5920815, -2.8630986), (-1.8046535, -1.0386719), (-1.7401559, -0.9722766), (-2.527584, -2.7967029), (-2.5920837, -2.8630977), (-1.8046542, -1.0386716), (-1.7401531, -0.97227734), (-2.5275838, -2.7967033), (-2.5920854, -2.863097), (-1.8046536, -1.0386705), (-1.7401514, -0.9722762), (-2.52758, -2.796704), (-2.5920806, -2.8631005), (-1.8046556, -1.0386736), (-1.7401589, -0.9722771), (-2.5275857, -2.7967014), (-2.5920818, -2.8630958), (-1.8046532, -1.0386715), (-1.7401552, -0.9722778), (-2.527582, -2.7967036), (-2.5920796, -2.8630981), (-1.8046547, -1.0386727), (-1.7401575, -0.97227705), (-2.5275826, -2.796702), (-2.5920792, -2.8630972), (-1.804651, -1.0386729), (-1.7401547, -0.97227937), (-2.5275853, -2.7967043), (-2.5920846, -2.8630965), (-1.8046561, -1.0386701), (-1.740155, -0.9722764), (-2.52758, -2.7967036), (-2.5920777, -2.8630996), (-1.8046515, -1.038674), (-1.740155, -0.9722778), (-2.527582, -2.796702), (-2.5920796, -2.863098), (-1.8046548, -1.0386735), (-1.7401586, -0.97227746), (-2.5275838, -2.7967002), (-2.592078, -2.8630953), (-1.8046536, -1.0386733), (-1.7401618, -0.9722798), (-2.5275872, -2.7967024), (-2.5920777, -2.8630943), (-1.8046468, -1.0386705), (-1.7401539, -0.9722806), (-2.527586, -2.7967067), (-2.5920818, -2.8630962), (-1.8046511, -1.0386684), (-1.7401549, -0.9722765), (-2.5275857, -2.7967043), (-2.592082, -2.863098), (-1.804652, -1.0386711), (-1.7401541, -0.97227687), (-2.527582, -2.7967033), (-2.592082, -2.8630981), (-1.804656, -1.0386723), (-1.7401558, -0.9722769), (-2.5275805, -2.796702), (-2.5920799, -2.863098), (-1.8046557, -1.038674), (-1.7401555, -0.97227705), (-2.52758, -2.7967), (-2.5920813, -2.8630972), (-1.8046558, -1.0386748), (-1.7401556, -0.9722782), (-2.5275803, -2.796701), (-2.5920787, -2.8630967), (-1.8046541, -1.0386741), (-1.7401586, -0.9722805), (-2.5275862, -2.7967038), (-2.5920837, -2.8630953), (-1.8046563, -1.0386689), (-1.7401553, -0.972276), (-2.5275795, -2.796704), (-2.5920775, -2.8631003), (-1.8046534, -1.0386747), (-1.7401596, -0.97227955), (-2.5275857, -2.796703), (-2.5920792, -2.8630953), (-1.8046484, -1.0386713), (-1.7401522, -0.97227967), (-2.5275855, -2.7967052), (-2.5920863, -2.8630962), (-1.804653, -1.0386678), (-1.7401501, -0.97227615), (-2.5275822, -2.7967055), (-2.592083, -2.8630993), (-1.8046538, -1.038671), (-1.7401532, -0.9722755), (-2.527581, -2.7967024), (-2.5920813, -2.8630989), (-1.8046552, -1.0386738), (-1.7401565, -0.9722773), (-2.5275817, -2.7967005), (-2.5920799, -2.8630955), (-1.8046553, -1.038673), (-1.7401596, -0.9722795), (-2.5275853, -2.7967024), (-2.5920784, -2.8630939), (-1.8046491, -1.0386707), (-1.7401543, -0.97228104), (-2.527585, -2.7967064), (-2.5920808, -2.8630962), (-1.8046502, -1.0386685), (-1.7401546, -0.97227734), (-2.5275855, -2.796705), (-2.592085, -2.8630972), (-1.8046545, -1.0386702), (-1.7401516, -0.97227603), (-2.5275805, -2.7967026), (-2.5920827, -2.863099), (-1.8046557, -1.038674), (-1.7401551, -0.97227734), (-2.5275812, -2.7967017), (-2.5920835, -2.8630977), (-1.8046577, -1.0386733), (-1.7401519, -0.97227764), (-2.527577, -2.796702), (-2.5920827, -2.8630989), (-1.8046579, -1.0386748), (-1.7401541, -0.9722774), (-2.52758, -2.7967012), (-2.5920846, -2.8630981), (-1.8046585, -1.038674), (-1.7401534, -0.9722772), (-2.5275779, -2.796702), (-2.5920818, -2.8630981), (-1.8046597, -1.0386744), (-1.7401562, -0.9722777), (-2.5275772, -2.7966998), (-2.59208, -2.863096), (-1.8046594, -1.0386746), (-1.7401575, -0.9722781), (-2.5275786, -2.796699), (-2.592081, -2.8630962), (-1.8046579, -1.0386755), (-1.7401541, -0.97227824), (-2.5275764, -2.7966993), (-2.5920796, -2.8630972), (-1.8046575, -1.0386764), (-1.7401565, -0.97227865), (-2.5275788, -2.7966995), (-2.592078, -2.8630962), (-1.8046556, -1.0386751), (-1.740158, -0.97227937), (-2.527583, -2.796701), (-2.5920799, -2.8630958), (-1.8046545, -1.0386733), (-1.7401588, -0.97227865), (-2.5275865, -2.796701), (-2.5920808, -2.8630946), (-1.8046498, -1.0386717), (-1.740154, -0.97227997), (-2.5275853, -2.796705), (-2.592084, -2.8630962), (-1.804654, -1.038669), (-1.7401557, -0.97227776), (-2.5275838, -2.796705), (-2.5920804, -2.8630972), (-1.804651, -1.0386698), (-1.7401536, -0.97227764), (-2.527585, -2.7967055), (-2.5920844, -2.8630984), (-1.8046525, -1.0386701), (-1.7401514, -0.9722756), (-2.527581, -2.7967043), (-2.5920806, -2.8630993), (-1.8046552, -1.0386719), (-1.7401563, -0.97227657), (-2.5275812, -2.796702), (-2.5920796, -2.863098), (-1.8046548, -1.0386733), (-1.7401567, -0.9722777), (-2.5275805, -2.7967024), (-2.5920794, -2.863098), (-1.8046558, -1.0386735), (-1.7401572, -0.97227746), (-2.5275807, -2.7967017), (-2.5920784, -2.863098), (-1.804654, -1.0386738), (-1.74016, -0.97227883), (-2.5275874, -2.7967024), (-2.5920796, -2.8630948), (-1.8046484, -1.0386717), (-1.7401549, -0.9722815), (-2.5275877, -2.7967064), (-2.592082, -2.863095), (-1.804649, -1.0386677), (-1.7401531, -0.9722793), (-2.5275836, -2.7967088), (-2.5920796, -2.8630986), (-1.8046521, -1.0386683), (-1.7401578, -0.972276), (-2.5275857, -2.7967045), (-2.5920823, -2.8630981), (-1.8046554, -1.0386707), (-1.7401571, -0.9722759), (-2.5275826, -2.7967024), (-2.5920804, -2.8630986), (-1.8046545, -1.0386735), (-1.7401562, -0.9722782), (-2.5275815, -2.7967024), (-2.5920777, -2.8630967), (-1.8046511, -1.0386722), (-1.7401562, -0.9722788), (-2.527584, -2.796704), (-2.5920813, -2.863096), (-1.8046545, -1.0386695), (-1.7401558, -0.9722768), (-2.5275836, -2.7967038), (-2.5920823, -2.8630986), (-1.8046552, -1.0386727), (-1.7401569, -0.9722774), (-2.5275831, -2.796702), (-2.5920794, -2.8630972), (-1.8046521, -1.0386735), (-1.7401583, -0.9722789), (-2.5275884, -2.7967021), (-2.5920827, -2.8630948), (-1.8046504, -1.0386703), (-1.740153, -0.9722789), (-2.5275857, -2.7967052), (-2.5920856, -2.8630974), (-1.8046516, -1.0386695), (-1.7401501, -0.97227633), (-2.5275822, -2.7967048), (-2.5920832, -2.8630996), (-1.8046534, -1.0386724), (-1.7401513, -0.97227615), (-2.5275788, -2.7967021), (-2.5920787, -2.8630989), (-1.8046534, -1.0386741), (-1.7401588, -0.97227854), (-2.527586, -2.7967021), (-2.5920792, -2.8630958), (-1.8046485, -1.0386715), (-1.7401536, -0.97227925), (-2.527585, -2.7967055), (-2.5920837, -2.8630962), (-1.8046541, -1.0386685), (-1.740154, -0.97227633), (-2.5275812, -2.796705), (-2.5920799, -2.8630993), (-1.8046541, -1.0386723), (-1.7401568, -0.97227716), (-2.5275822, -2.7967021), (-2.592078, -2.8630972), (-1.8046528, -1.0386738), (-1.7401586, -0.9722792), (-2.5275867, -2.7967017), (-2.592081, -2.8630958), (-1.8046511, -1.0386724), (-1.7401541, -0.9722789), (-2.527585, -2.7967029), (-2.5920856, -2.8630967), (-1.8046546, -1.0386711), (-1.7401525, -0.9722767), (-2.5275807, -2.7967026), (-2.5920844, -2.8630981), (-1.8046595, -1.0386732), (-1.7401558, -0.9722769), (-2.5275793, -2.796701), (-2.5920808, -2.863097), (-1.8046569, -1.0386738), (-1.7401539, -0.9722775), (-2.527576, -2.7967007), (-2.5920792, -2.863098), (-1.8046594, -1.0386748), (-1.740159, -0.9722777), (-2.5275803, -2.7966995), (-2.5920784, -2.8630955), (-1.804655, -1.0386744), (-1.7401564, -0.9722801), (-2.5275817, -2.7967021), (-2.5920806, -2.8630958), (-1.8046532, -1.0386722), (-1.7401531, -0.972278), (-2.5275803, -2.7967026), (-2.5920808, -2.8630977), (-1.8046547, -1.0386736), (-1.7401568, -0.9722779), (-2.527584, -2.7967012), (-2.5920804, -2.8630965), (-1.8046508, -1.0386729), (-1.7401527, -0.9722788), (-2.5275836, -2.7967038), (-2.592085, -2.8630962), (-1.804656, -1.0386697), (-1.7401545, -0.9722775), (-2.5275826, -2.7967045), (-2.5920818, -2.8630989), (-1.8046541, -1.038672), (-1.740156, -0.9722768), (-2.5275826, -2.796703), (-2.5920808, -2.8630977), (-1.8046525, -1.038672), (-1.7401546, -0.9722776), (-2.527585, -2.7967033), (-2.5920842, -2.8630977), (-1.804652, -1.038672), (-1.7401518, -0.9722775), (-2.527583, -2.7967043), (-2.5920827, -2.8630981), (-1.804656, -1.0386703), (-1.7401564, -0.97227556), (-2.527582, -2.7967029), (-2.5920799, -2.8630972), (-1.8046535, -1.0386707), (-1.7401559, -0.97227776), (-2.5275815, -2.796704), (-2.592078, -2.8630984), (-1.8046532, -1.0386728), (-1.7401582, -0.97227794), (-2.527584, -2.7967029), (-2.5920784, -2.8630962), (-1.8046517, -1.0386714), (-1.7401575, -0.97227913), (-2.5275838, -2.7967038), (-2.5920808, -2.8630967), (-1.8046553, -1.0386717), (-1.7401576, -0.972277), (-2.5275831, -2.7967024), (-2.5920808, -2.8630977), (-1.8046552, -1.0386734), (-1.7401569, -0.97227913), (-2.5275831, -2.7967033), (-2.5920796, -2.8630974), (-1.804652, -1.038673), (-1.7401551, -0.9722786), (-2.5275836, -2.7967026), (-2.5920808, -2.8630967), (-1.8046527, -1.0386722), (-1.7401557, -0.9722783), (-2.527582, -2.7967033), (-2.5920775, -2.8630977), (-1.8046528, -1.038674), (-1.740162, -0.97227997), (-2.5275908, -2.7967024), (-2.592081, -2.8630943), (-1.8046483, -1.0386705), (-1.740155, -0.97227997), (-2.5275884, -2.796706), (-2.5920844, -2.8630972), (-1.8046516, -1.038669), (-1.740154, -0.97227657), (-2.527584, -2.796705), (-2.5920825, -2.8630981), (-1.8046551, -1.0386707), (-1.7401568, -0.9722759), (-2.5275822, -2.7967024), (-2.592078, -2.8630984), (-1.8046514, -1.0386735), (-1.7401562, -0.9722784), (-2.5275822, -2.7967021), (-2.592076, -2.863097), (-1.804649, -1.0386747), (-1.7401559, -0.97228104), (-2.5275862, -2.7967038), (-2.5920804, -2.8630955), (-1.804649, -1.0386697), (-1.7401534, -0.9722776), (-2.5275831, -2.796705), (-2.5920796, -2.8630984), (-1.8046521, -1.0386708), (-1.7401571, -0.9722776), (-2.527585, -2.7967043), (-2.592081, -2.863096), (-1.804652, -1.0386689), (-1.7401545, -0.97227764), (-2.5275857, -2.7967055), (-2.5920846, -2.8630981), (-1.8046525, -1.0386695), (-1.7401522, -0.9722762), (-2.5275838, -2.7967052), (-2.5920866, -2.863099), (-1.804657, -1.0386697), (-1.7401545, -0.97227335), (-2.5275824, -2.796701), (-2.5920837, -2.8630986), (-1.8046559, -1.0386739), (-1.7401546, -0.97227746), (-2.5275807, -2.7967017), (-2.5920827, -2.8630972), (-1.8046572, -1.0386732), (-1.7401525, -0.97227824), (-2.5275774, -2.7967024), (-2.5920818, -2.8630996), (-1.8046578, -1.0386753), (-1.7401563, -0.9722768), (-2.5275805, -2.7966998), (-2.592081, -2.8630965), (-1.8046554, -1.0386738), (-1.7401537, -0.97227955), (-2.52758, -2.7967036), (-2.5920808, -2.863097), (-1.8046547, -1.0386721), (-1.7401558, -0.97227794), (-2.5275817, -2.7967029), (-2.59208, -2.863097), (-1.8046535, -1.038672), (-1.7401553, -0.97227734), (-2.5275831, -2.7967014), (-2.5920806, -2.8630965), (-1.8046509, -1.0386729), (-1.7401525, -0.97227854), (-2.5275838, -2.7967026), (-2.5920842, -2.8630967), (-1.8046535, -1.0386723), (-1.7401531, -0.9722781), (-2.5275812, -2.7967024), (-2.5920825, -2.863097), (-1.8046577, -1.0386729), (-1.7401583, -0.9722772), (-2.5275831, -2.796701), (-2.5920806, -2.8630965), (-1.804653, -1.0386732), (-1.740156, -0.9722775), (-2.5275843, -2.7967017), (-2.592082, -2.863097), (-1.8046558, -1.0386723), (-1.7401575, -0.97227824), (-2.5275826, -2.796703), (-2.5920804, -2.863097), (-1.8046533, -1.038672), (-1.7401551, -0.97227764), (-2.5275815, -2.7967029), (-2.5920792, -2.8630984), (-1.8046539, -1.0386733), (-1.7401567, -0.972278), (-2.527582, -2.7967024), (-2.5920792, -2.8630972), (-1.8046527, -1.0386734), (-1.740156, -0.97227794), (-2.527582, -2.7967021), (-2.5920768, -2.8630974), (-1.8046521, -1.0386738), (-1.7401578, -0.9722791), (-2.5275826, -2.7967021), (-2.5920765, -2.8630965), (-1.8046522, -1.0386735), (-1.7401615, -0.9722805), (-2.527588, -2.7967038), (-2.592077, -2.8630955), (-1.8046501, -1.0386709), (-1.740161, -0.9722792), (-2.5275905, -2.7967036), (-2.5920818, -2.8630955), (-1.8046491, -1.03867), (-1.7401547, -0.9722793), (-2.5275872, -2.7967072), (-2.5920832, -2.8630977), (-1.8046528, -1.0386677), (-1.7401575, -0.9722754), (-2.527586, -2.7967057), (-2.5920787, -2.8630972), (-1.8046485, -1.0386684), (-1.7401556, -0.972278), (-2.527587, -2.796707), (-2.592082, -2.8630972), (-1.8046489, -1.0386673), (-1.740152, -0.9722768), (-2.5275855, -2.7967076), (-2.5920832, -2.8630989), (-1.8046503, -1.0386677), (-1.7401522, -0.97227573), (-2.5275834, -2.7967067), (-2.5920827, -2.8631008), (-1.8046548, -1.0386708), (-1.7401552, -0.9722737), (-2.5275807, -2.7967017), (-2.592079, -2.8631), (-1.8046534, -1.0386751), (-1.7401571, -0.9722777), (-2.5275853, -2.7967007), (-2.5920815, -2.8630962), (-1.8046519, -1.0386729), (-1.7401534, -0.9722785), (-2.5275817, -2.7967036), (-2.5920794, -2.8630984), (-1.8046534, -1.0386729), (-1.7401571, -0.97227806), (-2.5275834, -2.7967038), (-2.5920792, -2.863098), (-1.8046533, -1.0386715), (-1.740158, -0.972277), (-2.527584, -2.7967024), (-2.5920792, -2.8630972), (-1.8046525, -1.0386735), (-1.7401617, -0.9722795), (-2.52759, -2.796702), (-2.5920792, -2.8630934), (-1.804649, -1.0386693), (-1.7401575, -0.9722804), (-2.5275896, -2.7967074), (-2.5920846, -2.863096), (-1.8046516, -1.0386664), (-1.7401538, -0.97227687), (-2.5275843, -2.7967074), (-2.5920804, -2.863099), (-1.8046511, -1.0386701), (-1.7401558, -0.9722763), (-2.5275843, -2.796704), (-2.5920787, -2.8630986), (-1.80465, -1.0386722), (-1.7401564, -0.97227734), (-2.527585, -2.7967024), (-2.5920784, -2.8630972), (-1.8046503, -1.0386734), (-1.7401571, -0.9722795), (-2.5275838, -2.7967033), (-2.5920775, -2.863096), (-1.8046508, -1.0386713), (-1.7401571, -0.9722791), (-2.527586, -2.796704), (-2.5920799, -2.8630967), (-1.8046486, -1.0386709), (-1.7401528, -0.97227746), (-2.527584, -2.7967036), (-2.5920832, -2.8630984), (-1.8046547, -1.0386724), (-1.7401545, -0.97227645), (-2.5275824, -2.7967012), (-2.5920808, -2.8630977), (-1.8046548, -1.0386728), (-1.7401586, -0.9722773), (-2.5275838, -2.7967021), (-2.5920792, -2.8630972), (-1.8046533, -1.0386721), (-1.740158, -0.9722779), (-2.5275846, -2.796703), (-2.5920818, -2.863097), (-1.8046538, -1.0386714), (-1.7401553, -0.9722773), (-2.527583, -2.7967038), (-2.592081, -2.8630986), (-1.8046546, -1.038673), (-1.740158, -0.9722771), (-2.5275848, -2.796701), (-2.5920806, -2.8630967), (-1.8046525, -1.0386733), (-1.7401545, -0.97227836), (-2.5275812, -2.796702), (-2.5920796, -2.863097), (-1.8046541, -1.0386732), (-1.7401578, -0.9722777), (-2.5275836, -2.7967021), (-2.592078, -2.8630974), (-1.804652, -1.0386739), (-1.7401586, -0.97228026), (-2.5275843, -2.796703), (-2.5920775, -2.8630943), (-1.8046523, -1.0386702), (-1.7401594, -0.9722796), (-2.527586, -2.7967045), (-2.5920792, -2.863096), (-1.8046505, -1.0386702), (-1.7401559, -0.9722782), (-2.5275846, -2.7967045), (-2.5920794, -2.8630974), (-1.8046502, -1.0386716), (-1.740155, -0.97227836), (-2.5275846, -2.7967036), (-2.592082, -2.8630972), (-1.8046548, -1.0386721), (-1.7401565, -0.9722777), (-2.5275826, -2.7967026), (-2.5920796, -2.8630984), (-1.8046532, -1.0386742), (-1.7401581, -0.9722782), (-2.5275855, -2.796701), (-2.59208, -2.8630962), (-1.8046507, -1.038674), (-1.740156, -0.9722805), (-2.527588, -2.7967036), (-2.5920832, -2.8630953), (-1.8046522, -1.0386695), (-1.7401562, -0.972278), (-2.5275838, -2.7967052), (-2.59208, -2.8630974), (-1.8046521, -1.0386709), (-1.7401545, -0.97227776), (-2.5275815, -2.7967043), (-2.592076, -2.8630981), (-1.8046502, -1.0386724), (-1.7401574, -0.9722783), (-2.5275853, -2.7967029), (-2.592082, -2.8630967), (-1.804652, -1.0386708), (-1.7401539, -0.9722777), (-2.5275836, -2.796705), (-2.5920808, -2.8630974), (-1.8046529, -1.0386701), (-1.7401572, -0.9722772), (-2.5275855, -2.796703), (-2.5920825, -2.8630967), (-1.804655, -1.0386717), (-1.7401567, -0.97227764), (-2.527583, -2.7967026), (-2.5920818, -2.8630974), (-1.8046532, -1.0386726), (-1.7401525, -0.97227746), (-2.5275826, -2.7967024), (-2.592085, -2.8630977), (-1.8046534, -1.0386722), (-1.7401496, -0.97227645), (-2.5275822, -2.7967026), (-2.5920877, -2.863099), (-1.8046589, -1.0386717), (-1.7401546, -0.9722735), (-2.5275803, -2.7967), (-2.5920806, -2.863099), (-1.8046553, -1.0386759), (-1.7401574, -0.9722776), (-2.5275817, -2.7967002), (-2.592078, -2.8630962), (-1.8046533, -1.0386738), (-1.7401553, -0.97228026), (-2.5275793, -2.7967036), (-2.592078, -2.8630974), (-1.8046553, -1.0386744), (-1.7401568, -0.97227895), (-2.527578, -2.7967012), (-2.5920765, -2.8630974), (-1.8046567, -1.0386758), (-1.7401621, -0.97227967), (-2.5275846, -2.7966998), (-2.5920746, -2.8630931), (-1.8046483, -1.0386727), (-1.74016, -0.9722836), (-2.527591, -2.796707), (-2.5920806, -2.8630927), (-1.8046486, -1.0386649), (-1.740158, -0.97227883), (-2.5275903, -2.7967088), (-2.5920813, -2.863097), (-1.8046473, -1.0386667), (-1.740156, -0.97227824), (-2.5275893, -2.7967083), (-2.5920794, -2.8630972), (-1.8046465, -1.0386673), (-1.7401556, -0.9722793), (-2.5275898, -2.7967098), (-2.5920823, -2.8630967), (-1.804647, -1.038665), (-1.7401519, -0.972277), (-2.5275853, -2.7967083), (-2.592084, -2.8630993), (-1.8046545, -1.0386695), (-1.7401549, -0.97227544), (-2.5275826, -2.796703), (-2.592083, -2.8630986), (-1.8046559, -1.0386728), (-1.7401536, -0.9722767), (-2.5275788, -2.7967012), (-2.5920827, -2.8630984), (-1.8046594, -1.0386752), (-1.7401551, -0.97227675), (-2.5275788, -2.7966988), (-2.5920818, -2.8630974), (-1.8046579, -1.0386757), (-1.7401569, -0.97227806), (-2.5275793, -2.7967005), (-2.592079, -2.8630958), (-1.8046541, -1.0386722), (-1.7401546, -0.9722781), (-2.5275803, -2.796703), (-2.592078, -2.8630974), (-1.8046521, -1.0386724), (-1.7401556, -0.9722778), (-2.5275824, -2.796702), (-2.592079, -2.8630972), (-1.8046513, -1.0386739), (-1.7401559, -0.9722791), (-2.5275855, -2.796703), (-2.592083, -2.863097), (-1.8046523, -1.0386711), (-1.7401522, -0.9722766), (-2.5275824, -2.7967033), (-2.592084, -2.8630989), (-1.8046561, -1.038672), (-1.7401549, -0.97227615), (-2.5275824, -2.796702), (-2.5920827, -2.8630972), (-1.8046533, -1.0386719), (-1.7401526, -0.9722776), (-2.5275826, -2.7967036), (-2.5920842, -2.863098), (-1.8046573, -1.038672), (-1.740157, -0.9722769), (-2.527582, -2.7967024), (-2.5920804, -2.8630974), (-1.8046547, -1.0386729), (-1.7401568, -0.9722782), (-2.5275826, -2.7967024), (-2.592081, -2.863097), (-1.8046554, -1.0386722), (-1.7401575, -0.9722782), (-2.5275822, -2.796703), (-2.592078, -2.8630974), (-1.8046527, -1.0386728), (-1.7401572, -0.9722791), (-2.5275836, -2.7967038), (-2.5920792, -2.863096), (-1.8046505, -1.0386702), (-1.7401543, -0.9722778), (-2.527583, -2.796705), (-2.5920804, -2.8630981), (-1.8046542, -1.0386703), (-1.7401559, -0.97227573), (-2.5275822, -2.7967026), (-2.592081, -2.863099), (-1.8046551, -1.038674), (-1.7401571, -0.97227746), (-2.5275822, -2.7967012), (-2.592079, -2.863097), (-1.8046526, -1.0386733), (-1.740158, -0.9722786), (-2.5275867, -2.7967021), (-2.5920804, -2.8630958), (-1.8046498, -1.0386715), (-1.7401537, -0.97227836), (-2.5275834, -2.7967038), (-2.5920808, -2.8630974), (-1.804653, -1.0386726), (-1.7401547, -0.97227836), (-2.5275817, -2.7967026), (-2.59208, -2.8630972), (-1.8046533, -1.038673), (-1.7401563, -0.97227734), (-2.5275848, -2.796701), (-2.5920815, -2.8630967), (-1.8046509, -1.0386722), (-1.7401522, -0.972278), (-2.5275836, -2.796704), (-2.5920842, -2.8630984), (-1.8046533, -1.0386717), (-1.7401522, -0.9722763), (-2.5275805, -2.7967029), (-2.592081, -2.8630996), (-1.8046566, -1.0386734), (-1.7401559, -0.972276), (-2.52758, -2.7967014), (-2.5920827, -2.8630993), (-1.8046596, -1.0386747), (-1.7401553, -0.9722765), (-2.5275779, -2.7966998), (-2.5920808, -2.863097), (-1.804658, -1.0386747), (-1.7401593, -0.9722779), (-2.5275826, -2.7966998), (-2.5920796, -2.8630953), (-1.8046534, -1.0386739), (-1.7401562, -0.9722801), (-2.5275822, -2.7967026), (-2.5920799, -2.8630958), (-1.8046573, -1.0386719), (-1.74016, -0.9722775), (-2.527582, -2.7967005), (-2.5920775, -2.8630953), (-1.8046547, -1.038674), (-1.7401597, -0.97228056), (-2.527584, -2.796702), (-2.5920765, -2.8630946), (-1.8046473, -1.0386721), (-1.7401532, -0.97228146), (-2.5275846, -2.796707), (-2.5920806, -2.8630974), (-1.80465, -1.0386698), (-1.7401544, -0.9722769), (-2.5275846, -2.796704), (-2.5920796, -2.863098), (-1.8046503, -1.0386708), (-1.7401547, -0.9722774), (-2.527583, -2.7967045), (-2.5920808, -2.8630972), (-1.8046534, -1.0386703), (-1.7401551, -0.9722777), (-2.5275815, -2.7967043), (-2.59208, -2.8630984), (-1.8046559, -1.0386727), (-1.7401576, -0.9722767), (-2.5275815, -2.7967007), (-2.5920799, -2.8630965), (-1.8046577, -1.0386736), (-1.7401589, -0.972278), (-2.5275803, -2.7967002), (-2.5920794, -2.8630955), (-1.8046583, -1.0386732), (-1.7401589, -0.97227913), (-2.527581, -2.7967021), (-2.5920815, -2.8630962), (-1.8046573, -1.0386723), (-1.7401551, -0.97227764), (-2.5275774, -2.796702), (-2.5920792, -2.8630989), (-1.8046587, -1.0386755), (-1.7401574, -0.9722771), (-2.5275779, -2.796699), (-2.5920799, -2.8630974), (-1.8046577, -1.0386764), (-1.7401568, -0.9722785), (-2.5275784, -2.7966993), (-2.592077, -2.863096), (-1.8046571, -1.0386753), (-1.7401614, -0.97228044), (-2.5275843, -2.7967017), (-2.592077, -2.8630943), (-1.8046478, -1.0386726), (-1.7401538, -0.97228295), (-2.527585, -2.7967079), (-2.5920813, -2.8630958), (-1.8046504, -1.0386667), (-1.7401528, -0.97227776), (-2.5275831, -2.7967083), (-2.5920806, -2.8630996), (-1.8046527, -1.0386691), (-1.7401562, -0.9722745), (-2.527584, -2.7967024), (-2.59208, -2.8630984), (-1.8046534, -1.0386733), (-1.7401592, -0.97227705), (-2.5275867, -2.7967002), (-2.592081, -2.8630958), (-1.804651, -1.0386722), (-1.7401538, -0.9722791), (-2.527585, -2.7967043), (-2.5920866, -2.8630958), (-1.8046548, -1.0386679), (-1.7401513, -0.97227603), (-2.527579, -2.796706), (-2.5920806, -2.8631012), (-1.8046548, -1.038673), (-1.7401553, -0.9722757), (-2.5275824, -2.7967017), (-2.59208, -2.8630986), (-1.8046542, -1.0386739), (-1.740159, -0.9722773), (-2.527586, -2.7967), (-2.5920808, -2.8630939), (-1.8046515, -1.0386711), (-1.7401556, -0.97228), (-2.5275853, -2.7967052), (-2.5920846, -2.8630965), (-1.8046557, -1.0386701), (-1.7401536, -0.9722766), (-2.5275786, -2.7967036), (-2.5920782, -2.863099), (-1.8046544, -1.0386735), (-1.7401558, -0.9722777), (-2.527581, -2.7967017), (-2.5920799, -2.8630974), (-1.8046547, -1.0386729), (-1.7401559, -0.97227734), (-2.5275812, -2.7967021), (-2.5920799, -2.8630974), (-1.8046532, -1.0386733), (-1.7401549, -0.9722777), (-2.5275812, -2.796702), (-2.592079, -2.8630977), (-1.8046525, -1.0386742), (-1.7401552, -0.9722798), (-2.527584, -2.7967036), (-2.5920818, -2.863096), (-1.8046517, -1.0386704), (-1.7401539, -0.972278), (-2.5275836, -2.7967048), (-2.592082, -2.8630974), (-1.8046515, -1.0386696), (-1.7401527, -0.97227585), (-2.5275836, -2.796704), (-2.5920827, -2.8630989), (-1.8046533, -1.038671), (-1.7401541, -0.9722758), (-2.5275846, -2.796703), (-2.592086, -2.8630986), (-1.8046552, -1.0386713), (-1.7401522, -0.972275), (-2.5275817, -2.796702), (-2.592084, -2.8630989), (-1.8046559, -1.038673), (-1.740154, -0.9722757), (-2.5275817, -2.7967012), (-2.5920832, -2.8630986), (-1.8046573, -1.038674), (-1.7401559, -0.97227657), (-2.5275807, -2.7966998), (-2.592082, -2.863097), (-1.8046579, -1.0386747), (-1.7401587, -0.9722781), (-2.527583, -2.7967002), (-2.5920808, -2.8630958), (-1.8046534, -1.0386727), (-1.7401539, -0.9722789), (-2.5275805, -2.7967038), (-2.5920784, -2.8630977), (-1.8046517, -1.0386728), (-1.7401549, -0.9722783), (-2.5275826, -2.7967024), (-2.5920794, -2.8630974), (-1.8046514, -1.0386739), (-1.7401557, -0.97228014), (-2.5275874, -2.7967048), (-2.592083, -2.8630972), (-1.8046489, -1.0386713), (-1.7401515, -0.97227895), (-2.5275843, -2.796706), (-2.5920854, -2.8630974), (-1.804656, -1.0386685), (-1.7401545, -0.97227526), (-2.5275812, -2.796704), (-2.5920815, -2.8631), (-1.8046548, -1.0386738), (-1.740155, -0.9722781), (-2.527581, -2.7967024), (-2.5920806, -2.863097), (-1.8046546, -1.0386722), (-1.7401551, -0.9722774), (-2.5275831, -2.796703), (-2.5920842, -2.8630984), (-1.804656, -1.0386721), (-1.7401546, -0.972276), (-2.5275822, -2.7967014), (-2.5920825, -2.8630977), (-1.804653, -1.0386727), (-1.7401522, -0.97227776), (-2.5275824, -2.7967036), (-2.592084, -2.8630986), (-1.8046558, -1.0386734), (-1.7401532, -0.9722769), (-2.5275784, -2.7967012), (-2.5920835, -2.8630993), (-1.8046607, -1.0386764), (-1.7401557, -0.97227734), (-2.5275803, -2.7966986), (-2.592084, -2.8630972), (-1.8046561, -1.0386748), (-1.740152, -0.97227776), (-2.5275795, -2.7967014), (-2.5920818, -2.8630972), (-1.8046539, -1.0386738), (-1.740152, -0.97227925), (-2.5275817, -2.7967038), (-2.5920837, -2.8630981), (-1.804654, -1.0386721), (-1.7401538, -0.972277), (-2.5275817, -2.7967026), (-2.59208, -2.8630989), (-1.8046536, -1.0386738), (-1.7401581, -0.9722768), (-2.5275853, -2.7967005), (-2.5920799, -2.8630967), (-1.8046514, -1.0386735), (-1.7401534, -0.97227913), (-2.5275826, -2.7967033), (-2.5920832, -2.863097), (-1.8046536, -1.0386722), (-1.7401533, -0.972278), (-2.5275824, -2.796703), (-2.5920832, -2.8630958), (-1.8046573, -1.0386695), (-1.7401586, -0.97227585), (-2.5275834, -2.7967021), (-2.5920804, -2.8630981), (-1.8046544, -1.0386733), (-1.7401596, -0.97227776), (-2.5275874, -2.7967021), (-2.59208, -2.8630955), (-1.804649, -1.0386703), (-1.7401531, -0.9722788), (-2.527587, -2.7967062), (-2.5920866, -2.863098), (-1.8046526, -1.0386682), (-1.740151, -0.972275), (-2.527582, -2.7967057), (-2.5920815, -2.8631008), (-1.8046516, -1.0386714), (-1.7401515, -0.972276), (-2.5275784, -2.7967045), (-2.5920775, -2.8631012), (-1.8046521, -1.0386741), (-1.7401563, -0.9722765), (-2.5275843, -2.7967014), (-2.592081, -2.8630965), (-1.8046526, -1.0386722), (-1.7401543, -0.97227806), (-2.5275826, -2.7967026), (-2.592082, -2.8630977), (-1.8046559, -1.0386728), (-1.7401552, -0.9722767), (-2.527581, -2.7967012), (-2.592084, -2.8630967), (-1.8046582, -1.0386728), (-1.7401527, -0.9722771), (-2.5275755, -2.796701), (-2.592083, -2.8630996), (-1.8046626, -1.0386772), (-1.7401583, -0.97227687), (-2.5275798, -2.796697), (-2.5920808, -2.8630965), (-1.8046557, -1.0386758), (-1.7401531, -0.97227806), (-2.5275798, -2.7967007), (-2.592083, -2.8630965), (-1.8046564, -1.0386734), (-1.7401521, -0.9722784), (-2.527578, -2.7967029), (-2.5920837, -2.8630981), (-1.8046601, -1.0386728), (-1.7401567, -0.9722755), (-2.5275798, -2.7967), (-2.5920808, -2.863098), (-1.8046575, -1.0386739), (-1.7401559, -0.97227645), (-2.5275786, -2.7967005), (-2.5920808, -2.8630977), (-1.8046553, -1.0386735), (-1.7401527, -0.97227746), (-2.5275803, -2.7967014), (-2.5920832, -2.8630972), (-1.8046552, -1.0386732), (-1.7401518, -0.97227734), (-2.5275779, -2.796702), (-2.592082, -2.8630993), (-1.8046587, -1.0386759), (-1.7401567, -0.9722766), (-2.5275805, -2.796698), (-2.592081, -2.863097), (-1.8046563, -1.0386759), (-1.7401565, -0.9722789), (-2.527581, -2.7967007), (-2.5920794, -2.8630955), (-1.8046558, -1.0386732), (-1.7401595, -0.97227854), (-2.5275857, -2.796701), (-2.59208, -2.8630953), (-1.8046514, -1.0386727), (-1.7401552, -0.9722792), (-2.5275812, -2.7967033), (-2.5920787, -2.8630974), (-1.8046533, -1.0386724), (-1.7401555, -0.9722793), (-2.5275834, -2.7967048), (-2.5920815, -2.863097), (-1.8046517, -1.0386692), (-1.7401537, -0.9722768), (-2.5275838, -2.796705), (-2.5920823, -2.863098), (-1.8046547, -1.0386704), (-1.740157, -0.9722762), (-2.5275834, -2.7967036), (-2.592079, -2.863098), (-1.8046522, -1.0386713), (-1.7401568, -0.9722771), (-2.5275843, -2.796703), (-2.5920818, -2.8630977), (-1.8046523, -1.0386728), (-1.7401526, -0.97227836), (-2.5275807, -2.7967033), (-2.592081, -2.863098), (-1.8046566, -1.0386724), (-1.7401587, -0.97227734), (-2.5275831, -2.7967021), (-2.5920792, -2.863098), (-1.804654, -1.0386736), (-1.7401593, -0.97227764), (-2.5275857, -2.7967005), (-2.5920799, -2.8630958), (-1.8046528, -1.0386736), (-1.7401568, -0.9722803), (-2.5275848, -2.7967036), (-2.592082, -2.8630965), (-1.8046522, -1.0386719), (-1.7401546, -0.9722784), (-2.5275822, -2.7967038), (-2.5920775, -2.863098), (-1.8046486, -1.0386733), (-1.7401538, -0.9722798), (-2.5275855, -2.7967048), (-2.5920837, -2.8630972), (-1.8046547, -1.0386703), (-1.7401563, -0.9722768), (-2.5275826, -2.7967038), (-2.5920777, -2.863097), (-1.8046507, -1.0386714), (-1.7401578, -0.9722788), (-2.5275848, -2.7967038), (-2.5920777, -2.8630965), (-1.8046515, -1.0386717), (-1.7401572, -0.9722788), (-2.5275836, -2.796703), (-2.592078, -2.8630967), (-1.8046517, -1.0386733), (-1.7401614, -0.9722796), (-2.5275898, -2.7967021), (-2.5920784, -2.8630934), (-1.8046473, -1.0386703), (-1.7401563, -0.9722809), (-2.527589, -2.7967076), (-2.5920827, -2.863097), (-1.8046511, -1.0386676), (-1.740156, -0.97227657), (-2.527587, -2.7967052), (-2.5920837, -2.8630984), (-1.8046525, -1.0386708), (-1.7401533, -0.9722765), (-2.5275815, -2.7967036), (-2.5920799, -2.8630989), (-1.8046558, -1.0386726), (-1.7401594, -0.9722771), (-2.5275836, -2.7967021), (-2.592078, -2.8630955), (-1.8046514, -1.0386707), (-1.7401583, -0.9722781), (-2.527587, -2.796703), (-2.5920813, -2.8630953), (-1.8046488, -1.0386696), (-1.7401507, -0.97227955), (-2.5275855, -2.7967079), (-2.5920846, -2.8630977), (-1.804649, -1.0386679), (-1.7401481, -0.9722765), (-2.527581, -2.7967072), (-2.5920832, -2.8631012), (-1.8046545, -1.0386705), (-1.7401544, -0.97227347), (-2.527582, -2.7967017), (-2.5920808, -2.8631003), (-1.8046546, -1.0386746), (-1.7401577, -0.9722768), (-2.5275846, -2.7967007), (-2.5920815, -2.863097), (-1.8046554, -1.038673), (-1.7401571, -0.9722775), (-2.5275826, -2.7967014), (-2.5920804, -2.8630972), (-1.8046544, -1.0386734), (-1.7401567, -0.972279), (-2.5275817, -2.7967029), (-2.59208, -2.8630972), (-1.8046559, -1.0386729), (-1.7401576, -0.97227764), (-2.5275824, -2.7967017), (-2.592079, -2.8630974), (-1.8046522, -1.0386739), (-1.7401565, -0.9722786), (-2.5275834, -2.7967014), (-2.5920787, -2.863096), (-1.8046528, -1.0386735), (-1.7401601, -0.972279), (-2.5275884, -2.7967007), (-2.5920794, -2.8630939), (-1.8046485, -1.0386726), (-1.7401567, -0.97228134), (-2.527589, -2.7967055), (-2.592084, -2.8630943), (-1.8046503, -1.0386659), (-1.7401519, -0.9722786), (-2.527584, -2.79671), (-2.5920813, -2.8630996), (-1.8046502, -1.0386685), (-1.7401543, -0.97227645), (-2.5275848, -2.7967052), (-2.5920832, -2.8630986), (-1.8046538, -1.038671), (-1.7401538, -0.97227734), (-2.527583, -2.796704), (-2.592082, -2.8630984), (-1.8046538, -1.0386723), (-1.7401558, -0.9722774), (-2.527583, -2.7967026), (-2.5920804, -2.8630984), (-1.8046529, -1.0386739), (-1.7401582, -0.97227824), (-2.5275862, -2.7967024), (-2.592079, -2.863095), (-1.8046484, -1.0386714), (-1.7401534, -0.9722803), (-2.527584, -2.7967057), (-2.5920808, -2.8630974), (-1.8046517, -1.0386701), (-1.7401551, -0.9722775), (-2.527583, -2.7967043), (-2.5920775, -2.8630974), (-1.8046505, -1.0386722), (-1.7401565, -0.972279), (-2.5275853, -2.7967033), (-2.5920825, -2.863097), (-1.8046547, -1.038671), (-1.7401564, -0.97227645), (-2.5275838, -2.7967024), (-2.5920823, -2.8630962), (-1.804654, -1.0386705), (-1.7401557, -0.9722776), (-2.5275846, -2.7967038), (-2.5920842, -2.8630981), (-1.8046536, -1.0386715), (-1.7401521, -0.9722761), (-2.527583, -2.7967024), (-2.592086, -2.8630984), (-1.8046561, -1.038672), (-1.7401525, -0.9722756), (-2.5275793, -2.7967026), (-2.5920815, -2.8630996), (-1.8046565, -1.0386738), (-1.7401563, -0.9722763), (-2.5275831, -2.7967002), (-2.5920813, -2.8630967), (-1.8046525, -1.0386736), (-1.7401564, -0.9722792), (-2.5275865, -2.796703), (-2.5920815, -2.863096), (-1.8046503, -1.0386702), (-1.7401532, -0.97227824), (-2.527584, -2.7967052), (-2.592082, -2.8630967), (-1.8046525, -1.0386691), (-1.7401539, -0.9722778), (-2.5275817, -2.796706), (-2.5920782, -2.8630989), (-1.8046522, -1.0386709), (-1.740156, -0.97227746), (-2.5275826, -2.7967048), (-2.5920806, -2.8630989), (-1.8046541, -1.0386732), (-1.7401571, -0.9722771), (-2.527583, -2.796701), (-2.592078, -2.8630967), (-1.8046507, -1.038673), (-1.740156, -0.97227937), (-2.5275853, -2.796704), (-2.5920823, -2.8630953), (-1.8046542, -1.0386683), (-1.7401581, -0.97227675), (-2.527586, -2.7967045), (-2.5920818, -2.863097), (-1.8046536, -1.0386697), (-1.740155, -0.97227824), (-2.5275803, -2.7967055), (-2.5920782, -2.8630989), (-1.8046541, -1.038673), (-1.7401586, -0.97227705), (-2.527584, -2.796701), (-2.5920787, -2.8630967), (-1.8046513, -1.038673), (-1.7401563, -0.9722793), (-2.5275853, -2.7967043), (-2.5920796, -2.863097), (-1.804649, -1.0386713), (-1.7401538, -0.9722781), (-2.5275862, -2.796704), (-2.592084, -2.8630974), (-1.804652, -1.0386697), (-1.7401527, -0.9722761), (-2.5275817, -2.7967052), (-2.5920808, -2.863101), (-1.8046544, -1.038673), (-1.7401555, -0.972276), (-2.527583, -2.796702), (-2.5920825, -2.8630977), (-1.8046563, -1.0386722), (-1.7401575, -0.9722767), (-2.5275831, -2.7967017), (-2.5920804, -2.8630977), (-1.8046544, -1.0386742), (-1.7401577, -0.9722787), (-2.5275855, -2.7967017), (-2.5920808, -2.8630958), (-1.8046505, -1.0386715), (-1.7401549, -0.97227913), (-2.527586, -2.7967052), (-2.5920846, -2.863096), (-1.8046547, -1.0386682), (-1.7401546, -0.9722759), (-2.5275826, -2.7967043), (-2.5920818, -2.8630986), (-1.8046551, -1.0386709), (-1.7401547, -0.97227734), (-2.5275788, -2.7967043), (-2.5920763, -2.8630989), (-1.8046511, -1.0386734), (-1.7401559, -0.97227913), (-2.5275838, -2.796704), (-2.5920823, -2.863096), (-1.8046545, -1.0386693), (-1.7401549, -0.97227675), (-2.5275834, -2.7967036), (-2.5920827, -2.8630981), (-1.8046557, -1.0386722), (-1.7401553, -0.9722761), (-2.5275803, -2.7967007), (-2.5920796, -2.863098), (-1.8046534, -1.0386758), (-1.740153, -0.97227937), (-2.5275803, -2.7967017), (-2.5920835, -2.8630967), (-1.804657, -1.0386729), (-1.7401522, -0.972278), (-2.5275776, -2.7967021), (-2.5920835, -2.8630989), (-1.8046595, -1.0386751), (-1.7401549, -0.9722766), (-2.5275788, -2.7966988), (-2.5920837, -2.8630965), (-1.8046597, -1.0386748), (-1.7401543, -0.9722776), (-2.5275755, -2.7966998), (-2.5920782, -2.8630986), (-1.8046583, -1.0386769), (-1.7401586, -0.9722784), (-2.527582, -2.7966993), (-2.5920804, -2.8630965), (-1.8046534, -1.0386753), (-1.7401549, -0.9722795), (-2.5275822, -2.7967021), (-2.5920794, -2.8630962), (-1.804651, -1.0386719), (-1.7401536, -0.97227806), (-2.5275824, -2.7967033), (-2.5920818, -2.8630974), (-1.8046561, -1.0386716), (-1.7401577, -0.9722768), (-2.5275826, -2.7967024), (-2.59208, -2.8630972), (-1.8046547, -1.0386726), (-1.7401567, -0.97227746), (-2.5275826, -2.7967017), (-2.5920794, -2.8630974), (-1.8046538, -1.0386726), (-1.740158, -0.9722771), (-2.5275838, -2.7967021), (-2.5920808, -2.863097), (-1.8046547, -1.0386723), (-1.7401564, -0.97227716), (-2.5275807, -2.7967017), (-2.5920813, -2.8630974), (-1.8046579, -1.0386735), (-1.7401559, -0.972277), (-2.5275793, -2.7967002), (-2.5920823, -2.8630972), (-1.8046583, -1.0386747), (-1.7401528, -0.97227824), (-2.527575, -2.7967007), (-2.5920792, -2.8630972), (-1.8046575, -1.0386747), (-1.7401541, -0.9722785), (-2.5275762, -2.7967007), (-2.5920794, -2.8630981), (-1.80466, -1.038676), (-1.7401608, -0.97227705), (-2.5275812, -2.7966974), (-2.5920773, -2.863096), (-1.8046532, -1.038676), (-1.740157, -0.97228056), (-2.5275846, -2.7967026), (-2.5920806, -2.863096), (-1.804651, -1.0386719), (-1.7401539, -0.97227865), (-2.527582, -2.7967043), (-2.5920787, -2.8630981), (-1.8046532, -1.038672), (-1.7401577, -0.97227675), (-2.5275846, -2.7967021), (-2.592083, -2.8630965), (-1.8046569, -1.0386717), (-1.7401576, -0.9722768), (-2.5275812, -2.796701), (-2.5920796, -2.8630967), (-1.8046567, -1.038674), (-1.7401582, -0.9722794), (-2.5275803, -2.7967017), (-2.592077, -2.863096), (-1.8046529, -1.0386726), (-1.7401564, -0.97227895), (-2.5275817, -2.7967033), (-2.5920782, -2.8630967), (-1.8046523, -1.0386719), (-1.7401558, -0.9722782), (-2.5275824, -2.796703), (-2.5920813, -2.8630967), (-1.8046572, -1.0386716), (-1.7401576, -0.9722765), (-2.527582, -2.796701), (-2.5920815, -2.8630967), (-1.8046559, -1.0386732), (-1.7401563, -0.97227895), (-2.5275824, -2.7967033), (-2.5920806, -2.863097), (-1.8046533, -1.0386721), (-1.740155, -0.97227764), (-2.5275812, -2.7967026), (-2.5920804, -2.8630972), (-1.8046548, -1.0386722), (-1.7401556, -0.97227824), (-2.5275807, -2.7967033), (-2.5920792, -2.863098), (-1.804655, -1.038673), (-1.7401581, -0.97227675), (-2.5275831, -2.796701), (-2.5920782, -2.863097), (-1.8046522, -1.0386742), (-1.7401584, -0.97228044), (-2.5275862, -2.796703), (-2.5920806, -2.8630946), (-1.8046504, -1.0386705), (-1.7401536, -0.9722795), (-2.527584, -2.7967055), (-2.5920837, -2.8630965), (-1.8046545, -1.0386688), (-1.7401544, -0.97227746), (-2.5275838, -2.7967055), (-2.5920835, -2.8630981), (-1.8046528, -1.0386697), (-1.7401514, -0.97227645), (-2.5275805, -2.7967055), (-2.5920825, -2.8631008), (-1.8046547, -1.0386728), (-1.740153, -0.9722754), (-2.52758, -2.796702), (-2.592081, -2.8630993), (-1.8046561, -1.0386746), (-1.7401581, -0.97227716), (-2.5275826, -2.7967005), (-2.5920799, -2.8630965), (-1.8046529, -1.0386735), (-1.7401576, -0.97227913), (-2.5275853, -2.7967024), (-2.5920787, -2.8630958), (-1.804651, -1.0386724), (-1.7401568, -0.9722798), (-2.5275862, -2.7967038), (-2.5920804, -2.8630958), (-1.8046484, -1.03867), (-1.7401528, -0.97227955), (-2.5275862, -2.7967076), (-2.5920832, -2.863098), (-1.8046498, -1.0386676), (-1.7401518, -0.9722749), (-2.5275836, -2.796706), (-2.5920846, -2.863101), (-1.8046556, -1.038671), (-1.7401547, -0.97227395), (-2.527582, -2.7967017), (-2.5920799, -2.8630998), (-1.8046539, -1.0386746), (-1.7401599, -0.972277), (-2.5275884, -2.796699), (-2.5920806, -2.8630946), (-1.8046511, -1.0386729), (-1.7401564, -0.97227937), (-2.5275836, -2.7967026), (-2.5920799, -2.8630965), (-1.8046527, -1.0386732), (-1.7401562, -0.97227955), (-2.5275826, -2.7967026), (-2.5920808, -2.8630965), (-1.8046529, -1.0386728), (-1.7401538, -0.97227865), (-2.527584, -2.7967029), (-2.5920827, -2.863097), (-1.8046508, -1.0386717), (-1.740152, -0.9722777), (-2.527584, -2.7967038), (-2.592085, -2.8630981), (-1.8046538, -1.0386713), (-1.7401516, -0.9722761), (-2.5275803, -2.7967026), (-2.5920835, -2.8630984), (-1.8046578, -1.0386733), (-1.7401545, -0.97227675), (-2.52758, -2.796701), (-2.5920806, -2.8630974), (-1.8046541, -1.0386736), (-1.7401571, -0.972279), (-2.5275846, -2.7967024), (-2.5920794, -2.8630958), (-1.804652, -1.0386723), (-1.740156, -0.9722788), (-2.5275815, -2.796703), (-2.5920775, -2.863097), (-1.8046528, -1.038673), (-1.7401606, -0.9722795), (-2.5275886, -2.7967029), (-2.5920818, -2.8630948), (-1.8046511, -1.0386708), (-1.7401545, -0.9722789), (-2.5275857, -2.7967038), (-2.5920827, -2.8630967), (-1.80465, -1.0386709), (-1.7401515, -0.97227746), (-2.5275843, -2.796703), (-2.5920846, -2.8630977), (-1.804652, -1.0386721), (-1.7401484, -0.972277), (-2.5275786, -2.7967029), (-2.5920823, -2.8630996), (-1.8046561, -1.0386745), (-1.7401553, -0.97227645), (-2.5275822, -2.7966993), (-2.5920825, -2.8630967), (-1.8046539, -1.038674), (-1.7401559, -0.97227883), (-2.5275865, -2.796703), (-2.5920827, -2.863096), (-1.8046515, -1.0386704), (-1.7401539, -0.972278), (-2.5275857, -2.7967048), (-2.5920863, -2.8630977), (-1.8046577, -1.0386701), (-1.7401558, -0.9722755), (-2.5275807, -2.7967024), (-2.5920784, -2.8630993), (-1.8046523, -1.0386752), (-1.7401569, -0.9722789), (-2.527582, -2.796702), (-2.592076, -2.863096), (-1.8046525, -1.0386734), (-1.7401593, -0.9722799), (-2.5275862, -2.7967021), (-2.5920804, -2.8630953), (-1.8046509, -1.0386719), (-1.740154, -0.97227913), (-2.527582, -2.7967038), (-2.5920794, -2.8630972), (-1.8046523, -1.0386716), (-1.7401551, -0.97227764), (-2.5275834, -2.7967036), (-2.5920827, -2.863098), (-1.804653, -1.038671), (-1.7401527, -0.9722766), (-2.5275815, -2.7967045), (-2.592082, -2.8630984), (-1.8046558, -1.0386705), (-1.7401575, -0.9722756), (-2.5275826, -2.7967024), (-2.5920787, -2.8630984), (-1.8046527, -1.0386734), (-1.7401577, -0.9722773), (-2.5275853, -2.7967017), (-2.5920799, -2.8630958), (-1.8046498, -1.0386701), (-1.7401543, -0.9722779), (-2.5275865, -2.7967048), (-2.5920854, -2.8630977), (-1.8046533, -1.0386692), (-1.7401531, -0.97227585), (-2.5275831, -2.7967052), (-2.5920825, -2.8630996), (-1.8046542, -1.0386715), (-1.7401546, -0.9722763), (-2.5275831, -2.7967021), (-2.5920846, -2.863098), (-1.8046571, -1.0386728), (-1.7401536, -0.97227675), (-2.5275788, -2.796702), (-2.5920813, -2.8630984), (-1.8046575, -1.0386745), (-1.7401568, -0.9722787), (-2.5275807, -2.7967017), (-2.5920804, -2.8630967), (-1.8046536, -1.0386733), (-1.7401575, -0.9722789), (-2.5275862, -2.7967026), (-2.5920796, -2.8630965), (-1.8046483, -1.0386722), (-1.7401519, -0.9722789), (-2.527583, -2.7967048), (-2.5920825, -2.8630974), (-1.8046527, -1.0386702), (-1.7401532, -0.9722766), (-2.5275824, -2.796704), (-2.5920784, -2.8630984), (-1.8046505, -1.0386716), (-1.740157, -0.97227854), (-2.527584, -2.7967045), (-2.5920775, -2.863096), (-1.8046516, -1.0386698), (-1.7401586, -0.97227895), (-2.5275874, -2.7967048), (-2.592083, -2.8630962), (-1.8046527, -1.038669), (-1.7401551, -0.97227687), (-2.5275853, -2.796705), (-2.5920851, -2.8630981), (-1.8046564, -1.0386705), (-1.7401551, -0.97227556), (-2.527582, -2.7967017), (-2.5920804, -2.8630981), (-1.8046535, -1.038674), (-1.7401589, -0.97227883), (-2.527586, -2.7967026), (-2.5920794, -2.8630965), (-1.8046513, -1.0386721), (-1.7401557, -0.97227895), (-2.5275815, -2.7967043), (-2.592076, -2.8630977), (-1.8046507, -1.0386734), (-1.7401583, -0.9722794), (-2.5275855, -2.7967026), (-2.592079, -2.8630962), (-1.8046514, -1.038673), (-1.7401558, -0.9722794), (-2.5275831, -2.7967029), (-2.5920794, -2.8630962), (-1.8046534, -1.0386727), (-1.7401581, -0.9722794), (-2.5275838, -2.796703), (-2.5920782, -2.8630965), (-1.8046526, -1.0386727), (-1.7401584, -0.97227895), (-2.5275853, -2.7967024), (-2.5920804, -2.8630943), (-1.8046514, -1.0386705), (-1.7401564, -0.9722789), (-2.5275846, -2.796704), (-2.5920792, -2.863097), (-1.8046526, -1.0386716), (-1.7401583, -0.9722786), (-2.5275855, -2.7967036), (-2.59208, -2.8630967), (-1.8046505, -1.0386707), (-1.7401565, -0.97227705), (-2.5275872, -2.796703), (-2.5920825, -2.8630967), (-1.804653, -1.0386708), (-1.7401567, -0.97227675), (-2.5275848, -2.7967024), (-2.5920804, -2.8630974), (-1.8046522, -1.0386728), (-1.7401552, -0.9722782), (-2.527582, -2.7967024), (-2.5920787, -2.8630977), (-1.8046535, -1.0386735), (-1.7401575, -0.9722787), (-2.5275822, -2.7967026), (-2.5920777, -2.8630972), (-1.8046536, -1.0386745), (-1.7401617, -0.9722793), (-2.527587, -2.7967002), (-2.5920773, -2.8630943), (-1.8046486, -1.0386739), (-1.7401563, -0.97228193), (-2.5275877, -2.7967048), (-2.5920835, -2.8630953), (-1.8046533, -1.0386686), (-1.7401537, -0.9722763), (-2.5275798, -2.7967043), (-2.5920782, -2.8630998), (-1.8046538, -1.0386742), (-1.7401587, -0.97227806), (-2.5275843, -2.7967005), (-2.5920782, -2.8630955), (-1.8046508, -1.0386735), (-1.7401572, -0.97227985), (-2.5275848, -2.796703), (-2.5920784, -2.8630967), (-1.8046515, -1.0386722), (-1.7401564, -0.972279), (-2.5275817, -2.796704), (-2.5920768, -2.8630972), (-1.804653, -1.0386733), (-1.7401603, -0.97227865), (-2.527586, -2.7967014), (-2.592078, -2.863095), (-1.8046529, -1.0386717), (-1.7401602, -0.9722795), (-2.5275862, -2.7967043), (-2.592082, -2.8630953), (-1.8046526, -1.0386683), (-1.7401543, -0.97227705), (-2.5275834, -2.796705), (-2.5920818, -2.863098), (-1.8046547, -1.0386703), (-1.7401564, -0.97227675), (-2.5275826, -2.7967038), (-2.5920804, -2.8630984), (-1.804654, -1.0386724), (-1.740156, -0.9722769), (-2.5275822, -2.7967021), (-2.5920806, -2.8630981), (-1.8046551, -1.0386733), (-1.7401556, -0.972278), (-2.5275784, -2.7967024), (-2.5920746, -2.8630974), (-1.8046514, -1.0386736), (-1.740158, -0.9722797), (-2.5275855, -2.7967038), (-2.5920832, -2.8630953), (-1.8046557, -1.0386689), (-1.7401559, -0.9722767), (-2.5275815, -2.796704), (-2.5920787, -2.8630986), (-1.8046527, -1.038673), (-1.7401564, -0.9722782), (-2.5275826, -2.7967026), (-2.5920804, -2.8630972), (-1.8046535, -1.0386734), (-1.7401559, -0.9722778), (-2.527584, -2.796701), (-2.592081, -2.863096), (-1.8046536, -1.0386724), (-1.7401563, -0.972278), (-2.527583, -2.7967024), (-2.5920813, -2.863097), (-1.8046557, -1.0386728), (-1.7401574, -0.9722784), (-2.5275822, -2.7967024), (-2.5920799, -2.8630967), (-1.8046544, -1.0386729), (-1.7401555, -0.9722785), (-2.5275798, -2.796703), (-2.5920782, -2.863098), (-1.8046558, -1.0386736), (-1.7401589, -0.97227746), (-2.527583, -2.7967), (-2.5920804, -2.8630948), (-1.8046523, -1.038673), (-1.740153, -0.97228014), (-2.5275831, -2.7967038), (-2.5920846, -2.863095), (-1.8046552, -1.0386692), (-1.7401534, -0.9722779), (-2.527581, -2.7967045), (-2.5920796, -2.8630984), (-1.8046536, -1.0386729), (-1.740157, -0.97227806), (-2.5275836, -2.7967021), (-2.59208, -2.863096), (-1.804652, -1.0386715), (-1.7401551, -0.9722781), (-2.5275826, -2.7967036), (-2.59208, -2.8630977), (-1.8046528, -1.0386727), (-1.7401549, -0.9722785), (-2.527585, -2.7967026), (-2.5920837, -2.8630965), (-1.8046523, -1.0386721), (-1.7401524, -0.9722779), (-2.5275824, -2.7967029), (-2.5920854, -2.8630981), (-1.8046582, -1.038673), (-1.7401546, -0.9722757), (-2.527579, -2.7967002), (-2.5920835, -2.8630989), (-1.80466, -1.0386753), (-1.7401562, -0.9722768), (-2.5275788, -2.7966988), (-2.5920815, -2.8630967), (-1.8046582, -1.0386751), (-1.7401537, -0.97227865), (-2.5275753, -2.796701), (-2.5920818, -2.8630986), (-1.8046637, -1.0386765), (-1.740158, -0.9722765), (-2.5275755, -2.796697), (-2.5920765, -2.8630977), (-1.804655, -1.0386791), (-1.7401568, -0.9722807), (-2.5275826, -2.7966998), (-2.5920813, -2.8630953), (-1.8046539, -1.0386732), (-1.7401533, -0.972279), (-2.5275798, -2.7967033), (-2.592079, -2.863097), (-1.8046541, -1.0386728), (-1.7401567, -0.97227925), (-2.527582, -2.7967036), (-2.592079, -2.8630972), (-1.8046516, -1.0386723), (-1.7401547, -0.9722782), (-2.5275824, -2.7967029), (-2.592081, -2.8630967), (-1.8046546, -1.0386716), (-1.7401556, -0.97227776), (-2.5275838, -2.7967033), (-2.5920832, -2.8630977), (-1.8046535, -1.0386708), (-1.7401527, -0.97227615), (-2.5275815, -2.7967036), (-2.5920815, -2.863098), (-1.8046545, -1.0386708), (-1.7401569, -0.972276), (-2.5275843, -2.7967026), (-2.592082, -2.8630967), (-1.8046551, -1.0386701), (-1.7401568, -0.9722763), (-2.5275817, -2.796703), (-2.5920796, -2.863097), (-1.8046545, -1.0386704), (-1.7401569, -0.9722778), (-2.5275834, -2.796704), (-2.592082, -2.8630981), (-1.8046558, -1.0386726), (-1.7401568, -0.9722777), (-2.5275824, -2.7967024), (-2.5920813, -2.8630972), (-1.8046551, -1.0386729), (-1.7401555, -0.9722774), (-2.527581, -2.7967017), (-2.5920827, -2.8630977), (-1.8046576, -1.0386739), (-1.7401541, -0.9722781), (-2.5275798, -2.796702), (-2.592081, -2.8630977), (-1.804653, -1.0386736), (-1.7401546, -0.97227824), (-2.5275831, -2.7967029), (-2.5920799, -2.8630965), (-1.8046515, -1.0386708), (-1.740153, -0.9722789), (-2.527581, -2.7967064), (-2.59208, -2.8630986), (-1.8046544, -1.0386709), (-1.7401577, -0.97227657), (-2.5275834, -2.7967024), (-2.5920784, -2.8630981), (-1.8046519, -1.0386738), (-1.7401575, -0.97227854), (-2.5275838, -2.7967026), (-2.5920768, -2.8630967), (-1.8046498, -1.0386733), (-1.7401572, -0.9722795), (-2.5275867, -2.7967026), (-2.592081, -2.863096), (-1.8046525, -1.0386715), (-1.7401562, -0.9722782), (-2.5275831, -2.7967036), (-2.592079, -2.863096), (-1.804653, -1.038671), (-1.7401581, -0.9722788), (-2.5275846, -2.796704), (-2.5920832, -2.863096), (-1.804657, -1.0386695), (-1.7401565, -0.9722772), (-2.5275817, -2.7967043), (-2.592081, -2.863097), (-1.8046563, -1.0386701), (-1.7401593, -0.9722774), (-2.5275848, -2.7967043), (-2.592079, -2.8630977), (-1.8046497, -1.038672), (-1.7401547, -0.9722786), (-2.5275843, -2.7967038), (-2.5920815, -2.8630974), (-1.8046533, -1.0386726), (-1.7401551, -0.97227836), (-2.52758, -2.7967038), (-2.592076, -2.8630986), (-1.8046508, -1.038673), (-1.7401543, -0.97227794), (-2.5275834, -2.7967026), (-2.5920837, -2.863098), (-1.8046553, -1.0386729), (-1.740156, -0.97227615), (-2.5275838, -2.796701), (-2.5920813, -2.863098), (-1.804653, -1.0386733), (-1.7401555, -0.97227794), (-2.5275822, -2.7967024), (-2.59208, -2.863097), (-1.8046546, -1.0386722), (-1.740157, -0.9722778), (-2.5275846, -2.796703), (-2.592082, -2.8630965), (-1.8046546, -1.0386704), (-1.7401576, -0.97227705), (-2.5275838, -2.7967038), (-2.5920796, -2.8630977), (-1.8046521, -1.0386716), (-1.7401559, -0.9722785), (-2.5275838, -2.7967048), (-2.5920804, -2.863097), (-1.8046526, -1.0386697), (-1.7401569, -0.97227687), (-2.527585, -2.7967036), (-2.5920804, -2.8630974), (-1.8046504, -1.0386714), (-1.7401541, -0.97227913), (-2.5275831, -2.7967057), (-2.5920808, -2.8630967), (-1.8046526, -1.038669), (-1.740155, -0.97227764), (-2.527583, -2.796706), (-2.59208, -2.8630989), (-1.8046542, -1.0386707), (-1.740157, -0.9722765), (-2.5275831, -2.7967036), (-2.5920796, -2.8630974), (-1.8046522, -1.0386714), (-1.740156, -0.97227794), (-2.527583, -2.7967029), (-2.5920794, -2.8630958), (-1.8046527, -1.0386701), (-1.740157, -0.97227806), (-2.5275853, -2.7967048), (-2.5920832, -2.8630972), (-1.8046564, -1.0386707), (-1.7401576, -0.9722766), (-2.5275831, -2.796702), (-2.592079, -2.8630977), (-1.8046519, -1.0386742), (-1.7401572, -0.9722796), (-2.5275853, -2.7967029), (-2.5920804, -2.8630965), (-1.8046521, -1.038672), (-1.7401558, -0.97227865), (-2.527583, -2.7967036), (-2.5920782, -2.8630974), (-1.804652, -1.0386736), (-1.74016, -0.97227967), (-2.5275881, -2.7967021), (-2.5920782, -2.863094), (-1.8046461, -1.0386716), (-1.7401534, -0.9722821), (-2.5275874, -2.7967072), (-2.5920823, -2.8630965), (-1.8046502, -1.0386685), (-1.7401532, -0.97227764), (-2.5275826, -2.7967064), (-2.5920823, -2.8630996), (-1.8046548, -1.0386715), (-1.7401553, -0.9722763), (-2.527583, -2.7967026), (-2.5920825, -2.863099), (-1.8046546, -1.0386728), (-1.7401547, -0.97227615), (-2.5275831, -2.7967017), (-2.5920818, -2.863098), (-1.8046536, -1.0386733), (-1.7401553, -0.9722779), (-2.5275812, -2.7967024), (-2.5920806, -2.8630972), (-1.8046578, -1.0386727), (-1.7401577, -0.97227705), (-2.5275793, -2.7967012), (-2.5920782, -2.863097), (-1.8046556, -1.0386742), (-1.7401571, -0.97227865), (-2.5275815, -2.796701), (-2.5920808, -2.863096), (-1.8046542, -1.0386724), (-1.7401552, -0.9722781), (-2.5275822, -2.7967029), (-2.592081, -2.8630958), (-1.8046533, -1.0386693), (-1.7401553, -0.9722767), (-2.5275855, -2.7967036), (-2.5920825, -2.8630972), (-1.8046501, -1.0386709), (-1.740152, -0.9722767), (-2.527584, -2.7967036), (-2.5920842, -2.8630981), (-1.8046532, -1.0386707), (-1.7401516, -0.9722762), (-2.5275826, -2.7967038), (-2.5920856, -2.863099), (-1.8046565, -1.0386717), (-1.7401543, -0.9722743), (-2.5275807, -2.796701), (-2.5920813, -2.863099), (-1.8046569, -1.0386745), (-1.7401582, -0.9722774), (-2.527583, -2.7966998), (-2.59208, -2.8630948), (-1.8046514, -1.0386734), (-1.7401536, -0.9722815), (-2.5275853, -2.7967052), (-2.5920856, -2.863096), (-1.8046548, -1.0386689), (-1.7401547, -0.972277), (-2.527583, -2.7967052), (-2.5920799, -2.8630981), (-1.8046532, -1.0386711), (-1.7401552, -0.97227776), (-2.5275798, -2.796704), (-2.5920756, -2.8630996), (-1.8046488, -1.0386751), (-1.7401562, -0.9722795), (-2.527587, -2.7967029), (-2.5920823, -2.8630955), (-1.8046509, -1.0386698), (-1.7401533, -0.97227854), (-2.5275862, -2.7967062), (-2.5920856, -2.8630977), (-1.8046536, -1.0386688), (-1.7401545, -0.9722762), (-2.5275846, -2.7967045), (-2.5920813, -2.8630984), (-1.8046513, -1.0386716), (-1.7401547, -0.97227734), (-2.5275836, -2.7967036), (-2.5920806, -2.8630986), (-1.8046529, -1.0386735), (-1.7401557, -0.9722784), (-2.527583, -2.7967024), (-2.59208, -2.8630974), (-1.8046538, -1.0386733), (-1.7401568, -0.9722784), (-2.5275831, -2.7967026), (-2.5920799, -2.8630967), (-1.8046509, -1.0386722), (-1.7401533, -0.9722779), (-2.527584, -2.7967029), (-2.592085, -2.863097), (-1.8046541, -1.0386716), (-1.7401512, -0.97227705), (-2.5275793, -2.7967026), (-2.5920823, -2.8630984), (-1.8046585, -1.038674), (-1.7401572, -0.972277), (-2.5275805, -2.7966998), (-2.5920808, -2.8630972), (-1.8046589, -1.038675), (-1.7401607, -0.97227764), (-2.5275836, -2.7966993), (-2.5920794, -2.8630948), (-1.8046527, -1.0386741), (-1.7401583, -0.97228146), (-2.527588, -2.796704), (-2.5920808, -2.8630948), (-1.8046484, -1.03867), (-1.7401526, -0.97227997), (-2.5275855, -2.796707), (-2.5920827, -2.8630965), (-1.8046488, -1.0386676), (-1.7401524, -0.97227734), (-2.5275862, -2.7967072), (-2.5920837, -2.8630981), (-1.804652, -1.038668), (-1.740154, -0.97227526), (-2.5275838, -2.7967048), (-2.5920818, -2.8630993), (-1.8046532, -1.0386719), (-1.7401544, -0.9722768), (-2.5275815, -2.7967038), (-2.5920784, -2.8630998), (-1.8046519, -1.0386742), (-1.7401553, -0.97227806), (-2.527582, -2.7967021), (-2.5920784, -2.8630974), (-1.804654, -1.0386739), (-1.7401601, -0.972279), (-2.527587, -2.7967014), (-2.5920813, -2.8630939), (-1.804652, -1.0386698), (-1.7401563, -0.9722792), (-2.5275857, -2.7967055), (-2.592082, -2.8630962), (-1.8046523, -1.0386685), (-1.7401569, -0.972277), (-2.5275867, -2.7967048), (-2.5920825, -2.863098), (-1.8046534, -1.0386703), (-1.7401558, -0.97227657), (-2.5275838, -2.7967033), (-2.5920808, -2.8630972), (-1.8046513, -1.0386714), (-1.7401534, -0.9722795), (-2.5275815, -2.7967057), (-2.5920806, -2.863097), (-1.8046541, -1.0386697), (-1.7401545, -0.97227806), (-2.52758, -2.796706), (-2.5920792, -2.863098), (-1.8046551, -1.0386702), (-1.7401569, -0.9722766), (-2.527582, -2.7967033), (-2.5920782, -2.863097), (-1.804651, -1.0386713), (-1.7401567, -0.9722791), (-2.5275862, -2.7967052), (-2.5920827, -2.8630974), (-1.8046545, -1.0386698), (-1.740156, -0.97227746), (-2.5275817, -2.7967052), (-2.5920794, -2.8630974), (-1.8046528, -1.0386704), (-1.7401553, -0.97227836), (-2.5275822, -2.796705), (-2.59208, -2.8630972), (-1.804653, -1.0386703), (-1.7401547, -0.97227734), (-2.5275826, -2.796704), (-2.5920813, -2.863097), (-1.8046552, -1.0386701), (-1.7401576, -0.9722772), (-2.5275831, -2.7967043), (-2.59208, -2.8630972), (-1.8046541, -1.0386704), (-1.7401575, -0.9722772), (-2.527584, -2.796704), (-2.5920815, -2.863097), (-1.804656, -1.0386702), (-1.7401577, -0.9722773), (-2.5275826, -2.7967038), (-2.5920782, -2.8630981), (-1.8046516, -1.0386727), (-1.740156, -0.9722775), (-2.527584, -2.7967024), (-2.59208, -2.8630972), (-1.8046505, -1.0386726), (-1.7401536, -0.9722782), (-2.5275824, -2.7967033), (-2.5920823, -2.8630981), (-1.8046571, -1.0386721), (-1.7401577, -0.9722771), (-2.5275824, -2.7967024), (-2.592079, -2.8630981), (-1.8046538, -1.038674), (-1.7401594, -0.9722778), (-2.527586, -2.7967005), (-2.59208, -2.8630958), (-1.8046514, -1.0386735), (-1.7401564, -0.97228), (-2.5275834, -2.7967033), (-2.5920775, -2.8630967), (-1.8046505, -1.0386733), (-1.7401537, -0.97227967), (-2.527582, -2.7967038), (-2.5920804, -2.8630974), (-1.8046529, -1.0386723), (-1.740156, -0.97227764), (-2.5275836, -2.7967017), (-2.5920815, -2.8630958), (-1.8046558, -1.0386724), (-1.7401584, -0.97227913), (-2.5275843, -2.7967026), (-2.5920813, -2.8630962), (-1.8046532, -1.0386717), (-1.7401549, -0.97227794), (-2.5275815, -2.7967038), (-2.5920796, -2.8630986), (-1.8046557, -1.038673), (-1.7401602, -0.97227675), (-2.5275857, -2.7967002), (-2.59208, -2.8630965), (-1.8046511, -1.0386734), (-1.7401562, -0.97227895), (-2.5275848, -2.796703), (-2.5920808, -2.8630972), (-1.804653, -1.0386721), (-1.7401551, -0.9722774), (-2.5275815, -2.7967024), (-2.5920792, -2.863098), (-1.8046542, -1.0386733), (-1.7401587, -0.97227734), (-2.5275843, -2.7967012), (-2.5920787, -2.863097), (-1.8046525, -1.0386741), (-1.7401567, -0.97227967), (-2.5275817, -2.7967026), (-2.5920782, -2.8630967), (-1.8046538, -1.0386724), (-1.7401577, -0.9722791), (-2.527582, -2.7967038), (-2.5920749, -2.8630955), (-1.8046514, -1.0386711), (-1.7401617, -0.9722794), (-2.527587, -2.796704), (-2.5920799, -2.863095), (-1.8046504, -1.0386696), (-1.7401537, -0.972279), (-2.5275865, -2.7967052), (-2.5920851, -2.8630974), (-1.8046504, -1.0386693), (-1.7401493, -0.9722773), (-2.527582, -2.7967067), (-2.5920835, -2.8631003), (-1.804656, -1.0386697), (-1.7401564, -0.9722723), (-2.5275807, -2.796701), (-2.5920784, -2.8630998), (-1.804657, -1.0386757), (-1.7401624, -0.9722778), (-2.5275855, -2.7966988), (-2.5920813, -2.8630939), (-1.8046545, -1.0386734), (-1.7401563, -0.97228044), (-2.5275831, -2.7967033), (-2.592079, -2.863096), (-1.8046522, -1.0386709), (-1.7401553, -0.9722797), (-2.5275817, -2.7967062), (-2.59208, -2.863098), (-1.8046535, -1.0386713), (-1.7401546, -0.9722776), (-2.5275803, -2.7967036), (-2.5920777, -2.8630984), (-1.8046525, -1.0386729), (-1.7401558, -0.97227806), (-2.527581, -2.7967024), (-2.5920777, -2.863097), (-1.8046538, -1.0386728), (-1.7401576, -0.9722785), (-2.527584, -2.7967024), (-2.5920827, -2.8630955), (-1.8046558, -1.0386708), (-1.7401568, -0.97227716), (-2.5275843, -2.7967026), (-2.592081, -2.8630974), (-1.8046515, -1.0386732), (-1.740154, -0.9722787), (-2.5275848, -2.7967029), (-2.5920837, -2.863097), (-1.8046509, -1.0386709), (-1.7401512, -0.97227657), (-2.5275838, -2.7967038), (-2.5920875, -2.8630974), (-1.8046588, -1.0386683), (-1.7401536, -0.97227407), (-2.527578, -2.7967036), (-2.5920808, -2.863101), (-1.804657, -1.038674), (-1.7401539, -0.97227466), (-2.527578, -2.796699), (-2.5920832, -2.863099), (-1.8046601, -1.0386771), (-1.7401568, -0.9722778), (-2.5275795, -2.7966986), (-2.5920794, -2.8630967), (-1.8046546, -1.0386757), (-1.7401536, -0.97227883), (-2.5275803, -2.7967007), (-2.5920844, -2.863097), (-1.8046575, -1.0386739), (-1.740152, -0.97227687), (-2.5275755, -2.796701), (-2.5920804, -2.863099), (-1.8046596, -1.0386759), (-1.7401583, -0.9722781), (-2.52758, -2.7967), (-2.5920784, -2.8630965), (-1.8046529, -1.0386744), (-1.7401563, -0.97227985), (-2.5275857, -2.7967029), (-2.5920818, -2.863096), (-1.8046505, -1.0386717), (-1.7401537, -0.97227955), (-2.5275853, -2.7967055), (-2.5920844, -2.863096), (-1.8046548, -1.0386683), (-1.7401547, -0.972276), (-2.5275817, -2.7967045), (-2.5920799, -2.8630986), (-1.8046545, -1.0386714), (-1.7401562, -0.97227716), (-2.527582, -2.796703), (-2.592081, -2.8630977), (-1.8046546, -1.0386729), (-1.7401544, -0.9722784), (-2.5275795, -2.7967024), (-2.5920792, -2.8630972), (-1.8046541, -1.0386735), (-1.7401569, -0.97227824), (-2.5275834, -2.7967017), (-2.5920792, -2.8630955), (-1.8046528, -1.0386717), (-1.7401565, -0.9722788), (-2.527581, -2.7967033), (-2.5920773, -2.8630972), (-1.8046552, -1.0386732), (-1.740161, -0.9722784), (-2.527585, -2.796701), (-2.5920792, -2.8630948), (-1.8046523, -1.0386723), (-1.7401555, -0.9722799), (-2.5275836, -2.796704), (-2.5920846, -2.863096), (-1.8046572, -1.0386693), (-1.7401557, -0.9722758), (-2.5275817, -2.7967033), (-2.5920813, -2.8630996), (-1.8046551, -1.038673), (-1.7401558, -0.97227705), (-2.5275817, -2.7967021), (-2.59208, -2.863098), (-1.8046552, -1.0386734), (-1.7401589, -0.9722772), (-2.5275838, -2.7967005), (-2.5920784, -2.8630958), (-1.8046516, -1.0386733), (-1.740156, -0.9722797), (-2.5275838, -2.7967036), (-2.59208, -2.8630958), (-1.8046508, -1.03867), (-1.7401531, -0.97227865), (-2.5275824, -2.7967067), (-2.5920808, -2.8630996), (-1.8046544, -1.0386715), (-1.7401558, -0.9722764), (-2.5275805, -2.796703), (-2.5920792, -2.8630993), (-1.8046551, -1.0386748), (-1.7401569, -0.972278), (-2.527581, -2.7967002), (-2.5920782, -2.8630974), (-1.8046542, -1.0386751), (-1.7401584, -0.97227865), (-2.5275831, -2.796701), (-2.5920768, -2.8630948), (-1.8046509, -1.0386724), (-1.7401587, -0.9722808), (-2.527589, -2.7967043), (-2.5920846, -2.8630948), (-1.8046521, -1.0386674), (-1.740155, -0.9722764), (-2.5275867, -2.7967057), (-2.592084, -2.8630984), (-1.8046507, -1.0386698), (-1.7401512, -0.97227645), (-2.527583, -2.796705), (-2.5920835, -2.8630986), (-1.8046528, -1.0386704), (-1.740152, -0.9722765), (-2.527582, -2.7967048), (-2.5920827, -2.8631), (-1.8046546, -1.0386726), (-1.7401532, -0.97227585), (-2.5275803, -2.7967024), (-2.5920825, -2.8630996), (-1.8046566, -1.0386746), (-1.7401545, -0.9722778), (-2.5275812, -2.7967017), (-2.5920856, -2.8630972), (-1.8046582, -1.0386728), (-1.7401506, -0.9722764), (-2.5275755, -2.7967005), (-2.592085, -2.8630996), (-1.8046632, -1.0386758), (-1.740155, -0.97227454), (-2.5275753, -2.7966971), (-2.5920804, -2.8630993), (-1.804661, -1.0386791), (-1.7401577, -0.97227746), (-2.5275772, -2.7966957), (-2.592077, -2.8630948), (-1.8046559, -1.0386777), (-1.740157, -0.9722828), (-2.5275798, -2.7967017), (-2.5920806, -2.8630943), (-1.8046567, -1.0386723), (-1.7401552, -0.97227895), (-2.5275795, -2.7967026), (-2.5920806, -2.8630972), (-1.804656, -1.0386736), (-1.7401551, -0.9722781), (-2.527579, -2.7967014), (-2.5920806, -2.863098), (-1.8046585, -1.0386745), (-1.7401563, -0.97227687), (-2.5275779, -2.7966998), (-2.592079, -2.863097), (-1.8046575, -1.0386755), (-1.7401602, -0.97227955), (-2.5275831, -2.7967), (-2.5920787, -2.8630931), (-1.8046533, -1.0386719), (-1.7401563, -0.97228056), (-2.5275838, -2.7967043), (-2.5920808, -2.863096), (-1.8046508, -1.0386703), (-1.740154, -0.9722772), (-2.5275834, -2.7967038), (-2.5920794, -2.8630977), (-1.804651, -1.038672), (-1.7401538, -0.9722775), (-2.5275826, -2.796702), (-2.5920823, -2.863097), (-1.8046557, -1.038671), (-1.740156, -0.9722754), (-2.527582, -2.7967021), (-2.5920813, -2.8630989), (-1.8046551, -1.0386739), (-1.7401593, -0.9722769), (-2.5275855, -2.7966993), (-2.5920773, -2.863095), (-1.804648, -1.0386741), (-1.7401551, -0.97228074), (-2.5275872, -2.796704), (-2.5920856, -2.8630955), (-1.8046545, -1.0386682), (-1.7401533, -0.972276), (-2.5275807, -2.7967055), (-2.5920796, -2.8630998), (-1.8046546, -1.0386715), (-1.7401564, -0.9722761), (-2.5275815, -2.7967029), (-2.5920796, -2.8630989), (-1.804655, -1.0386727), (-1.7401568, -0.97227687), (-2.527582, -2.7967017), (-2.5920792, -2.8630977), (-1.8046511, -1.0386744), (-1.7401526, -0.9722789), (-2.5275815, -2.7967021), (-2.5920823, -2.863097), (-1.8046554, -1.038673), (-1.7401564, -0.9722776), (-2.5275817, -2.7967012), (-2.5920794, -2.863097), (-1.8046528, -1.0386734), (-1.7401533, -0.97227895), (-2.5275803, -2.7967036), (-2.5920808, -2.8630981), (-1.8046578, -1.0386728), (-1.7401576, -0.9722767), (-2.5275798, -2.796701), (-2.592082, -2.8630981), (-1.8046592, -1.0386739), (-1.7401558, -0.9722757), (-2.5275786, -2.7967), (-2.592081, -2.8630984), (-1.8046577, -1.0386748), (-1.7401581, -0.97227705), (-2.5275824, -2.7966998), (-2.5920799, -2.8630967), (-1.8046538, -1.0386746), (-1.7401584, -0.9722801), (-2.5275877, -2.7967033), (-2.5920827, -2.8630953), (-1.8046508, -1.0386704), (-1.740153, -0.972279), (-2.5275836, -2.7967055), (-2.5920808, -2.8630974), (-1.8046532, -1.03867), (-1.7401549, -0.97227764), (-2.5275805, -2.7967057), (-2.5920784, -2.8630998), (-1.804651, -1.0386721), (-1.7401528, -0.9722765), (-2.5275812, -2.7967036), (-2.59208, -2.8630993), (-1.8046541, -1.0386733), (-1.7401572, -0.9722768), (-2.527583, -2.7967007), (-2.5920794, -2.8630965), (-1.804652, -1.038673), (-1.7401569, -0.9722784), (-2.527585, -2.796702), (-2.592079, -2.8630958), (-1.8046507, -1.0386714), (-1.7401564, -0.9722783), (-2.5275853, -2.7967036), (-2.5920799, -2.8630962), (-1.8046528, -1.0386711), (-1.7401582, -0.9722789), (-2.5275857, -2.7967036), (-2.592082, -2.8630955), (-1.8046553, -1.0386708), (-1.740157, -0.97227824), (-2.527582, -2.796703), (-2.592082, -2.8630972), (-1.8046577, -1.0386719), (-1.740156, -0.97227585), (-2.5275795, -2.7967012), (-2.5920823, -2.8630993), (-1.8046567, -1.038675), (-1.7401533, -0.9722763), (-2.527578, -2.7967005), (-2.5920792, -2.8630993), (-1.8046563, -1.0386759), (-1.740158, -0.9722789), (-2.5275812, -2.7967007), (-2.592077, -2.8630955), (-1.8046541, -1.0386734), (-1.7401599, -0.972279), (-2.5275836, -2.7967012), (-2.592076, -2.8630946), (-1.8046509, -1.038672), (-1.7401571, -0.9722806), (-2.527584, -2.7967052), (-2.5920796, -2.8630965), (-1.8046508, -1.03867), (-1.7401552, -0.9722785), (-2.5275846, -2.7967057), (-2.5920823, -2.8630977), (-1.8046523, -1.0386693), (-1.7401536, -0.97227603), (-2.5275838, -2.7967052), (-2.5920827, -2.863099), (-1.8046534, -1.0386707), (-1.7401522, -0.9722759), (-2.52758, -2.796703), (-2.592083, -2.8630984), (-1.8046571, -1.0386723), (-1.7401549, -0.9722775), (-2.52758, -2.796703), (-2.5920818, -2.8630984), (-1.8046557, -1.0386723), (-1.7401543, -0.97227615), (-2.527582, -2.7967017), (-2.5920825, -2.863098), (-1.8046538, -1.0386724), (-1.7401533, -0.9722769), (-2.5275812, -2.7967029), (-2.5920823, -2.8630984), (-1.8046573, -1.0386733), (-1.7401563, -0.9722759), (-2.5275815, -2.7966995), (-2.5920825, -2.863097), (-1.8046546, -1.0386742), (-1.7401545, -0.9722781), (-2.527584, -2.7967021), (-2.5920813, -2.8630958), (-1.8046503, -1.0386702), (-1.7401534, -0.9722782), (-2.5275855, -2.7967052), (-2.5920866, -2.863098), (-1.8046571, -1.0386695), (-1.7401552, -0.9722738), (-2.5275812, -2.7967012), (-2.5920806, -2.8630989), (-1.8046554, -1.0386747), (-1.7401565, -0.9722787), (-2.5275815, -2.796702), (-2.5920782, -2.863097), (-1.80465, -1.0386734), (-1.7401518, -0.9722799), (-2.5275815, -2.796705), (-2.592083, -2.8630986), (-1.8046556, -1.0386724), (-1.7401546, -0.9722762), (-2.5275803, -2.7967024), (-2.5920792, -2.8631), (-1.8046538, -1.0386748), (-1.7401556, -0.9722777), (-2.5275812, -2.7967012), (-2.5920792, -2.863097), (-1.8046559, -1.0386741), (-1.7401595, -0.9722795), (-2.5275836, -2.7967014), (-2.5920799, -2.8630943), (-1.804653, -1.0386717), (-1.7401558, -0.97227967), (-2.527584, -2.7967043), (-2.5920808, -2.863097), (-1.8046527, -1.0386711), (-1.740157, -0.9722772), (-2.5275846, -2.796703), (-2.5920813, -2.863097), (-1.8046547, -1.0386708), (-1.7401584, -0.97227645), (-2.5275848, -2.7967026), (-2.5920799, -2.8630974), (-1.8046525, -1.0386716), (-1.7401562, -0.9722782), (-2.5275831, -2.796703), (-2.5920787, -2.8630972), (-1.8046525, -1.0386735), (-1.7401596, -0.9722789), (-2.527588, -2.7967017), (-2.5920804, -2.863096), (-1.8046508, -1.0386729), (-1.7401552, -0.9722794), (-2.527583, -2.7967033), (-2.5920794, -2.863096), (-1.8046539, -1.0386709), (-1.7401584, -0.9722792), (-2.527583, -2.7967043), (-2.592077, -2.8630972), (-1.804651, -1.0386722), (-1.7401569, -0.9722788), (-2.527585, -2.796704), (-2.5920804, -2.863097), (-1.8046519, -1.0386709), (-1.7401556, -0.97227865), (-2.5275848, -2.796705), (-2.5920835, -2.8630972), (-1.8046535, -1.0386708), (-1.7401531, -0.9722782), (-2.5275822, -2.7967048), (-2.592083, -2.8630974), (-1.8046544, -1.0386705), (-1.7401543, -0.9722766), (-2.5275824, -2.7967026), (-2.5920808, -2.8630989), (-1.8046538, -1.0386742), (-1.7401569, -0.9722776), (-2.527583, -2.7967012), (-2.592078, -2.863097), (-1.8046521, -1.0386733), (-1.7401567, -0.97227865), (-2.5275815, -2.7967024), (-2.5920775, -2.8630965), (-1.804654, -1.0386735), (-1.7401596, -0.97227913), (-2.5275853, -2.796702), (-2.592079, -2.8630955), (-1.8046507, -1.0386711), (-1.7401557, -0.97227913), (-2.527586, -2.7967055), (-2.5920842, -2.8630962), (-1.8046539, -1.0386679), (-1.7401559, -0.97227573), (-2.527586, -2.7967052), (-2.5920835, -2.8630986), (-1.8046521, -1.038669), (-1.7401526, -0.972276), (-2.5275817, -2.7967055), (-2.592081, -2.8630993), (-1.8046556, -1.038671), (-1.7401575, -0.9722763), (-2.5275817, -2.7967026), (-2.592077, -2.8630984), (-1.8046517, -1.0386734), (-1.7401576, -0.9722792), (-2.5275836, -2.7967033), (-2.5920777, -2.8630955), (-1.8046517, -1.0386708), (-1.7401586, -0.9722782), (-2.5275862, -2.796703), (-2.5920796, -2.863096), (-1.8046497, -1.0386703), (-1.7401541, -0.97227824), (-2.527586, -2.7967055), (-2.5920844, -2.8630958), (-1.8046538, -1.038667), (-1.7401549, -0.9722778), (-2.5275824, -2.7967083), (-2.592078, -2.8631), (-1.8046516, -1.0386713), (-1.7401572, -0.9722774), (-2.5275853, -2.7967033), (-2.5920804, -2.863097), (-1.8046503, -1.038671), (-1.7401547, -0.97227764), (-2.527585, -2.796704), (-2.5920806, -2.8630981), (-1.804652, -1.0386716), (-1.7401558, -0.9722771), (-2.5275834, -2.7967029), (-2.5920808, -2.863098), (-1.8046559, -1.0386723), (-1.7401589, -0.9722765), (-2.5275838, -2.7967007), (-2.5920794, -2.8630965), (-1.8046535, -1.0386739), (-1.740159, -0.9722793), (-2.5275846, -2.7967026), (-2.5920775, -2.8630958), (-1.8046508, -1.038671), (-1.7401575, -0.97227925), (-2.5275848, -2.7967043), (-2.5920792, -2.8630965), (-1.8046525, -1.0386716), (-1.7401575, -0.9722788), (-2.5275831, -2.796703), (-2.5920777, -2.8630967), (-1.8046519, -1.0386733), (-1.74016, -0.97227955), (-2.5275881, -2.7967029), (-2.5920813, -2.8630953), (-1.8046519, -1.0386705), (-1.7401556, -0.9722787), (-2.5275834, -2.7967052), (-2.59208, -2.863098), (-1.8046541, -1.0386709), (-1.7401578, -0.97227657), (-2.5275831, -2.7967026), (-2.5920782, -2.8630981), (-1.8046519, -1.038673), (-1.740156, -0.97227883), (-2.5275836, -2.796704), (-2.5920804, -2.863097), (-1.8046517, -1.038671), (-1.7401541, -0.9722777), (-2.527582, -2.7967043), (-2.592077, -2.863098), (-1.8046513, -1.038672), (-1.7401583, -0.9722775), (-2.5275853, -2.7967014), (-2.5920796, -2.8630962), (-1.804652, -1.0386736), (-1.7401593, -0.9722799), (-2.5275865, -2.7967024), (-2.5920777, -2.8630953), (-1.8046523, -1.0386729), (-1.740159, -0.97228056), (-2.5275843, -2.7967036), (-2.5920787, -2.8630962), (-1.8046516, -1.038672), (-1.7401565, -0.97227883), (-2.527583, -2.7967038), (-2.592077, -2.8630955), (-1.8046522, -1.038671), (-1.7401612, -0.9722793), (-2.5275886, -2.7967036), (-2.59208, -2.8630958), (-1.8046482, -1.0386697), (-1.7401559, -0.9722793), (-2.527589, -2.7967074), (-2.5920835, -2.8630955), (-1.8046527, -1.0386655), (-1.7401581, -0.9722767), (-2.5275874, -2.7967074), (-2.5920792, -2.8630974), (-1.8046467, -1.0386676), (-1.7401563, -0.9722788), (-2.5275881, -2.7967086), (-2.592077, -2.863097), (-1.8046434, -1.038667), (-1.7401545, -0.9722794), (-2.5275924, -2.796711), (-2.5920844, -2.863097), (-1.8046463, -1.0386628), (-1.7401514, -0.9722767), (-2.527587, -2.7967114), (-2.5920832, -2.8630998), (-1.8046504, -1.0386664), (-1.7401536, -0.97227544), (-2.527585, -2.7967074), (-2.5920827, -2.8631005), (-1.8046525, -1.038669), (-1.7401556, -0.972274), (-2.527585, -2.7967038), (-2.5920832, -2.8630984), (-1.8046546, -1.0386709), (-1.7401546, -0.9722757), (-2.5275824, -2.7967024), (-2.5920806, -2.8630989), (-1.8046534, -1.0386739), (-1.7401575, -0.9722777), (-2.5275836, -2.796702), (-2.5920784, -2.8630967), (-1.804652, -1.0386728), (-1.7401564, -0.9722793), (-2.527583, -2.7967026), (-2.5920799, -2.8630967), (-1.8046526, -1.038673), (-1.7401538, -0.9722786), (-2.5275838, -2.7967026), (-2.5920827, -2.8630967), (-1.8046507, -1.0386715), (-1.7401526, -0.97227746), (-2.5275855, -2.7967036), (-2.592084, -2.863097), (-1.8046521, -1.0386713), (-1.7401527, -0.9722778), (-2.5275836, -2.7967036), (-2.5920832, -2.8630967), (-1.8046527, -1.0386708), (-1.7401532, -0.9722777), (-2.527583, -2.796705), (-2.592083, -2.8630986), (-1.8046546, -1.0386709), (-1.7401546, -0.9722756), (-2.5275824, -2.7967024), (-2.5920818, -2.8630989), (-1.8046554, -1.0386733), (-1.7401577, -0.97227657), (-2.5275846, -2.7967005), (-2.5920823, -2.8630965), (-1.8046536, -1.038673), (-1.7401531, -0.97227806), (-2.5275815, -2.7967021), (-2.5920825, -2.863097), (-1.8046538, -1.0386723), (-1.7401534, -0.97227764), (-2.5275812, -2.7967021), (-2.5920808, -2.863097), (-1.8046541, -1.038673), (-1.7401564, -0.97227776), (-2.5275834, -2.7967021), (-2.5920799, -2.8630974), (-1.8046517, -1.038673), (-1.7401547, -0.97227937), (-2.5275846, -2.796704), (-2.5920818, -2.863097), (-1.8046522, -1.0386709), (-1.7401546, -0.9722776), (-2.527583, -2.796704), (-2.5920813, -2.8630972), (-1.8046551, -1.0386703), (-1.7401575, -0.9722774), (-2.5275836, -2.7967038), (-2.592081, -2.8630984), (-1.8046539, -1.0386721), (-1.7401563, -0.9722776), (-2.5275831, -2.7967036), (-2.5920806, -2.863098), (-1.8046542, -1.0386724), (-1.7401563, -0.9722768), (-2.5275822, -2.7967014), (-2.5920787, -2.8630972), (-1.8046523, -1.0386745), (-1.7401567, -0.97227985), (-2.527583, -2.7967026), (-2.592079, -2.8630967), (-1.8046538, -1.0386732), (-1.7401594, -0.9722787), (-2.5275848, -2.7967021), (-2.592078, -2.8630965), (-1.8046517, -1.038673), (-1.7401575, -0.9722795), (-2.5275824, -2.7967038), (-2.592075, -2.863096), (-1.8046511, -1.0386715), (-1.7401612, -0.9722799), (-2.5275862, -2.7967036), (-2.592077, -2.863095), (-1.8046523, -1.0386703), (-1.7401608, -0.97227913), (-2.5275881, -2.796705), (-2.5920813, -2.8630939), (-1.8046508, -1.0386666), (-1.7401571, -0.9722799), (-2.5275877, -2.7967093), (-2.5920787, -2.8630974), (-1.8046479, -1.0386668), (-1.7401582, -0.97227836), (-2.527589, -2.796709), (-2.5920784, -2.8630974), (-1.8046466, -1.0386667), (-1.740158, -0.97227776), (-2.5275903, -2.7967083), (-2.5920792, -2.8630967), (-1.8046448, -1.0386658), (-1.7401539, -0.9722781), (-2.5275893, -2.7967095), (-2.5920815, -2.863097), (-1.8046472, -1.0386649), (-1.7401555, -0.97227776), (-2.527589, -2.79671), (-2.59208, -2.8630981), (-1.8046471, -1.0386661), (-1.740156, -0.972277), (-2.527589, -2.7967086), (-2.5920799, -2.8630989), (-1.8046473, -1.038668), (-1.7401559, -0.9722781), (-2.5275874, -2.7967079), (-2.5920815, -2.8630967), (-1.8046503, -1.0386672), (-1.7401528, -0.9722765), (-2.5275826, -2.7967055), (-2.592081, -2.8630986), (-1.804654, -1.0386716), (-1.7401568, -0.97227705), (-2.5275836, -2.7967024), (-2.5920813, -2.863098), (-1.8046546, -1.038673), (-1.7401595, -0.97227746), (-2.5275884, -2.796701), (-2.5920813, -2.8630939), (-1.8046491, -1.0386703), (-1.740153, -0.9722793), (-2.5275857, -2.7967057), (-2.5920842, -2.8630972), (-1.8046497, -1.0386683), (-1.7401501, -0.97227675), (-2.5275836, -2.7967062), (-2.592084, -2.8630996), (-1.8046545, -1.0386708), (-1.7401539, -0.9722756), (-2.5275817, -2.7967026), (-2.592082, -2.8630989), (-1.8046558, -1.0386738), (-1.7401563, -0.97227734), (-2.5275805, -2.7967007), (-2.592079, -2.863098), (-1.8046535, -1.0386761), (-1.7401552, -0.9722795), (-2.5275803, -2.796701), (-2.5920799, -2.8630967), (-1.8046556, -1.0386745), (-1.7401565, -0.9722784), (-2.5275815, -2.7967007), (-2.592079, -2.8630953), (-1.8046545, -1.0386727), (-1.7401563, -0.97227836), (-2.5275807, -2.7967021), (-2.592081, -2.8630977), (-1.8046571, -1.038674), (-1.7401541, -0.9722776), (-2.5275788, -2.7967005), (-2.5920844, -2.8630972), (-1.8046598, -1.0386748), (-1.7401537, -0.9722775), (-2.5275776, -2.7966993), (-2.5920832, -2.863098), (-1.8046594, -1.0386751), (-1.7401556, -0.97227645), (-2.5275803, -2.7966993), (-2.592082, -2.8630972), (-1.8046577, -1.0386744), (-1.7401553, -0.97227716), (-2.5275788, -2.7967007), (-2.5920799, -2.8630984), (-1.8046557, -1.0386751), (-1.7401541, -0.9722776), (-2.527579, -2.7967005), (-2.5920813, -2.8630974), (-1.8046557, -1.0386754), (-1.7401549, -0.9722788), (-2.527581, -2.7967005), (-2.5920837, -2.8630965), (-1.8046569, -1.0386736), (-1.7401519, -0.97227776), (-2.5275779, -2.796702), (-2.5920837, -2.863099), (-1.8046596, -1.0386744), (-1.7401541, -0.9722755), (-2.5275764, -2.7967), (-2.5920799, -2.8630986), (-1.8046587, -1.0386754), (-1.7401586, -0.9722777), (-2.5275812, -2.7966995), (-2.5920804, -2.8630955), (-1.8046545, -1.038673), (-1.740155, -0.9722781), (-2.527581, -2.7967024), (-2.5920782, -2.8630972), (-1.8046515, -1.0386726), (-1.7401552, -0.97227937), (-2.5275846, -2.7967048), (-2.5920844, -2.8630955), (-1.8046557, -1.0386678), (-1.7401549, -0.97227687), (-2.527583, -2.7967052), (-2.5920823, -2.8630981), (-1.8046528, -1.0386695), (-1.7401539, -0.97227615), (-2.5275843, -2.7967045), (-2.5920846, -2.863098), (-1.8046558, -1.0386703), (-1.740154, -0.97227556), (-2.5275803, -2.7967029), (-2.592079, -2.8630996), (-1.8046533, -1.0386751), (-1.7401583, -0.9722785), (-2.5275846, -2.7967014), (-2.5920782, -2.863096), (-1.8046507, -1.0386728), (-1.7401568, -0.9722802), (-2.527588, -2.796704), (-2.5920813, -2.8630955), (-1.8046466, -1.0386698), (-1.7401518, -0.9722795), (-2.5275884, -2.796708), (-2.592086, -2.8630974), (-1.8046507, -1.0386655), (-1.7401539, -0.97227556), (-2.5275874, -2.7967083), (-2.5920827, -2.8631), (-1.8046484, -1.0386685), (-1.7401513, -0.9722758), (-2.5275834, -2.7967064), (-2.5920818, -2.8631005), (-1.8046529, -1.0386709), (-1.7401547, -0.9722749), (-2.5275836, -2.7967029), (-2.5920806, -2.8630996), (-1.8046527, -1.0386735), (-1.7401592, -0.97227746), (-2.5275877, -2.7967017), (-2.5920796, -2.8630962), (-1.8046483, -1.0386722), (-1.740152, -0.972279), (-2.5275857, -2.796705), (-2.592087, -2.8630977), (-1.804655, -1.0386688), (-1.7401531, -0.9722751), (-2.527582, -2.7967045), (-2.5920806, -2.8631005), (-1.8046521, -1.0386724), (-1.7401536, -0.972276), (-2.527583, -2.7967029), (-2.5920844, -2.8630986), (-1.804656, -1.0386726), (-1.7401531, -0.9722765), (-2.5275767, -2.7967024), (-2.592079, -2.8630996), (-1.8046602, -1.0386751), (-1.7401606, -0.9722767), (-2.5275793, -2.7966974), (-2.5920765, -2.8630958), (-1.8046559, -1.0386775), (-1.7401601, -0.97228116), (-2.5275824, -2.7966995), (-2.592078, -2.8630939), (-1.8046545, -1.0386736), (-1.7401588, -0.97228), (-2.5275843, -2.7967017), (-2.5920796, -2.8630946), (-1.8046505, -1.0386721), (-1.7401534, -0.9722802), (-2.527582, -2.7967052), (-2.592081, -2.8630972), (-1.8046541, -1.0386704), (-1.7401558, -0.97227657), (-2.527584, -2.7967024), (-2.5920808, -2.8630977), (-1.8046527, -1.0386724), (-1.7401557, -0.9722776), (-2.5275857, -2.796703), (-2.5920842, -2.8630965), (-1.804653, -1.0386702), (-1.7401521, -0.9722769), (-2.5275803, -2.7967045), (-2.5920806, -2.8631), (-1.8046553, -1.0386721), (-1.7401568, -0.9722751), (-2.527582, -2.7967017), (-2.5920808, -2.863098), (-1.8046553, -1.0386724), (-1.7401564, -0.97227746), (-2.5275817, -2.7967024), (-2.5920792, -2.8630967), (-1.8046509, -1.0386723), (-1.7401538, -0.9722792), (-2.5275853, -2.7967045), (-2.592086, -2.8630965), (-1.804654, -1.0386686), (-1.740153, -0.97227585), (-2.5275838, -2.7967055), (-2.5920827, -2.8630998), (-1.8046535, -1.0386714), (-1.740153, -0.9722757), (-2.5275807, -2.7967029), (-2.592081, -2.8631), (-1.8046544, -1.0386746), (-1.7401568, -0.9722772), (-2.5275831, -2.7967012), (-2.5920782, -2.8630972), (-1.8046523, -1.0386745), (-1.7401556, -0.9722797), (-2.5275812, -2.7967029), (-2.5920796, -2.8630972), (-1.8046544, -1.0386727), (-1.7401571, -0.9722778), (-2.5275834, -2.7967024), (-2.592079, -2.8630953), (-1.8046515, -1.0386705), (-1.7401578, -0.97227836), (-2.527587, -2.796704), (-2.5920837, -2.8630955), (-1.804655, -1.0386686), (-1.7401553, -0.97227645), (-2.5275822, -2.796705), (-2.592081, -2.8630993), (-1.8046552, -1.0386715), (-1.7401572, -0.9722765), (-2.5275822, -2.7967021), (-2.5920777, -2.8630972), (-1.8046507, -1.0386728), (-1.7401558, -0.9722795), (-2.5275855, -2.7967043), (-2.5920818, -2.863097), (-1.8046498, -1.0386703), (-1.7401521, -0.97227734), (-2.5275846, -2.7967045), (-2.5920858, -2.8630974), (-1.8046565, -1.0386689), (-1.7401534, -0.9722748), (-2.52758, -2.7967033), (-2.5920799, -2.8631003), (-1.8046542, -1.038675), (-1.7401563, -0.9722768), (-2.527582, -2.7966995), (-2.5920796, -2.863096), (-1.8046542, -1.038674), (-1.7401574, -0.9722795), (-2.5275812, -2.796702), (-2.5920775, -2.8630962), (-1.8046526, -1.0386735), (-1.7401576, -0.9722791), (-2.527585, -2.796702), (-2.59208, -2.8630958), (-1.8046525, -1.0386723), (-1.7401569, -0.9722801), (-2.5275865, -2.796704), (-2.5920835, -2.8630955), (-1.8046519, -1.0386692), (-1.7401539, -0.9722773), (-2.5275834, -2.7967055), (-2.592081, -2.8630984), (-1.8046536, -1.0386709), (-1.7401564, -0.9722766), (-2.5275836, -2.7967029), (-2.5920794, -2.8630965), (-1.8046496, -1.0386705), (-1.7401538, -0.97227854), (-2.5275855, -2.7967057), (-2.5920837, -2.8630981), (-1.804653, -1.0386704), (-1.7401532, -0.9722766), (-2.5275815, -2.7967033), (-2.59208, -2.8630989), (-1.8046538, -1.0386742), (-1.7401571, -0.97227806), (-2.5275843, -2.7967014), (-2.5920808, -2.8630967), (-1.8046534, -1.038673), (-1.7401576, -0.9722774), (-2.527585, -2.7967017), (-2.5920796, -2.863097), (-1.8046509, -1.0386723), (-1.7401553, -0.9722788), (-2.527585, -2.7967036), (-2.5920837, -2.8630972), (-1.8046538, -1.0386722), (-1.7401533, -0.9722784), (-2.5275824, -2.796704), (-2.5920804, -2.8630974), (-1.8046516, -1.0386713), (-1.7401553, -0.97227913), (-2.5275846, -2.7967057), (-2.592084, -2.8630965), (-1.8046567, -1.0386688), (-1.7401562, -0.97227716), (-2.5275836, -2.796705), (-2.5920837, -2.8630981), (-1.8046541, -1.0386705), (-1.7401522, -0.9722772), (-2.5275786, -2.7967045), (-2.5920796, -2.8630996), (-1.8046552, -1.038673), (-1.7401565, -0.9722764), (-2.5275822, -2.7967017), (-2.5920792, -2.8630977), (-1.8046519, -1.0386741), (-1.740153, -0.9722796), (-2.527582, -2.7967036), (-2.5920835, -2.8630972), (-1.8046547, -1.0386721), (-1.7401539, -0.97227806), (-2.5275826, -2.7967033), (-2.5920813, -2.863098), (-1.8046528, -1.0386724), (-1.7401565, -0.97227764), (-2.527585, -2.7967026), (-2.5920818, -2.8630958), (-1.8046529, -1.0386701), (-1.7401558, -0.97227746), (-2.5275843, -2.7967038), (-2.5920827, -2.8630981), (-1.8046566, -1.038672), (-1.7401576, -0.97227675), (-2.5275822, -2.796702), (-2.5920784, -2.8630967), (-1.8046536, -1.0386733), (-1.7401606, -0.97227883), (-2.5275867, -2.7967017), (-2.5920787, -2.8630943), (-1.8046511, -1.0386709), (-1.7401583, -0.9722794), (-2.5275843, -2.7967048), (-2.5920782, -2.8630972), (-1.804653, -1.0386714), (-1.7401578, -0.97227836), (-2.5275834, -2.7967038), (-2.5920777, -2.8630972), (-1.8046519, -1.0386723), (-1.7401571, -0.9722788), (-2.5275822, -2.7967029), (-2.5920765, -2.863097), (-1.8046511, -1.0386734), (-1.740158, -0.97227985), (-2.527585, -2.7967033), (-2.5920768, -2.8630958), (-1.8046498, -1.0386701), (-1.740158, -0.9722778), (-2.5275862, -2.796704), (-2.5920787, -2.863097), (-1.8046497, -1.038671), (-1.7401567, -0.9722787), (-2.527585, -2.7967052), (-2.592081, -2.8630958), (-1.8046525, -1.0386682), (-1.7401545, -0.9722766), (-2.5275855, -2.7967055), (-2.592086, -2.8630984), (-1.8046546, -1.0386682), (-1.7401543, -0.9722744), (-2.527584, -2.7967048), (-2.592082, -2.8630998), (-1.8046534, -1.0386703), (-1.7401545, -0.97227526), (-2.5275822, -2.7967045), (-2.5920792, -2.8631008), (-1.8046521, -1.0386738), (-1.7401558, -0.9722773), (-2.5275836, -2.796702), (-2.5920806, -2.863097), (-1.8046522, -1.0386723), (-1.7401543, -0.97227824), (-2.5275817, -2.7967029), (-2.59208, -2.8630974), (-1.804656, -1.0386728), (-1.7401593, -0.972278), (-2.527584, -2.796702), (-2.5920794, -2.8630965), (-1.8046532, -1.0386739), (-1.7401587, -0.97227937), (-2.5275853, -2.7967017), (-2.5920792, -2.863095), (-1.8046505, -1.0386728), (-1.7401547, -0.9722806), (-2.5275853, -2.796704), (-2.592083, -2.8630958), (-1.8046539, -1.0386701), (-1.7401562, -0.9722777), (-2.527583, -2.7967043), (-2.5920792, -2.8630986), (-1.8046525, -1.038673), (-1.7401563, -0.97227794), (-2.5275826, -2.796702), (-2.592079, -2.863097), (-1.8046541, -1.0386742), (-1.7401594, -0.97227937), (-2.527586, -2.7967012), (-2.5920796, -2.863094), (-1.8046494, -1.0386717), (-1.7401541, -0.97227997), (-2.527584, -2.7967045), (-2.592079, -2.863097), (-1.8046504, -1.0386709), (-1.7401562, -0.97227865), (-2.5275843, -2.7967048), (-2.5920808, -2.8630967), (-1.804654, -1.0386701), (-1.7401577, -0.9722772), (-2.5275846, -2.7967043), (-2.5920806, -2.8630981), (-1.804655, -1.0386717), (-1.7401588, -0.97227687), (-2.5275838, -2.796702), (-2.5920806, -2.8630974), (-1.8046545, -1.0386735), (-1.7401578, -0.97227776), (-2.527584, -2.7967014), (-2.5920794, -2.863097), (-1.804652, -1.0386733), (-1.7401551, -0.97227865), (-2.5275815, -2.7967029), (-2.5920792, -2.8630977), (-1.8046552, -1.0386727), (-1.7401588, -0.97227734), (-2.5275826, -2.7967024), (-2.592078, -2.8630972), (-1.8046513, -1.0386728), (-1.7401563, -0.97227925), (-2.5275853, -2.7967043), (-2.5920823, -2.863096), (-1.8046528, -1.0386695), (-1.7401549, -0.9722771), (-2.527584, -2.7967043), (-2.5920804, -2.863098), (-1.8046521, -1.0386708), (-1.740157, -0.97227633), (-2.527586, -2.7967029), (-2.5920796, -2.8630981), (-1.8046502, -1.0386732), (-1.7401537, -0.97227824), (-2.5275817, -2.796703), (-2.592083, -2.8630984), (-1.8046558, -1.0386724), (-1.7401527, -0.9722766), (-2.5275793, -2.796703), (-2.592083, -2.8630993), (-1.8046583, -1.0386738), (-1.740154, -0.97227633), (-2.527578, -2.7967), (-2.5920808, -2.8630989), (-1.8046575, -1.0386773), (-1.7401575, -0.9722788), (-2.5275793, -2.7966986), (-2.5920787, -2.8630948), (-1.8046573, -1.0386752), (-1.7401593, -0.9722808), (-2.527582, -2.7967017), (-2.5920775, -2.8630943), (-1.8046521, -1.0386721), (-1.7401568, -0.97227997), (-2.5275843, -2.7967029), (-2.5920804, -2.8630958), (-1.8046503, -1.0386714), (-1.7401541, -0.97227794), (-2.5275843, -2.796703), (-2.592082, -2.8630972), (-1.8046521, -1.0386721), (-1.7401524, -0.9722777), (-2.527581, -2.796703), (-2.5920813, -2.8630977), (-1.8046565, -1.0386721), (-1.7401582, -0.97227633), (-2.527583, -2.7967002), (-2.59208, -2.8630965), (-1.8046539, -1.0386732), (-1.7401563, -0.97227883), (-2.5275826, -2.7967026), (-2.5920815, -2.8630967), (-1.8046548, -1.0386717), (-1.7401552, -0.9722768), (-2.5275834, -2.7967021), (-2.5920827, -2.8630958), (-1.8046559, -1.0386701), (-1.7401586, -0.9722777), (-2.5275838, -2.7967036), (-2.5920796, -2.8630967), (-1.8046522, -1.0386717), (-1.7401544, -0.9722779), (-2.527581, -2.7967038), (-2.5920784, -2.8630986), (-1.8046532, -1.0386732), (-1.7401556, -0.97227824), (-2.5275793, -2.7967026), (-2.5920773, -2.8630972), (-1.8046557, -1.0386729), (-1.7401601, -0.9722781), (-2.5275831, -2.7967021), (-2.5920787, -2.8630965), (-1.8046532, -1.0386727), (-1.7401563, -0.9722785), (-2.5275822, -2.7967029), (-2.5920796, -2.8630977), (-1.804654, -1.0386738), (-1.7401577, -0.9722783), (-2.5275846, -2.796701), (-2.5920804, -2.8630958), (-1.8046522, -1.0386722), (-1.7401546, -0.97227806), (-2.5275817, -2.7967026), (-2.5920813, -2.8630974), (-1.8046572, -1.0386733), (-1.7401568, -0.9722768), (-2.5275803, -2.7967002), (-2.5920808, -2.863097), (-1.8046573, -1.0386738), (-1.740157, -0.972278), (-2.5275795, -2.7967012), (-2.5920806, -2.8630977), (-1.8046589, -1.0386739), (-1.7401582, -0.9722773), (-2.5275798, -2.7967007), (-2.592077, -2.8630974), (-1.8046519, -1.0386752), (-1.7401572, -0.97227967), (-2.5275857, -2.7967026), (-2.5920808, -2.863095), (-1.8046494, -1.03867), (-1.740152, -0.9722788), (-2.5275865, -2.7967057), (-2.592085, -2.863098), (-1.8046502, -1.0386692), (-1.740151, -0.97227573), (-2.527582, -2.796705), (-2.5920827, -2.8631008), (-1.8046559, -1.0386727), (-1.740154, -0.97227484), (-2.5275798, -2.7967007), (-2.592083, -2.8630993), (-1.8046576, -1.0386755), (-1.7401534, -0.9722768), (-2.5275767, -2.7966995), (-2.5920813, -2.8630986), (-1.8046608, -1.038677), (-1.7401588, -0.9722784), (-2.5275798, -2.796698), (-2.5920796, -2.8630948), (-1.8046556, -1.0386763), (-1.7401553, -0.97228134), (-2.5275812, -2.7967026), (-2.5920808, -2.8630958), (-1.8046551, -1.0386719), (-1.7401555, -0.97227895), (-2.527581, -2.7967036), (-2.5920806, -2.863098), (-1.8046558, -1.0386723), (-1.7401563, -0.9722769), (-2.5275805, -2.7967021), (-2.5920804, -2.8630977), (-1.8046548, -1.0386738), (-1.7401555, -0.9722785), (-2.5275798, -2.796702), (-2.5920773, -2.8630974), (-1.804654, -1.0386732), (-1.7401593, -0.9722772), (-2.5275843, -2.7967002), (-2.5920768, -2.8630955), (-1.8046522, -1.0386734), (-1.7401625, -0.97227985), (-2.5275881, -2.7967026), (-2.5920787, -2.863094), (-1.8046494, -1.0386708), (-1.7401547, -0.9722802), (-2.5275848, -2.7967055), (-2.592082, -2.8630962), (-1.804653, -1.0386685), (-1.7401536, -0.97227633), (-2.5275826, -2.7967038), (-2.5920823, -2.8630986), (-1.8046552, -1.0386727), (-1.7401565, -0.9722766), (-2.5275824, -2.796701), (-2.59208, -2.8630967), (-1.8046522, -1.0386732), (-1.7401531, -0.972279), (-2.5275803, -2.7967036), (-2.592079, -2.8630974), (-1.8046521, -1.0386726), (-1.740155, -0.9722782), (-2.5275822, -2.7967029), (-2.592082, -2.8630972), (-1.8046577, -1.0386722), (-1.7401574, -0.9722771), (-2.5275807, -2.7967012), (-2.5920794, -2.863097), (-1.8046544, -1.0386732), (-1.7401581, -0.97227764), (-2.5275853, -2.7967005), (-2.592081, -2.8630953), (-1.8046538, -1.0386727), (-1.7401572, -0.9722794), (-2.5275815, -2.7967033), (-2.5920782, -2.8630965), (-1.8046553, -1.0386724), (-1.7401593, -0.9722797), (-2.5275831, -2.7967033), (-2.592079, -2.8630955), (-1.8046536, -1.0386717), (-1.7401574, -0.9722788), (-2.5275817, -2.7967029), (-2.5920775, -2.863097), (-1.8046507, -1.0386732), (-1.7401532, -0.97227865), (-2.5275822, -2.7967029), (-2.5920818, -2.8630977), (-1.8046525, -1.0386732), (-1.7401546, -0.972278), (-2.5275846, -2.7967024), (-2.5920804, -2.8630967), (-1.804652, -1.0386721), (-1.7401555, -0.9722777), (-2.5275822, -2.7967026), (-2.592081, -2.863098), (-1.8046583, -1.0386726), (-1.7401592, -0.9722763), (-2.5275817, -2.7967005), (-2.5920827, -2.8630977), (-1.8046569, -1.0386748), (-1.7401546, -0.9722776), (-2.5275807, -2.7967005), (-2.5920804, -2.8630967), (-1.8046546, -1.0386739), (-1.7401586, -0.9722796), (-2.5275848, -2.796703), (-2.5920782, -2.8630946), (-1.8046511, -1.0386698), (-1.7401568, -0.9722801), (-2.5275862, -2.796706), (-2.592082, -2.863096), (-1.8046497, -1.0386679), (-1.7401522, -0.97227764), (-2.5275846, -2.7967072), (-2.5920813, -2.863099), (-1.8046494, -1.0386705), (-1.7401526, -0.97227705), (-2.527583, -2.796704), (-2.5920799, -2.8630986), (-1.8046528, -1.0386727), (-1.7401562, -0.9722771), (-2.5275838, -2.7967021), (-2.5920808, -2.8630972), (-1.804652, -1.0386728), (-1.7401544, -0.9722784), (-2.5275846, -2.7967026), (-2.5920827, -2.8630972), (-1.8046507, -1.0386722), (-1.7401512, -0.97227716), (-2.5275846, -2.7967029), (-2.592087, -2.863098), (-1.8046561, -1.0386708), (-1.7401539, -0.9722745), (-2.5275815, -2.796702), (-2.5920818, -2.8630998), (-1.8046542, -1.0386739), (-1.7401555, -0.97227585), (-2.5275838, -2.7967014), (-2.592083, -2.8630981), (-1.8046564, -1.0386727), (-1.740157, -0.97227615), (-2.5275822, -2.7967005), (-2.5920815, -2.863097), (-1.8046557, -1.0386733), (-1.7401547, -0.9722776), (-2.5275795, -2.7967017), (-2.592082, -2.8630974), (-1.8046569, -1.0386734), (-1.7401541, -0.9722779), (-2.5275798, -2.7967012), (-2.5920818, -2.8630977), (-1.8046559, -1.0386753), (-1.740155, -0.9722792), (-2.5275815, -2.7967017), (-2.5920804, -2.8630967), (-1.804653, -1.0386732), (-1.7401528, -0.9722792), (-2.5275788, -2.7967045), (-2.5920787, -2.8630977), (-1.8046535, -1.0386711), (-1.7401563, -0.972278), (-2.5275838, -2.7967043), (-2.592082, -2.8630972), (-1.8046528, -1.0386702), (-1.740154, -0.97227734), (-2.5275838, -2.796705), (-2.5920815, -2.8630989), (-1.804653, -1.038671), (-1.7401557, -0.9722767), (-2.527585, -2.796703), (-2.5920825, -2.8630965), (-1.8046529, -1.0386704), (-1.740155, -0.9722781), (-2.5275822, -2.7967048), (-2.5920806, -2.8630984), (-1.8046547, -1.0386722), (-1.7401564, -0.9722774), (-2.5275826, -2.7967029), (-2.5920813, -2.8630981), (-1.8046551, -1.0386729), (-1.7401564, -0.97227716), (-2.5275824, -2.7967024), (-2.5920806, -2.8630981), (-1.8046566, -1.038673), (-1.7401576, -0.97227776), (-2.52758, -2.7967029), (-2.5920796, -2.8630972), (-1.8046548, -1.0386721), (-1.7401559, -0.9722777), (-2.5275824, -2.796703), (-2.5920796, -2.8630965), (-1.8046519, -1.0386698), (-1.7401563, -0.97227746), (-2.527585, -2.796705), (-2.5920813, -2.8630974), (-1.8046521, -1.0386704), (-1.7401553, -0.972278), (-2.5275857, -2.7967048), (-2.592085, -2.863097), (-1.8046535, -1.0386692), (-1.7401507, -0.9722764), (-2.5275779, -2.7967055), (-2.5920799, -2.8630993), (-1.8046561, -1.038671), (-1.7401586, -0.9722765), (-2.5275831, -2.7967024), (-2.592078, -2.8630958), (-1.8046513, -1.0386709), (-1.740157, -0.9722798), (-2.5275853, -2.7967055), (-2.5920823, -2.8630967), (-1.8046547, -1.0386701), (-1.7401551, -0.97227657), (-2.5275826, -2.7967026), (-2.5920827, -2.8630984), (-1.8046547, -1.0386734), (-1.7401538, -0.97227734), (-2.5275803, -2.796702), (-2.5920804, -2.8630977), (-1.8046541, -1.0386742), (-1.7401562, -0.9722788), (-2.527583, -2.7967014), (-2.5920784, -2.8630962), (-1.8046519, -1.0386738), (-1.7401576, -0.9722802), (-2.5275857, -2.7967043), (-2.5920804, -2.863097), (-1.8046517, -1.038671), (-1.7401555, -0.97227764), (-2.5275824, -2.7967036), (-2.592077, -2.8630981), (-1.8046515, -1.0386732), (-1.7401625, -0.9722779), (-2.527592, -2.796701), (-2.5920818, -2.8630939), (-1.8046496, -1.0386705), (-1.7401546, -0.9722801), (-2.5275843, -2.796706), (-2.5920813, -2.8630977), (-1.8046516, -1.0386709), (-1.7401538, -0.9722772), (-2.5275834, -2.796703), (-2.5920799, -2.8630981), (-1.8046538, -1.0386727), (-1.7401581, -0.97227734), (-2.5275838, -2.7967024), (-2.5920784, -2.8630972), (-1.8046521, -1.0386722), (-1.7401582, -0.97227836), (-2.5275853, -2.7967033), (-2.5920796, -2.8630958), (-1.804651, -1.0386701), (-1.740156, -0.9722787), (-2.5275843, -2.7967055), (-2.5920806, -2.8630974), (-1.8046553, -1.0386703), (-1.7401588, -0.9722769), (-2.5275836, -2.7967036), (-2.5920787, -2.8630984), (-1.8046528, -1.0386733), (-1.7401575, -0.9722781), (-2.527583, -2.7967017), (-2.592078, -2.8630962), (-1.8046533, -1.0386735), (-1.7401583, -0.97227997), (-2.5275817, -2.796703), (-2.5920768, -2.8630955), (-1.8046538, -1.0386722), (-1.7401595, -0.9722798), (-2.5275834, -2.796703), (-2.5920768, -2.8630946), (-1.8046521, -1.0386709), (-1.7401586, -0.9722794), (-2.5275831, -2.7967045), (-2.5920777, -2.8630967), (-1.8046522, -1.038671), (-1.7401568, -0.97227836), (-2.5275834, -2.7967036), (-2.5920799, -2.8630974), (-1.8046534, -1.0386727), (-1.7401564, -0.9722785), (-2.5275824, -2.7967029), (-2.592081, -2.8630977), (-1.8046582, -1.0386724), (-1.7401593, -0.9722769), (-2.5275815, -2.796702), (-2.5920799, -2.8630965), (-1.804655, -1.038672), (-1.7401568, -0.9722776), (-2.5275822, -2.796703), (-2.592079, -2.8630962), (-1.8046527, -1.03867), (-1.740157, -0.97227734), (-2.5275846, -2.7967043), (-2.5920808, -2.8630967), (-1.8046528, -1.0386695), (-1.7401557, -0.9722782), (-2.5275834, -2.7967057), (-2.5920796, -2.863098), (-1.8046536, -1.0386708), (-1.7401574, -0.9722765), (-2.5275838, -2.7967024), (-2.5920792, -2.8630974), (-1.804651, -1.038673), (-1.7401549, -0.97227854), (-2.5275824, -2.7967026), (-2.5920808, -2.8630972), (-1.8046553, -1.038673), (-1.7401583, -0.97227716), (-2.5275846, -2.7967007), (-2.5920794, -2.863097), (-1.8046513, -1.038674), (-1.7401563, -0.97227937), (-2.527586, -2.7967029), (-2.592082, -2.863097), (-1.8046521, -1.0386722), (-1.7401545, -0.9722789), (-2.527584, -2.7967043), (-2.5920815, -2.863097), (-1.8046521, -1.038671), (-1.7401541, -0.97227806), (-2.5275826, -2.7967045), (-2.5920794, -2.863098), (-1.8046515, -1.0386711), (-1.7401569, -0.9722778), (-2.527586, -2.7967045), (-2.5920835, -2.863097), (-1.8046535, -1.0386698), (-1.7401521, -0.9722778), (-2.52758, -2.7967062), (-2.5920813, -2.8630993), (-1.8046564, -1.0386707), (-1.7401575, -0.97227544), (-2.5275826, -2.7967026), (-2.5920813, -2.863099), (-1.8046554, -1.0386735), (-1.7401568, -0.9722773), (-2.5275824, -2.796701), (-2.5920784, -2.8630967), (-1.8046527, -1.0386745), (-1.7401593, -0.9722809), (-2.5275865, -2.7967036), (-2.5920799, -2.8630953), (-1.8046525, -1.038671), (-1.7401575, -0.9722795), (-2.527583, -2.7967048), (-2.5920787, -2.8630962), (-1.8046533, -1.0386708), (-1.7401574, -0.972278), (-2.5275834, -2.7967024), (-2.5920775, -2.8630962), (-1.8046504, -1.0386728), (-1.7401574, -0.97227997), (-2.5275846, -2.7967045), (-2.5920808, -2.863096), (-1.8046542, -1.0386705), (-1.7401567, -0.9722778), (-2.5275826, -2.7967033), (-2.592078, -2.8630977), (-1.8046513, -1.0386722), (-1.7401562, -0.97227865), (-2.5275822, -2.7967045), (-2.5920784, -2.8630967), (-1.8046514, -1.03867), (-1.7401551, -0.9722781), (-2.527586, -2.7967057), (-2.5920832, -2.8630984), (-1.804651, -1.0386698), (-1.7401526, -0.97227526), (-2.5275848, -2.7967036), (-2.5920856, -2.8630996), (-1.8046564, -1.0386714), (-1.7401547, -0.9722741), (-2.527581, -2.7967012), (-2.5920813, -2.8630986), (-1.8046566, -1.0386745), (-1.740158, -0.97227716), (-2.527583, -2.7967005), (-2.592081, -2.863097), (-1.8046548, -1.0386733), (-1.7401552, -0.9722776), (-2.5275826, -2.7967014), (-2.592081, -2.8630972), (-1.8046523, -1.0386734), (-1.7401544, -0.9722779), (-2.5275843, -2.7967017), (-2.5920823, -2.8630974), (-1.804651, -1.0386738), (-1.7401532, -0.9722791), (-2.5275857, -2.796703), (-2.5920842, -2.8630958), (-1.8046521, -1.0386695), (-1.7401532, -0.9722775), (-2.5275836, -2.7967057), (-2.5920818, -2.8630986), (-1.8046509, -1.0386702), (-1.7401521, -0.97227633), (-2.527583, -2.7967045), (-2.5920806, -2.8630989), (-1.8046517, -1.0386704), (-1.7401557, -0.9722755), (-2.527585, -2.7967036), (-2.5920835, -2.863099), (-1.804654, -1.0386717), (-1.7401526, -0.9722756), (-2.5275795, -2.7967029), (-2.5920813, -2.8630998), (-1.8046558, -1.0386733), (-1.7401549, -0.9722754), (-2.5275805, -2.7967014), (-2.5920808, -2.863099), (-1.8046556, -1.0386732), (-1.7401569, -0.97227573), (-2.5275836, -2.7967002), (-2.592082, -2.8630967), (-1.8046539, -1.0386738), (-1.7401563, -0.97227824), (-2.5275831, -2.7967012), (-2.592079, -2.8630962), (-1.8046522, -1.0386738), (-1.7401592, -0.9722801), (-2.527588, -2.7967026), (-2.5920806, -2.8630946), (-1.8046511, -1.0386702), (-1.7401565, -0.97227925), (-2.527585, -2.7967052), (-2.5920818, -2.8630965), (-1.8046525, -1.0386702), (-1.7401541, -0.97227746), (-2.5275822, -2.7967045), (-2.5920782, -2.8630993), (-1.8046502, -1.038673), (-1.7401527, -0.9722782), (-2.5275826, -2.7967038), (-2.592082, -2.8630981), (-1.8046538, -1.0386722), (-1.7401558, -0.9722766), (-2.5275836, -2.7967017), (-2.5920813, -2.8630977), (-1.8046508, -1.0386733), (-1.7401533, -0.97227794), (-2.5275855, -2.7967026), (-2.5920837, -2.8630974), (-1.8046542, -1.038672), (-1.7401559, -0.9722767), (-2.5275838, -2.796702), (-2.5920832, -2.8630977), (-1.804654, -1.0386733), (-1.7401558, -0.9722782), (-2.5275846, -2.7967021), (-2.5920796, -2.8630965), (-1.8046507, -1.0386719), (-1.7401555, -0.9722785), (-2.5275862, -2.7967038), (-2.592083, -2.8630965), (-1.8046511, -1.0386709), (-1.7401533, -0.9722775), (-2.5275846, -2.7967048), (-2.5920825, -2.8630981), (-1.8046541, -1.0386698), (-1.7401564, -0.9722764), (-2.5275826, -2.7967043), (-2.5920799, -2.8630981), (-1.8046544, -1.0386704), (-1.7401574, -0.97227687), (-2.5275824, -2.7967038), (-2.5920775, -2.8630981), (-1.8046514, -1.0386726), (-1.7401563, -0.97227746), (-2.5275834, -2.7967021), (-2.5920806, -2.8630974), (-1.8046536, -1.0386733), (-1.7401537, -0.9722789), (-2.5275793, -2.7967033), (-2.5920792, -2.8630972), (-1.8046536, -1.0386724), (-1.7401553, -0.97227824), (-2.527582, -2.7967029), (-2.5920818, -2.8630974), (-1.8046589, -1.0386729), (-1.7401594, -0.9722773), (-2.5275807, -2.7967007), (-2.5920787, -2.8630967), (-1.8046557, -1.0386745), (-1.7401584, -0.9722789), (-2.527584, -2.7967014), (-2.5920804, -2.8630958), (-1.8046522, -1.0386723), (-1.740155, -0.9722785), (-2.5275824, -2.796703), (-2.5920792, -2.8630972), (-1.8046536, -1.0386735), (-1.7401602, -0.97227865), (-2.5275877, -2.7967014), (-2.59208, -2.8630953), (-1.8046514, -1.0386721), (-1.7401578, -0.97227865), (-2.527586, -2.7967029), (-2.5920806, -2.863096), (-1.8046511, -1.0386711), (-1.7401555, -0.97228014), (-2.527587, -2.796706), (-2.592083, -2.8630972), (-1.8046522, -1.0386693), (-1.7401558, -0.97227705), (-2.527584, -2.7967055), (-2.59208, -2.8630986), (-1.804652, -1.0386711), (-1.740154, -0.9722776), (-2.5275817, -2.7967043), (-2.5920787, -2.8630986), (-1.8046511, -1.0386732), (-1.7401559, -0.97227895), (-2.5275843, -2.796704), (-2.5920799, -2.8630972), (-1.8046498, -1.0386711), (-1.7401543, -0.97227776), (-2.5275838, -2.7967038), (-2.5920804, -2.8630972), (-1.8046516, -1.0386711), (-1.7401556, -0.9722776), (-2.527584, -2.7967038), (-2.5920808, -2.8630984), (-1.8046538, -1.0386721), (-1.7401562, -0.9722776), (-2.5275834, -2.7967036), (-2.59208, -2.863097), (-1.8046528, -1.0386708), (-1.7401565, -0.9722774), (-2.5275846, -2.796703), (-2.5920823, -2.8630958), (-1.8046545, -1.03867), (-1.7401547, -0.97227645), (-2.5275831, -2.7967036), (-2.5920832, -2.863098), (-1.8046557, -1.0386709), (-1.7401572, -0.97227615), (-2.527583, -2.7967026), (-2.592081, -2.863098), (-1.8046556, -1.0386724), (-1.7401565, -0.97227794), (-2.5275822, -2.7967026), (-2.5920818, -2.8630972), (-1.8046538, -1.0386723), (-1.7401527, -0.97227794), (-2.5275822, -2.7967038), (-2.5920815, -2.8630984), (-1.8046534, -1.0386724), (-1.7401555, -0.9722771), (-2.5275822, -2.7967026), (-2.5920804, -2.8630984), (-1.8046546, -1.0386733), (-1.7401595, -0.9722777), (-2.5275867, -2.7967017), (-2.5920792, -2.8630962), (-1.8046485, -1.038672), (-1.740155, -0.9722796), (-2.527587, -2.796706), (-2.5920825, -2.8630967), (-1.8046496, -1.0386684), (-1.7401518, -0.9722778), (-2.527584, -2.7967072), (-2.5920808, -2.8630981), (-1.804649, -1.0386701), (-1.7401522, -0.9722776), (-2.527585, -2.7967045), (-2.5920854, -2.8630974), (-1.8046553, -1.0386698), (-1.7401526, -0.9722751), (-2.527579, -2.7967024), (-2.592081, -2.8630996), (-1.8046572, -1.0386744), (-1.7401571, -0.9722776), (-2.5275795, -2.796701), (-2.5920784, -2.8630965), (-1.8046548, -1.038674), (-1.740158, -0.9722795), (-2.5275831, -2.7967026), (-2.5920804, -2.8630962), (-1.8046548, -1.0386723), (-1.7401553, -0.97227824), (-2.527579, -2.796702), (-2.5920765, -2.8630967), (-1.8046528, -1.0386734), (-1.7401578, -0.9722789), (-2.5275853, -2.7967029), (-2.5920815, -2.8630955), (-1.8046519, -1.0386696), (-1.7401556, -0.9722771), (-2.5275846, -2.7967043), (-2.5920827, -2.8630967), (-1.8046534, -1.0386683), (-1.7401537, -0.9722764), (-2.5275848, -2.796705), (-2.5920863, -2.8630981), (-1.8046553, -1.0386692), (-1.7401531, -0.9722743), (-2.527581, -2.7967033), (-2.5920808, -2.8631), (-1.8046564, -1.0386736), (-1.7401584, -0.9722765), (-2.5275831, -2.7967007), (-2.5920804, -2.863097), (-1.8046541, -1.0386733), (-1.7401565, -0.97227883), (-2.5275815, -2.796703), (-2.5920768, -2.8630958), (-1.8046533, -1.0386707), (-1.74016, -0.9722789), (-2.527584, -2.796705), (-2.5920784, -2.8630972), (-1.8046528, -1.0386715), (-1.7401574, -0.97227895), (-2.527582, -2.7967038), (-2.5920758, -2.863097), (-1.8046504, -1.0386728), (-1.7401577, -0.97228), (-2.5275877, -2.796704), (-2.5920818, -2.8630958), (-1.804649, -1.0386702), (-1.7401522, -0.97227794), (-2.5275862, -2.7967057), (-2.592086, -2.8630977), (-1.8046542, -1.0386689), (-1.7401537, -0.97227675), (-2.5275815, -2.7967052), (-2.5920818, -2.8630993), (-1.8046551, -1.0386728), (-1.7401552, -0.9722772), (-2.5275815, -2.7967024), (-2.59208, -2.8630977), (-1.8046536, -1.0386734), (-1.7401551, -0.97227937), (-2.527583, -2.7967038), (-2.5920832, -2.8630958), (-1.8046551, -1.0386698), (-1.740153, -0.9722783), (-2.52758, -2.7967052), (-2.5920832, -2.8630974), (-1.8046566, -1.0386701), (-1.7401547, -0.9722778), (-2.527582, -2.7967052), (-2.592082, -2.863098), (-1.8046556, -1.0386702), (-1.7401556, -0.97227687), (-2.5275815, -2.7967043), (-2.5920808, -2.863099), (-1.8046551, -1.0386732), (-1.7401568, -0.9722778), (-2.5275824, -2.7967024), (-2.5920806, -2.8630967), (-1.8046541, -1.0386721), (-1.7401558, -0.97227836), (-2.5275817, -2.7967036), (-2.5920794, -2.8630974), (-1.804654, -1.0386727), (-1.7401567, -0.9722784), (-2.5275838, -2.7967026), (-2.5920818, -2.8630974), (-1.8046525, -1.0386738), (-1.7401526, -0.9722793), (-2.527583, -2.7967036), (-2.5920846, -2.8630974), (-1.8046569, -1.0386717), (-1.7401559, -0.972277), (-2.5275815, -2.7967029), (-2.5920775, -2.8630981), (-1.8046505, -1.038673), (-1.740154, -0.9722781), (-2.527582, -2.7967026), (-2.5920815, -2.863097), (-1.804656, -1.0386724), (-1.7401574, -0.9722769), (-2.5275822, -2.7967007), (-2.5920815, -2.8630965), (-1.8046554, -1.0386721), (-1.7401556, -0.9722768), (-2.5275826, -2.7967024), (-2.592082, -2.8630977), (-1.8046532, -1.0386722), (-1.7401531, -0.9722766), (-2.5275826, -2.796702), (-2.5920844, -2.8630977), (-1.804657, -1.0386726), (-1.7401536, -0.9722762), (-2.5275803, -2.7967012), (-2.5920856, -2.8630993), (-1.8046594, -1.0386742), (-1.7401532, -0.9722753), (-2.5275784, -2.7967), (-2.592083, -2.8630998), (-1.8046584, -1.0386767), (-1.7401553, -0.9722769), (-2.52758, -2.7966988), (-2.592081, -2.8630977), (-1.8046538, -1.0386761), (-1.7401538, -0.9722784), (-2.527583, -2.7967007), (-2.5920815, -2.8630965), (-1.8046519, -1.038673), (-1.7401527, -0.97227865), (-2.5275846, -2.796703), (-2.5920863, -2.863097), (-1.8046535, -1.0386707), (-1.7401489, -0.97227645), (-2.527578, -2.796704), (-2.5920835, -2.8631005), (-1.8046584, -1.0386728), (-1.7401536, -0.972274), (-2.5275764, -2.7967005), (-2.5920808, -2.8630993), (-1.80466, -1.0386754), (-1.740159, -0.9722774), (-2.5275803, -2.7966998), (-2.5920784, -2.8630958), (-1.804655, -1.0386739), (-1.740158, -0.9722793), (-2.5275836, -2.7967024), (-2.5920792, -2.8630965), (-1.8046525, -1.038673), (-1.7401549, -0.9722797), (-2.527581, -2.7967043), (-2.5920808, -2.863098), (-1.8046567, -1.0386721), (-1.7401568, -0.9722765), (-2.5275805, -2.7967007), (-2.5920796, -2.8630984), (-1.8046554, -1.038676), (-1.7401584, -0.9722782), (-2.5275831, -2.796699), (-2.5920792, -2.8630943), (-1.8046525, -1.0386733), (-1.7401569, -0.9722809), (-2.5275857, -2.796704), (-2.59208, -2.8630958), (-1.804649, -1.0386701), (-1.7401528, -0.9722787), (-2.5275862, -2.7967062), (-2.5920823, -2.863096), (-1.8046478, -1.0386672), (-1.740153, -0.97227734), (-2.5275872, -2.7967067), (-2.5920827, -2.8630981), (-1.8046495, -1.0386683), (-1.7401526, -0.97227633), (-2.527585, -2.7967067), (-2.5920825, -2.8630993), (-1.8046514, -1.0386696), (-1.7401538, -0.972276), (-2.5275857, -2.7967048), (-2.5920868, -2.8630986), (-1.8046546, -1.0386698), (-1.7401503, -0.97227395), (-2.5275798, -2.7967029), (-2.5920844, -2.8631017), (-1.8046582, -1.0386741), (-1.7401544, -0.972274), (-2.5275786, -2.796699), (-2.5920823, -2.8630989), (-1.8046603, -1.0386761), (-1.7401584, -0.9722771), (-2.527579, -2.7966988), (-2.5920784, -2.863097), (-1.8046567, -1.0386751), (-1.7401583, -0.97227824), (-2.527581, -2.7967002), (-2.5920784, -2.8630955), (-1.8046552, -1.0386735), (-1.7401572, -0.9722803), (-2.5275815, -2.7967036), (-2.5920794, -2.8630965), (-1.8046526, -1.0386714), (-1.7401547, -0.972278), (-2.5275815, -2.796704), (-2.5920784, -2.8630984), (-1.8046526, -1.0386723), (-1.740157, -0.9722781), (-2.5275836, -2.7967036), (-2.592079, -2.8630965), (-1.8046516, -1.0386705), (-1.7401567, -0.9722785), (-2.5275855, -2.796705), (-2.5920825, -2.8630962), (-1.8046535, -1.0386689), (-1.740153, -0.9722767), (-2.5275795, -2.7967045), (-2.5920796, -2.8630998), (-1.8046554, -1.0386734), (-1.7401577, -0.9722774), (-2.5275834, -2.7967017), (-2.5920806, -2.863096), (-1.8046529, -1.0386717), (-1.7401546, -0.97227794), (-2.5275836, -2.7967033), (-2.592083, -2.8630965), (-1.8046561, -1.0386705), (-1.7401574, -0.97227794), (-2.527583, -2.796704), (-2.5920794, -2.8630965), (-1.8046513, -1.03867), (-1.7401556, -0.97227836), (-2.5275838, -2.7967057), (-2.5920804, -2.863098), (-1.8046551, -1.0386709), (-1.7401589, -0.9722765), (-2.5275846, -2.7967021), (-2.5920794, -2.863097), (-1.8046511, -1.0386723), (-1.740155, -0.9722777), (-2.527582, -2.7967026), (-2.592081, -2.8630981), (-1.8046561, -1.0386729), (-1.7401568, -0.9722763), (-2.527582, -2.7967007), (-2.5920806, -2.863097), (-1.8046541, -1.0386733), (-1.7401584, -0.97227854), (-2.527588, -2.796702), (-2.5920823, -2.8630946), (-1.8046503, -1.0386708), (-1.7401525, -0.9722797), (-2.5275843, -2.7967057), (-2.5920835, -2.8630981), (-1.8046505, -1.0386696), (-1.7401502, -0.97227633), (-2.5275803, -2.7967064), (-2.592079, -2.8630998), (-1.8046523, -1.0386703), (-1.7401541, -0.9722766), (-2.5275817, -2.796704), (-2.5920792, -2.8630986), (-1.8046521, -1.038673), (-1.7401558, -0.97227794), (-2.5275822, -2.796702), (-2.5920782, -2.863097), (-1.8046527, -1.0386733), (-1.7401572, -0.97227865), (-2.527583, -2.7967021), (-2.5920799, -2.8630967), (-1.8046559, -1.038674), (-1.7401605, -0.97227925), (-2.527586, -2.7967017), (-2.5920815, -2.863095), (-1.8046558, -1.0386716), (-1.7401602, -0.97227865), (-2.5275857, -2.7967036), (-2.5920808, -2.8630965), (-1.8046521, -1.0386709), (-1.7401558, -0.9722788), (-2.527586, -2.7967052), (-2.5920835, -2.8630972), (-1.804655, -1.0386707), (-1.7401552, -0.972277), (-2.5275805, -2.796703), (-2.592078, -2.8630989), (-1.8046523, -1.0386742), (-1.7401581, -0.9722791), (-2.5275862, -2.796703), (-2.5920806, -2.8630958), (-1.8046513, -1.038671), (-1.7401553, -0.9722793), (-2.5275843, -2.7967052), (-2.5920784, -2.8630981), (-1.8046489, -1.0386719), (-1.7401547, -0.97227794), (-2.5275836, -2.796704), (-2.59208, -2.8630974), (-1.8046514, -1.0386717), (-1.7401538, -0.9722779), (-2.5275831, -2.7967029), (-2.592081, -2.8630972), (-1.804654, -1.0386721), (-1.7401571, -0.9722776), (-2.5275836, -2.7967029), (-2.5920794, -2.8630977), (-1.8046501, -1.0386734), (-1.7401549, -0.9722787), (-2.5275846, -2.7967026), (-2.59208, -2.8630967), (-1.8046519, -1.0386721), (-1.7401582, -0.9722784), (-2.5275898, -2.7967033), (-2.592084, -2.8630962), (-1.8046483, -1.0386698), (-1.7401521, -0.9722789), (-2.5275903, -2.7967074), (-2.5920908, -2.8630955), (-1.8046532, -1.0386634), (-1.7401506, -0.97227347), (-2.5275846, -2.7967072), (-2.5920846, -2.863102), (-1.8046513, -1.0386708), (-1.7401507, -0.97227407), (-2.527583, -2.7967024), (-2.5920851, -2.8630998), (-1.8046544, -1.0386735), (-1.7401514, -0.9722756), (-2.527579, -2.796701), (-2.592082, -2.8630993), (-1.8046582, -1.0386758), (-1.7401558, -0.9722769), (-2.5275798, -2.7966983), (-2.5920794, -2.8630967), (-1.8046534, -1.0386759), (-1.7401539, -0.972279), (-2.52758, -2.7967012), (-2.592079, -2.863097), (-1.8046553, -1.0386742), (-1.7401556, -0.97227865), (-2.527579, -2.796701), (-2.5920815, -2.863097), (-1.8046582, -1.0386745), (-1.7401568, -0.9722778), (-2.5275795, -2.7967002), (-2.5920782, -2.8630967), (-1.8046548, -1.0386755), (-1.7401552, -0.9722798), (-2.5275812, -2.796701), (-2.5920825, -2.8630953), (-1.8046569, -1.0386719), (-1.7401578, -0.97227776), (-2.5275822, -2.7967017), (-2.5920787, -2.8630962), (-1.804653, -1.0386728), (-1.7401572, -0.97227865), (-2.5275836, -2.7967021), (-2.592081, -2.863096), (-1.804655, -1.038673), (-1.7401572, -0.9722784), (-2.5275846, -2.796701), (-2.5920813, -2.8630955), (-1.8046532, -1.0386729), (-1.7401555, -0.9722796), (-2.5275824, -2.7967038), (-2.5920777, -2.863096), (-1.8046498, -1.0386704), (-1.7401559, -0.9722793), (-2.527586, -2.7967055), (-2.5920837, -2.8630972), (-1.8046521, -1.038669), (-1.7401522, -0.97227615), (-2.5275834, -2.7967048), (-2.592083, -2.8630981), (-1.8046554, -1.0386703), (-1.7401568, -0.9722765), (-2.5275826, -2.7967036), (-2.5920792, -2.8630972), (-1.8046507, -1.0386713), (-1.7401555, -0.9722789), (-2.5275843, -2.7967052), (-2.5920808, -2.8630974), (-1.8046527, -1.0386709), (-1.7401544, -0.97227824), (-2.5275815, -2.7967043), (-2.5920784, -2.863098), (-1.8046538, -1.0386724), (-1.7401584, -0.9722776), (-2.5275843, -2.7967014), (-2.5920813, -2.863096), (-1.8046558, -1.0386734), (-1.7401607, -0.9722788), (-2.527587, -2.7967014), (-2.5920794, -2.8630946), (-1.80465, -1.038671), (-1.7401551, -0.9722808), (-2.5275865, -2.7967062), (-2.5920842, -2.863096), (-1.8046525, -1.0386683), (-1.7401536, -0.9722774), (-2.5275826, -2.796706), (-2.5920818, -2.8630986), (-1.8046553, -1.0386709), (-1.7401563, -0.9722774), (-2.527581, -2.7967038), (-2.5920792, -2.8630984), (-1.8046538, -1.0386739), (-1.7401565, -0.9722782), (-2.5275822, -2.7967014), (-2.5920775, -2.8630967), (-1.8046514, -1.0386741), (-1.7401578, -0.9722805), (-2.5275874, -2.7967036), (-2.5920825, -2.8630953), (-1.8046511, -1.0386704), (-1.7401532, -0.97227824), (-2.5275834, -2.7967045), (-2.5920815, -2.8630989), (-1.8046534, -1.0386729), (-1.7401555, -0.9722776), (-2.527582, -2.7967026), (-2.5920792, -2.8630974), (-1.8046515, -1.038673), (-1.7401543, -0.97227854), (-2.527582, -2.7967033), (-2.5920799, -2.8630977), (-1.8046527, -1.0386728), (-1.7401549, -0.97227865), (-2.5275836, -2.7967026), (-2.592082, -2.8630967), (-1.8046546, -1.0386721), (-1.7401572, -0.97227764), (-2.5275838, -2.7967021), (-2.5920815, -2.8630965), (-1.8046554, -1.038672), (-1.7401571, -0.9722768), (-2.5275826, -2.7967014), (-2.5920804, -2.8630974), (-1.8046542, -1.0386736), (-1.7401593, -0.97227806), (-2.5275874, -2.7967012), (-2.5920804, -2.8630958), (-1.8046495, -1.0386715), (-1.7401571, -0.97227937), (-2.5275886, -2.796705), (-2.5920823, -2.8630955), (-1.8046504, -1.0386679), (-1.7401532, -0.97227734), (-2.5275836, -2.7967072), (-2.5920806, -2.8630989), (-1.8046521, -1.0386688), (-1.7401568, -0.97227484), (-2.527584, -2.7967043), (-2.5920782, -2.8630993), (-1.8046507, -1.0386728), (-1.7401555, -0.9722779), (-2.5275831, -2.7967024), (-2.592081, -2.8630974), (-1.8046542, -1.0386735), (-1.7401567, -0.97227776), (-2.5275831, -2.7967014), (-2.5920787, -2.8630972), (-1.8046523, -1.0386745), (-1.7401565, -0.9722797), (-2.5275824, -2.796702), (-2.5920777, -2.8630962), (-1.804652, -1.0386728), (-1.7401581, -0.9722791), (-2.527585, -2.796703), (-2.5920787, -2.8630948), (-1.8046516, -1.0386704), (-1.7401577, -0.97227997), (-2.5275853, -2.796706), (-2.5920796, -2.8630962), (-1.8046515, -1.0386684), (-1.7401577, -0.9722766), (-2.5275872, -2.7967045), (-2.5920815, -2.8630974), (-1.8046515, -1.0386707), (-1.7401556, -0.972277), (-2.5275848, -2.796703), (-2.5920813, -2.863097), (-1.8046523, -1.0386708), (-1.7401547, -0.9722785), (-2.5275824, -2.796705), (-2.5920804, -2.8630967), (-1.8046542, -1.03867), (-1.7401569, -0.9722779), (-2.5275836, -2.7967048), (-2.5920806, -2.863097), (-1.8046538, -1.0386704), (-1.7401562, -0.97227657)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4.7 4.7 4.7 4.7 0.  0. ]\n",
            "Time predict 10.60335373878479\n",
            "Time model 74.53663158416748\n",
            "Episode reward -2228.5139966849238\n",
            "[(0.0, 0.0), (2.9953916, 2.9953916), (5.969321, 5.969321), (8.9071045, 8.9071045), (11.848123, 11.848123), (14.800484, 14.800484), (17.737246, 17.737246), (20.657902, 20.657902), (23.611317, 23.611317), (26.57066, 26.57066), (29.418123, 29.418123), (32.103264, 32.103264), (34.632008, 34.632008), (37.01353, 37.013535), (39.254482, 39.254494), (41.360203, 41.36026), (43.33844, 43.33881), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (45.0, 45.0), (38.166454, 45.0), (31.309961, 45.0), (24.902962, 45.0), (18.921427, 45.0), (13.387801, 45.0), (8.550476, 45.0), (4.4299555, 45.0), (0.78879374, 45.0), (-2.4604504, 42.58009), (-5.405187, 35.557316), (-8.069072, 28.843195), (-10.290364, 22.604382), (-11.677735, 16.808414), (-10.603796, 11.453585), (-8.113588, 6.8014197), (-8.014453, 2.8434525), (-10.0242405, -0.68985516), (-12.274786, -3.8347366), (-14.503122, -6.666722), (-16.633585, -9.283392), (-18.653383, -11.723798), (-20.562113, -13.996415), (-22.363926, -16.080524), (-24.086058, -18.016365), (-25.742352, -19.858614), (-27.337355, -21.619371), (-28.876228, -23.306818), (-30.3409, -24.917746), (-31.673853, -26.301601), (-32.659378, -27.025137), (-32.899834, -26.806152), (-32.358067, -26.186306), (-31.500156, -26.01455), (-30.60976, -26.428585), (-29.59636, -27.05565), (-28.365582, -27.651974), (-26.996405, -28.207935), (-25.618607, -28.765865), (-24.297411, -29.321701), (-23.065102, -29.871609), (-21.945927, -30.422424), (-20.953827, -30.978184), (-20.102123, -31.53564), (-19.388683, -32.09459), (-18.791552, -32.64778), (-18.268873, -33.138596), (-17.80084, -33.530308), (-17.426634, -33.856026), (-17.181408, -34.152157), (-17.06328, -34.42624), (-17.051058, -34.66831), (-17.12554, -34.872078), (-17.276997, -35.041607), (-17.499176, -35.185352), (-17.782944, -35.309322), (-18.115723, -35.416214), (-18.487326, -35.50814), (-18.890871, -35.58821), (-19.316296, -35.659367), (-19.755283, -35.72371), (-20.201141, -35.783314), (-20.648651, -35.840816), (-21.09419, -35.89831), (-21.534836, -35.95763), (-21.96845, -36.020145), (-22.39194, -36.085655), (-22.803366, -36.153706), (-23.20006, -36.224224), (-23.579632, -36.29755), (-23.940767, -36.3743), (-24.284225, -36.454834), (-24.610456, -36.538742), (-24.91741, -36.624817), (-25.204275, -36.712143), (-25.471933, -36.800682), (-25.720804, -36.890335), (-25.950624, -36.980328), (-26.161018, -37.069614), (-26.351849, -37.157227), (-26.5227, -37.242336), (-26.67316, -37.324303), (-26.80293, -37.402496), (-26.91176, -37.47626), (-27.116762, -37.373173), (-27.557156, -36.863377), (-28.234695, -35.9987), (-29.091537, -34.994247), (-30.015478, -33.67919), (-30.92047, -31.822186), (-31.791824, -29.549166), (-32.621864, -27.008505), (-33.3996, -24.31309), (-34.110916, -21.534662), (-34.743908, -18.732237), (-35.300884, -15.97953), (-35.775894, -13.318974), (-36.139935, -10.7638035), (-36.359848, -8.359999), (-36.404922, -6.1441326), (-36.247948, -4.1521707), (-35.870743, -2.470294), (-35.27083, -1.1828948), (-34.461613, -0.33297005), (-33.46864, 0.09900516), (-32.323353, 0.18595499), (-31.060637, 0.009474398), (-29.715477, -0.3621796), (-28.31895, -0.8795633), (-26.894445, -1.5029694), (-25.457138, -2.200731), (-24.016901, -2.9584243), (-22.584595, -3.7617924), (-21.172907, -4.5933356), (-19.795063, -5.4485054), (-18.471167, -6.332482), (-17.222286, -7.233296), (-16.074797, -8.127003), (-15.054181, -8.996326), (-14.16592, -9.828338), (-13.4051285, -10.6164055), (-12.76714, -11.354415), (-12.245665, -12.044831), (-11.820418, -12.689495), (-11.462686, -13.286324), (-11.145135, -13.8381815), (-10.847947, -14.343829), (-10.5640135, -14.8044815), (-10.293083, -15.224359), (-10.040189, -15.607773), (-9.816757, -15.959401), (-9.6346445, -16.281319), (-9.497616, -16.574215), (-9.403042, -16.835133), (-9.347068, -17.062632), (-9.326455, -17.257137), (-9.337262, -17.418854), (-9.3752, -17.54827), (-9.4358, -17.645792), (-9.514637, -17.712711), (-9.606873, -17.75111), (-9.7091, -17.762972), (-9.819728, -17.750566), (-9.937154, -17.716242), (-10.059625, -17.662157), (-10.185143, -17.590292), (-10.3118105, -17.502579), (-10.437877, -17.400906), (-10.5617695, -17.286602), (-10.681517, -17.161407), (-10.796266, -17.027483), (-10.906306, -16.886375), (-11.01203, -16.739414), (-11.115599, -16.588028), (-11.220155, -16.433556), (-11.327724, -16.276146), (-11.438678, -16.115934), (-11.552465, -15.953446), (-11.667524, -15.788551), (-11.783486, -15.621454), (-11.900816, -15.452737), (-12.018782, -15.282053), (-12.136647, -15.109876), (-12.253722, -14.937624), (-12.369341, -14.765962), (-12.482675, -14.595595), (-12.592604, -14.427336), (-12.696755, -14.260985), (-12.7924, -14.0972805), (-12.8772955, -13.938098), (-12.949344, -13.7844), (-13.007385, -13.637167), (-13.051227, -13.4974785), (-13.081216, -13.3655815), (-13.097929, -13.24228), (-13.101955, -13.1288), (-13.093906, -13.025346), (-13.074567, -12.931769), (-13.04502, -12.847395), (-13.00662, -12.771258), (-12.960621, -12.702378), (-12.908046, -12.6398325), (-12.849807, -12.582791), (-12.786698, -12.530535), (-12.719345, -12.482428), (-12.64839, -12.437667), (-12.574391, -12.395706), (-12.49741, -12.356023), (-12.416036, -12.317455), (-12.328682, -12.278928), (-12.234682, -12.23987), (-12.133583, -12.200083), (-12.025264, -12.159558), (-11.909657, -12.118303), (-11.786746, -12.076272), (-11.656489, -12.033379), (-11.51879, -11.989515), (-11.373481, -11.944521), (-11.219544, -11.898222), (-11.057225, -11.850561), (-10.888792, -11.801671), (-10.718502, -11.751952), (-10.553, -11.701769), (-10.397842, -11.650654), (-10.254939, -11.597064), (-10.125053, -11.539024), (-10.008653, -11.47471), (-9.904734, -11.402117), (-9.812189, -11.320107), (-9.730126, -11.228472), (-9.657705, -11.126749), (-9.593932, -11.014736), (-9.53737, -10.892955), (-9.486122, -10.762657), (-9.43789, -10.625358), (-9.391219, -10.482569), (-9.345447, -10.334918), (-9.299639, -10.183737), (-9.253017, -10.031045), (-9.204889, -9.877758), (-9.154624, -9.724492), (-9.101848, -9.571798), (-9.046331, -9.420171), (-8.987937, -9.269052), (-8.926648, -9.118976), (-8.862486, -8.971498), (-8.79547, -8.826891), (-8.725652, -8.685198), (-8.653328, -8.546624), (-8.579004, -8.411639), (-8.503099, -8.280095), (-8.425841, -8.152518), (-8.346984, -8.029997), (-8.266756, -7.912638), (-8.185841, -7.800327), (-8.104401, -7.6928306), (-8.022493, -7.5898647), (-7.9402537, -7.491161), (-7.857861, -7.3959613), (-7.775545, -7.3041377), (-7.693569, -7.216143), (-7.61214, -7.1317406), (-7.5313835, -7.050568), (-7.451388, -6.9722815), (-7.3718348, -6.8965683), (-7.2929983, -6.823194), (-7.2156816, -6.751972), (-7.139977, -6.6826305), (-7.065766, -6.61485), (-6.99294, -6.548364), (-6.9214473, -6.4829664), (-6.8513083, -6.418117), (-6.7825174, -6.353772), (-6.715053, -6.290308), (-6.648905, -6.2276196), (-6.583974, -6.1655335), (-6.5202055, -6.1038966), (-6.457571, -6.042599), (-6.395649, -5.9815516), (-6.334539, -5.920707), (-6.2747693, -5.8600535), (-6.216299, -5.7995176), (-6.158903, -5.738967), (-6.1024146, -5.678308), (-6.0467577, -5.617508), (-5.991881, -5.5565515), (-5.9377346, -5.495426), (-5.884179, -5.433702), (-5.8307977, -5.3719063), (-5.776826, -5.3116093), (-5.721438, -5.2539115), (-5.664065, -5.1996775), (-5.6045203, -5.149549), (-5.542942, -5.1039963), (-5.4622784, -5.018344), (-5.3520565, -4.856709), (-5.244007, -4.6683254), (-5.172473, -4.5076056), (-5.137242, -4.37346), (-5.1174793, -4.234227), (-5.0994506, -4.0748568), (-5.0835805, -3.9060748), (-4.994834, -3.9329865), (-4.7848005, -4.208266), (-4.532658, -4.411698), (-4.3064847, -4.42032), (-4.1179852, -4.42899), (-3.9549522, -4.5634413), (-3.8114817, -4.6968694), (-3.686177, -4.706351), (-3.5745583, -4.6665187), (-3.5333257, -4.508149), (-3.551617, -4.2961373), (-3.5124688, -4.3572783), (-3.5441663, -4.1430945), (-3.6379647, -3.6648235), (-3.4338214, -4.1743393), (-3.4090145, -4.095439), (-3.8260405, -2.572276), (-3.6556182, -2.8817682), (-2.9014277, -4.9964743), (-2.7866545, -4.7276683), (-3.3700993, -2.1995344), (-3.3755417, -2.1525471), (-2.6911376, -4.562803), (-2.7052863, -4.4696164), (-3.4503586, -1.8439883), (-3.4127026, -1.7473944), (-2.5734675, -4.2191267), (-2.5841649, -4.113459), (-2.3921194, -1.4017609), (-0.28531215, -1.3578528), (2.6900468, -4.058819), (5.282898, -4.7228007), (6.6367297, -3.1520298), (7.615186, -3.5380642), (7.861404, -5.918999), (5.811716, -6.103397), (3.2147598, -3.8740108), (2.7589808, -1.4533577), (4.3096743, -1.2314718), (5.1806293, -3.2514775), (4.07159, -3.7320182), (2.2917554, -1.8958288), (1.6337631, -0.016654262), (2.058537, -0.09506393), (2.2947488, -1.3426604), (1.7830703, -0.99888337), (0.98705995, 0.74443775), (0.5744848, 1.2657145), (0.33322707, 0.26826218), (0.047809206, 0.28550607), (-0.22313918, 1.7627599), (-0.57940304, 2.1873503), (-0.873773, 1.1961167), (-1.0993494, 1.2041652), (-1.6577188, 2.447384), (-2.6318138, 3.1126847), (-3.2578757, 3.2432384), (-3.0499768, 3.907371), (-2.916918, 4.674906), (-3.812374, 4.36003), (-4.7129526, 3.9040325), (-4.4727516, 4.4826107), (-4.1164346, 4.932051), (-4.614113, 4.4494205), (-5.140847, 3.8859215), (-4.7623863, 4.09287), (-4.1040893, 4.4955425), (-4.1792774, 4.1176724), (-4.471643, 3.4987266), (-3.980569, 3.623836), (-3.1636775, 4.001048), (-3.0394428, 3.6393535), (-3.2164645, 2.9844902), (-2.6959455, 3.038427), (-1.8447481, 3.4054787), (-1.6820836, 3.0883048), (-1.8915681, 2.4332476), (-1.4534336, 2.433623), (-0.65408695, 2.7954216), (-0.55153126, 2.537107), (-0.9046997, 1.907836), (-0.6266032, 1.8818141), (0.06324828, 2.2490413), (0.05638007, 2.0473156), (-0.46119237, 1.4499825), (-0.35344183, 1.4031366), (0.21736991, 1.7573521), (-0.061924797, 0.81269807), (-0.5525263, -0.3963383), (0.10125318, 0.5007017), (0.4331055, 0.8074623), (-0.571554, -1.187964), (-1.0913581, -1.8533467), (-0.49497488, -0.33285728), (-0.4568791, -0.5083419), (-1.3913621, -2.764846), (-2.0001595, -3.3392084), (-1.7899132, -1.8265615), (-1.775833, -1.8560202), (-2.3964891, -3.905507), (-2.8355372, -4.5972357), (-2.6924908, -3.3004124), (-2.6640773, -2.9871674), (-3.0461895, -4.3435836), (-3.1720517, -4.7189946), (-2.8951266, -3.5569143), (-2.8725886, -3.2722898), (-3.2153273, -4.4227138), (-3.2362552, -4.7108727), (-2.8723612, -3.6600103), (-2.829473, -3.4849432), (-3.1668742, -4.58322), (-3.140905, -4.7400007), (-2.7396603, -3.6489666), (-2.6948264, -3.5629454), (-3.0150247, -4.705806), (-3.0967839, -4.6299877), (-2.8456452, -3.2971325), (-2.6004162, -3.3762434), (-2.5996659, -4.829451), (-2.9815345, -4.6201), (-3.2345688, -2.8627553), (-2.6905677, -2.9090705), (-2.0338116, -4.695578), (-2.3293092, -4.982866), (-3.4119432, -3.137715), (-3.3989491, -2.5426238), (-2.0661368, -4.1070714), (-1.5468633, -5.110758), (-2.6687012, -3.9849234), (-3.3862684, -2.672431), (-2.5258923, -3.3363094), (-1.8196139, -4.5897946), (-2.3308933, -4.216617), (-2.954114, -2.912433), (-2.7324002, -2.9967217), (-2.366067, -4.03715), (-2.3591173, -4.050985), (-2.579212, -3.0171177), (-2.8167858, -2.7797697), (-2.9011438, -3.5160532), (-2.7202303, -3.5313394), (-2.5571828, -2.6974626), (-2.779552, -2.6371408), (-3.0912871, -3.3164492), (-2.946145, -3.0935445), (-2.6198716, -2.2200568), (-2.7683852, -2.428778), (-3.1271288, -3.2434266), (-2.974833, -2.80271), (-2.589661, -1.7780435), (-2.7384045, -2.1676815), (-3.110043, -3.1631246), (-2.895111, -2.6201677), (-2.4509723, -1.4363548), (-2.6422868, -1.9119213), (-3.06043, -3.0761034), (-2.7810702, -2.4934666), (-2.2575426, -1.1560034), (-2.4797146, -1.6406244), (-2.979739, -2.9780254), (-2.6865408, -2.4396145), (-2.0696378, -0.9341829), (-2.2822378, -1.3498417), (-2.8833904, -2.8834553), (-2.6280499, -2.4596634), (-1.9166465, -0.7559534), (-2.0891259, -1.0365807), (-2.7989197, -2.7611394), (-2.6120415, -2.4936802), (-1.8098876, -0.63446337), (-1.9226279, -0.77110255), (-2.7273664, -2.621269), (-2.6181805, -2.4885504), (-1.7504597, -0.54991126), (-1.794751, -0.5799343), (-2.656505, -2.4856396), (-2.6243763, -2.433344), (-1.7328948, -0.46838138), (-1.7158828, -0.46978143), (-2.5879662, -2.4259212), (-2.6076152, -2.4091349), (-1.7228289, -0.4030667), (-1.6764923, -0.36183688), (-2.5471354, -2.337978), (-2.5932348, -2.3695765), (-1.7137648, -0.3740124), (-1.6459961, -0.30815646), (-2.5092134, -2.278082), (-2.5734, -2.336559), (-1.7042278, -0.36092976), (-1.6224346, -0.2872257), (-2.4732873, -2.2496142), (-2.541038, -2.3231108), (-1.6821804, -0.36627853), (-1.6039222, -0.29377323), (-2.4476316, -2.2489877), (-2.4748223, -2.2439594), (-1.5651237, -0.16987988), (-1.559518, -0.20181735), (-2.5188503, -2.3733678), (-2.5186555, -2.32951), (-1.5259387, -0.07636006), (-1.4944407, -0.09668596), (-2.4824195, -2.3940222), (-2.515323, -2.4048953), (-1.530379, -0.11038069), (-1.4872061, -0.10328964), (-2.4531465, -2.413372), (-2.4885805, -2.4425762), (-1.5221657, -0.15965123), (-1.4861841, -0.15879469), (-2.450917, -2.4735947), (-2.4930239, -2.5153794), (-1.5413412, -0.26465413), (-1.5095297, -0.283255), (-2.4587383, -2.5865445), (-2.5020552, -2.6403396), (-1.5868075, -0.41285354), (-1.56744, -0.4176093), (-2.4863224, -2.684875), (-2.508834, -2.7373843), (-1.6047224, -0.5486558), (-1.5979512, -0.52881604), (-2.5094783, -2.712585), (-2.5208807, -2.7793689), (-1.6136128, -0.6911805), (-1.6125978, -0.69275165), (-2.5354156, -2.8129106), (-2.5786812, -2.8996506), (-1.6872407, -0.89262354), (-1.6454867, -0.8508944), (-2.5280828, -2.8587546), (-2.6047764, -2.9851987), (-1.7647829, -1.0944581), (-1.678627, -0.99161243), (-2.4917417, -2.8599203), (-2.576861, -2.982551), (-1.7872543, -1.1709669), (-1.7061286, -1.0808251), (-2.4827507, -2.897764), (-2.557415, -2.9980958), (-1.791197, -1.210386), (-1.7255409, -1.1370602), (-2.4903212, -2.9368136), (-2.5513515, -3.0156946), (-1.7918124, -1.230761), (-1.7420318, -1.171546), (-2.50792, -2.9678748), (-2.56259, -3.028852), (-1.8024219, -1.2363517), (-1.7561308, -1.1857324), (-2.5236797, -2.986836), (-2.5757053, -3.039072), (-1.8154421, -1.2380285), (-1.7735568, -1.1891176), (-2.5431027, -2.9931526), (-2.5919218, -3.041063), (-1.8295472, -1.2346517), (-1.789994, -1.1860939), (-2.5616257, -2.9918149), (-2.6081405, -3.0368242), (-1.8424941, -1.2262889), (-1.8030945, -1.177749), (-2.5763564, -2.985254), (-2.6214247, -3.0286295), (-1.8521965, -1.2145218), (-1.8115674, -1.1654091), (-2.586041, -2.9747663), (-2.630392, -3.0177019), (-1.8577356, -1.2006088), (-1.8151549, -1.1503354), (-2.590661, -2.9613483), (-2.6350005, -3.0047007), (-1.8593062, -1.1851933), (-1.8144891, -1.1333452), (-2.5910668, -2.9457414), (-2.6360848, -2.9900532), (-1.8578265, -1.1683859), (-1.810747, -1.1146427), (-2.5885284, -2.928466), (-2.6347783, -2.9742427), (-1.854393, -1.1508732), (-1.805118, -1.0950266), (-2.5843146, -2.9098673), (-2.6322968, -2.9573264), (-1.8500868, -1.1326449), (-1.7986221, -1.0746973), (-2.5793495, -2.8904626), (-2.629411, -2.939815), (-1.8455923, -1.1140736), (-1.7919155, -1.0540295), (-2.5741954, -2.8707078), (-2.6264782, -2.9219103), (-1.8411884, -1.0952804), (-1.7853717, -1.0336293), (-2.5691445, -2.8514326), (-2.623551, -2.9044104), (-1.8367621, -1.076664), (-1.7789234, -1.0136093), (-2.5642018, -2.8331041), (-2.6205747, -2.888065), (-1.8322539, -1.0591857), (-1.7724758, -0.9947735), (-2.5592105, -2.816046), (-2.6174457, -2.8731205), (-1.8276472, -1.0433245), (-1.7659749, -0.9776676), (-2.5540125, -2.8006449), (-2.6140306, -2.859863), (-1.8229427, -1.0294048), (-1.7594723, -0.9626304), (-2.5486064, -2.7871542), (-2.610307, -2.8484752), (-1.8181877, -1.0176235), (-1.7530903, -0.9498665), (-2.543099, -2.7757149), (-2.6063488, -2.8390281), (-1.8134964, -1.0080413), (-1.7470001, -0.93944967), (-2.537682, -2.7663763), (-2.6023316, -2.831509), (-1.809023, -1.0006093), (-1.7413763, -0.93134683), (-2.5325568, -2.7591112), (-2.5984397, -2.8258507), (-1.8049331, -0.9952184), (-1.7363977, -0.92544794), (-2.5279136, -2.7538257), (-2.5948398, -2.8219395), (-1.8013519, -0.99170965), (-1.732177, -0.92159235), (-2.5238836, -2.7503903), (-2.591655, -2.8196397), (-1.7983552, -0.98991495), (-1.7287635, -0.91960365), (-2.520533, -2.7486506), (-2.5889575, -2.8188038), (-1.7959788, -0.98965305), (-1.7261616, -0.9192812), (-2.5178661, -2.7484276), (-2.5867486, -2.8192666), (-1.7942015, -0.9907412), (-1.7243356, -0.9204246), (-2.5158677, -2.7495332), (-2.5850182, -2.8208513), (-1.7929646, -0.992982), (-1.7232, -0.92282426), (-2.51448, -2.7517805), (-2.583733, -2.8233829), (-1.7922266, -0.9961738), (-1.7226815, -0.92625993), (-2.513627, -2.7549677), (-2.5828438, -2.8266811), (-1.79192, -1.0001227), (-1.7226908, -0.930512), (-2.5132456, -2.758887), (-2.5823054, -2.8305597), (-1.7919885, -1.0046315), (-1.7231622, -0.9353702), (-2.5132847, -2.763344), (-2.582078, -2.8348405), (-1.7923756, -1.0095052), (-1.7240272, -0.940621), (-2.5136967, -2.7681415), (-2.5821366, -2.8393438), (-1.7930326, -1.0145556), (-1.7252077, -0.9460741), (-2.5144255, -2.7731142), (-2.582451, -2.8439233), (-1.7939107, -1.0196187), (-1.7266325, -0.9515469), (-2.515408, -2.7780964), (-2.5829809, -2.8484397), (-1.7949709, -1.0245539), (-1.728248, -0.95688385), (-2.5166023, -2.7829463), (-2.583697, -2.8527758), (-1.7961637, -1.0292379), (-1.7299836, -0.96195203), (-2.5179465, -2.7875464), (-2.5845573, -2.8568344), (-1.7974437, -1.0335763), (-1.7317835, -0.96664745), (-2.5193903, -2.7917998), (-2.5855196, -2.8605397), (-1.7987617, -1.0374945), (-1.7335869, -0.9708922), (-2.5208778, -2.7956393), (-2.5865412, -2.8638337), (-1.8000764, -1.0409384), (-1.735341, -0.9746302), (-2.522357, -2.7990136), (-2.5875802, -2.8666828), (-1.8013444, -1.0438766), (-1.7370067, -0.97782314), (-2.5237992, -2.8018925), (-2.5886128, -2.8690658), (-1.8025353, -1.0462904), (-1.7385359, -0.9804532), (-2.5251553, -2.804262), (-2.5896118, -2.8709815), (-1.8036363, -1.0481848), (-1.7399106, -0.9825174), (-2.526396, -2.8061178), (-2.5905454, -2.8724391), (-1.8046259, -1.0495818), (-1.7411163, -0.98403716), (-2.5275035, -2.8074727), (-2.5913928, -2.8734517), (-1.8054838, -1.0505037), (-1.742143, -0.98504496), (-2.5284789, -2.8083608), (-2.5921519, -2.8740466), (-1.8062031, -1.0509795), (-1.742977, -0.9855762), (-2.529301, -2.808822), (-2.5928135, -2.8742688), (-1.8067921, -1.051053), (-1.7436322, -0.9856678), (-2.5299723, -2.8088887), (-2.5933645, -2.874158), (-1.80724, -1.0507834), (-1.7441032, -0.9853866), (-2.5304897, -2.808616), (-2.5938125, -2.8737574), (-1.8075649, -1.050213), (-1.7444078, -0.98477906), (-2.530863, -2.808049), (-2.5941596, -2.873116), (-1.8077703, -1.0494019), (-1.7445555, -0.98390645), (-2.5310946, -2.8072436), (-2.594401, -2.8722854), (-1.8078635, -1.0484041), (-1.7445697, -0.98283064), (-2.5312097, -2.8062527), (-2.5945542, -2.8713048), (-1.8078592, -1.0472637), (-1.7444576, -0.9816028), (-2.5312018, -2.80513), (-2.594612, -2.8702302), (-1.8077621, -1.046038), (-1.7442409, -0.98027873), (-2.5311003, -2.8039203), (-2.5945997, -2.8690958), (-1.8075976, -1.0447652), (-1.7439393, -0.97890383), (-2.5309093, -2.8026688), (-2.5945163, -2.8679466), (-1.8073734, -1.043493), (-1.7435776, -0.97752523), (-2.53066, -2.8014126), (-2.5943792, -2.866808), (-1.8071014, -1.0422509), (-1.7431653, -0.97618324), (-2.5303576, -2.8001935), (-2.5942001, -2.865718), (-1.8067969, -1.0410687), (-1.7427207, -0.9749021), (-2.5300124, -2.7990346), (-2.5939775, -2.864698), (-1.8064715, -1.0399768), (-1.7422665, -0.97371733), (-2.5296478, -2.7979596), (-2.5937362, -2.8637621), (-1.806144, -1.0389879), (-1.7418169, -0.972645), (-2.5292735, -2.7969875), (-2.5934753, -2.862927), (-1.8058116, -1.0381188), (-1.7413793, -0.9717046), (-2.5289085, -2.7961354), (-2.5932176, -2.8622031), (-1.8054867, -1.0373704), (-1.7409544, -0.9708957), (-2.528548, -2.795412), (-2.5929608, -2.8616037), (-1.8051873, -1.0367571), (-1.7405698, -0.9702258), (-2.5282078, -2.7948115), (-2.5927126, -2.8611195), (-1.8049139, -1.0362767), (-1.7402236, -0.9697011), (-2.5278914, -2.7943406), (-2.5924745, -2.8607519), (-1.8046657, -1.0359269), (-1.7399199, -0.9693186), (-2.5276082, -2.7939944), (-2.5922592, -2.860493), (-1.8044492, -1.0356944), (-1.7396584, -0.9690626), (-2.5273626, -2.793767), (-2.592066, -2.860339), (-1.8042631, -1.0355716), (-1.7394474, -0.96892947), (-2.5271559, -2.7936506), (-2.5919003, -2.8602805), (-1.8041157, -1.0355496), (-1.7392815, -0.96890444), (-2.5269847, -2.7936347), (-2.5917594, -2.8603067), (-1.8040001, -1.035613), (-1.739163, -0.9689728), (-2.526857, -2.7937043), (-2.5916476, -2.8604097), (-1.8039184, -1.0357563), (-1.7390836, -0.96912146), (-2.5267599, -2.793842), (-2.591561, -2.8605704), (-1.8038703, -1.0359621), (-1.7390466, -0.9693402), (-2.5266955, -2.794042), (-2.5914962, -2.8607793), (-1.803849, -1.036216), (-1.7390451, -0.9696128), (-2.526667, -2.79429), (-2.5914576, -2.8610227), (-1.8038495, -1.0365018), (-1.7390729, -0.9699224), (-2.5266683, -2.7945733), (-2.5914402, -2.8612945), (-1.8038683, -1.0368106), (-1.7391253, -0.97025573), (-2.526695, -2.7948785), (-2.5914445, -2.8615808), (-1.8039114, -1.0371314), (-1.7391989, -0.97060126), (-2.526738, -2.795193), (-2.5914629, -2.8618715), (-1.8039689, -1.037454), (-1.7392942, -0.9709496), (-2.5268056, -2.7955089), (-2.5915003, -2.8621554), (-1.8040376, -1.0377641), (-1.7393985, -0.9712882), (-2.5268855, -2.7958193), (-2.5915473, -2.8624306), (-1.8041102, -1.0380595), (-1.7395071, -0.97161204), (-2.5269723, -2.7961152), (-2.5916016, -2.8626902), (-1.8041906, -1.0383348), (-1.7396213, -0.9719098), (-2.5270636, -2.796386), (-2.5916655, -2.862927), (-1.804275, -1.0385847), (-1.7397308, -0.972179), (-2.5271537, -2.7966304), (-2.5917287, -2.8631387), (-1.8043617, -1.0388062), (-1.7398463, -0.97241753), (-2.5272472, -2.7968433), (-2.5917923, -2.8633177), (-1.8044405, -1.0389941), (-1.7399529, -0.9726237), (-2.527341, -2.7970285), (-2.5918555, -2.863472), (-1.8045123, -1.0391501), (-1.740051, -0.97279155), (-2.5274289, -2.79718), (-2.5919237, -2.8635945), (-1.8045858, -1.0392698), (-1.7401342, -0.97292143), (-2.5275056, -2.7972984), (-2.5919821, -2.8636906), (-1.8046466, -1.0393622), (-1.7402122, -0.9730194), (-2.5275762, -2.797384), (-2.5920355, -2.863754), (-1.8047029, -1.0394222), (-1.7402787, -0.9730868), (-2.5276394, -2.797442), (-2.5920854, -2.8637908), (-1.8047509, -1.0394506), (-1.7403328, -0.9731196), (-2.5276895, -2.7974722), (-2.5921283, -2.8638089), (-1.8047911, -1.0394602), (-1.7403723, -0.9731279), (-2.5277293, -2.7974768), (-2.5921626, -2.8638015), (-1.8048224, -1.039443), (-1.7404091, -0.9731106), (-2.5277646, -2.7974586), (-2.592187, -2.863775), (-1.8048366, -1.0394082), (-1.7404249, -0.97307503), (-2.5277915, -2.7974265), (-2.5922127, -2.8637345), (-1.8048509, -1.039353), (-1.7404363, -0.9730179), (-2.5278058, -2.7973764), (-2.5922246, -2.8636844), (-1.8048538, -1.0392935), (-1.7404362, -0.972951), (-2.5278163, -2.7973115), (-2.592238, -2.8636193), (-1.8048536, -1.0392184), (-1.7404274, -0.9728737), (-2.5278158, -2.7972443), (-2.592246, -2.8635535), (-1.8048509, -1.0391387), (-1.7404134, -0.9727871), (-2.5278075, -2.797168), (-2.5922415, -2.8634841), (-1.8048396, -1.0390605), (-1.7403966, -0.9727001), (-2.5277984, -2.797086), (-2.5922391, -2.8634086), (-1.8048261, -1.0389793), (-1.7403698, -0.9726127), (-2.5277767, -2.7970061), (-2.592229, -2.8633394), (-1.8048098, -1.0389036), (-1.7403452, -0.9725261), (-2.5277596, -2.796926), (-2.592219, -2.8632672), (-1.8047907, -1.0388271), (-1.7403157, -0.97244614), (-2.5277364, -2.7968543), (-2.5922027, -2.863204), (-1.8047718, -1.038758), (-1.7402949, -0.9723702), (-2.5277169, -2.7967844), (-2.5921814, -2.8631413), (-1.8047459, -1.0386951), (-1.7402656, -0.97230536), (-2.5276945, -2.7967243), (-2.5921695, -2.8630865), (-1.8047262, -1.0386361), (-1.7402345, -0.97224444), (-2.5276687, -2.7966726), (-2.5921528, -2.8630416), (-1.8047061, -1.038587), (-1.740208, -0.97219145), (-2.527645, -2.7966251), (-2.5921352, -2.863005), (-1.804686, -1.0385499), (-1.7401835, -0.9721482), (-2.5276244, -2.796587), (-2.5921195, -2.862974), (-1.8046689, -1.038519), (-1.7401632, -0.9721143), (-2.5276086, -2.7965546), (-2.5921102, -2.8629487), (-1.8046527, -1.0384959), (-1.7401389, -0.9720886), (-2.5275877, -2.7965326), (-2.592095, -2.8629332), (-1.80464, -1.0384812), (-1.7401221, -0.9720735), (-2.5275676, -2.7965198), (-2.5920799, -2.8629239), (-1.8046314, -1.0384735), (-1.7401153, -0.9720633), (-2.5275583, -2.7965093), (-2.5920675, -2.8629181), (-1.8046134, -1.0384738), (-1.7400987, -0.9720673), (-2.5275512, -2.7965128), (-2.5920627, -2.8629181), (-1.8046055, -1.038471), (-1.7400877, -0.9720672), (-2.5275397, -2.796519), (-2.592057, -2.8629298), (-1.8046061, -1.0384822), (-1.7400857, -0.9720727), (-2.5275307, -2.7965229), (-2.5920491, -2.8629403), (-1.8046081, -1.0384994), (-1.7400877, -0.9720873), (-2.5275254, -2.796532), (-2.5920439, -2.8629515), (-1.8046049, -1.0385184), (-1.7400858, -0.9721079), (-2.5275218, -2.796547), (-2.5920393, -2.8629649), (-1.8046021, -1.0385346), (-1.7400873, -0.9721283), (-2.5275269, -2.796568), (-2.5920408, -2.8629813), (-1.8046017, -1.0385501), (-1.7400892, -0.9721476), (-2.5275278, -2.7965891), (-2.5920405, -2.8630016), (-1.8046043, -1.0385717), (-1.7400916, -0.97217077), (-2.5275269, -2.7966092), (-2.5920439, -2.8630197), (-1.8046148, -1.0385916), (-1.7401018, -0.9721899), (-2.5275323, -2.7966256), (-2.5920436, -2.8630385), (-1.804613, -1.0386155), (-1.740108, -0.97221315), (-2.5275407, -2.7966444), (-2.5920453, -2.863053), (-1.8046144, -1.0386323), (-1.7401128, -0.972237), (-2.5275495, -2.796667), (-2.592056, -2.8630686), (-1.8046232, -1.0386461), (-1.7401161, -0.9722528), (-2.5275478, -2.796685), (-2.592059, -2.863089), (-1.804633, -1.0386646), (-1.7401288, -0.97226673), (-2.5275564, -2.7966971), (-2.5920599, -2.8631015), (-1.8046341, -1.0386801), (-1.740135, -0.97228426), (-2.527562, -2.7967117), (-2.5920627, -2.8631127), (-1.8046418, -1.038693), (-1.7401457, -0.9722996), (-2.5275662, -2.7967234), (-2.592063, -2.86312), (-1.8046441, -1.0387021), (-1.7401491, -0.97231144), (-2.5275698, -2.7967346), (-2.5920644, -2.8631299), (-1.8046457, -1.0387113), (-1.740157, -0.9723209), (-2.5275824, -2.7967422), (-2.5920749, -2.863133), (-1.8046476, -1.0387129), (-1.7401557, -0.97232556), (-2.5275853, -2.7967503), (-2.5920796, -2.8631396), (-1.8046528, -1.0387158), (-1.740159, -0.97232807), (-2.5275867, -2.7967534), (-2.5920825, -2.8631432), (-1.8046585, -1.0387197), (-1.7401663, -0.97233045), (-2.5275905, -2.7967532), (-2.592083, -2.8631427), (-1.8046618, -1.0387208), (-1.740173, -0.97233105), (-2.5275974, -2.796752), (-2.5920882, -2.8631413), (-1.8046623, -1.0387205), (-1.7401698, -0.9723309), (-2.5275965, -2.7967522), (-2.592091, -2.8631423), (-1.804665, -1.0387175), (-1.7401701, -0.9723258), (-2.527598, -2.796749), (-2.5920951, -2.8631384), (-1.8046671, -1.038714), (-1.7401682, -0.9723225), (-2.5275934, -2.7967455), (-2.5920887, -2.863138), (-1.8046672, -1.038715), (-1.7401755, -0.97231954), (-2.5275993, -2.7967386), (-2.5920925, -2.863131), (-1.8046674, -1.0387084), (-1.7401725, -0.97231495), (-2.527597, -2.7967362), (-2.592091, -2.8631265), (-1.8046657, -1.0387037), (-1.740171, -0.97231257), (-2.5275974, -2.7967331), (-2.5920894, -2.86312), (-1.8046603, -1.0386946), (-1.7401701, -0.97230715), (-2.5275998, -2.7967322), (-2.5920901, -2.863117), (-1.8046596, -1.038688), (-1.7401656, -0.97229826), (-2.5275967, -2.7967257), (-2.5920947, -2.8631144), (-1.804664, -1.0386832), (-1.740166, -0.97228974), (-2.5275924, -2.796718), (-2.59209, -2.8631105), (-1.8046627, -1.0386814), (-1.7401663, -0.9722867), (-2.5275967, -2.7967122), (-2.5920904, -2.8631034), (-1.8046591, -1.0386757), (-1.7401642, -0.9722829), (-2.5275943, -2.7967098), (-2.5920897, -2.8630996), (-1.8046588, -1.0386709), (-1.7401615, -0.97227937), (-2.5275922, -2.7967062), (-2.5920906, -2.8630972), (-1.8046592, -1.0386674), (-1.7401576, -0.9722732), (-2.5275853, -2.7967021), (-2.5920863, -2.8630965), (-1.8046589, -1.0386678), (-1.740157, -0.9722716), (-2.5275843, -2.7966974), (-2.5920835, -2.863092), (-1.8046544, -1.0386647), (-1.7401571, -0.97226906), (-2.5275846, -2.7966955), (-2.5920806, -2.863089), (-1.804654, -1.0386624), (-1.7401581, -0.97226894), (-2.5275857, -2.796695), (-2.592082, -2.863088), (-1.8046526, -1.0386603), (-1.7401553, -0.97226673), (-2.527585, -2.7966943), (-2.5920808, -2.863086), (-1.8046505, -1.0386579), (-1.7401562, -0.97226596), (-2.5275874, -2.7966933), (-2.59208, -2.863085), (-1.8046471, -1.038657), (-1.7401544, -0.9722665), (-2.5275865, -2.7966955), (-2.5920787, -2.8630853), (-1.8046448, -1.0386549), (-1.7401484, -0.97226465), (-2.5275834, -2.7966955), (-2.592084, -2.863087), (-1.8046492, -1.0386549), (-1.7401469, -0.9722613), (-2.52758, -2.7966926), (-2.5920844, -2.8630881), (-1.8046554, -1.038658), (-1.7401501, -0.97226125), (-2.5275748, -2.7966907), (-2.5920768, -2.8630896), (-1.8046514, -1.0386631), (-1.7401526, -0.9722641), (-2.527579, -2.7966888), (-2.5920775, -2.863088), (-1.8046517, -1.0386652), (-1.7401552, -0.97226864), (-2.5275822, -2.7966921), (-2.592078, -2.8630865), (-1.8046494, -1.038662), (-1.7401538, -0.97227), (-2.5275834, -2.796697), (-2.5920787, -2.8630886), (-1.8046476, -1.0386611), (-1.7401489, -0.9722693), (-2.527578, -2.7966988), (-2.5920784, -2.8630934), (-1.8046511, -1.0386642), (-1.7401518, -0.9722686), (-2.52758, -2.796697), (-2.5920768, -2.8630934), (-1.8046451, -1.0386668), (-1.7401469, -0.9722728), (-2.5275779, -2.7967007), (-2.592078, -2.8630958), (-1.8046511, -1.0386683), (-1.7401539, -0.9722724), (-2.5275822, -2.7966993), (-2.5920794, -2.8630943), (-1.8046501, -1.0386693), (-1.7401532, -0.9722768), (-2.5275826, -2.7967026), (-2.5920804, -2.8630965), (-1.8046538, -1.0386705), (-1.740156, -0.9722744), (-2.527582, -2.7966998), (-2.59208, -2.8630972), (-1.8046545, -1.0386735), (-1.7401541, -0.972278), (-2.5275779, -2.7967021), (-2.5920784, -2.8630974), (-1.8046532, -1.038674), (-1.7401544, -0.9722787), (-2.5275834, -2.7967026), (-2.5920818, -2.863098), (-1.8046514, -1.0386742), (-1.7401534, -0.9722801), (-2.527583, -2.7967045), (-2.5920813, -2.863099), (-1.8046527, -1.0386746), (-1.7401545, -0.9722806), (-2.5275838, -2.796706), (-2.5920815, -2.8631), (-1.8046513, -1.038674), (-1.7401534, -0.9722804), (-2.5275836, -2.7967072), (-2.5920808, -2.8631005), (-1.8046519, -1.038673), (-1.7401539, -0.97227913), (-2.5275831, -2.796707), (-2.5920832, -2.8631012), (-1.8046548, -1.0386729), (-1.740155, -0.97227836), (-2.5275803, -2.7967067), (-2.5920782, -2.863101), (-1.8046534, -1.0386741), (-1.740159, -0.9722807), (-2.527589, -2.796707), (-2.5920832, -2.8630993), (-1.8046504, -1.038672), (-1.7401536, -0.97228056), (-2.5275857, -2.7967098), (-2.5920858, -2.8631017), (-1.8046552, -1.0386714), (-1.7401527, -0.972277), (-2.5275793, -2.7967067), (-2.5920796, -2.8631032), (-1.8046548, -1.0386766), (-1.7401572, -0.9722801), (-2.5275824, -2.7967045), (-2.5920792, -2.863101), (-1.8046545, -1.0386771), (-1.7401586, -0.97228163), (-2.5275848, -2.7967052), (-2.5920835, -2.8630984), (-1.8046561, -1.0386735), (-1.7401544, -0.9722804), (-2.527581, -2.7967064), (-2.592083, -2.8630996), (-1.8046579, -1.0386723), (-1.7401562, -0.97227824), (-2.5275803, -2.7967052), (-2.5920804, -2.8631015), (-1.8046566, -1.0386764), (-1.7401589, -0.97228014), (-2.5275843, -2.7967033), (-2.5920804, -2.8630977), (-1.8046541, -1.0386741), (-1.7401564, -0.9722805), (-2.5275834, -2.796704), (-2.5920844, -2.8630977), (-1.8046554, -1.0386723), (-1.7401526, -0.97227806), (-2.5275803, -2.796705), (-2.5920818, -2.8631012), (-1.804657, -1.038675), (-1.7401593, -0.9722769), (-2.5275848, -2.7967007), (-2.5920813, -2.8630972), (-1.8046545, -1.0386736), (-1.7401558, -0.97227925), (-2.527583, -2.796703), (-2.5920832, -2.8630972), (-1.8046576, -1.0386727), (-1.7401565, -0.9722776), (-2.5275788, -2.7967021), (-2.592077, -2.863098), (-1.8046544, -1.0386752), (-1.7401575, -0.97228044), (-2.5275838, -2.7967026), (-2.592081, -2.8630958), (-1.804652, -1.0386715), (-1.7401544, -0.97227836), (-2.527584, -2.7967043), (-2.5920808, -2.863098), (-1.8046529, -1.0386709), (-1.7401575, -0.97227746), (-2.5275843, -2.7967038), (-2.5920835, -2.8630965), (-1.8046546, -1.0386691), (-1.7401521, -0.97227603), (-2.5275793, -2.7967033), (-2.5920818, -2.863098), (-1.8046578, -1.038672), (-1.7401568, -0.9722759), (-2.5275815, -2.7967002), (-2.5920808, -2.8630965), (-1.8046532, -1.0386723), (-1.740154, -0.9722771), (-2.5275831, -2.7967017), (-2.5920837, -2.8630955), (-1.8046548, -1.0386702), (-1.7401533, -0.97227603), (-2.5275822, -2.7967029), (-2.5920837, -2.8630989), (-1.8046552, -1.0386726), (-1.7401539, -0.97227556), (-2.5275812, -2.7967005), (-2.5920825, -2.863097), (-1.8046545, -1.0386727), (-1.7401527, -0.97227687), (-2.5275805, -2.7967007), (-2.5920837, -2.8630972), (-1.8046578, -1.0386732), (-1.740153, -0.9722749), (-2.5275774, -2.7966993), (-2.5920827, -2.8630993), (-1.8046594, -1.0386765), (-1.7401558, -0.9722769), (-2.527579, -2.7966986), (-2.5920792, -2.863096), (-1.8046536, -1.0386744), (-1.740154, -0.9722781), (-2.527581, -2.796701), (-2.5920808, -2.8630967), (-1.8046535, -1.0386734), (-1.740155, -0.97227806), (-2.5275824, -2.7967014), (-2.5920782, -2.8630958), (-1.8046504, -1.0386715), (-1.7401562, -0.9722784), (-2.5275838, -2.7967038), (-2.5920804, -2.8630955), (-1.8046544, -1.038669), (-1.7401587, -0.97227687), (-2.5275865, -2.7967038), (-2.5920808, -2.8630974), (-1.8046522, -1.0386705), (-1.7401564, -0.97227705), (-2.5275846, -2.796704), (-2.592083, -2.8630972), (-1.8046564, -1.0386697), (-1.7401567, -0.97227633), (-2.5275817, -2.7967033), (-2.592079, -2.8630981), (-1.8046529, -1.0386732), (-1.7401559, -0.97227746), (-2.527583, -2.796702), (-2.59208, -2.863097), (-1.8046517, -1.0386727), (-1.7401528, -0.97227824), (-2.5275798, -2.7967026), (-2.59208, -2.8630974), (-1.8046547, -1.0386736), (-1.7401538, -0.97227824), (-2.5275788, -2.796702), (-2.5920796, -2.8630984), (-1.8046565, -1.0386755), (-1.7401592, -0.972278), (-2.5275831, -2.7966993), (-2.5920794, -2.863096), (-1.8046526, -1.0386744), (-1.7401544, -0.972279), (-2.52758, -2.7967021), (-2.5920794, -2.863097), (-1.8046567, -1.038673), (-1.7401578, -0.97227734), (-2.5275822, -2.796701), (-2.5920808, -2.8630967), (-1.8046536, -1.0386721), (-1.7401545, -0.97227675), (-2.5275831, -2.7967024), (-2.5920832, -2.8630981), (-1.804657, -1.0386732), (-1.7401583, -0.9722775), (-2.5275826, -2.7967017), (-2.592077, -2.8630962), (-1.8046527, -1.0386727), (-1.7401592, -0.97227937), (-2.527584, -2.796703), (-2.5920787, -2.8630953), (-1.8046519, -1.0386703), (-1.7401569, -0.97227883), (-2.5275836, -2.7967043), (-2.5920784, -2.8630962), (-1.8046516, -1.0386715), (-1.740156, -0.9722792), (-2.5275826, -2.7967038), (-2.5920787, -2.8630967), (-1.804651, -1.038672), (-1.7401536, -0.9722776), (-2.5275822, -2.7967036), (-2.5920815, -2.863099), (-1.8046559, -1.0386728), (-1.7401575, -0.97227705), (-2.5275831, -2.7967017), (-2.5920794, -2.863097), (-1.8046521, -1.0386733), (-1.7401583, -0.9722784), (-2.5275877, -2.7967024), (-2.592082, -2.863095), (-1.8046508, -1.0386701), (-1.7401533, -0.9722795), (-2.5275853, -2.7967067), (-2.5920837, -2.8630974), (-1.8046519, -1.0386696), (-1.7401534, -0.9722769), (-2.5275838, -2.7967045), (-2.592083, -2.8630984), (-1.8046539, -1.0386707), (-1.7401547, -0.97227633), (-2.5275836, -2.796703), (-2.592083, -2.863098), (-1.8046558, -1.0386721), (-1.7401558, -0.97227705), (-2.5275805, -2.7967029), (-2.592078, -2.8630986), (-1.8046523, -1.038674), (-1.7401593, -0.9722788), (-2.5275874, -2.7967021), (-2.5920784, -2.8630946), (-1.8046458, -1.0386709), (-1.7401503, -0.97228086), (-2.5275838, -2.7967076), (-2.592082, -2.863098), (-1.8046498, -1.038668), (-1.740153, -0.97227633), (-2.5275838, -2.7967079), (-2.59208, -2.8631008), (-1.80465, -1.0386696), (-1.7401538, -0.97227585), (-2.5275853, -2.7967062), (-2.592083, -2.8631003), (-1.804654, -1.0386704), (-1.7401575, -0.9722742), (-2.527587, -2.7967021), (-2.5920844, -2.8630974), (-1.8046556, -1.0386703), (-1.7401578, -0.97227573), (-2.5275867, -2.7967026), (-2.5920842, -2.8630972), (-1.8046526, -1.0386709), (-1.7401514, -0.9722779), (-2.527581, -2.796705), (-2.5920832, -2.863099), (-1.8046579, -1.0386723), (-1.7401565, -0.97227603), (-2.5275803, -2.7967014), (-2.5920804, -2.8630984), (-1.8046563, -1.0386742), (-1.7401578, -0.97227824), (-2.5275826, -2.796701), (-2.5920782, -2.8630962), (-1.8046523, -1.0386741), (-1.7401589, -0.9722805), (-2.5275843, -2.7967033), (-2.5920768, -2.863096), (-1.80465, -1.0386734), (-1.7401572, -0.9722806), (-2.527586, -2.796703), (-2.592079, -2.8630948), (-1.8046498, -1.0386705), (-1.740157, -0.9722794), (-2.5275846, -2.7967055), (-2.5920784, -2.863097), (-1.8046502, -1.0386705), (-1.7401556, -0.97227854), (-2.5275834, -2.7967052), (-2.592079, -2.8630977), (-1.8046514, -1.0386713), (-1.7401562, -0.972278), (-2.5275834, -2.796703), (-2.592079, -2.8630967), (-1.8046536, -1.0386717), (-1.7401578, -0.97227806), (-2.5275846, -2.7967033), (-2.5920806, -2.863096), (-1.8046517, -1.0386702), (-1.7401553, -0.9722782), (-2.5275838, -2.7967048), (-2.5920808, -2.863097), (-1.8046521, -1.0386695), (-1.7401552, -0.9722773), (-2.5275877, -2.7967052), (-2.592086, -2.8630977), (-1.8046539, -1.0386691), (-1.740154, -0.97227556), (-2.527584, -2.7967048), (-2.5920837, -2.8630993), (-1.8046544, -1.0386704), (-1.7401541, -0.97227556), (-2.5275817, -2.796704), (-2.5920808, -2.8631), (-1.8046528, -1.0386727), (-1.7401552, -0.9722767), (-2.5275853, -2.7967026), (-2.592083, -2.8630977), (-1.8046505, -1.0386715), (-1.740152, -0.97227734), (-2.527583, -2.7967043), (-2.5920806, -2.8630989), (-1.8046526, -1.0386721), (-1.7401553, -0.97227687), (-2.5275846, -2.796703), (-2.592083, -2.8630967), (-1.8046523, -1.0386708), (-1.740153, -0.97227865), (-2.5275853, -2.7967052), (-2.5920877, -2.8630962), (-1.8046553, -1.0386679), (-1.7401514, -0.97227514), (-2.5275795, -2.7967045), (-2.5920818, -2.8631008), (-1.8046561, -1.0386724), (-1.7401543, -0.9722757), (-2.5275793, -2.7967026), (-2.5920804, -2.8630998), (-1.8046565, -1.0386745), (-1.7401599, -0.9722771), (-2.5275846, -2.7966998), (-2.5920777, -2.8630953), (-1.8046492, -1.038673), (-1.7401533, -0.97228026), (-2.5275846, -2.7967048), (-2.5920854, -2.8630965), (-1.8046551, -1.0386695), (-1.740153, -0.97227645), (-2.5275812, -2.7967045), (-2.5920799, -2.8631), (-1.8046532, -1.0386735), (-1.7401592, -0.97227746), (-2.5275872, -2.7967017), (-2.5920784, -2.8630962), (-1.8046464, -1.0386722), (-1.740153, -0.97227997), (-2.527588, -2.7967057), (-2.592086, -2.863096), (-1.8046514, -1.0386667), (-1.7401493, -0.9722752), (-2.5275795, -2.7967067), (-2.5920815, -2.863101), (-1.8046554, -1.0386708), (-1.7401562, -0.972274), (-2.527583, -2.7967014), (-2.5920815, -2.8630986), (-1.8046556, -1.0386745), (-1.7401559, -0.9722788), (-2.527582, -2.7967021), (-2.5920804, -2.8630965), (-1.8046513, -1.0386721), (-1.7401534, -0.97227764), (-2.5275836, -2.7967036), (-2.5920827, -2.8630981), (-1.8046552, -1.0386711), (-1.7401569, -0.97227615), (-2.5275824, -2.7967026), (-2.5920813, -2.8630981), (-1.8046567, -1.0386732), (-1.7401577, -0.97227764), (-2.5275822, -2.796702), (-2.5920796, -2.8630972), (-1.8046539, -1.0386727), (-1.7401563, -0.9722775), (-2.527582, -2.7967021), (-2.5920796, -2.8630974), (-1.8046541, -1.0386732), (-1.7401578, -0.9722778), (-2.5275848, -2.796701), (-2.592081, -2.8630953), (-1.804654, -1.0386717), (-1.7401563, -0.97227955), (-2.5275838, -2.7967045), (-2.5920818, -2.8630962), (-1.8046525, -1.0386696), (-1.7401541, -0.97227836), (-2.5275824, -2.7967055), (-2.5920796, -2.8630977), (-1.8046519, -1.0386713), (-1.7401546, -0.97227806), (-2.5275843, -2.7967043), (-2.5920818, -2.863098), (-1.8046529, -1.0386711), (-1.7401556, -0.9722769), (-2.527584, -2.7967033), (-2.5920827, -2.8630981), (-1.8046557, -1.0386723), (-1.7401557, -0.972277), (-2.5275805, -2.7967024), (-2.59208, -2.8630984), (-1.8046559, -1.0386735), (-1.740155, -0.972278), (-2.5275776, -2.7967021), (-2.5920782, -2.8630974), (-1.8046567, -1.038675), (-1.7401589, -0.9722792), (-2.5275831, -2.796701), (-2.5920792, -2.863096), (-1.8046525, -1.0386735), (-1.7401567, -0.97227913), (-2.5275824, -2.7967017), (-2.5920775, -2.863095), (-1.804652, -1.0386732), (-1.7401556, -0.9722812), (-2.5275831, -2.7967038), (-2.592081, -2.8630962), (-1.8046523, -1.0386714), (-1.7401547, -0.97227764), (-2.5275834, -2.796703), (-2.5920818, -2.863098), (-1.8046546, -1.0386719), (-1.7401552, -0.9722776), (-2.5275805, -2.7967036), (-2.5920784, -2.863098), (-1.8046538, -1.0386719), (-1.7401583, -0.9722766), (-2.5275846, -2.796702), (-2.59208, -2.8630967), (-1.8046521, -1.0386722), (-1.7401545, -0.97227806), (-2.527583, -2.7967026), (-2.5920823, -2.8630955), (-1.8046565, -1.0386695), (-1.7401584, -0.9722759), (-2.5275838, -2.7967017), (-2.592079, -2.863097), (-1.8046513, -1.0386723), (-1.7401558, -0.97227794), (-2.527584, -2.796703), (-2.592082, -2.8630962), (-1.8046556, -1.0386701), (-1.7401575, -0.9722772), (-2.5275834, -2.7967036), (-2.592081, -2.863098), (-1.8046544, -1.0386724), (-1.740156, -0.97227806), (-2.5275822, -2.7967029), (-2.5920794, -2.863097), (-1.8046527, -1.0386723), (-1.7401558, -0.97227776), (-2.5275807, -2.7967024), (-2.5920773, -2.8630974), (-1.8046533, -1.0386734), (-1.7401572, -0.972279), (-2.527583, -2.796703), (-2.59208, -2.8630965), (-1.8046526, -1.0386717), (-1.7401538, -0.9722779), (-2.5275831, -2.796703), (-2.5920835, -2.8630967), (-1.8046536, -1.0386703), (-1.7401528, -0.9722773), (-2.527583, -2.796704), (-2.592084, -2.8630984), (-1.804655, -1.0386724), (-1.740154, -0.9722764), (-2.5275815, -2.7967024), (-2.5920827, -2.863099), (-1.8046572, -1.0386733), (-1.7401571, -0.9722759), (-2.5275824, -2.7966998), (-2.5920813, -2.8630967), (-1.8046542, -1.0386746), (-1.7401557, -0.97228014), (-2.5275853, -2.7967033), (-2.5920825, -2.8630948), (-1.8046508, -1.0386696), (-1.740153, -0.9722785), (-2.5275836, -2.796706), (-2.5920818, -2.8630989), (-1.8046545, -1.038671), (-1.7401564, -0.97227573), (-2.5275831, -2.7967024), (-2.5920794, -2.8630996), (-1.8046527, -1.0386745), (-1.7401565, -0.9722774), (-2.5275822, -2.7967012), (-2.5920763, -2.8630972), (-1.8046492, -1.0386752), (-1.7401571, -0.9722805), (-2.5275867, -2.796703), (-2.5920796, -2.8630955), (-1.8046502, -1.0386707), (-1.7401569, -0.9722785), (-2.5275843, -2.7967038), (-2.592078, -2.8630965), (-1.8046513, -1.0386714), (-1.7401574, -0.97227895), (-2.527586, -2.7967038), (-2.5920806, -2.8630965), (-1.8046497, -1.0386707), (-1.7401532, -0.97227865), (-2.5275872, -2.7967057), (-2.592088, -2.863097), (-1.8046541, -1.0386682), (-1.7401508, -0.972276), (-2.5275798, -2.7967057), (-2.5920808, -2.8631012), (-1.804656, -1.0386728), (-1.7401577, -0.97227526), (-2.5275838, -2.7967014), (-2.5920808, -2.8630984), (-1.8046526, -1.0386736), (-1.7401547, -0.972278), (-2.5275834, -2.796703), (-2.5920813, -2.8630981), (-1.8046528, -1.0386726), (-1.7401565, -0.97227746), (-2.527585, -2.7967026), (-2.5920818, -2.8630955), (-1.804655, -1.0386708), (-1.7401582, -0.97227806), (-2.527584, -2.7967029), (-2.5920799, -2.8630958), (-1.8046539, -1.0386709), (-1.7401582, -0.97227913), (-2.527584, -2.796704), (-2.592079, -2.8630958), (-1.8046508, -1.0386702), (-1.7401559, -0.9722781), (-2.527584, -2.7967045), (-2.592078, -2.8630974), (-1.8046514, -1.0386723), (-1.7401578, -0.9722798), (-2.5275846, -2.7967052), (-2.5920806, -2.8630977), (-1.8046527, -1.0386711), (-1.7401547, -0.9722787), (-2.5275817, -2.7967055), (-2.5920799, -2.8630981), (-1.8046548, -1.0386707), (-1.740158, -0.97227764), (-2.5275834, -2.7967038), (-2.59208, -2.8630974), (-1.8046553, -1.038672), (-1.7401586, -0.97227633), (-2.5275815, -2.7967017), (-2.5920773, -2.8630986), (-1.8046523, -1.0386745), (-1.7401562, -0.9722785), (-2.5275824, -2.796702), (-2.592079, -2.8630972), (-1.8046538, -1.0386729), (-1.7401581, -0.97227806), (-2.527584, -2.7967021), (-2.592079, -2.8630958), (-1.8046526, -1.0386723), (-1.7401576, -0.9722791), (-2.527585, -2.7967033), (-2.5920827, -2.863097), (-1.8046521, -1.0386715), (-1.740152, -0.9722777), (-2.527582, -2.796705), (-2.5920823, -2.8630986), (-1.8046558, -1.0386708), (-1.7401574, -0.97227603), (-2.5275836, -2.7967021), (-2.5920813, -2.8630974), (-1.8046552, -1.0386728), (-1.7401569, -0.9722773), (-2.5275824, -2.7967007), (-2.59208, -2.863096), (-1.8046534, -1.0386735), (-1.7401565, -0.9722791), (-2.5275838, -2.7967017), (-2.5920799, -2.863096), (-1.8046519, -1.0386722), (-1.7401558, -0.97227854), (-2.5275855, -2.7967038), (-2.592082, -2.8630967), (-1.8046522, -1.038671), (-1.7401546, -0.9722779), (-2.5275822, -2.7967036), (-2.5920787, -2.8630974), (-1.8046528, -1.0386719), (-1.7401567, -0.9722772), (-2.5275822, -2.796702), (-2.5920784, -2.863097), (-1.8046514, -1.0386732), (-1.7401538, -0.9722785), (-2.5275834, -2.7967026), (-2.592083, -2.863097), (-1.8046523, -1.0386727), (-1.7401524, -0.9722786), (-2.5275834, -2.7967029), (-2.5920854, -2.8630967), (-1.8046546, -1.0386711), (-1.7401528, -0.97227633), (-2.527581, -2.7967017), (-2.5920818, -2.8630977), (-1.8046542, -1.0386742), (-1.740157, -0.97227967), (-2.5275855, -2.7967029), (-2.5920818, -2.8630948), (-1.8046544, -1.0386704), (-1.740156, -0.97227967), (-2.5275836, -2.7967057), (-2.5920818, -2.8630977), (-1.8046516, -1.0386704), (-1.7401532, -0.9722775), (-2.5275853, -2.7967048), (-2.5920866, -2.8630974), (-1.8046569, -1.0386691), (-1.7401533, -0.972275), (-2.5275795, -2.7967038), (-2.5920813, -2.8631005), (-1.8046556, -1.0386734), (-1.7401557, -0.9722751), (-2.5275824, -2.7967005), (-2.592082, -2.8630981), (-1.8046558, -1.0386738), (-1.7401543, -0.9722782), (-2.5275772, -2.7967029), (-2.5920799, -2.8630984), (-1.8046585, -1.0386735), (-1.7401553, -0.97227746), (-2.5275753, -2.796702), (-2.5920765, -2.8630989), (-1.804657, -1.0386759), (-1.7401599, -0.9722788), (-2.52758, -2.7967002), (-2.5920763, -2.8630953), (-1.8046527, -1.0386739), (-1.7401589, -0.97228104), (-2.527589, -2.7967029), (-2.592082, -2.8630934), (-1.8046466, -1.038668), (-1.7401519, -0.97227955), (-2.5275903, -2.7967095), (-2.5920854, -2.8630967), (-1.8046464, -1.038664), (-1.7401488, -0.9722768), (-2.5275865, -2.7967112), (-2.5920875, -2.8631003), (-1.8046516, -1.0386643), (-1.7401482, -0.9722717), (-2.5275807, -2.7967057), (-2.5920846, -2.8631036), (-1.8046542, -1.0386734), (-1.7401522, -0.9722728), (-2.527584, -2.7966993), (-2.592087, -2.8630996), (-1.8046576, -1.0386752), (-1.7401547, -0.97227603), (-2.5275822, -2.796699), (-2.5920837, -2.863097), (-1.8046564, -1.0386752), (-1.7401549, -0.9722788), (-2.527581, -2.7967017), (-2.5920835, -2.8630972), (-1.8046582, -1.0386733), (-1.740154, -0.9722769), (-2.5275798, -2.796701), (-2.5920825, -2.863098), (-1.8046576, -1.0386734), (-1.7401545, -0.972277), (-2.5275772, -2.7967012), (-2.5920792, -2.8630981), (-1.8046569, -1.0386747), (-1.7401572, -0.97227824), (-2.5275798, -2.7967017), (-2.5920775, -2.8630972), (-1.8046528, -1.0386736), (-1.7401576, -0.972279), (-2.5275838, -2.7967024), (-2.5920773, -2.8630958), (-1.8046504, -1.0386714), (-1.7401577, -0.9722792), (-2.527585, -2.7967048), (-2.5920799, -2.8630962), (-1.8046516, -1.0386697), (-1.740155, -0.9722782), (-2.5275836, -2.7967052), (-2.5920808, -2.8630977), (-1.8046514, -1.0386703), (-1.7401539, -0.9722776), (-2.5275853, -2.796705), (-2.5920858, -2.8630977), (-1.8046554, -1.0386693), (-1.740153, -0.9722751), (-2.527581, -2.7967036), (-2.5920823, -2.8631005), (-1.8046556, -1.0386733), (-1.7401567, -0.97227454), (-2.527584, -2.7966998), (-2.5920799, -2.8630977), (-1.8046504, -1.0386747), (-1.7401555, -0.97227985), (-2.5275855, -2.7967036), (-2.5920806, -2.8630962), (-1.80465, -1.0386705), (-1.7401534, -0.97227854), (-2.5275855, -2.796706), (-2.5920818, -2.8630965), (-1.8046503, -1.0386673), (-1.7401567, -0.9722772), (-2.5275884, -2.7967067), (-2.5920835, -2.8630972), (-1.8046508, -1.0386673), (-1.7401524, -0.9722777), (-2.527583, -2.796708), (-2.5920804, -2.8630996), (-1.8046519, -1.0386691), (-1.7401563, -0.9722753), (-2.527586, -2.7967045), (-2.5920846, -2.8630984), (-1.8046556, -1.0386709), (-1.7401549, -0.97227615), (-2.5275824, -2.7967029), (-2.592082, -2.8630993), (-1.8046545, -1.0386742), (-1.740156, -0.9722775), (-2.5275834, -2.7967017), (-2.5920794, -2.863097), (-1.8046516, -1.0386727), (-1.7401555, -0.97227824), (-2.5275824, -2.7967026), (-2.592079, -2.863097), (-1.804654, -1.0386732), (-1.7401583, -0.9722796), (-2.5275834, -2.7967033), (-2.5920782, -2.863097), (-1.8046519, -1.0386724), (-1.7401571, -0.9722792), (-2.527584, -2.796704), (-2.5920799, -2.8630958), (-1.8046539, -1.0386708), (-1.7401586, -0.97227806), (-2.527584, -2.7967036), (-2.5920794, -2.8630967), (-1.8046534, -1.0386716), (-1.7401584, -0.9722788), (-2.527585, -2.7967033), (-2.5920794, -2.8630958), (-1.8046515, -1.0386709), (-1.7401571, -0.97227836), (-2.5275857, -2.7967036), (-2.5920806, -2.8630965), (-1.8046496, -1.0386709), (-1.7401537, -0.97227776), (-2.5275848, -2.796704), (-2.592081, -2.8630977), (-1.8046511, -1.038672), (-1.7401541, -0.9722783), (-2.5275846, -2.7967038), (-2.5920837, -2.8630981), (-1.804654, -1.0386722), (-1.7401538, -0.9722766), (-2.5275817, -2.7967017), (-2.5920813, -2.8630977), (-1.8046545, -1.0386741), (-1.7401565, -0.97227865), (-2.5275826, -2.796702), (-2.5920784, -2.8630974), (-1.8046511, -1.0386739), (-1.7401565, -0.972279), (-2.5275867, -2.7967029), (-2.5920823, -2.8630955), (-1.8046522, -1.03867), (-1.7401552, -0.9722784), (-2.5275826, -2.7967055), (-2.5920799, -2.8630965), (-1.8046522, -1.0386685), (-1.7401553, -0.9722771), (-2.5275853, -2.7967055), (-2.5920837, -2.8630974), (-1.8046535, -1.0386688), (-1.7401538, -0.9722765), (-2.5275848, -2.7967055), (-2.5920854, -2.8630981), (-1.8046545, -1.0386684), (-1.7401527, -0.9722753), (-2.5275812, -2.7967052), (-2.5920818, -2.8631012), (-1.8046552, -1.0386728), (-1.7401552, -0.9722746), (-2.5275812, -2.7967005), (-2.592082, -2.8630993), (-1.8046566, -1.0386761), (-1.7401552, -0.9722785), (-2.5275779, -2.796701), (-2.5920775, -2.8630974), (-1.8046564, -1.0386759), (-1.7401595, -0.97227997), (-2.527582, -2.796701), (-2.5920773, -2.8630953), (-1.8046533, -1.0386739), (-1.7401576, -0.97228044), (-2.5275846, -2.7967026), (-2.5920794, -2.863096), (-1.804649, -1.0386719), (-1.7401538, -0.97227865), (-2.5275838, -2.7967048), (-2.5920799, -2.8630967), (-1.8046503, -1.0386697), (-1.7401541, -0.9722775), (-2.5275862, -2.7967045), (-2.5920863, -2.8630974), (-1.8046579, -1.0386698), (-1.7401569, -0.9722751), (-2.5275826, -2.796702), (-2.5920799, -2.863099), (-1.8046528, -1.0386753), (-1.7401571, -0.9722788), (-2.5275846, -2.7967007), (-2.5920804, -2.863095), (-1.8046529, -1.0386726), (-1.7401546, -0.9722793), (-2.5275807, -2.7967029), (-2.592079, -2.8630958), (-1.8046534, -1.038672), (-1.7401559, -0.9722784), (-2.5275807, -2.7967033), (-2.592078, -2.863098), (-1.8046526, -1.0386724), (-1.7401564, -0.9722776), (-2.5275836, -2.7967021), (-2.5920823, -2.863097), (-1.8046554, -1.038673), (-1.7401571, -0.97227746), (-2.527584, -2.7967007), (-2.5920804, -2.863096), (-1.8046516, -1.0386724), (-1.740154, -0.9722795), (-2.5275836, -2.796705), (-2.5920827, -2.863097), (-1.8046521, -1.03867), (-1.740153, -0.9722771), (-2.527584, -2.7967045), (-2.592085, -2.863098), (-1.8046561, -1.0386693), (-1.7401546, -0.9722752), (-2.5275815, -2.796704), (-2.592081, -2.8631003), (-1.8046536, -1.0386741), (-1.7401555, -0.9722772), (-2.5275862, -2.7967012), (-2.592084, -2.8630962), (-1.8046519, -1.038671), (-1.7401527, -0.97227776), (-2.5275831, -2.7967045), (-2.5920818, -2.8630974), (-1.80465, -1.0386709), (-1.7401525, -0.97227746), (-2.5275853, -2.796703), (-2.5920858, -2.8630974), (-1.8046575, -1.0386716), (-1.7401549, -0.97227556), (-2.5275793, -2.7967017), (-2.592081, -2.863099), (-1.8046575, -1.0386742), (-1.7401555, -0.9722768), (-2.5275793, -2.7966998), (-2.5920806, -2.8630967), (-1.8046546, -1.0386747), (-1.7401538, -0.9722781), (-2.52758, -2.7967007), (-2.59208, -2.8630977), (-1.8046525, -1.0386746), (-1.7401537, -0.97227895), (-2.5275846, -2.7967029), (-2.5920846, -2.8630967), (-1.8046553, -1.0386709), (-1.7401551, -0.9722764), (-2.5275812, -2.7967038), (-2.5920777, -2.863099), (-1.8046511, -1.0386727), (-1.7401569, -0.9722785), (-2.5275831, -2.7967033), (-2.592078, -2.8630972), (-1.804653, -1.0386732), (-1.7401606, -0.9722794), (-2.5275884, -2.7967026), (-2.5920804, -2.863095), (-1.804648, -1.0386715), (-1.7401513, -0.97227955), (-2.527586, -2.796705), (-2.5920875, -2.8630977), (-1.8046558, -1.0386689), (-1.7401533, -0.97227424), (-2.52758, -2.7967033), (-2.5920808, -2.8631005), (-1.8046553, -1.0386744), (-1.7401543, -0.97227603), (-2.5275793, -2.7967002), (-2.5920804, -2.8630984), (-1.8046566, -1.0386757), (-1.7401596, -0.9722778), (-2.5275848, -2.7966995), (-2.592079, -2.8630953), (-1.804649, -1.0386739), (-1.7401546, -0.972281), (-2.5275855, -2.7967048), (-2.5920837, -2.8630965), (-1.8046546, -1.0386702), (-1.7401532, -0.9722767), (-2.52758, -2.7967026), (-2.592081, -2.8630984), (-1.8046565, -1.038674), (-1.7401558, -0.97227705), (-2.5275793, -2.7967005), (-2.5920825, -2.8630977), (-1.8046609, -1.0386752), (-1.7401584, -0.9722776), (-2.5275795, -2.7966993), (-2.5920782, -2.8630977), (-1.8046548, -1.0386766), (-1.7401586, -0.9722795), (-2.527583, -2.7967002), (-2.592078, -2.863095), (-1.8046546, -1.0386741), (-1.7401607, -0.9722807), (-2.5275848, -2.7967021), (-2.592076, -2.863095), (-1.8046498, -1.0386715), (-1.7401586, -0.9722802), (-2.5275855, -2.796706), (-2.5920756, -2.863095), (-1.8046465, -1.038668), (-1.7401575, -0.9722799), (-2.527591, -2.7967076), (-2.592083, -2.8630962), (-1.8046468, -1.0386666), (-1.7401521, -0.9722777), (-2.5275881, -2.7967086), (-2.5920827, -2.8630977), (-1.804647, -1.0386676), (-1.7401525, -0.97227764), (-2.5275881, -2.7967072), (-2.5920842, -2.8630974), (-1.8046471, -1.0386678), (-1.7401489, -0.9722771), (-2.5275843, -2.7967079), (-2.592084, -2.8630986), (-1.8046527, -1.038668), (-1.7401558, -0.9722756), (-2.5275865, -2.7967048), (-2.592084, -2.8630989), (-1.8046538, -1.0386714), (-1.7401541, -0.9722766), (-2.5275834, -2.7967024), (-2.592081, -2.8630962), (-1.8046507, -1.0386704), (-1.7401534, -0.9722784), (-2.5275853, -2.7967055), (-2.5920858, -2.863097), (-1.8046544, -1.0386686), (-1.7401518, -0.97227556), (-2.5275798, -2.7967045), (-2.5920815, -2.8630993), (-1.804658, -1.0386713), (-1.7401592, -0.9722758), (-2.5275834, -2.7967012), (-2.5920792, -2.863097), (-1.8046516, -1.0386735), (-1.7401551, -0.9722791), (-2.527584, -2.7967029), (-2.5920813, -2.8630967), (-1.8046508, -1.0386723), (-1.740153, -0.97227824), (-2.5275836, -2.7967033), (-2.5920832, -2.8630965), (-1.8046534, -1.0386705), (-1.7401537, -0.97227746), (-2.5275838, -2.7967036), (-2.592085, -2.863098), (-1.8046564, -1.038672), (-1.7401551, -0.97227573), (-2.527582, -2.7967005), (-2.5920827, -2.863097), (-1.8046554, -1.0386735), (-1.740154, -0.9722794), (-2.5275812, -2.7967038), (-2.5920799, -2.8630974), (-1.8046519, -1.0386724), (-1.7401544, -0.9722793), (-2.5275836, -2.7967045), (-2.5920823, -2.8630965), (-1.8046525, -1.0386688), (-1.7401539, -0.9722764), (-2.5275831, -2.7967055), (-2.5920808, -2.8630993), (-1.804654, -1.0386714), (-1.740157, -0.972276), (-2.5275834, -2.7967024), (-2.592079, -2.863099), (-1.8046535, -1.0386741), (-1.7401611, -0.9722778), (-2.527588, -2.7967014), (-2.592079, -2.8630955), (-1.8046495, -1.0386723), (-1.7401552, -0.9722798), (-2.527584, -2.7967048), (-2.5920813, -2.8630967), (-1.8046522, -1.0386704), (-1.7401543, -0.972278), (-2.5275826, -2.7967048), (-2.5920806, -2.8630974), (-1.8046536, -1.0386705), (-1.7401546, -0.9722776), (-2.527582, -2.7967043), (-2.5920792, -2.8630989), (-1.8046526, -1.0386724), (-1.7401563, -0.9722774), (-2.5275848, -2.796703), (-2.592082, -2.863098), (-1.804653, -1.0386724), (-1.7401555, -0.97227794), (-2.5275822, -2.7967033), (-2.5920796, -2.8630972), (-1.8046535, -1.0386722), (-1.7401563, -0.97227776), (-2.527584, -2.7967029), (-2.592081, -2.8630977), (-1.8046527, -1.0386732), (-1.7401587, -0.9722787), (-2.527588, -2.7967024), (-2.5920808, -2.8630955), (-1.80465, -1.0386705), (-1.740155, -0.97227854), (-2.527584, -2.7967052), (-2.5920804, -2.8630974), (-1.8046536, -1.0386709), (-1.7401567, -0.972277), (-2.527583, -2.7967036), (-2.5920787, -2.8630981), (-1.8046532, -1.0386715), (-1.7401586, -0.9722771), (-2.5275848, -2.7967026), (-2.5920794, -2.8630974), (-1.8046511, -1.0386732), (-1.740155, -0.97227865), (-2.5275826, -2.7967026), (-2.592081, -2.8630974), (-1.8046569, -1.0386724), (-1.74016, -0.9722767), (-2.527584, -2.7967014), (-2.5920784, -2.8630962), (-1.8046503, -1.038672), (-1.7401557, -0.9722785), (-2.5275853, -2.7967043), (-2.5920827, -2.8630972), (-1.8046521, -1.0386697), (-1.740153, -0.97227657), (-2.527583, -2.796704), (-2.5920806, -2.8630989), (-1.8046528, -1.0386729), (-1.7401556, -0.97227764), (-2.527583, -2.796703), (-2.5920799, -2.863097), (-1.8046515, -1.0386711), (-1.7401552, -0.9722774), (-2.527586, -2.796703), (-2.5920832, -2.8630967), (-1.8046507, -1.0386703), (-1.7401521, -0.9722776), (-2.5275836, -2.796706), (-2.5920837, -2.8630984), (-1.804653, -1.0386686), (-1.7401541, -0.9722753), (-2.5275857, -2.7967048), (-2.5920858, -2.8630977), (-1.8046557, -1.0386679), (-1.7401532, -0.9722752), (-2.5275807, -2.7967052), (-2.5920813, -2.8631008), (-1.8046556, -1.0386735), (-1.7401545, -0.9722761), (-2.5275795, -2.7967012), (-2.592083, -2.863099), (-1.8046591, -1.0386754), (-1.7401558, -0.9722764), (-2.5275793, -2.796699), (-2.5920804, -2.8630977), (-1.8046557, -1.0386759), (-1.7401568, -0.97227985), (-2.5275822, -2.7967017), (-2.5920784, -2.8630958), (-1.8046529, -1.038673), (-1.7401576, -0.97227985), (-2.5275848, -2.7967036), (-2.5920804, -2.863097), (-1.8046505, -1.0386722), (-1.7401536, -0.9722787), (-2.527585, -2.796704), (-2.5920835, -2.863097), (-1.804651, -1.0386704), (-1.7401522, -0.9722775), (-2.5275843, -2.7967048), (-2.592082, -2.8630981), (-1.8046521, -1.0386713), (-1.7401552, -0.9722766), (-2.5275848, -2.7967026), (-2.5920818, -2.8630962), (-1.8046507, -1.0386707), (-1.7401531, -0.97227865), (-2.5275867, -2.7967055), (-2.592088, -2.8630965), (-1.8046544, -1.0386679), (-1.740151, -0.972276), (-2.5275793, -2.7967057), (-2.5920808, -2.8631012), (-1.804654, -1.038673), (-1.7401539, -0.97227585), (-2.5275834, -2.7967021), (-2.5920837, -2.8630989), (-1.8046542, -1.038673), (-1.740154, -0.9722764), (-2.5275815, -2.7967017), (-2.592081, -2.8630977), (-1.8046571, -1.0386728), (-1.7401581, -0.97227705), (-2.5275812, -2.7967017), (-2.5920799, -2.8630974), (-1.8046551, -1.0386739), (-1.7401584, -0.97227836), (-2.527587, -2.7967014), (-2.5920825, -2.8630958), (-1.8046505, -1.0386716), (-1.7401533, -0.97227854), (-2.527585, -2.7967048), (-2.5920823, -2.8630984), (-1.8046521, -1.0386716), (-1.7401552, -0.9722773), (-2.5275831, -2.7967038), (-2.5920799, -2.8630977), (-1.8046516, -1.038672), (-1.7401544, -0.97227883), (-2.527583, -2.796704), (-2.5920792, -2.8630977), (-1.8046498, -1.0386729), (-1.7401536, -0.97227937), (-2.5275831, -2.7967043), (-2.5920808, -2.863098), (-1.8046534, -1.038672), (-1.7401564, -0.9722764), (-2.5275846, -2.796701), (-2.5920823, -2.8630967), (-1.8046547, -1.038673), (-1.7401568, -0.97227854), (-2.5275815, -2.7967024), (-2.5920799, -2.8630967), (-1.8046571, -1.0386734), (-1.7401582, -0.9722779), (-2.527581, -2.7967002), (-2.5920799, -2.8630965), (-1.8046561, -1.0386742), (-1.7401581, -0.9722787), (-2.527583, -2.796702), (-2.5920794, -2.863096), (-1.8046526, -1.0386716), (-1.7401564, -0.9722782), (-2.5275834, -2.796703), (-2.592081, -2.863097), (-1.8046554, -1.0386719), (-1.7401575, -0.97227776), (-2.5275834, -2.7967029), (-2.592079, -2.8630972), (-1.8046508, -1.0386728), (-1.7401562, -0.9722793), (-2.5275862, -2.7967043), (-2.592085, -2.8630965), (-1.8046564, -1.03867), (-1.7401564, -0.97227633), (-2.5275826, -2.796702), (-2.5920794, -2.863098), (-1.8046514, -1.0386746), (-1.7401528, -0.9722793), (-2.5275805, -2.7967024), (-2.5920815, -2.8630972), (-1.8046572, -1.0386728), (-1.7401544, -0.9722772), (-2.5275755, -2.7967014), (-2.592079, -2.8630984), (-1.8046579, -1.0386753), (-1.740155, -0.9722772), (-2.5275772, -2.7966995), (-2.5920796, -2.8630981), (-1.8046583, -1.0386761), (-1.7401574, -0.97227836), (-2.5275784, -2.7967005), (-2.5920775, -2.863096), (-1.8046529, -1.0386727), (-1.7401547, -0.97227925), (-2.5275824, -2.7967045), (-2.5920806, -2.8630965), (-1.8046546, -1.0386697), (-1.7401572, -0.9722768), (-2.5275838, -2.7967033), (-2.5920813, -2.8630977), (-1.8046563, -1.0386719), (-1.7401593, -0.9722759), (-2.527581, -2.796701), (-2.5920765, -2.8630974), (-1.8046554, -1.0386745), (-1.740161, -0.9722786), (-2.5275846, -2.7966993), (-2.592079, -2.8630934), (-1.8046535, -1.038673), (-1.7401574, -0.97228056), (-2.527583, -2.7967026), (-2.5920806, -2.8630958), (-1.8046551, -1.0386728), (-1.740157, -0.9722788), (-2.5275803, -2.7967024), (-2.592079, -2.863097), (-1.8046556, -1.0386732), (-1.7401569, -0.97227746), (-2.5275817, -2.7967012), (-2.5920784, -2.863097), (-1.8046542, -1.0386741), (-1.7401581, -0.97227937), (-2.527582, -2.7967017), (-2.5920782, -2.8630955), (-1.8046533, -1.0386726), (-1.7401553, -0.9722796), (-2.5275793, -2.7967038), (-2.592078, -2.863098), (-1.8046557, -1.0386732), (-1.7401581, -0.9722776), (-2.5275807, -2.796702), (-2.5920796, -2.8630972), (-1.804655, -1.0386734), (-1.7401553, -0.97227776), (-2.5275803, -2.7967017), (-2.592081, -2.8630974), (-1.8046577, -1.0386735), (-1.740156, -0.97227705), (-2.5275795, -2.7966998), (-2.5920808, -2.8630967), (-1.8046578, -1.0386745), (-1.7401582, -0.9722779), (-2.5275812, -2.7966995), (-2.592079, -2.8630955), (-1.8046557, -1.0386742), (-1.7401572, -0.97227895), (-2.527579, -2.7967005), (-2.592077, -2.8630962), (-1.8046556, -1.038675), (-1.74016, -0.97227925), (-2.5275836, -2.7967005), (-2.592078, -2.8630948), (-1.8046529, -1.0386732), (-1.7401583, -0.97228074), (-2.5275846, -2.7967038), (-2.5920792, -2.8630953), (-1.8046513, -1.0386704), (-1.740157, -0.97227895), (-2.5275836, -2.7967045), (-2.5920758, -2.863097), (-1.8046501, -1.0386717), (-1.7401592, -0.97227913), (-2.5275884, -2.7967045), (-2.5920827, -2.8630965), (-1.804651, -1.03867), (-1.7401534, -0.97227746), (-2.527583, -2.7967055), (-2.5920813, -2.8630998), (-1.8046534, -1.0386714), (-1.7401545, -0.9722757), (-2.5275815, -2.7967029), (-2.5920787, -2.8630993), (-1.8046527, -1.0386735), (-1.7401577, -0.97227675), (-2.5275846, -2.7967005), (-2.5920796, -2.863096), (-1.8046523, -1.0386724), (-1.7401555, -0.97227806), (-2.5275822, -2.7967029), (-2.59208, -2.8630977), (-1.8046546, -1.038673), (-1.7401583, -0.97227746), (-2.5275838, -2.7967021), (-2.5920796, -2.8630977), (-1.8046536, -1.0386732), (-1.7401574, -0.9722779), (-2.527585, -2.796702), (-2.5920806, -2.863097), (-1.8046523, -1.0386724), (-1.7401555, -0.97227806), (-2.5275822, -2.7967029), (-2.59208, -2.8630977), (-1.8046546, -1.038673), (-1.7401583, -0.97227746), (-2.5275838, -2.7967014), (-2.5920777, -2.8630962), (-1.8046514, -1.0386728), (-1.740157, -0.97227925), (-2.527584, -2.796703), (-2.5920799, -2.8630953), (-1.8046527, -1.0386704), (-1.740156, -0.9722786), (-2.5275812, -2.7967048), (-2.5920775, -2.8630967), (-1.8046536, -1.038671), (-1.7401582, -0.97227925), (-2.527583, -2.796704), (-2.5920775, -2.8630967), (-1.8046515, -1.0386717), (-1.7401571, -0.9722784), (-2.5275857, -2.7967038), (-2.5920815, -2.8630965), (-1.8046528, -1.0386705), (-1.7401575, -0.97227705), (-2.527586, -2.7967029), (-2.5920827, -2.8630972), (-1.8046517, -1.0386714), (-1.7401516, -0.97227687), (-2.527582, -2.7967033), (-2.5920818, -2.8630972), (-1.8046551, -1.0386704), (-1.7401571, -0.9722776), (-2.5275836, -2.7967036), (-2.5920823, -2.8630977), (-1.804656, -1.0386724), (-1.740157, -0.9722781), (-2.5275826, -2.7967021), (-2.5920808, -2.8630965), (-1.804653, -1.0386727), (-1.7401539, -0.9722785), (-2.5275831, -2.7967033), (-2.5920818, -2.8630967), (-1.804652, -1.0386708), (-1.7401536, -0.9722787), (-2.5275843, -2.7967055), (-2.5920846, -2.8630977), (-1.8046514, -1.0386697), (-1.7401499, -0.97227675), (-2.5275824, -2.7967055), (-2.5920832, -2.863099), (-1.8046541, -1.0386714), (-1.7401549, -0.9722762), (-2.5275831, -2.7967026), (-2.5920827, -2.8630993), (-1.8046545, -1.0386745), (-1.7401527, -0.97227806), (-2.5275793, -2.7967014), (-2.5920796, -2.8630967), (-1.8046539, -1.0386741), (-1.7401563, -0.9722797), (-2.5275812, -2.796702), (-2.592081, -2.8630958), (-1.8046577, -1.038673), (-1.7401551, -0.97227895), (-2.5275764, -2.7967026), (-2.5920782, -2.8630977), (-1.8046594, -1.0386746), (-1.740162, -0.9722789), (-2.527582, -2.7967005), (-2.5920775, -2.8630953), (-1.8046572, -1.0386736), (-1.7401607, -0.9722792), (-2.527583, -2.7967007), (-2.592078, -2.863095), (-1.8046545, -1.0386724), (-1.7401608, -0.9722797), (-2.5275831, -2.7967033), (-2.5920765, -2.8630955), (-1.804654, -1.0386717), (-1.7401607, -0.9722795), (-2.5275853, -2.796704), (-2.5920784, -2.8630955), (-1.8046504, -1.0386701), (-1.7401569, -0.9722791), (-2.5275838, -2.7967057), (-2.5920777, -2.8630965), (-1.804649, -1.0386686), (-1.740154, -0.9722784), (-2.5275843, -2.7967074), (-2.5920787, -2.8630974), (-1.8046491, -1.038668), (-1.7401558, -0.9722774), (-2.5275867, -2.7967067), (-2.5920818, -2.8630974), (-1.80465, -1.0386677), (-1.7401532, -0.97227716), (-2.5275865, -2.7967067), (-2.592085, -2.8630981), (-1.8046516, -1.0386684), (-1.7401521, -0.9722747), (-2.5275838, -2.7967048), (-2.5920846, -2.8630986), (-1.8046539, -1.0386686), (-1.7401547, -0.9722754), (-2.527585, -2.796705), (-2.5920846, -2.8630993), (-1.8046552, -1.0386703), (-1.7401527, -0.97227395), (-2.5275805, -2.7967026), (-2.5920827, -2.863101), (-1.8046554, -1.0386758), (-1.7401546, -0.972277), (-2.5275817, -2.796699), (-2.592081, -2.8630965), (-1.8046533, -1.0386748), (-1.7401555, -0.9722803), (-2.5275857, -2.7967036), (-2.5920827, -2.863096), (-1.8046511, -1.0386709), (-1.7401532, -0.9722782), (-2.5275843, -2.7967048), (-2.5920813, -2.8630981), (-1.8046516, -1.0386721), (-1.7401551, -0.9722789), (-2.5275824, -2.796705), (-2.59208, -2.8630977), (-1.8046535, -1.038671), (-1.7401552, -0.9722784), (-2.5275815, -2.796705), (-2.5920794, -2.8630977), (-1.8046539, -1.0386709), (-1.740157, -0.97227836), (-2.5275848, -2.7967043), (-2.5920818, -2.863097), (-1.8046534, -1.0386711), (-1.7401568, -0.9722777), (-2.527584, -2.7967033), (-2.5920815, -2.8630962), (-1.8046536, -1.0386707), (-1.7401553, -0.972277), (-2.5275838, -2.7967024), (-2.5920806, -2.8630972), (-1.804652, -1.0386726), (-1.7401567, -0.97227794), (-2.5275853, -2.796702), (-2.5920804, -2.8630962), (-1.8046523, -1.0386727), (-1.7401562, -0.97227913), (-2.5275836, -2.796703), (-2.5920815, -2.863096), (-1.8046539, -1.0386703), (-1.7401549, -0.9722768), (-2.5275836, -2.7967038), (-2.5920825, -2.8630984), (-1.8046528, -1.0386713), (-1.7401544, -0.97227716), (-2.527583, -2.7967033), (-2.5920799, -2.8630981), (-1.8046538, -1.0386732), (-1.7401577, -0.97227824), (-2.5275836, -2.7967029), (-2.592079, -2.8630972), (-1.8046507, -1.0386727), (-1.7401549, -0.97227955), (-2.5275846, -2.7967048), (-2.5920832, -2.863097), (-1.804655, -1.0386705), (-1.7401553, -0.97227794), (-2.527583, -2.7967045), (-2.59208, -2.863098), (-1.804653, -1.0386711), (-1.7401583, -0.9722775), (-2.5275853, -2.796703), (-2.59208, -2.8630972), (-1.804652, -1.0386726), (-1.7401557, -0.97227865), (-2.527585, -2.7967036), (-2.5920818, -2.863098), (-1.8046526, -1.0386724), (-1.740155, -0.9722779), (-2.5275838, -2.7967038), (-2.5920823, -2.8630972), (-1.8046516, -1.0386711), (-1.7401522, -0.9722777), (-2.5275812, -2.796704), (-2.5920804, -2.8630986), (-1.8046557, -1.0386726), (-1.7401592, -0.9722773), (-2.5275838, -2.7967017), (-2.5920787, -2.8630958), (-1.8046515, -1.0386723), (-1.7401559, -0.9722788), (-2.5275826, -2.796703), (-2.5920794, -2.863097), (-1.8046533, -1.0386721), (-1.7401564, -0.97227865), (-2.5275824, -2.7967038), (-2.5920792, -2.863096), (-1.804655, -1.0386703), (-1.7401599, -0.972278), (-2.5275857, -2.796703), (-2.5920818, -2.8630965), (-1.8046526, -1.0386716), (-1.7401541, -0.9722781), (-2.5275838, -2.7967038), (-2.5920835, -2.8630981), (-1.8046533, -1.0386713), (-1.7401528, -0.97227615), (-2.5275826, -2.796703), (-2.5920842, -2.8630984), (-1.8046564, -1.0386724), (-1.7401534, -0.9722775), (-2.5275798, -2.7967029), (-2.5920832, -2.8630981), (-1.8046578, -1.038673), (-1.7401539, -0.9722756), (-2.5275779, -2.7966993), (-2.5920806, -2.8630984), (-1.8046576, -1.038677), (-1.7401576, -0.9722786), (-2.5275812, -2.7966986), (-2.5920796, -2.8630948), (-1.8046522, -1.0386747), (-1.7401514, -0.9722809), (-2.5275805, -2.7967036), (-2.5920835, -2.8630977), (-1.8046532, -1.0386728), (-1.7401489, -0.97227776), (-2.5275793, -2.7967026), (-2.5920858, -2.863098), (-1.8046588, -1.0386729), (-1.7401524, -0.9722756), (-2.5275755, -2.7967002), (-2.5920799, -2.8631), (-1.8046598, -1.0386757), (-1.7401582, -0.97227496), (-2.52758, -2.7966979), (-2.5920827, -2.8630967), (-1.8046576, -1.0386742), (-1.7401534, -0.97227705), (-2.5275788, -2.7967012), (-2.5920827, -2.8630981), (-1.8046603, -1.0386739), (-1.7401582, -0.9722765), (-2.5275798, -2.7967), (-2.5920794, -2.8630967), (-1.8046554, -1.0386734), (-1.7401565, -0.9722779), (-2.5275822, -2.7967014), (-2.5920808, -2.8630958), (-1.8046533, -1.0386714), (-1.7401545, -0.9722783), (-2.527582, -2.7967036), (-2.592079, -2.8630972), (-1.8046534, -1.0386732), (-1.7401601, -0.97227925), (-2.5275884, -2.796702), (-2.5920815, -2.8630936), (-1.8046496, -1.0386701), (-1.7401524, -0.9722795), (-2.527586, -2.7967062), (-2.5920858, -2.8630972), (-1.8046516, -1.0386678), (-1.7401509, -0.9722759), (-2.5275815, -2.796707), (-2.592081, -2.8631), (-1.804653, -1.0386695), (-1.7401555, -0.9722757), (-2.5275848, -2.7967048), (-2.5920842, -2.8630989), (-1.8046558, -1.0386714), (-1.7401539, -0.97227657), (-2.527579, -2.7967033), (-2.592079, -2.8630998), (-1.8046538, -1.0386755), (-1.7401549, -0.97227895), (-2.5275807, -2.7967017), (-2.5920804, -2.8630967), (-1.8046535, -1.0386732), (-1.7401544, -0.97227895), (-2.527583, -2.7967033), (-2.592081, -2.8630974), (-1.8046547, -1.0386723), (-1.7401584, -0.97227794), (-2.527584, -2.7967029), (-2.592079, -2.863097), (-1.8046526, -1.0386732), (-1.7401588, -0.9722803), (-2.527588, -2.7967045), (-2.5920835, -2.8630958), (-1.8046513, -1.0386691), (-1.7401525, -0.9722769), (-2.527582, -2.7967045), (-2.5920799, -2.8630993), (-1.8046527, -1.0386728), (-1.7401562, -0.972277), (-2.5275834, -2.796702), (-2.5920808, -2.863097), (-1.8046541, -1.0386723), (-1.7401568, -0.9722779), (-2.5275826, -2.7967033), (-2.5920804, -2.8630981), (-1.8046563, -1.0386726), (-1.740159, -0.9722766), (-2.527583, -2.7967005), (-2.5920794, -2.863096), (-1.8046533, -1.0386727), (-1.7401576, -0.9722792), (-2.5275836, -2.7967033), (-2.5920787, -2.8630965), (-1.8046534, -1.0386716), (-1.7401576, -0.9722781), (-2.5275834, -2.7967033), (-2.5920799, -2.8630972), (-1.8046511, -1.0386715), (-1.740154, -0.9722784), (-2.5275834, -2.7967052), (-2.592081, -2.8630967), (-1.8046527, -1.038669), (-1.7401552, -0.97227764), (-2.5275831, -2.7967057), (-2.59208, -2.8630974), (-1.8046527, -1.0386696), (-1.740156, -0.9722776), (-2.5275846, -2.7967052), (-2.592082, -2.8630972), (-1.8046517, -1.0386685), (-1.740153, -0.9722763), (-2.5275824, -2.7967057), (-2.5920808, -2.8630986), (-1.8046545, -1.0386695), (-1.7401568, -0.9722769), (-2.5275834, -2.796705), (-2.5920806, -2.863098), (-1.8046552, -1.0386702), (-1.7401586, -0.9722762), (-2.527582, -2.7967033), (-2.5920763, -2.8630981), (-1.8046533, -1.0386733), (-1.7401612, -0.97227776), (-2.5275865, -2.7967014), (-2.5920784, -2.8630962), (-1.8046501, -1.0386728), (-1.7401551, -0.97228026), (-2.5275834, -2.7967048), (-2.5920782, -2.863097), (-1.8046508, -1.038671), (-1.740157, -0.9722781), (-2.5275855, -2.7967043), (-2.5920808, -2.8630974), (-1.8046536, -1.038671), (-1.7401584, -0.97227716), (-2.527585, -2.7967033), (-2.5920799, -2.8630984), (-1.8046532, -1.0386729), (-1.7401576, -0.97227764), (-2.5275838, -2.7967026), (-2.592079, -2.8630974), (-1.8046522, -1.0386724), (-1.7401572, -0.9722779), (-2.5275846, -2.7967029), (-2.5920796, -2.863096), (-1.8046526, -1.0386713), (-1.7401578, -0.97227895), (-2.5275838, -2.7967038), (-2.5920796, -2.863097), (-1.8046533, -1.0386722), (-1.740156, -0.97227836), (-2.527582, -2.796703), (-2.5920792, -2.8630972), (-1.804653, -1.0386723), (-1.7401558, -0.9722786), (-2.5275817, -2.7967036), (-2.5920794, -2.8630974), (-1.804654, -1.0386727), (-1.7401563, -0.9722777), (-2.5275826, -2.796702), (-2.5920808, -2.863097), (-1.8046554, -1.0386729), (-1.7401584, -0.97227705), (-2.5275846, -2.7967007), (-2.5920804, -2.8630965), (-1.8046522, -1.038673), (-1.7401546, -0.9722786), (-2.5275817, -2.7967026), (-2.5920799, -2.8630972), (-1.8046545, -1.038673), (-1.7401582, -0.9722775), (-2.5275848, -2.7967012), (-2.5920794, -2.863097), (-1.8046511, -1.0386735), (-1.7401569, -0.97227883), (-2.5275853, -2.7967026), (-2.5920796, -2.8630967), (-1.8046525, -1.0386733), (-1.7401597, -0.9722797), (-2.5275886, -2.796703), (-2.5920804, -2.8630955), (-1.8046495, -1.0386707), (-1.7401551, -0.97227925), (-2.5275862, -2.7967052), (-2.5920827, -2.8630974), (-1.8046505, -1.038669), (-1.7401531, -0.9722762), (-2.5275834, -2.7967062), (-2.5920818, -2.8630993), (-1.8046525, -1.0386696), (-1.740154, -0.9722755), (-2.527584, -2.7967043), (-2.592083, -2.8630981), (-1.8046553, -1.03867), (-1.7401567, -0.97227615), (-2.5275826, -2.796703), (-2.592079, -2.8630984), (-1.8046522, -1.0386734), (-1.740158, -0.97227824), (-2.5275853, -2.7967026), (-2.5920784, -2.8630953), (-1.804647, -1.038671), (-1.7401514, -0.9722802), (-2.527586, -2.7967064), (-2.5920835, -2.8630962), (-1.8046492, -1.0386674), (-1.7401514, -0.9722777), (-2.5275857, -2.7967072), (-2.592084, -2.8630984), (-1.8046494, -1.0386683), (-1.7401507, -0.97227603), (-2.5275848, -2.7967057), (-2.5920866, -2.8630989), (-1.8046547, -1.0386698), (-1.740151, -0.9722748), (-2.5275805, -2.7967038), (-2.5920827, -2.8630989), (-1.8046545, -1.0386705), (-1.7401534, -0.972276), (-2.5275817, -2.7967043), (-2.5920818, -2.8631003), (-1.8046559, -1.0386733), (-1.7401601, -0.9722757), (-2.527585, -2.7966995), (-2.5920782, -2.863096), (-1.8046527, -1.038674), (-1.74016, -0.97227937), (-2.5275884, -2.796702), (-2.592083, -2.863094), (-1.8046523, -1.0386702), (-1.7401547, -0.97227937), (-2.5275834, -2.7967048), (-2.5920784, -2.8630967), (-1.8046515, -1.038672), (-1.7401571, -0.97227967), (-2.527584, -2.7967043), (-2.5920792, -2.8630962), (-1.8046525, -1.0386715), (-1.7401587, -0.9722791), (-2.5275872, -2.7967043), (-2.5920806, -2.8630962), (-1.8046486, -1.03867), (-1.7401534, -0.97227937), (-2.5275865, -2.7967072), (-2.592085, -2.8630974), (-1.8046502, -1.0386686), (-1.74015, -0.97227716), (-2.527583, -2.7967067), (-2.5920844, -2.8631005), (-1.8046551, -1.0386713), (-1.7401536, -0.97227496), (-2.5275817, -2.796702), (-2.5920818, -2.863099), (-1.8046558, -1.0386745), (-1.740157, -0.97227824), (-2.5275815, -2.7967014), (-2.5920823, -2.8630977), (-1.8046579, -1.0386753), (-1.7401564, -0.972279), (-2.527582, -2.7967012), (-2.5920808, -2.8630962), (-1.804653, -1.0386728), (-1.7401539, -0.97227865), (-2.527584, -2.7967029), (-2.592083, -2.863097), (-1.8046508, -1.038672), (-1.7401514, -0.9722782), (-2.527583, -2.7967043), (-2.5920813, -2.8630974), (-1.8046514, -1.0386715), (-1.7401541, -0.9722783), (-2.5275822, -2.7967036), (-2.5920794, -2.8630972), (-1.8046526, -1.0386724), (-1.740156, -0.97227806), (-2.5275826, -2.7967021), (-2.592081, -2.8630967), (-1.8046546, -1.0386716), (-1.7401567, -0.97227615), (-2.5275867, -2.7967014), (-2.592085, -2.8630967), (-1.8046539, -1.0386715), (-1.740155, -0.9722768), (-2.5275857, -2.7967024), (-2.5920856, -2.8630974), (-1.8046528, -1.0386716), (-1.7401507, -0.97227687), (-2.5275817, -2.7967036), (-2.592084, -2.8630986), (-1.8046539, -1.0386719), (-1.7401521, -0.9722759), (-2.527581, -2.7967029), (-2.5920815, -2.8630996), (-1.8046541, -1.0386732), (-1.7401578, -0.9722763), (-2.5275862, -2.796702), (-2.5920804, -2.8630965), (-1.8046507, -1.0386708), (-1.7401547, -0.9722787), (-2.5275836, -2.7967052), (-2.5920808, -2.8630972), (-1.8046554, -1.0386695), (-1.7401589, -0.9722761), (-2.5275807, -2.7967038), (-2.5920746, -2.8630989), (-1.8046502, -1.038674), (-1.740158, -0.9722795), (-2.527585, -2.7967038), (-2.592077, -2.863097), (-1.8046514, -1.0386721), (-1.7401587, -0.97227854), (-2.5275853, -2.7967029), (-2.5920799, -2.8630953), (-1.8046535, -1.0386697), (-1.7401582, -0.9722783), (-2.5275843, -2.7967048), (-2.5920808, -2.863097), (-1.804654, -1.0386703), (-1.7401563, -0.9722776), (-2.5275826, -2.7967043), (-2.592079, -2.8630986), (-1.8046535, -1.038673), (-1.7401582, -0.9722781), (-2.527584, -2.796702), (-2.5920787, -2.8630955), (-1.804652, -1.0386722), (-1.7401574, -0.97227865), (-2.5275834, -2.7967024), (-2.5920787, -2.8630967), (-1.804653, -1.0386742), (-1.7401581, -0.9722798), (-2.5275838, -2.7967029), (-2.5920796, -2.863097), (-1.8046528, -1.0386724), (-1.7401559, -0.97227776), (-2.5275822, -2.796702), (-2.5920782, -2.863097), (-1.8046539, -1.0386744), (-1.7401613, -0.97227967), (-2.5275881, -2.7967012), (-2.59208, -2.8630943), (-1.8046496, -1.038672), (-1.740155, -0.97228044), (-2.5275843, -2.7967048), (-2.5920784, -2.863097), (-1.8046507, -1.0386709), (-1.7401568, -0.97227806), (-2.5275853, -2.7967038), (-2.5920806, -2.8630967), (-1.8046511, -1.0386709), (-1.7401552, -0.97227824), (-2.5275834, -2.7967043), (-2.5920796, -2.8630967), (-1.8046535, -1.0386709), (-1.7401592, -0.97227794), (-2.5275857, -2.796703), (-2.5920808, -2.8630955), (-1.8046548, -1.0386701), (-1.740158, -0.9722776), (-2.5275824, -2.7967038), (-2.592078, -2.863097), (-1.8046532, -1.0386715), (-1.7401593, -0.97227925), (-2.5275857, -2.796704), (-2.5920804, -2.8630965), (-1.8046505, -1.0386707), (-1.7401546, -0.9722782), (-2.5275836, -2.796704), (-2.592081, -2.8630977), (-1.8046532, -1.0386729), (-1.740155, -0.97227865), (-2.5275817, -2.7967036), (-2.5920784, -2.863098), (-1.8046523, -1.0386724), (-1.7401565, -0.97227734), (-2.527584, -2.7967021), (-2.5920796, -2.863097), (-1.804651, -1.0386723), (-1.7401553, -0.972278), (-2.5275834, -2.7967026), (-2.5920808, -2.8630974), (-1.8046546, -1.0386733), (-1.7401593, -0.9722775), (-2.527586, -2.7967002), (-2.59208, -2.8630955), (-1.8046534, -1.0386735), (-1.7401587, -0.97227913), (-2.5275862, -2.7967024), (-2.5920806, -2.863095), (-1.80465, -1.038671), (-1.7401537, -0.9722805), (-2.5275855, -2.7967067), (-2.5920837, -2.863097), (-1.8046511, -1.038668), (-1.7401524, -0.97227657), (-2.5275838, -2.7967064), (-2.5920842, -2.8631003), (-1.8046539, -1.038671), (-1.7401524, -0.972276), (-2.5275803, -2.796704), (-2.5920813, -2.863101), (-1.8046546, -1.038674), (-1.7401557, -0.9722756), (-2.5275846, -2.7967007), (-2.5920815, -2.8630967), (-1.804651, -1.0386724), (-1.7401526, -0.9722793), (-2.5275834, -2.7967048), (-2.5920842, -2.863097), (-1.8046545, -1.0386703), (-1.740153, -0.97227687), (-2.5275798, -2.796703), (-2.59208, -2.863099), (-1.8046584, -1.0386746), (-1.7401626, -0.9722773), (-2.5275838, -2.796699), (-2.5920768, -2.8630948), (-1.8046525, -1.0386742), (-1.7401595, -0.9722818), (-2.5275853, -2.7967038), (-2.592078, -2.8630943), (-1.8046516, -1.0386704), (-1.7401589, -0.9722796), (-2.5275853, -2.7967048), (-2.5920796, -2.863096), (-1.8046515, -1.0386697), (-1.7401549, -0.9722782), (-2.5275834, -2.7967052), (-2.5920813, -2.8630962), (-1.8046529, -1.0386685), (-1.7401524, -0.9722774), (-2.5275784, -2.7967055), (-2.592079, -2.8630972), (-1.8046547, -1.03867), (-1.7401564, -0.9722774), (-2.5275817, -2.7967045), (-2.592079, -2.8630977), (-1.8046539, -1.0386709), (-1.7401569, -0.97227824), (-2.5275836, -2.7967043), (-2.5920799, -2.8630981), (-1.804654, -1.0386722), (-1.7401584, -0.9722779), (-2.5275846, -2.7967033), (-2.5920804, -2.8630958), (-1.8046522, -1.03867), (-1.7401565, -0.9722777), (-2.5275855, -2.7967048), (-2.5920837, -2.8630962), (-1.8046561, -1.0386685), (-1.7401572, -0.9722773), (-2.527584, -2.7967052), (-2.592081, -2.8630981), (-1.804654, -1.0386714), (-1.7401568, -0.97227734), (-2.5275836, -2.7967026), (-2.5920794, -2.8630974), (-1.8046501, -1.0386732), (-1.7401536, -0.9722796), (-2.5275824, -2.7967043), (-2.5920782, -2.8630967), (-1.8046503, -1.0386715), (-1.7401568, -0.9722793), (-2.527585, -2.7967038), (-2.592079, -2.863096), (-1.804651, -1.0386711), (-1.7401564, -0.97227937), (-2.5275846, -2.7967045), (-2.5920825, -2.8630958), (-1.8046544, -1.0386695), (-1.7401549, -0.97227687), (-2.5275831, -2.7967052), (-2.592082, -2.8630998), (-1.804654, -1.0386721), (-1.7401549, -0.9722763), (-2.5275826, -2.796703), (-2.592082, -2.8630996), (-1.8046544, -1.0386732), (-1.7401562, -0.9722763), (-2.5275843, -2.7967014), (-2.5920813, -2.8630981), (-1.8046535, -1.0386746), (-1.7401559, -0.9722788), (-2.5275805, -2.796702), (-2.5920784, -2.8630967), (-1.8046542, -1.0386729), (-1.7401567, -0.9722787), (-2.5275836, -2.796703), (-2.5920815, -2.8630967), (-1.8046513, -1.0386713), (-1.7401528, -0.9722773), (-2.527584, -2.7967043), (-2.5920844, -2.8630981), (-1.8046558, -1.0386708), (-1.7401552, -0.972276), (-2.5275834, -2.796702), (-2.592082, -2.863097), (-1.8046535, -1.0386721), (-1.740155, -0.9722779), (-2.527581, -2.7967033), (-2.5920792, -2.8630981), (-1.8046551, -1.0386727), (-1.7401569, -0.97227705), (-2.527582, -2.7967012), (-2.5920804, -2.8630967), (-1.8046522, -1.0386724), (-1.7401527, -0.9722779), (-2.5275826, -2.7967036), (-2.592083, -2.8630981), (-1.8046533, -1.0386714), (-1.7401536, -0.9722762), (-2.527584, -2.7967033), (-2.592083, -2.863098), (-1.804654, -1.0386708), (-1.7401556, -0.9722771), (-2.527582, -2.7967043), (-2.5920796, -2.8630972), (-1.8046523, -1.0386704), (-1.7401553, -0.9722778), (-2.5275855, -2.7967045), (-2.5920844, -2.8630967), (-1.804655, -1.038669), (-1.7401547, -0.97227615), (-2.527583, -2.7967036), (-2.5920823, -2.8630986), (-1.8046552, -1.0386726), (-1.7401562, -0.97227645), (-2.527583, -2.796701), (-2.5920806, -2.863097), (-1.8046519, -1.0386735), (-1.7401568, -0.9722791), (-2.527585, -2.7967024), (-2.5920787, -2.8630958), (-1.8046511, -1.0386723), (-1.7401556, -0.97227883), (-2.527583, -2.7967038), (-2.5920792, -2.8630974), (-1.8046507, -1.0386717), (-1.7401555, -0.97227955), (-2.5275853, -2.796706), (-2.59208, -2.863098), (-1.8046509, -1.0386701), (-1.7401562, -0.9722768), (-2.5275855, -2.7967043), (-2.5920806, -2.8630981), (-1.804652, -1.0386713), (-1.7401557, -0.9722766), (-2.527585, -2.7967026), (-2.592082, -2.863098), (-1.8046508, -1.0386717), (-1.740153, -0.9722764), (-2.5275843, -2.7967033), (-2.592084, -2.8630989), (-1.8046534, -1.0386723), (-1.740152, -0.97227633), (-2.5275817, -2.7967021), (-2.5920835, -2.8630984), (-1.804655, -1.0386734), (-1.740155, -0.97227687), (-2.5275838, -2.796701), (-2.5920823, -2.863097), (-1.804651, -1.0386728), (-1.7401522, -0.9722786), (-2.527584, -2.7967043), (-2.5920851, -2.863097), (-1.8046551, -1.03867), (-1.7401526, -0.9722766), (-2.5275807, -2.7967043), (-2.5920808, -2.8630998), (-1.8046553, -1.0386721), (-1.740158, -0.97227544), (-2.527583, -2.7967021), (-2.59208, -2.8630986), (-1.804655, -1.038674), (-1.7401589, -0.9722778), (-2.5275857, -2.796701), (-2.5920804, -2.863096), (-1.8046509, -1.0386734), (-1.7401559, -0.9722796), (-2.5275836, -2.7967036), (-2.5920782, -2.863096), (-1.8046514, -1.038671), (-1.7401575, -0.9722786), (-2.5275855, -2.796704), (-2.5920794, -2.863097), (-1.8046497, -1.0386713), (-1.7401541, -0.9722792), (-2.5275853, -2.7967057), (-2.592083, -2.8630962), (-1.8046521, -1.0386686), (-1.7401545, -0.9722772), (-2.5275843, -2.796705), (-2.5920796, -2.8630984), (-1.804652, -1.0386719), (-1.7401572, -0.972278), (-2.527585, -2.7967038), (-2.59208, -2.8630967), (-1.8046514, -1.0386709), (-1.740156, -0.9722778), (-2.527584, -2.7967036), (-2.5920794, -2.8630977), (-1.8046532, -1.0386726), (-1.7401578, -0.97227764), (-2.5275843, -2.7967021), (-2.5920792, -2.8630965), (-1.8046521, -1.038673), (-1.7401614, -0.97227937), (-2.5275912, -2.796702), (-2.5920823, -2.863094), (-1.8046491, -1.0386705), (-1.7401541, -0.972279), (-2.5275862, -2.7967055), (-2.5920827, -2.8630981), (-1.8046533, -1.0386703), (-1.740155, -0.9722755), (-2.5275812, -2.7967029), (-2.5920796, -2.8631003), (-1.8046535, -1.0386734), (-1.7401545, -0.9722761), (-2.5275824, -2.7967017), (-2.5920813, -2.8630981), (-1.8046539, -1.0386746), (-1.7401558, -0.97227883), (-2.5275824, -2.796702), (-2.5920796, -2.8630972), (-1.8046513, -1.0386738), (-1.740152, -0.9722793), (-2.5275817, -2.7967036), (-2.5920808, -2.8630981), (-1.8046521, -1.038673), (-1.7401549, -0.9722779), (-2.5275836, -2.7967029), (-2.592083, -2.8630974), (-1.8046559, -1.038672), (-1.7401569, -0.9722764), (-2.5275824, -2.7967007), (-2.59208, -2.8630972), (-1.8046556, -1.0386736), (-1.74016, -0.9722776), (-2.5275843, -2.7967005), (-2.5920773, -2.8630958), (-1.8046517, -1.0386736), (-1.7401578, -0.9722801), (-2.5275826, -2.7967029), (-2.592077, -2.8630955), (-1.8046542, -1.038673), (-1.7401606, -0.9722807), (-2.5275836, -2.7967036), (-2.5920768, -2.8630948), (-1.8046517, -1.0386708), (-1.7401592, -0.97227937), (-2.527586, -2.7967038), (-2.5920794, -2.8630962), (-1.8046513, -1.0386714), (-1.7401572, -0.97227895), (-2.5275838, -2.796704), (-2.5920777, -2.863097), (-1.8046519, -1.0386709), (-1.7401583, -0.9722772), (-2.5275862, -2.7967036), (-2.5920804, -2.8630972), (-1.8046502, -1.0386705), (-1.7401543, -0.9722783), (-2.5275857, -2.7967055), (-2.5920832, -2.8630981), (-1.8046514, -1.0386697), (-1.7401533, -0.97227645), (-2.5275843, -2.7967052), (-2.5920842, -2.8630989), (-1.8046552, -1.038671), (-1.7401546, -0.9722762), (-2.527583, -2.7967021), (-2.5920835, -2.8630981), (-1.8046557, -1.0386734), (-1.7401538, -0.97227687), (-2.5275795, -2.7967012), (-2.5920815, -2.8630984), (-1.8046578, -1.038675), (-1.7401571, -0.9722772), (-2.5275795, -2.7966998), (-2.5920782, -2.863097), (-1.8046547, -1.0386757), (-1.7401549, -0.97228014), (-2.5275795, -2.796702), (-2.5920796, -2.863097), (-1.8046536, -1.0386736), (-1.7401553, -0.97227836), (-2.5275807, -2.7967017), (-2.592078, -2.863097), (-1.8046528, -1.0386735), (-1.7401546, -0.97227937), (-2.5275807, -2.7967038), (-2.5920792, -2.8630977), (-1.8046546, -1.0386716), (-1.7401584, -0.9722764), (-2.5275838, -2.7967017), (-2.5920796, -2.8630974), (-1.8046538, -1.0386734), (-1.740159, -0.9722774), (-2.527586, -2.796701), (-2.5920796, -2.8630953), (-1.8046504, -1.0386709), (-1.7401574, -0.9722775), (-2.5275874, -2.7967036), (-2.5920818, -2.8630967), (-1.8046532, -1.03867), (-1.7401577, -0.97227657), (-2.5275855, -2.7967026), (-2.5920806, -2.8630972), (-1.8046522, -1.0386727), (-1.7401584, -0.972278), (-2.527588, -2.7967014), (-2.5920808, -2.8630955), (-1.8046484, -1.0386714), (-1.7401522, -0.97227824), (-2.5275843, -2.7967038), (-2.5920808, -2.8630967), (-1.8046492, -1.0386711), (-1.7401533, -0.9722781), (-2.5275848, -2.7967043), (-2.592083, -2.863097), (-1.8046525, -1.0386696), (-1.740151, -0.9722771), (-2.5275793, -2.7967055), (-2.5920804, -2.8630989), (-1.8046557, -1.0386707), (-1.7401574, -0.97227544), (-2.5275822, -2.7967029), (-2.592079, -2.8630974), (-1.8046532, -1.0386705), (-1.740157, -0.97227716), (-2.5275826, -2.7967036), (-2.592079, -2.8630981), (-1.8046532, -1.0386726), (-1.7401565, -0.97227764), (-2.5275836, -2.7967021), (-2.5920823, -2.863097), (-1.8046534, -1.0386724), (-1.7401531, -0.9722786), (-2.527584, -2.796704), (-2.592085, -2.863097), (-1.804653, -1.0386703), (-1.7401515, -0.972277), (-2.5275824, -2.7967048), (-2.5920846, -2.8630998), (-1.8046557, -1.038672), (-1.7401536, -0.9722745), (-2.52758, -2.7967012), (-2.5920832, -2.8631003), (-1.8046588, -1.0386754), (-1.7401552, -0.9722756), (-2.5275793, -2.7966993), (-2.5920815, -2.8630984), (-1.804658, -1.0386759), (-1.7401574, -0.9722791), (-2.5275803, -2.7967002), (-2.5920784, -2.863096), (-1.8046544, -1.0386747), (-1.7401588, -0.97227985), (-2.5275838, -2.796702), (-2.5920768, -2.8630939), (-1.8046486, -1.0386708), (-1.7401545, -0.97228104), (-2.5275865, -2.7967064), (-2.5920835, -2.863096), (-1.804651, -1.0386683), (-1.7401528, -0.9722767), (-2.5275824, -2.7967062), (-2.5920808, -2.8631008), (-1.8046538, -1.0386722), (-1.7401555, -0.972276), (-2.5275834, -2.7967021), (-2.5920815, -2.863099), (-1.8046548, -1.0386742), (-1.7401578, -0.97227734), (-2.527583, -2.7967014), (-2.5920773, -2.8630977), (-1.8046529, -1.0386748), (-1.7401603, -0.9722797), (-2.5275865, -2.796702), (-2.5920796, -2.8630943), (-1.8046507, -1.0386704), (-1.7401553, -0.97227955), (-2.5275843, -2.796705), (-2.592079, -2.8630972), (-1.8046511, -1.0386721), (-1.740157, -0.9722786), (-2.527584, -2.7967024), (-2.592078, -2.8630962), (-1.8046513, -1.0386727), (-1.7401578, -0.97227913), (-2.527585, -2.7967026), (-2.5920794, -2.863096), (-1.8046527, -1.0386714), (-1.740158, -0.972278), (-2.5275853, -2.7967029), (-2.5920804, -2.8630965), (-1.8046522, -1.038672), (-1.7401565, -0.97227734), (-2.527585, -2.7967021), (-2.5920815, -2.8630972), (-1.8046533, -1.0386728), (-1.7401567, -0.9722782), (-2.5275846, -2.796703), (-2.5920823, -2.8630967), (-1.8046559, -1.0386705), (-1.7401575, -0.9722776), (-2.5275826, -2.7967036), (-2.5920784, -2.863098), (-1.8046526, -1.0386729), (-1.7401588, -0.97227854), (-2.527587, -2.7967026), (-2.5920813, -2.8630948), (-1.8046501, -1.0386707), (-1.7401536, -0.9722802), (-2.5275834, -2.796707), (-2.5920806, -2.8630977), (-1.8046517, -1.03867), (-1.7401551, -0.97227836), (-2.5275824, -2.7967052), (-2.5920794, -2.8630972), (-1.8046526, -1.0386705), (-1.7401547, -0.9722781), (-2.5275817, -2.796705), (-2.5920799, -2.8630977), (-1.8046532, -1.0386713), (-1.7401556, -0.9722781), (-2.5275822, -2.7967036), (-2.5920768, -2.8630977), (-1.8046503, -1.0386739), (-1.7401586, -0.97228), (-2.5275898, -2.7967033), (-2.5920835, -2.8630948), (-1.8046521, -1.0386693), (-1.740157, -0.9722776), (-2.5275855, -2.796704), (-2.5920806, -2.8630977), (-1.804652, -1.0386716), (-1.7401555, -0.97227776), (-2.5275822, -2.796703), (-2.5920784, -2.863098), (-1.8046538, -1.0386728), (-1.7401583, -0.9722779), (-2.5275843, -2.7967017), (-2.5920799, -2.8630958), (-1.8046541, -1.0386724), (-1.740158, -0.9722789), (-2.5275826, -2.7967026), (-2.5920794, -2.8630967), (-1.8046554, -1.038674), (-1.74016, -0.9722794), (-2.527585, -2.796702), (-2.5920777, -2.8630955), (-1.8046491, -1.0386713), (-1.740157, -0.9722791), (-2.5275877, -2.796705), (-2.5920796, -2.8630948), (-1.8046459, -1.0386682), (-1.7401543, -0.9722809), (-2.5275917, -2.7967095), (-2.592085, -2.8630962), (-1.8046479, -1.0386647), (-1.740151, -0.9722772), (-2.5275846, -2.7967107), (-2.592085, -2.8630996), (-1.8046545, -1.0386654), (-1.7401527, -0.9722727), (-2.5275817, -2.7967048), (-2.5920837, -2.863102), (-1.804655, -1.0386734), (-1.7401528, -0.9722746), (-2.52758, -2.7967002), (-2.5920813, -2.8630993), (-1.8046572, -1.0386755), (-1.7401576, -0.9722775), (-2.5275807, -2.7966998), (-2.5920784, -2.863096), (-1.8046542, -1.0386744), (-1.7401574, -0.9722799), (-2.527584, -2.7967021), (-2.5920804, -2.8630953), (-1.8046496, -1.0386726), (-1.7401491, -0.9722799), (-2.5275807, -2.7967048), (-2.5920854, -2.8630986), (-1.8046572, -1.0386711), (-1.7401545, -0.9722746), (-2.52758, -2.7967017), (-2.5920818, -2.8630989), (-1.8046577, -1.0386741), (-1.7401553, -0.9722767), (-2.527578, -2.7967), (-2.5920794, -2.8630989), (-1.8046566, -1.0386766), (-1.740159, -0.97227806), (-2.5275826, -2.7967), (-2.5920784, -2.8630955), (-1.804653, -1.0386735), (-1.740158, -0.972279), (-2.5275838, -2.7967012), (-2.5920773, -2.8630948), (-1.8046517, -1.0386724), (-1.7401583, -0.9722803), (-2.5275853, -2.7967033), (-2.5920799, -2.8630946), (-1.8046486, -1.0386703), (-1.7401519, -0.97227967), (-2.5275853, -2.796706), (-2.5920851, -2.8630977), (-1.8046538, -1.0386691), (-1.740152, -0.9722749), (-2.5275795, -2.7967043), (-2.592082, -2.863099), (-1.8046587, -1.038671), (-1.7401599, -0.9722745), (-2.5275838, -2.7967), (-2.5920777, -2.8630974), (-1.804652, -1.0386738), (-1.7401593, -0.97227776), (-2.527586, -2.796701), (-2.5920784, -2.8630939), (-1.804651, -1.03867), (-1.740158, -0.9722804), (-2.5275867, -2.7967067), (-2.5920818, -2.8630953), (-1.8046535, -1.0386672), (-1.7401562, -0.9722781), (-2.5275805, -2.7967067), (-2.5920777, -2.8630984), (-1.8046535, -1.038671), (-1.7401557, -0.9722774), (-2.5275815, -2.7967036), (-2.5920799, -2.863098), (-1.8046545, -1.0386724), (-1.7401563, -0.9722781), (-2.5275807, -2.7967029), (-2.5920782, -2.8630977), (-1.8046526, -1.0386738), (-1.7401557, -0.97227824), (-2.5275824, -2.7967021), (-2.5920784, -2.863097), (-1.8046528, -1.0386732), (-1.7401605, -0.9722794), (-2.5275888, -2.7967021), (-2.5920818, -2.8630939), (-1.8046497, -1.0386703), (-1.7401526, -0.97227955), (-2.527585, -2.796706), (-2.592084, -2.8630967), (-1.8046525, -1.038669), (-1.7401543, -0.97227764), (-2.5275857, -2.7967055), (-2.5920835, -2.8630981), (-1.8046526, -1.0386707), (-1.740154, -0.97227645), (-2.5275834, -2.796704), (-2.5920813, -2.8631), (-1.8046526, -1.0386723), (-1.7401533, -0.9722762), (-2.5275798, -2.7967038), (-2.59208, -2.8631008), (-1.8046547, -1.0386747), (-1.7401558, -0.9722761), (-2.527583, -2.7966998), (-2.5920823, -2.8630981), (-1.8046559, -1.0386748), (-1.740156, -0.97227734), (-2.5275807, -2.7967005), (-2.592081, -2.8630981), (-1.8046571, -1.0386748), (-1.7401563, -0.9722784), (-2.5275784, -2.7967017), (-2.5920782, -2.863097), (-1.8046563, -1.0386735), (-1.740158, -0.97227806), (-2.5275831, -2.7967014), (-2.5920792, -2.8630965), (-1.8046504, -1.0386732), (-1.7401536, -0.9722798), (-2.527585, -2.7967045), (-2.592086, -2.863096), (-1.8046558, -1.0386697), (-1.740153, -0.9722762), (-2.5275798, -2.7967021), (-2.5920815, -2.863098), (-1.8046576, -1.038674), (-1.7401565, -0.9722775), (-2.52758, -2.7967), (-2.5920796, -2.8630965), (-1.8046559, -1.0386742), (-1.740157, -0.9722786), (-2.527581, -2.796701), (-2.592079, -2.8630953), (-1.8046553, -1.0386728), (-1.7401589, -0.9722795), (-2.5275822, -2.7967033), (-2.5920777, -2.8630965), (-1.8046534, -1.0386723), (-1.7401577, -0.97227883), (-2.5275824, -2.7967024), (-2.5920787, -2.8630965), (-1.8046544, -1.0386728), (-1.7401567, -0.97227836), (-2.5275807, -2.7967021), (-2.5920808, -2.8630965), (-1.8046558, -1.0386728), (-1.7401536, -0.97227794), (-2.527579, -2.7967014), (-2.592081, -2.8630967), (-1.8046565, -1.0386733), (-1.7401556, -0.97227776), (-2.5275795, -2.796701), (-2.5920804, -2.863096), (-1.8046577, -1.0386734), (-1.7401572, -0.9722791), (-2.52758, -2.7967014), (-2.5920815, -2.863097), (-1.8046584, -1.0386744), (-1.7401582, -0.97227776), (-2.5275824, -2.7966993), (-2.59208, -2.8630958), (-1.8046545, -1.0386751), (-1.7401569, -0.97227937), (-2.5275831, -2.7967012), (-2.5920796, -2.8630962), (-1.8046528, -1.0386736), (-1.7401552, -0.9722804), (-2.5275834, -2.796704), (-2.5920832, -2.863097), (-1.8046529, -1.0386713), (-1.7401506, -0.97227764), (-2.527581, -2.7967052), (-2.5920851, -2.8631005), (-1.8046571, -1.0386716), (-1.7401539, -0.9722738), (-2.527579, -2.796701), (-2.59208, -2.8630989), (-1.8046559, -1.038675), (-1.7401567, -0.9722778), (-2.52758, -2.7967012), (-2.592078, -2.8630977), (-1.8046528, -1.038674), (-1.7401556, -0.9722784), (-2.5275826, -2.7967017), (-2.592079, -2.8630967), (-1.8046527, -1.0386732), (-1.7401599, -0.972279), (-2.5275877, -2.7967026), (-2.5920808, -2.8630948), (-1.8046507, -1.0386707), (-1.7401547, -0.9722791), (-2.527586, -2.7967045), (-2.5920854, -2.8630965), (-1.8046546, -1.0386695), (-1.7401518, -0.9722763), (-2.5275803, -2.796704), (-2.5920808, -2.8630996), (-1.8046546, -1.0386723), (-1.7401553, -0.972276), (-2.5275822, -2.796702), (-2.592081, -2.863098), (-1.8046539, -1.0386734), (-1.7401552, -0.97227806), (-2.5275803, -2.7967026), (-2.59208, -2.8630965), (-1.8046545, -1.0386717), (-1.7401537, -0.97227806), (-2.5275812, -2.7967033), (-2.59208, -2.8630965), (-1.8046515, -1.0386707), (-1.7401552, -0.972278), (-2.527586, -2.7967045), (-2.592085, -2.8630967), (-1.8046556, -1.0386686), (-1.7401549, -0.9722756), (-2.5275822, -2.7967043), (-2.59208, -2.8631003), (-1.8046534, -1.0386739), (-1.7401578, -0.9722768), (-2.527585, -2.7967005), (-2.5920804, -2.8630962), (-1.804652, -1.0386738), (-1.7401551, -0.97227937), (-2.5275843, -2.7967026), (-2.5920842, -2.8630962), (-1.8046554, -1.0386714), (-1.7401546, -0.97227776), (-2.5275805, -2.7967029), (-2.5920777, -2.8630977), (-1.8046529, -1.0386744), (-1.7401576, -0.97227967), (-2.5275838, -2.7967021), (-2.5920796, -2.8630955), (-1.8046528, -1.0386721), (-1.7401567, -0.9722786), (-2.5275831, -2.796702), (-2.5920796, -2.8630962), (-1.8046532, -1.0386738), (-1.740158, -0.9722792), (-2.5275853, -2.796702), (-2.59208, -2.863096), (-1.8046519, -1.0386724), (-1.7401557, -0.97228014), (-2.5275853, -2.7967045), (-2.592085, -2.8630958), (-1.8046548, -1.0386691), (-1.7401534, -0.9722779), (-2.527581, -2.796706), (-2.5920813, -2.863098), (-1.8046557, -1.0386705), (-1.7401555, -0.97227794), (-2.5275784, -2.796704), (-2.592076, -2.8630977), (-1.8046536, -1.0386738), (-1.7401572, -0.97228044), (-2.527583, -2.796704), (-2.592078, -2.8630958), (-1.8046502, -1.0386708), (-1.7401569, -0.9722786), (-2.5275853, -2.7967033), (-2.592079, -2.8630953), (-1.8046509, -1.0386705), (-1.7401572, -0.972278), (-2.5275867, -2.796704), (-2.5920844, -2.8630974), (-1.8046557, -1.03867), (-1.7401541, -0.9722753), (-2.5275807, -2.7967026), (-2.5920808, -2.8630996), (-1.8046552, -1.0386741), (-1.7401564, -0.97227716), (-2.5275846, -2.7967012), (-2.592084, -2.8630972), (-1.8046528, -1.0386729), (-1.7401507, -0.9722778), (-2.52758, -2.796703), (-2.5920813, -2.8630986), (-1.8046547, -1.0386744), (-1.7401551, -0.9722783), (-2.5275798, -2.7967017), (-2.592079, -2.863097), (-1.8046534, -1.0386733), (-1.7401571, -0.9722776), (-2.527584, -2.7967017), (-2.5920792, -2.8630958), (-1.8046525, -1.0386709), (-1.7401569, -0.9722787), (-2.527585, -2.796704), (-2.5920808, -2.8630967), (-1.8046521, -1.0386709), (-1.7401571, -0.97227716), (-2.527586, -2.7967024), (-2.5920815, -2.8630967), (-1.804651, -1.0386724), (-1.7401526, -0.97227806), (-2.5275831, -2.796703), (-2.592085, -2.8630977), (-1.8046556, -1.0386708), (-1.7401534, -0.97227514), (-2.5275817, -2.7967021), (-2.5920832, -2.863099), (-1.8046565, -1.0386727), (-1.7401552, -0.9722748), (-2.5275807, -2.7967005), (-2.592083, -2.8630993), (-1.8046583, -1.0386759), (-1.7401556, -0.9722767), (-2.5275807, -2.7966983), (-2.5920823, -2.863096), (-1.8046567, -1.0386745), (-1.7401541, -0.972279), (-2.5275795, -2.7967021), (-2.5920796, -2.863097), (-1.8046527, -1.0386734), (-1.7401531, -0.97227895), (-2.5275831, -2.7967038), (-2.5920851, -2.8630981), (-1.8046533, -1.0386713), (-1.7401514, -0.9722761), (-2.5275803, -2.7967043), (-2.592081, -2.8630993), (-1.8046563, -1.0386717), (-1.740157, -0.972277), (-2.5275803, -2.7967024), (-2.592079, -2.863098), (-1.8046553, -1.0386736), (-1.7401581, -0.97227764), (-2.527582, -2.7967014), (-2.5920784, -2.863097), (-1.8046544, -1.0386742), (-1.7401582, -0.97227955), (-2.527582, -2.7967021), (-2.5920763, -2.8630967), (-1.804653, -1.038674), (-1.7401621, -0.97228014), (-2.5275888, -2.7967029), (-2.5920792, -2.863094), (-1.8046461, -1.0386709), (-1.7401501, -0.9722816), (-2.5275826, -2.7967079), (-2.5920818, -2.863098), (-1.8046536, -1.0386696), (-1.7401572, -0.9722767), (-2.527585, -2.7967036), (-2.5920818, -2.8630981), (-1.8046542, -1.0386713), (-1.7401567, -0.9722761), (-2.5275848, -2.7967026), (-2.5920815, -2.863098), (-1.8046527, -1.0386724), (-1.7401551, -0.9722769), (-2.527584, -2.796702), (-2.5920823, -2.863097), (-1.8046517, -1.0386715), (-1.7401524, -0.9722773), (-2.5275834, -2.7967033), (-2.5920837, -2.8630965), (-1.8046536, -1.0386707), (-1.7401528, -0.972278), (-2.5275824, -2.7967045), (-2.5920846, -2.8630972), (-1.8046544, -1.0386698), (-1.7401519, -0.9722773), (-2.527581, -2.7967048), (-2.5920825, -2.863099), (-1.8046564, -1.0386716), (-1.7401567, -0.9722755), (-2.5275826, -2.7967021), (-2.5920823, -2.8630986), (-1.8046567, -1.0386736), (-1.7401576, -0.97227716), (-2.5275831, -2.7967007), (-2.5920796, -2.863096), (-1.8046503, -1.0386722), (-1.7401538, -0.97227836), (-2.5275855, -2.7967038), (-2.5920851, -2.863096), (-1.8046551, -1.0386683), (-1.7401543, -0.97227675), (-2.5275812, -2.7967052), (-2.5920796, -2.8630993), (-1.8046535, -1.0386734), (-1.7401565, -0.9722774), (-2.5275822, -2.796702), (-2.5920768, -2.8630977), (-1.8046502, -1.0386745), (-1.7401568, -0.97228116), (-2.527585, -2.796704), (-2.592079, -2.8630953), (-1.8046502, -1.0386705), (-1.7401563, -0.9722794), (-2.5275843, -2.796705), (-2.5920775, -2.8630967), (-1.8046497, -1.0386708), (-1.740157, -0.97227854), (-2.5275853, -2.7967045), (-2.592082, -2.8630962), (-1.804655, -1.0386697), (-1.7401553, -0.97227633), (-2.5275815, -2.7967036), (-2.592081, -2.8630996), (-1.8046565, -1.0386733), (-1.7401564, -0.9722767), (-2.52758, -2.796701), (-2.59208, -2.8630967), (-1.8046564, -1.038673), (-1.740156, -0.9722778), (-2.5275788, -2.7967014), (-2.5920794, -2.8630967), (-1.8046594, -1.0386741), (-1.7401605, -0.97227854), (-2.5275812, -2.7967005), (-2.5920796, -2.8630965), (-1.804657, -1.0386752), (-1.7401611, -0.97227955), (-2.527586, -2.7967), (-2.5920806, -2.863094), (-1.8046525, -1.0386727), (-1.7401549, -0.9722802), (-2.5275831, -2.7967045), (-2.5920796, -2.863097), (-1.8046513, -1.0386708), (-1.7401565, -0.9722771), (-2.5275857, -2.796703), (-2.592081, -2.8630967), (-1.8046501, -1.0386711), (-1.7401528, -0.9722791), (-2.5275862, -2.7967057), (-2.5920858, -2.863098), (-1.8046539, -1.0386704), (-1.7401531, -0.9722766), (-2.5275807, -2.7967033), (-2.5920794, -2.863099), (-1.804653, -1.0386747), (-1.7401549, -0.9722785), (-2.5275793, -2.7967017), (-2.592076, -2.863097), (-1.8046525, -1.0386741), (-1.7401594, -0.9722803), (-2.5275877, -2.7967033), (-2.5920799, -2.863095), (-1.8046504, -1.0386703), (-1.7401569, -0.9722786), (-2.5275834, -2.7967045), (-2.5920784, -2.8630962), (-1.8046542, -1.0386705), (-1.7401592, -0.9722778), (-2.527585, -2.7967024), (-2.5920792, -2.8630962), (-1.8046511, -1.038672), (-1.7401562, -0.97227865), (-2.5275838, -2.7967038), (-2.5920806, -2.8630972), (-1.8046556, -1.0386716), (-1.7401587, -0.97227716), (-2.5275831, -2.7967026), (-2.5920804, -2.863098), (-1.8046563, -1.0386729), (-1.7401574, -0.9722766), (-2.527581, -2.796701), (-2.5920796, -2.8630967), (-1.8046525, -1.038673), (-1.7401534, -0.9722786), (-2.5275812, -2.796703), (-2.59208, -2.863098), (-1.8046552, -1.0386733), (-1.7401584, -0.97227746), (-2.5275826, -2.7967005), (-2.5920796, -2.8630958), (-1.8046539, -1.0386729), (-1.7401562, -0.9722787), (-2.527582, -2.7967029), (-2.5920794, -2.863097), (-1.804654, -1.0386732), (-1.7401577, -0.9722778), (-2.5275846, -2.7967007), (-2.5920796, -2.8630958), (-1.8046529, -1.0386738), (-1.7401586, -0.97227925), (-2.5275865, -2.7967024), (-2.5920808, -2.863095), (-1.804649, -1.0386709), (-1.7401519, -0.9722805), (-2.5275848, -2.7967064), (-2.5920851, -2.863098), (-1.8046546, -1.0386702), (-1.740154, -0.9722767), (-2.5275815, -2.7967038), (-2.5920799, -2.8630984), (-1.8046536, -1.0386728), (-1.7401567, -0.97227794), (-2.5275834, -2.7967021), (-2.5920804, -2.8630972), (-1.8046535, -1.0386735), (-1.7401559, -0.9722792), (-2.5275831, -2.7967033), (-2.59208, -2.8630972), (-1.8046539, -1.0386721), (-1.740158, -0.9722779), (-2.5275843, -2.796703), (-2.5920804, -2.863096), (-1.8046522, -1.0386709), (-1.7401552, -0.9722783), (-2.527583, -2.796704), (-2.5920782, -2.8630967), (-1.8046502, -1.0386713), (-1.7401567, -0.9722787), (-2.527585, -2.7967038), (-2.592079, -2.8630965), (-1.8046522, -1.0386716), (-1.7401575, -0.9722789), (-2.527584, -2.796703), (-2.5920792, -2.8630965), (-1.8046535, -1.0386727), (-1.7401593, -0.9722792), (-2.5275855, -2.796703), (-2.59208, -2.8630967), (-1.8046515, -1.0386721), (-1.7401552, -0.97227865), (-2.5275822, -2.796704), (-2.592078, -2.863096), (-1.8046526, -1.0386707), (-1.7401595, -0.97227806), (-2.527587, -2.7967033), (-2.592082, -2.863096), (-1.8046533, -1.0386702), (-1.7401562, -0.9722775), (-2.5275836, -2.7967045), (-2.5920813, -2.8630974), (-1.8046558, -1.0386707), (-1.740159, -0.9722765), (-2.5275843, -2.7967029), (-2.592079, -2.8630977), (-1.8046517, -1.0386719), (-1.7401558, -0.9722787), (-2.5275824, -2.7967043), (-2.5920782, -2.8630981), (-1.8046532, -1.0386726), (-1.7401581, -0.9722777), (-2.527584, -2.796702), (-2.5920782, -2.8630958), (-1.8046514, -1.0386723), (-1.7401567, -0.9722788), (-2.5275831, -2.7967024), (-2.5920787, -2.8630974), (-1.8046522, -1.0386739), (-1.7401564, -0.9722783), (-2.527583, -2.7967021), (-2.5920792, -2.863097), (-1.804652, -1.0386727), (-1.7401558, -0.97227824), (-2.5275838, -2.7967029), (-2.5920825, -2.8630974), (-1.8046561, -1.0386719), (-1.7401571, -0.9722762), (-2.527582, -2.7967017), (-2.5920792, -2.8630986), (-1.804655, -1.0386744), (-1.7401602, -0.97227925), (-2.5275862, -2.7967029), (-2.5920796, -2.863095), (-1.8046494, -1.038671), (-1.7401538, -0.9722807), (-2.5275862, -2.796707), (-2.5920827, -2.8630962), (-1.8046501, -1.0386673), (-1.7401532, -0.97227675), (-2.5275848, -2.7967067), (-2.5920823, -2.8630996), (-1.8046522, -1.0386707), (-1.740154, -0.9722759), (-2.527583, -2.796703), (-2.5920806, -2.863099), (-1.8046532, -1.0386736), (-1.7401572, -0.97227705), (-2.5275853, -2.796701), (-2.5920804, -2.863097), (-1.8046517, -1.0386738), (-1.7401538, -0.97227937), (-2.5275817, -2.7967036), (-2.592082, -2.8630972), (-1.8046558, -1.0386722), (-1.7401568, -0.97227705), (-2.5275824, -2.7967014), (-2.5920787, -2.8630974), (-1.8046521, -1.0386738), (-1.7401565, -0.97227824), (-2.5275834, -2.7967014), (-2.5920792, -2.8630965), (-1.8046533, -1.0386728), (-1.740159, -0.9722791), (-2.5275865, -2.7967033), (-2.5920808, -2.8630948), (-1.8046507, -1.03867), (-1.740156, -0.97227955), (-2.5275881, -2.7967057), (-2.592085, -2.8630962), (-1.804653, -1.0386678), (-1.7401545, -0.97227645), (-2.5275855, -2.7967055), (-2.592083, -2.8630986), (-1.8046505, -1.0386702), (-1.7401521, -0.97227615), (-2.5275836, -2.7967045), (-2.5920804, -2.863099), (-1.8046507, -1.0386722), (-1.7401557, -0.9722774), (-2.5275881, -2.796703), (-2.592085, -2.863097), (-1.8046503, -1.0386705), (-1.7401512, -0.9722778), (-2.527584, -2.796705), (-2.5920837, -2.8630977), (-1.8046495, -1.0386704), (-1.7401493, -0.9722775), (-2.5275843, -2.7967052), (-2.5920856, -2.8630989), (-1.8046508, -1.03867), (-1.7401496, -0.9722756), (-2.5275822, -2.7967052), (-2.5920835, -2.8631), (-1.8046548, -1.0386705), (-1.7401531, -0.97227496), (-2.5275803, -2.796703), (-2.5920815, -2.8630998), (-1.8046547, -1.0386734), (-1.7401552, -0.97227675), (-2.5275834, -2.7967021), (-2.5920846, -2.8630967), (-1.804658, -1.0386719), (-1.7401557, -0.9722768), (-2.5275805, -2.7967012), (-2.5920818, -2.8630972), (-1.804655, -1.0386734), (-1.7401536, -0.972279), (-2.5275824, -2.7967033), (-2.5920846, -2.863097), (-1.8046544, -1.0386714), (-1.7401515, -0.9722773), (-2.5275803, -2.796704), (-2.5920818, -2.8630996), (-1.8046557, -1.0386732), (-1.7401564, -0.97227734), (-2.5275826, -2.796702), (-2.5920813, -2.8630962), (-1.8046535, -1.038672), (-1.7401543, -0.97227746), (-2.5275822, -2.7967021), (-2.5920815, -2.863097), (-1.8046546, -1.0386724), (-1.7401552, -0.9722773), (-2.5275812, -2.796702), (-2.5920823, -2.8630977), (-1.8046565, -1.0386738), (-1.7401538, -0.9722783), (-2.5275805, -2.796702), (-2.5920846, -2.8630974), (-1.8046595, -1.0386727), (-1.7401546, -0.97227645), (-2.527578, -2.7967012), (-2.5920823, -2.8630984), (-1.8046598, -1.0386746), (-1.7401562, -0.97227705), (-2.5275772, -2.7967002), (-2.5920784, -2.8630989), (-1.8046564, -1.0386769), (-1.7401576, -0.97227854), (-2.5275822, -2.7966998), (-2.5920804, -2.8630953), (-1.8046516, -1.038674), (-1.7401515, -0.9722802), (-2.527581, -2.7967038), (-2.592082, -2.8630981), (-1.8046553, -1.038673), (-1.7401567, -0.97227734), (-2.527582, -2.7967002), (-2.5920796, -2.8630955), (-1.8046547, -1.0386729), (-1.7401565, -0.97227854), (-2.5275795, -2.796702), (-2.5920782, -2.863097), (-1.8046563, -1.038674), (-1.7401562, -0.9722783), (-2.5275779, -2.7967005), (-2.5920818, -2.863098), (-1.8046616, -1.0386759), (-1.7401567, -0.9722772), (-2.5275767, -2.796698), (-2.592081, -2.863096), (-1.8046587, -1.0386752), (-1.7401541, -0.9722776), (-2.5275767, -2.7966993), (-2.5920804, -2.8630967), (-1.8046585, -1.0386744), (-1.7401587, -0.9722777), (-2.527582, -2.7967), (-2.5920794, -2.8630953), (-1.8046552, -1.0386728), (-1.7401578, -0.9722795), (-2.5275824, -2.796703), (-2.5920794, -2.863096), (-1.8046542, -1.0386721), (-1.7401577, -0.97227883), (-2.5275843, -2.7967029), (-2.5920799, -2.8630967), (-1.8046497, -1.0386724), (-1.7401522, -0.97227824), (-2.5275846, -2.7967043), (-2.5920868, -2.8630984), (-1.8046551, -1.0386695), (-1.7401514, -0.9722746), (-2.527581, -2.7967036), (-2.5920832, -2.863101), (-1.8046552, -1.0386735), (-1.740154, -0.9722749), (-2.527582, -2.7967), (-2.5920823, -2.8630981), (-1.8046559, -1.038675), (-1.7401557, -0.97227854), (-2.5275784, -2.796702), (-2.5920777, -2.8630984), (-1.8046554, -1.0386752), (-1.7401584, -0.9722783), (-2.527585, -2.7967007), (-2.5920818, -2.8630958), (-1.8046504, -1.0386719), (-1.7401524, -0.972279), (-2.5275865, -2.7967057), (-2.5920846, -2.8630981), (-1.80465, -1.0386696), (-1.7401512, -0.97227716), (-2.5275834, -2.7967072), (-2.5920823, -2.8630993), (-1.8046529, -1.0386703), (-1.7401541, -0.97227645), (-2.5275831, -2.7967036), (-2.5920827, -2.8630984), (-1.8046557, -1.0386723), (-1.7401557, -0.972277), (-2.527582, -2.796702), (-2.5920804, -2.863097), (-1.804652, -1.0386723), (-1.7401531, -0.97227764), (-2.5275826, -2.7967026), (-2.5920842, -2.8630984), (-1.804654, -1.0386727), (-1.7401509, -0.9722762), (-2.5275793, -2.796702), (-2.5920832, -2.8630984), (-1.8046576, -1.0386735), (-1.7401549, -0.9722761), (-2.5275803, -2.7966993), (-2.5920825, -2.8630972), (-1.8046548, -1.0386747), (-1.7401534, -0.9722775), (-2.527583, -2.7967002), (-2.5920846, -2.8630967), (-1.8046569, -1.0386729), (-1.7401539, -0.97227705), (-2.5275786, -2.7967014), (-2.592082, -2.8630984), (-1.8046597, -1.0386747), (-1.7401581, -0.9722762), (-2.5275798, -2.7966993), (-2.592079, -2.863097), (-1.8046561, -1.0386744), (-1.7401586, -0.9722788), (-2.527584, -2.7967012), (-2.5920804, -2.8630955), (-1.8046529, -1.038673), (-1.740156, -0.972279), (-2.5275812, -2.7967026), (-2.5920763, -2.8630972), (-1.8046516, -1.0386734), (-1.7401601, -0.9722794), (-2.527588, -2.796702), (-2.59208, -2.863095), (-1.8046484, -1.0386726), (-1.740151, -0.97228044), (-2.527585, -2.796705), (-2.5920882, -2.8630967), (-1.8046553, -1.0386692), (-1.7401501, -0.97227615), (-2.5275793, -2.7967057), (-2.5920823, -2.8630998), (-1.8046561, -1.0386709), (-1.7401546, -0.9722769), (-2.5275795, -2.796704), (-2.592078, -2.8630986), (-1.8046527, -1.038673), (-1.7401564, -0.97227883), (-2.5275846, -2.796704), (-2.5920842, -2.863096), (-1.8046554, -1.0386695), (-1.740155, -0.9722761), (-2.5275834, -2.7967024), (-2.5920832, -2.8630984), (-1.8046544, -1.0386735), (-1.7401541, -0.9722769), (-2.5275815, -2.796701), (-2.592081, -2.863097), (-1.8046545, -1.0386733), (-1.7401556, -0.9722775), (-2.5275817, -2.7967017), (-2.5920815, -2.8630977), (-1.8046544, -1.038674), (-1.7401558, -0.9722795), (-2.5275838, -2.7967033), (-2.5920796, -2.8630958), (-1.8046521, -1.038671), (-1.7401565, -0.9722783), (-2.5275822, -2.7967033), (-2.5920787, -2.8630972), (-1.8046542, -1.038673), (-1.7401565, -0.9722795), (-2.5275795, -2.796703), (-2.5920792, -2.8630967), (-1.8046569, -1.0386734), (-1.7401553, -0.9722781), (-2.5275772, -2.7967007), (-2.5920768, -2.8630984), (-1.804655, -1.0386777), (-1.740159, -0.9722804), (-2.5275834, -2.7966998), (-2.5920799, -2.863094), (-1.8046544, -1.0386732), (-1.7401581, -0.97227985), (-2.5275862, -2.7967024), (-2.592083, -2.8630939), (-1.8046522, -1.038669), (-1.740153, -0.9722786), (-2.5275848, -2.7967052), (-2.5920863, -2.8630977), (-1.8046556, -1.0386692), (-1.7401521, -0.97227407), (-2.5275793, -2.7967026), (-2.592082, -2.8631003), (-1.8046559, -1.0386738), (-1.740156, -0.97227615), (-2.5275824, -2.7967012), (-2.5920794, -2.8630974), (-1.8046521, -1.0386727), (-1.7401545, -0.972278), (-2.5275807, -2.7967038), (-2.5920787, -2.8630981), (-1.804653, -1.0386727), (-1.7401564, -0.97227776), (-2.5275826, -2.7967024), (-2.5920804, -2.8630972), (-1.8046548, -1.0386719), (-1.7401572, -0.97227734), (-2.5275824, -2.7967029), (-2.5920784, -2.8630974), (-1.8046541, -1.0386722), (-1.7401595, -0.9722784), (-2.5275853, -2.796703), (-2.5920808, -2.863096), (-1.8046528, -1.0386713), (-1.7401549, -0.9722781), (-2.5275822, -2.7967038), (-2.5920787, -2.8630977), (-1.804652, -1.0386721), (-1.7401564, -0.97227824), (-2.5275834, -2.7967036), (-2.59208, -2.8630972), (-1.8046552, -1.0386711), (-1.7401593, -0.9722766), (-2.5275836, -2.7967026), (-2.5920777, -2.8630972), (-1.8046517, -1.0386727), (-1.7401582, -0.9722793), (-2.5275853, -2.7967036), (-2.5920784, -2.8630955), (-1.8046497, -1.0386698), (-1.7401556, -0.9722791), (-2.5275865, -2.796707), (-2.5920827, -2.863098), (-1.8046509, -1.0386682), (-1.7401534, -0.972276), (-2.5275865, -2.7967062), (-2.5920854, -2.8630986), (-1.8046538, -1.0386689), (-1.740156, -0.9722756), (-2.5275857, -2.7967048), (-2.5920842, -2.8630986), (-1.8046535, -1.0386703), (-1.7401507, -0.9722759), (-2.527577, -2.7967043), (-2.5920794, -2.8631012), (-1.8046557, -1.0386744), (-1.7401528, -0.9722751), (-2.527577, -2.7966995), (-2.592079, -2.8630996), (-1.8046575, -1.0386772), (-1.7401596, -0.97227865), (-2.5275826, -2.7966995), (-2.5920784, -2.8630943), (-1.8046521, -1.0386729), (-1.7401556, -0.97228014), (-2.5275831, -2.796704), (-2.5920784, -2.8630962), (-1.8046514, -1.0386707), (-1.7401583, -0.9722781), (-2.5275862, -2.7967026), (-2.5920806, -2.8630965), (-1.804651, -1.038672), (-1.7401534, -0.9722776), (-2.5275824, -2.7967029), (-2.5920842, -2.8630986), (-1.8046576, -1.0386726), (-1.740154, -0.9722756), (-2.5275795, -2.7967007), (-2.592084, -2.8630986), (-1.8046606, -1.0386739), (-1.7401557, -0.97227496), (-2.527576, -2.796699), (-2.5920792, -2.8630986), (-1.8046604, -1.0386767), (-1.740159, -0.97227687), (-2.527578, -2.7966979), (-2.5920787, -2.863098), (-1.8046588, -1.0386776), (-1.7401597, -0.97227913), (-2.5275815, -2.7966993), (-2.5920782, -2.8630953), (-1.8046533, -1.0386738), (-1.7401553, -0.9722793), (-2.527581, -2.7967033), (-2.592079, -2.863098), (-1.8046519, -1.0386739), (-1.740155, -0.97227854), (-2.5275831, -2.7967014), (-2.59208, -2.8630962), (-1.8046509, -1.0386726), (-1.7401534, -0.97227824), (-2.527584, -2.7967033), (-2.5920842, -2.8630977), (-1.804655, -1.0386717), (-1.7401547, -0.97227645), (-2.527583, -2.7967021), (-2.5920832, -2.863098), (-1.8046569, -1.0386729), (-1.7401558, -0.97227687), (-2.5275793, -2.7967014), (-2.5920815, -2.8630984), (-1.8046591, -1.038675), (-1.7401564, -0.97227645), (-2.5275776, -2.7966995), (-2.59208, -2.8630977), (-1.8046579, -1.0386757), (-1.7401565, -0.97227776), (-2.527579, -2.7966998), (-2.5920777, -2.863097), (-1.8046535, -1.0386741), (-1.7401563, -0.97227865), (-2.527583, -2.7967017), (-2.5920796, -2.8630953), (-1.8046529, -1.0386715), (-1.7401557, -0.9722792), (-2.5275824, -2.7967048), (-2.5920813, -2.8630984), (-1.8046558, -1.038673), (-1.7401575, -0.9722775), (-2.5275824, -2.796701), (-2.5920792, -2.8630962), (-1.8046536, -1.0386736), (-1.7401575, -0.97227925), (-2.5275822, -2.7967017), (-2.5920765, -2.8630962), (-1.8046529, -1.0386748), (-1.7401594, -0.9722808), (-2.5275848, -2.7967021), (-2.5920787, -2.863095), (-1.8046498, -1.0386707), (-1.740155, -0.9722787), (-2.527585, -2.7967052), (-2.5920832, -2.8630958), (-1.8046553, -1.0386682), (-1.7401536, -0.9722768), (-2.5275784, -2.796705), (-2.5920787, -2.8630977), (-1.8046533, -1.038671), (-1.7401555, -0.97227865), (-2.5275836, -2.7967048), (-2.5920823, -2.8630967), (-1.8046523, -1.0386693), (-1.7401536, -0.9722774), (-2.527585, -2.7967052), (-2.5920851, -2.8630981), (-1.8046554, -1.0386705), (-1.7401549, -0.9722755), (-2.5275824, -2.7967024), (-2.592082, -2.8630993), (-1.8046545, -1.038674), (-1.7401563, -0.9722772), (-2.5275838, -2.7967012), (-2.5920796, -2.8630962), (-1.804652, -1.0386728), (-1.7401564, -0.9722793), (-2.527584, -2.7967033), (-2.5920796, -2.863096), (-1.8046522, -1.0386709), (-1.7401567, -0.97227865), (-2.5275836, -2.7967033), (-2.5920804, -2.8630962), (-1.8046532, -1.0386723), (-1.7401553, -0.9722791), (-2.527582, -2.7967026), (-2.5920804, -2.8630965), (-1.8046526, -1.0386726), (-1.7401534, -0.9722782), (-2.527583, -2.7967029), (-2.5920851, -2.863097), (-1.8046564, -1.0386716), (-1.7401536, -0.9722772), (-2.5275803, -2.7967033), (-2.592081, -2.8630986), (-1.8046558, -1.0386734), (-1.7401582, -0.9722767), (-2.5275843, -2.7967002), (-2.5920792, -2.8630962), (-1.804651, -1.0386733), (-1.740158, -0.9722787), (-2.5275881, -2.7967029), (-2.5920825, -2.863095), (-1.8046507, -1.0386695), (-1.7401525, -0.97227895), (-2.5275846, -2.796707), (-2.5920825, -2.8630986), (-1.8046523, -1.0386702), (-1.7401559, -0.9722767), (-2.5275846, -2.7967033), (-2.59208, -2.8630981), (-1.8046514, -1.0386726), (-1.7401538, -0.97227776), (-2.5275803, -2.7967033), (-2.592078, -2.8630989), (-1.8046527, -1.0386744), (-1.7401565, -0.9722785), (-2.527583, -2.7967024), (-2.5920792, -2.8630972), (-1.8046532, -1.0386736), (-1.7401582, -0.9722788), (-2.5275855, -2.7967014), (-2.5920796, -2.8630953), (-1.8046523, -1.0386719), (-1.7401569, -0.97227854), (-2.5275826, -2.7967024), (-2.5920782, -2.863097), (-1.8046538, -1.0386744), (-1.7401621, -0.9722793), (-2.5275884, -2.7967005), (-2.592079, -2.8630936), (-1.8046494, -1.0386723), (-1.740157, -0.97228134), (-2.5275884, -2.796705), (-2.5920815, -2.8630958), (-1.804649, -1.0386693), (-1.7401551, -0.9722782), (-2.527586, -2.7967057), (-2.5920808, -2.863098), (-1.8046519, -1.0386714), (-1.7401553, -0.9722774), (-2.5275824, -2.7967029), (-2.5920787, -2.8630977), (-1.8046536, -1.0386724), (-1.740158, -0.972278), (-2.527584, -2.7967021), (-2.592079, -2.8630958), (-1.8046503, -1.0386715), (-1.740156, -0.97227836), (-2.527585, -2.796704), (-2.5920796, -2.863097), (-1.804651, -1.0386713), (-1.7401564, -0.9722779), (-2.5275857, -2.796703), (-2.5920808, -2.8630972), (-1.8046523, -1.0386726), (-1.7401555, -0.97227824), (-2.5275822, -2.7967029), (-2.5920813, -2.8630977), (-1.8046572, -1.0386736), (-1.7401568, -0.9722774), (-2.5275803, -2.7967005), (-2.5920808, -2.8630974), (-1.8046573, -1.0386751), (-1.740159, -0.9722785), (-2.5275838, -2.7967), (-2.5920768, -2.8630955), (-1.8046507, -1.0386748), (-1.7401603, -0.972281), (-2.5275867, -2.7967024), (-2.5920773, -2.8630955), (-1.8046509, -1.0386726), (-1.7401587, -0.97228044), (-2.527585, -2.7967048), (-2.5920818, -2.8630955), (-1.8046534, -1.0386691), (-1.740153, -0.9722769), (-2.5275793, -2.7967055), (-2.5920787, -2.8630998), (-1.804654, -1.0386723), (-1.7401568, -0.97227746), (-2.5275834, -2.7967024), (-2.592081, -2.863098), (-1.8046542, -1.0386732), (-1.7401559, -0.9722778), (-2.5275815, -2.7967021), (-2.592078, -2.8630962), (-1.804652, -1.0386728), (-1.7401565, -0.9722793), (-2.5275848, -2.7967033), (-2.5920815, -2.863096), (-1.8046528, -1.03867), (-1.7401558, -0.97227734), (-2.5275846, -2.7967033), (-2.592083, -2.8630974), (-1.8046536, -1.0386723), (-1.7401532, -0.9722779), (-2.5275815, -2.7967021), (-2.5920827, -2.8630967), (-1.8046554, -1.0386728), (-1.7401539, -0.9722787), (-2.5275826, -2.796703), (-2.592085, -2.8630967), (-1.8046573, -1.038671), (-1.7401551, -0.9722752), (-2.5275807, -2.7967014), (-2.5920806, -2.8630989), (-1.8046554, -1.0386748), (-1.7401562, -0.9722775), (-2.5275812, -2.7966998), (-2.5920799, -2.8630962), (-1.8046544, -1.0386751), (-1.7401558, -0.97227937), (-2.527581, -2.796701), (-2.5920794, -2.8630958), (-1.8046546, -1.0386733), (-1.7401576, -0.9722787), (-2.527584, -2.7967017), (-2.5920808, -2.8630967), (-1.8046513, -1.0386733), (-1.7401512, -0.97227883), (-2.5275822, -2.796703), (-2.5920858, -2.8630972), (-1.8046539, -1.0386717), (-1.7401493, -0.9722772), (-2.527578, -2.7967038), (-2.5920832, -2.8631), (-1.8046575, -1.0386741), (-1.740152, -0.972276), (-2.527577, -2.7966998), (-2.5920832, -2.8630989), (-1.8046604, -1.0386753), (-1.7401552, -0.9722755), (-2.5275776, -2.7966986), (-2.5920815, -2.8630972), (-1.8046591, -1.0386754), (-1.7401574, -0.9722773), (-2.5275803, -2.796699), (-2.5920799, -2.863096), (-1.8046552, -1.038673), (-1.7401569, -0.9722773), (-2.5275831, -2.7967014), (-2.592079, -2.8630974), (-1.8046534, -1.0386734), (-1.7401577, -0.97227854), (-2.5275857, -2.7967029), (-2.592083, -2.863097), (-1.804651, -1.0386726), (-1.7401516, -0.9722781), (-2.5275838, -2.7967036), (-2.5920846, -2.8630974), (-1.804652, -1.0386709), (-1.7401505, -0.97227705), (-2.5275807, -2.7967036), (-2.5920823, -2.8630993), (-1.8046556, -1.038674), (-1.7401567, -0.9722771), (-2.5275838, -2.7967002), (-2.5920799, -2.8630958), (-1.8046523, -1.0386735), (-1.7401593, -0.97227997), (-2.5275865, -2.7967033), (-2.5920787, -2.8630953), (-1.8046476, -1.0386711), (-1.7401513, -0.97228056), (-2.5275853, -2.7967064), (-2.5920844, -2.8630965), (-1.8046539, -1.0386685), (-1.7401572, -0.9722773), (-2.5275865, -2.7967045), (-2.5920835, -2.863096), (-1.8046534, -1.038669), (-1.7401544, -0.9722776), (-2.5275843, -2.7967057), (-2.5920832, -2.8630986), (-1.8046523, -1.0386704), (-1.7401525, -0.9722763), (-2.5275812, -2.796705), (-2.59208, -2.8630996), (-1.8046547, -1.0386715), (-1.7401564, -0.97227645), (-2.527581, -2.7967033), (-2.5920768, -2.863098), (-1.8046498, -1.0386722), (-1.7401559, -0.9722798), (-2.5275855, -2.796706), (-2.5920808, -2.8630977), (-1.8046536, -1.0386697), (-1.7401578, -0.97227705), (-2.5275836, -2.796705), (-2.5920792, -2.8630972), (-1.8046514, -1.0386701), (-1.7401564, -0.9722782), (-2.5275846, -2.7967048), (-2.5920823, -2.863097), (-1.8046535, -1.0386696), (-1.7401546, -0.9722761), (-2.5275865, -2.7967033), (-2.5920851, -2.8630974), (-1.8046532, -1.0386705), (-1.7401537, -0.9722759), (-2.527583, -2.7967033), (-2.592081, -2.8630981), (-1.8046529, -1.0386709), (-1.740155, -0.97227716), (-2.5275822, -2.7967045), (-2.5920796, -2.8630993), (-1.8046525, -1.0386736), (-1.7401571, -0.97227764), (-2.527585, -2.796702), (-2.5920799, -2.8630972), (-1.8046517, -1.0386727), (-1.7401555, -0.97227806), (-2.5275824, -2.7967021), (-2.5920799, -2.8630962), (-1.8046557, -1.0386728), (-1.7401588, -0.97227955), (-2.5275831, -2.796703), (-2.5920777, -2.8630965), (-1.804652, -1.038673), (-1.7401577, -0.97227955), (-2.5275846, -2.7967029), (-2.5920796, -2.8630962), (-1.8046533, -1.0386728), (-1.7401582, -0.9722795), (-2.5275838, -2.796703), (-2.5920782, -2.8630965), (-1.8046511, -1.0386719), (-1.7401567, -0.97227854), (-2.5275836, -2.7967036), (-2.5920784, -2.8630972), (-1.8046532, -1.0386722), (-1.7401586, -0.9722777), (-2.5275848, -2.7967017), (-2.5920804, -2.863095), (-1.8046516, -1.0386723), (-1.740155, -0.9722795), (-2.527583, -2.7967038), (-2.5920787, -2.863096), (-1.804654, -1.0386707), (-1.7401603, -0.97227883), (-2.5275872, -2.796704), (-2.5920827, -2.8630953), (-1.804655, -1.038669), (-1.7401583, -0.97227687), (-2.527585, -2.7967038), (-2.5920796, -2.8630974), (-1.8046509, -1.0386716), (-1.7401547, -0.9722778), (-2.5275817, -2.7967036), (-2.5920794, -2.8630984), (-1.8046546, -1.0386729), (-1.7401574, -0.97227776), (-2.5275834, -2.7967021), (-2.5920796, -2.8630977), (-1.8046513, -1.0386745), (-1.7401559, -0.97228), (-2.5275855, -2.7967038), (-2.5920806, -2.8630962), (-1.8046498, -1.0386705), (-1.7401533, -0.97227854), (-2.527584, -2.796706), (-2.5920815, -2.8630989), (-1.804653, -1.0386713), (-1.7401558, -0.97227705), (-2.5275831, -2.7967036), (-2.5920792, -2.8630989), (-1.8046521, -1.0386728), (-1.7401567, -0.9722768), (-2.5275843, -2.796702), (-2.5920806, -2.863097), (-1.8046519, -1.0386723), (-1.7401543, -0.972278), (-2.5275831, -2.7967026), (-2.5920813, -2.863097), (-1.8046528, -1.0386723), (-1.7401545, -0.9722777), (-2.5275822, -2.7967029), (-2.5920799, -2.8630981), (-1.8046538, -1.0386732), (-1.7401587, -0.972277), (-2.5275862, -2.7967007), (-2.5920806, -2.8630965), (-1.8046519, -1.0386728), (-1.7401569, -0.9722791), (-2.5275862, -2.796704), (-2.592084, -2.8630955), (-1.8046551, -1.0386684), (-1.7401559, -0.9722763), (-2.5275831, -2.7967045), (-2.5920813, -2.8630981), (-1.8046546, -1.0386705), (-1.7401563, -0.972277), (-2.5275824, -2.796704), (-2.5920777, -2.8630974), (-1.8046491, -1.0386714), (-1.7401546, -0.9722791), (-2.5275824, -2.7967057), (-2.592078, -2.863098), (-1.804653, -1.03867), (-1.7401594, -0.97227657), (-2.5275853, -2.7967038), (-2.5920782, -2.8630972), (-1.8046521, -1.0386708), (-1.7401599, -0.97227806), (-2.5275865, -2.7967043), (-2.5920794, -2.863097), (-1.8046495, -1.0386711), (-1.7401541, -0.972278), (-2.5275867, -2.796704), (-2.5920842, -2.8630974), (-1.8046517, -1.0386711), (-1.7401516, -0.97227675), (-2.527582, -2.7967033), (-2.5920823, -2.8630989), (-1.8046554, -1.038673), (-1.7401577, -0.9722763), (-2.5275826, -2.796701), (-2.5920773, -2.863098), (-1.8046515, -1.0386754), (-1.7401581, -0.9722806), (-2.5275862, -2.7967021), (-2.5920806, -2.8630934), (-1.8046507, -1.0386703), (-1.7401544, -0.9722801), (-2.5275836, -2.796706), (-2.592082, -2.8630977), (-1.8046534, -1.038671), (-1.7401536, -0.97227734), (-2.5275817, -2.7967033), (-2.5920808, -2.8630981), (-1.8046545, -1.0386727), (-1.7401562, -0.97227705), (-2.5275822, -2.7967017), (-2.5920792, -2.863098), (-1.8046539, -1.0386732), (-1.7401577, -0.9722776), (-2.5275836, -2.7967021), (-2.5920815, -2.8630972), (-1.8046575, -1.0386723), (-1.7401588, -0.9722768), (-2.5275817, -2.7967017), (-2.592079, -2.8630965), (-1.8046534, -1.0386721), (-1.7401562, -0.9722786), (-2.5275817, -2.7967038), (-2.5920784, -2.8630977), (-1.804654, -1.0386722), (-1.7401587, -0.97227836), (-2.5275848, -2.7967036), (-2.5920813, -2.8630974), (-1.8046559, -1.0386714), (-1.7401589, -0.9722771), (-2.5275834, -2.796703), (-2.592078, -2.8630965), (-1.8046498, -1.0386705), (-1.7401557, -0.97227854), (-2.5275846, -2.7967052), (-2.5920813, -2.8630962), (-1.8046527, -1.0386684), (-1.7401538, -0.9722775), (-2.5275822, -2.796706), (-2.592081, -2.8630989), (-1.8046551, -1.038671), (-1.740157, -0.9722761), (-2.5275826, -2.7967026), (-2.5920804, -2.8630993), (-1.8046547, -1.0386745), (-1.7401547, -0.972277), (-2.5275793, -2.7967), (-2.5920794, -2.8630974), (-1.8046544, -1.0386753), (-1.7401531, -0.9722789), (-2.5275779, -2.796702), (-2.59208, -2.863098), (-1.8046578, -1.038674), (-1.7401581, -0.97227705), (-2.5275807, -2.7967), (-2.5920784, -2.8630972), (-1.8046553, -1.0386757), (-1.7401601, -0.9722792), (-2.5275853, -2.7966998), (-2.5920794, -2.8630946), (-1.8046505, -1.0386717), (-1.7401559, -0.9722795), (-2.5275867, -2.7967055), (-2.5920844, -2.863096), (-1.8046539, -1.0386672), (-1.740155, -0.972277), (-2.5275848, -2.7967074), (-2.5920825, -2.8630989), (-1.8046523, -1.0386701), (-1.7401547, -0.9722765), (-2.527584, -2.7967045), (-2.592081, -2.863099), (-1.8046525, -1.0386722), (-1.7401552, -0.97227687), (-2.5275834, -2.7967024), (-2.592081, -2.8630977), (-1.8046523, -1.0386733), (-1.7401541, -0.97227883), (-2.5275812, -2.796703), (-2.59208, -2.8630977), (-1.8046553, -1.0386721), (-1.7401562, -0.9722771), (-2.5275807, -2.796703), (-2.5920787, -2.863098), (-1.8046533, -1.0386724), (-1.740157, -0.9722776), (-2.5275826, -2.796703), (-2.5920782, -2.8630962), (-1.8046519, -1.0386708), (-1.7401582, -0.9722786), (-2.5275893, -2.796704), (-2.592084, -2.8630967), (-1.8046491, -1.0386703), (-1.740151, -0.97227746), (-2.5275857, -2.7967052), (-2.5920873, -2.8630986), (-1.8046523, -1.0386692), (-1.7401491, -0.97227514), (-2.5275822, -2.7967052), (-2.5920854, -2.8630996), (-1.8046553, -1.0386698), (-1.7401515, -0.9722749), (-2.52758, -2.7967045), (-2.592085, -2.863101), (-1.804659, -1.0386723), (-1.7401536, -0.97227377), (-2.5275764, -2.7967002), (-2.5920808, -2.8630993), (-1.80466, -1.0386755), (-1.740159, -0.97227746), (-2.5275812, -2.7966998), (-2.5920794, -2.8630955), (-1.8046553, -1.0386734), (-1.7401564, -0.9722802), (-2.5275812, -2.7967033), (-2.592078, -2.8630962), (-1.8046503, -1.0386719), (-1.740156, -0.9722795), (-2.5275857, -2.7967052), (-2.592082, -2.8630972), (-1.8046508, -1.0386698), (-1.740152, -0.9722777), (-2.527584, -2.7967055), (-2.5920854, -2.8630981), (-1.8046567, -1.0386704), (-1.7401553, -0.9722756), (-2.5275822, -2.796703), (-2.592082, -2.8630993), (-1.804655, -1.0386733), (-1.7401547, -0.97227675), (-2.5275822, -2.7967007), (-2.5920823, -2.8630972), (-1.8046558, -1.038673), (-1.7401551, -0.972277), (-2.5275795, -2.7967012), (-2.592081, -2.8630981), (-1.8046572, -1.0386746), (-1.7401538, -0.9722773), (-2.5275748, -2.7967002), (-2.5920787, -2.8630981), (-1.804659, -1.0386763), (-1.7401577, -0.97227806), (-2.5275786, -2.7966986), (-2.5920782, -2.8630958), (-1.8046559, -1.038676), (-1.7401577, -0.9722801), (-2.5275795, -2.7967014), (-2.5920753, -2.8630958), (-1.804654, -1.038674), (-1.7401599, -0.97228), (-2.5275853, -2.7967021), (-2.5920804, -2.8630953), (-1.8046504, -1.0386709), (-1.7401546, -0.9722778), (-2.5275843, -2.7967038), (-2.5920825, -2.8630965), (-1.8046557, -1.0386698), (-1.7401569, -0.97227645), (-2.5275834, -2.7967026), (-2.5920799, -2.8630981), (-1.8046525, -1.0386727), (-1.7401556, -0.97227687), (-2.527583, -2.7967021), (-2.5920815, -2.8630984), (-1.8046553, -1.0386735), (-1.7401563, -0.9722769), (-2.527582, -2.796701), (-2.5920806, -2.8630972), (-1.804654, -1.0386739), (-1.7401555, -0.9722786), (-2.5275826, -2.796702), (-2.5920796, -2.8630972), (-1.8046509, -1.0386735), (-1.7401552, -0.9722789), (-2.5275855, -2.796703), (-2.592083, -2.863097), (-1.8046525, -1.0386713), (-1.7401524, -0.97227675), (-2.5275812, -2.7967033), (-2.5920815, -2.8630996), (-1.8046561, -1.038673), (-1.7401558, -0.97227633), (-2.5275807, -2.7967017), (-2.5920804, -2.8630977), (-1.8046542, -1.0386739), (-1.7401565, -0.97227824), (-2.5275822, -2.7967012), (-2.5920787, -2.8630962), (-1.8046532, -1.0386728), (-1.7401563, -0.9722786), (-2.5275826, -2.7967029), (-2.59208, -2.8630977), (-1.8046561, -1.0386726), (-1.7401593, -0.97227705), (-2.5275822, -2.7967012), (-2.5920784, -2.863096), (-1.8046552, -1.0386734), (-1.7401599, -0.9722789), (-2.5275848, -2.7967012), (-2.592078, -2.8630946), (-1.8046517, -1.0386721), (-1.7401575, -0.9722798), (-2.5275822, -2.7967036), (-2.5920768, -2.8630967), (-1.804652, -1.0386729), (-1.740157, -0.9722793), (-2.527582, -2.7967026), (-2.5920784, -2.8630965), (-1.8046548, -1.0386735), (-1.7401597, -0.97227895), (-2.5275848, -2.7967014), (-2.5920784, -2.8630958), (-1.8046502, -1.0386722), (-1.7401552, -0.97227895), (-2.5275848, -2.796704), (-2.5920825, -2.8630953), (-1.8046542, -1.038668), (-1.7401552, -0.97227705), (-2.5275831, -2.7967052), (-2.5920825, -2.8630967), (-1.8046526, -1.038668), (-1.7401531, -0.97227645), (-2.5275826, -2.7967052), (-2.592082, -2.863098), (-1.8046556, -1.0386707), (-1.7401545, -0.9722765), (-2.5275793, -2.7967033), (-2.5920813, -2.8630998), (-1.8046565, -1.0386739), (-1.740153, -0.9722754), (-2.5275772, -2.7967005), (-2.5920796, -2.8630998), (-1.8046571, -1.038676), (-1.7401582, -0.97227794), (-2.5275817, -2.7967), (-2.5920804, -2.8630965), (-1.8046545, -1.0386742), (-1.7401565, -0.97227883), (-2.5275826, -2.796702), (-2.5920796, -2.863096), (-1.8046541, -1.0386716), (-1.7401565, -0.97227776), (-2.527583, -2.7967026), (-2.5920818, -2.8630974), (-1.8046556, -1.0386733), (-1.7401572, -0.97227746), (-2.5275834, -2.7967017), (-2.5920808, -2.8630965), (-1.8046528, -1.0386716), (-1.740154, -0.9722785), (-2.5275815, -2.7967038), (-2.5920784, -2.8630974), (-1.8046533, -1.0386733), (-1.7401575, -0.9722797), (-2.5275857, -2.796703), (-2.5920842, -2.8630958), (-1.8046539, -1.0386703), (-1.7401532, -0.9722773), (-2.527581, -2.7967045), (-2.5920792, -2.8630993), (-1.8046521, -1.0386734), (-1.7401583, -0.9722777), (-2.5275877, -2.7967017), (-2.5920815, -2.8630946), (-1.8046502, -1.0386696), (-1.7401533, -0.9722787), (-2.5275848, -2.7967067), (-2.5920818, -2.8630981), (-1.8046519, -1.0386702), (-1.7401558, -0.9722776), (-2.5275834, -2.7967048), (-2.5920796, -2.8630981), (-1.804654, -1.038671), (-1.7401574, -0.97227764), (-2.5275826, -2.796704), (-2.592078, -2.8630984), (-1.8046513, -1.0386729), (-1.7401557, -0.9722778), (-2.5275831, -2.796702), (-2.5920792, -2.863097), (-1.8046525, -1.0386733), (-1.7401562, -0.9722786), (-2.5275824, -2.7967029), (-2.59208, -2.8630977), (-1.8046561, -1.038673), (-1.740159, -0.97227705), (-2.5275831, -2.796701), (-2.5920777, -2.8630972), (-1.8046523, -1.0386733), (-1.7401581, -0.97227794), (-2.5275848, -2.7967014), (-2.5920799, -2.863096), (-1.8046517, -1.0386727), (-1.7401555, -0.97227824), (-2.527583, -2.7967026), (-2.5920815, -2.8630974), (-1.804658, -1.0386732), (-1.7401588, -0.9722761), (-2.5275795, -2.7966993), (-2.592078, -2.8630984), (-1.8046572, -1.0386769), (-1.7401602, -0.972279), (-2.527584, -2.7966998), (-2.5920799, -2.8630946), (-1.8046514, -1.038673), (-1.740155, -0.97228116), (-2.5275865, -2.7967048), (-2.5920827, -2.863096), (-1.8046509, -1.0386703), (-1.7401543, -0.97227824), (-2.5275853, -2.7967055), (-2.5920827, -2.8630981), (-1.8046535, -1.0386707), (-1.7401556, -0.9722771), (-2.5275822, -2.7967043), (-2.5920787, -2.863099), (-1.804652, -1.0386736), (-1.740156, -0.9722785), (-2.5275838, -2.7967026), (-2.5920796, -2.863097), (-1.804651, -1.0386727), (-1.7401549, -0.97227955), (-2.527583, -2.796705), (-2.5920813, -2.8630972), (-1.8046542, -1.0386703), (-1.740155, -0.97227657), (-2.527583, -2.7967026), (-2.5920815, -2.8630977), (-1.8046515, -1.0386733), (-1.7401552, -0.97227865), (-2.527585, -2.7967026), (-2.5920799, -2.8630972), (-1.8046532, -1.0386724), (-1.7401577, -0.9722776), (-2.5275843, -2.7967021), (-2.5920796, -2.8630965), (-1.8046507, -1.038672), (-1.7401544, -0.9722786), (-2.5275857, -2.7967036), (-2.5920842, -2.8630962), (-1.8046525, -1.0386705), (-1.7401543, -0.9722774), (-2.5275846, -2.796703), (-2.5920835, -2.863097), (-1.8046535, -1.0386713), (-1.7401531, -0.97227716), (-2.5275817, -2.7967038), (-2.5920813, -2.8630986), (-1.8046554, -1.038673), (-1.7401581, -0.97227675), (-2.5275843, -2.796701), (-2.5920792, -2.8630965), (-1.8046517, -1.0386729), (-1.7401555, -0.97227937), (-2.5275836, -2.7967036), (-2.5920827, -2.8630974), (-1.8046535, -1.0386724), (-1.7401531, -0.972278), (-2.5275822, -2.796703), (-2.5920823, -2.8630958), (-1.8046532, -1.0386695), (-1.7401549, -0.97227687), (-2.527585, -2.7967036), (-2.5920823, -2.8630972), (-1.8046498, -1.0386705), (-1.7401514, -0.9722778), (-2.5275846, -2.796705), (-2.5920854, -2.8630977), (-1.8046541, -1.0386693), (-1.7401496, -0.9722753), (-2.5275772, -2.7967048), (-2.5920832, -2.8631017), (-1.8046592, -1.0386739), (-1.7401544, -0.97227407), (-2.5275772, -2.7966988), (-2.5920815, -2.863099), (-1.8046608, -1.038677), (-1.7401597, -0.9722766), (-2.5275812, -2.7966974), (-2.5920804, -2.8630962), (-1.8046564, -1.0386765), (-1.7401574, -0.97228044), (-2.5275822, -2.7967005), (-2.5920799, -2.8630943), (-1.804653, -1.0386726), (-1.7401534, -0.9722802), (-2.5275822, -2.7967036), (-2.5920825, -2.8630962), (-1.8046532, -1.0386715), (-1.740154, -0.9722778), (-2.5275826, -2.7967029), (-2.5920806, -2.8630974), (-1.8046522, -1.0386728), (-1.740154, -0.9722782), (-2.5275822, -2.7967029), (-2.5920823, -2.8630972), (-1.8046539, -1.0386722), (-1.7401534, -0.97227883), (-2.5275831, -2.7967043), (-2.592083, -2.8630981), (-1.8046523, -1.0386714), (-1.740153, -0.9722759), (-2.5275843, -2.7967029), (-2.5920844, -2.8630972), (-1.8046532, -1.0386713), (-1.7401527, -0.9722781), (-2.5275834, -2.7967043), (-2.592083, -2.8630986), (-1.8046529, -1.0386716), (-1.7401537, -0.9722765), (-2.5275822, -2.7967029), (-2.5920832, -2.8630984), (-1.8046564, -1.0386723), (-1.7401549, -0.9722762), (-2.527582, -2.7967017), (-2.5920823, -2.863098), (-1.8046556, -1.0386724), (-1.7401562, -0.9722766), (-2.5275817, -2.7967021), (-2.5920813, -2.8630977), (-1.8046541, -1.0386729), (-1.7401534, -0.9722778), (-2.5275805, -2.796703), (-2.5920806, -2.8630977), (-1.8046558, -1.0386727), (-1.7401574, -0.9722783), (-2.5275826, -2.7967029), (-2.5920794, -2.8630972), (-1.8046541, -1.0386721), (-1.7401588, -0.9722783), (-2.527585, -2.7967036), (-2.5920796, -2.8630965), (-1.8046514, -1.0386705), (-1.7401567, -0.9722784), (-2.5275843, -2.796705), (-2.59208, -2.8630972), (-1.8046521, -1.0386705), (-1.7401551, -0.9722779), (-2.5275853, -2.7967048), (-2.5920851, -2.8630974), (-1.8046534, -1.0386704), (-1.7401499, -0.9722761), (-2.5275793, -2.7967033), (-2.5920818, -2.8631005), (-1.8046556, -1.0386751), (-1.7401559, -0.9722764), (-2.527582, -2.7967002), (-2.5920808, -2.8630984), (-1.8046551, -1.0386755), (-1.7401571, -0.9722783), (-2.5275807, -2.7967002), (-2.5920765, -2.8630965), (-1.8046529, -1.0386742), (-1.7401606, -0.97227955), (-2.5275881, -2.7967029), (-2.5920813, -2.8630943), (-1.8046505, -1.0386695), (-1.7401537, -0.97227955), (-2.5275843, -2.7967072), (-2.5920815, -2.863097), (-1.804652, -1.0386677), (-1.7401544, -0.9722763), (-2.527584, -2.7967048), (-2.5920835, -2.863098), (-1.8046544, -1.0386705), (-1.7401551, -0.9722764), (-2.527584, -2.7967029), (-2.5920815, -2.863098), (-1.8046527, -1.0386724), (-1.7401551, -0.9722769), (-2.5275838, -2.796702), (-2.592081, -2.863097), (-1.8046513, -1.0386727), (-1.7401538, -0.97227824), (-2.5275826, -2.7967029), (-2.5920813, -2.8630962), (-1.8046527, -1.0386703), (-1.7401526, -0.9722783), (-2.5275803, -2.7967055), (-2.5920808, -2.8630996), (-1.8046564, -1.038673), (-1.7401571, -0.9722764), (-2.5275815, -2.7967007), (-2.59208, -2.863097), (-1.8046535, -1.0386733), (-1.7401565, -0.9722775), (-2.5275834, -2.796702), (-2.592079, -2.8630974), (-1.8046513, -1.0386727), (-1.7401557, -0.972279), (-2.5275846, -2.7967036), (-2.592082, -2.8630967), (-1.8046554, -1.0386716), (-1.7401578, -0.9722776), (-2.5275834, -2.7967029), (-2.5920782, -2.8630977), (-1.8046508, -1.0386732), (-1.7401571, -0.9722785), (-2.5275855, -2.7967021), (-2.5920794, -2.8630958), (-1.8046523, -1.0386723), (-1.7401582, -0.9722788), (-2.5275857, -2.7967024), (-2.59208, -2.8630962), (-1.8046529, -1.0386728), (-1.7401581, -0.97227925), (-2.527586, -2.796703), (-2.5920815, -2.8630955), (-1.8046534, -1.0386708), (-1.7401568, -0.97227913), (-2.5275838, -2.796705), (-2.592079, -2.863098), (-1.8046513, -1.0386714), (-1.7401582, -0.9722785), (-2.5275886, -2.7967048), (-2.5920827, -2.8630967), (-1.8046482, -1.0386695), (-1.7401513, -0.9722784), (-2.5275855, -2.7967074), (-2.592084, -2.8630977), (-1.8046501, -1.0386678), (-1.7401499, -0.9722764), (-2.5275807, -2.7967072), (-2.5920813, -2.863102), (-1.8046541, -1.0386716), (-1.740155, -0.9722741), (-2.527582, -2.7967014), (-2.5920808, -2.863099), (-1.8046552, -1.038674), (-1.7401582, -0.9722769), (-2.5275846, -2.7967007), (-2.5920794, -2.8630955), (-1.8046527, -1.0386721), (-1.7401574, -0.97227883), (-2.5275817, -2.796703), (-2.5920782, -2.8630967), (-1.8046552, -1.0386728), (-1.7401588, -0.9722784), (-2.5275824, -2.7967017), (-2.5920787, -2.8630967), (-1.8046547, -1.0386741), (-1.74016, -0.9722795), (-2.5275865, -2.796702), (-2.5920813, -2.8630958), (-1.8046517, -1.0386713), (-1.7401541, -0.9722777), (-2.527583, -2.7967033), (-2.592081, -2.8630981), (-1.8046544, -1.0386729), (-1.740156, -0.97227776), (-2.5275824, -2.796702), (-2.5920794, -2.8630977), (-1.8046539, -1.0386732), (-1.7401577, -0.9722776), (-2.5275826, -2.7967026), (-2.5920784, -2.863096), (-1.8046525, -1.0386713), (-1.7401569, -0.972279), (-2.527582, -2.7967043), (-2.5920773, -2.8630962), (-1.8046526, -1.0386705), (-1.7401575, -0.97227937), (-2.527583, -2.796705), (-2.5920792, -2.8630962), (-1.8046533, -1.0386696), (-1.7401576, -0.972277), (-2.527585, -2.796704), (-2.5920815, -2.863097), (-1.8046533, -1.0386696), (-1.740156, -0.97227806), (-2.5275834, -2.7967052), (-2.5920799, -2.8630974), (-1.8046545, -1.0386696), (-1.7401586, -0.9722769), (-2.527584, -2.7967048), (-2.59208, -2.8630974), (-1.8046521, -1.0386711), (-1.7401545, -0.9722773), (-2.5275831, -2.7967026), (-2.5920808, -2.8630974), (-1.8046523, -1.0386729), (-1.7401541, -0.9722782), (-2.5275812, -2.7967021), (-2.5920782, -2.8630972), (-1.8046542, -1.0386747), (-1.7401623, -0.9722795), (-2.527587, -2.7967005), (-2.592077, -2.8630946), (-1.8046503, -1.0386736), (-1.7401593, -0.9722812), (-2.5275874, -2.7967045), (-2.5920806, -2.8630955), (-1.8046519, -1.03867), (-1.7401565, -0.9722785), (-2.5275824, -2.7967045), (-2.5920753, -2.8630972), (-1.8046504, -1.0386719), (-1.7401597, -0.9722801), (-2.5275886, -2.7967052), (-2.5920806, -2.8630946), (-1.8046467, -1.0386679), (-1.7401539, -0.97227967), (-2.52759, -2.7967083), (-2.5920856, -2.8630972), (-1.8046494, -1.0386664), (-1.7401503, -0.97227645), (-2.5275822, -2.7967079), (-2.592082, -2.8631005), (-1.8046548, -1.0386705), (-1.7401565, -0.97227484), (-2.527583, -2.7967017), (-2.5920784, -2.8630986), (-1.804653, -1.0386746), (-1.7401577, -0.9722784), (-2.5275836, -2.7967012), (-2.5920794, -2.8630958), (-1.804652, -1.0386723), (-1.7401557, -0.97227925), (-2.5275834, -2.7967038), (-2.5920808, -2.8630958), (-1.8046551, -1.0386707), (-1.7401594, -0.97227776), (-2.5275857, -2.796703), (-2.5920808, -2.863096), (-1.804654, -1.0386705), (-1.7401587, -0.97227776), (-2.5275853, -2.796703), (-2.5920794, -2.8630962), (-1.8046523, -1.0386713), (-1.740157, -0.9722795), (-2.5275834, -2.7967045), (-2.592077, -2.8630967), (-1.8046497, -1.0386719), (-1.7401575, -0.97227937), (-2.5275862, -2.7967043), (-2.5920808, -2.8630967), (-1.8046498, -1.038671), (-1.7401533, -0.9722776), (-2.527585, -2.7967045), (-2.592085, -2.8630986), (-1.8046561, -1.038671), (-1.7401549, -0.9722763), (-2.5275815, -2.7967036), (-2.59208, -2.8630998), (-1.8046547, -1.0386734), (-1.7401587, -0.9722764), (-2.527582, -2.7967005), (-2.592076, -2.8630972), (-1.804652, -1.0386751), (-1.7401587, -0.9722805), (-2.5275862, -2.7967021), (-2.5920787, -2.863095), (-1.8046497, -1.0386715), (-1.7401565, -0.97227913), (-2.5275848, -2.7967036), (-2.592079, -2.8630958), (-1.8046511, -1.0386709), (-1.7401571, -0.9722785), (-2.5275838, -2.7967038), (-2.5920775, -2.863097), (-1.8046516, -1.0386721), (-1.7401569, -0.97227883), (-2.527582, -2.796703), (-2.5920794, -2.8630977), (-1.8046547, -1.0386738), (-1.7401571, -0.97227824), (-2.527584, -2.7967014), (-2.5920804, -2.8630958), (-1.8046527, -1.0386715), (-1.7401555, -0.9722784), (-2.5275843, -2.7967038), (-2.592083, -2.8630974), (-1.8046523, -1.0386719), (-1.740152, -0.97227806), (-2.5275838, -2.796704), (-2.5920866, -2.8630984), (-1.8046553, -1.0386711), (-1.740152, -0.972275), (-2.527582, -2.7967021), (-2.5920854, -2.863099), (-1.8046575, -1.0386723), (-1.7401532, -0.9722744), (-2.5275793, -2.7967007), (-2.592083, -2.8631), (-1.8046576, -1.0386759), (-1.7401555, -0.9722761), (-2.5275812, -2.7966979), (-2.5920818, -2.8630974), (-1.8046564, -1.0386765), (-1.740157, -0.97227824), (-2.5275815, -2.7966993), (-2.5920792, -2.8630958), (-1.8046523, -1.0386741), (-1.7401547, -0.97227967), (-2.5275812, -2.796703), (-2.5920775, -2.8630972), (-1.8046511, -1.0386732), (-1.7401537, -0.9722784), (-2.5275812, -2.7967026), (-2.5920813, -2.8630967), (-1.8046547, -1.0386716), (-1.7401557, -0.9722777), (-2.5275824, -2.7967038), (-2.5920804, -2.8630967), (-1.804653, -1.0386702), (-1.7401547, -0.97227746), (-2.5275826, -2.7967043), (-2.5920823, -2.863097), (-1.804657, -1.0386702), (-1.74016, -0.9722762), (-2.5275855, -2.7967021), (-2.5920806, -2.8630962), (-1.8046525, -1.0386715), (-1.7401556, -0.97227925), (-2.5275831, -2.7967038), (-2.5920806, -2.8630967), (-1.8046535, -1.038672), (-1.7401559, -0.9722775), (-2.527583, -2.7967026), (-2.5920818, -2.8630974), (-1.8046539, -1.0386727), (-1.7401534, -0.9722785), (-2.5275826, -2.7967038), (-2.592083, -2.8630984), (-1.8046546, -1.0386723), (-1.7401546, -0.97227705), (-2.527582, -2.7967024), (-2.592081, -2.863098), (-1.804655, -1.0386728), (-1.7401565, -0.97227746), (-2.5275817, -2.7967029), (-2.5920775, -2.8630967), (-1.8046495, -1.0386708), (-1.7401539, -0.9722787), (-2.5275857, -2.7967057), (-2.5920832, -2.8630984), (-1.8046511, -1.0386697), (-1.7401526, -0.9722764), (-2.5275822, -2.7967062), (-2.592081, -2.8631005), (-1.8046546, -1.0386719), (-1.7401563, -0.9722756), (-2.5275834, -2.7967017), (-2.5920804, -2.8630986), (-1.8046548, -1.0386736), (-1.7401617, -0.9722776), (-2.5275886, -2.7967014), (-2.5920806, -2.863094), (-1.80465, -1.03867), (-1.7401544, -0.9722799), (-2.5275848, -2.7967067), (-2.592082, -2.8630974), (-1.8046532, -1.0386685), (-1.7401556, -0.9722766), (-2.5275838, -2.7967052), (-2.592082, -2.8630984), (-1.8046546, -1.0386708), (-1.7401567, -0.97227556), (-2.5275838, -2.796702), (-2.5920796, -2.863098), (-1.8046501, -1.0386735), (-1.7401553, -0.972279), (-2.527584, -2.7967033), (-2.592078, -2.8630965), (-1.8046505, -1.0386717), (-1.7401567, -0.9722794), (-2.527584, -2.796704), (-2.5920773, -2.863096), (-1.8046514, -1.0386713), (-1.7401594, -0.9722789), (-2.5275867, -2.7967036), (-2.5920787, -2.863096), (-1.8046505, -1.038671), (-1.7401568, -0.9722793), (-2.527584, -2.7967043), (-2.5920784, -2.8630965), (-1.804651, -1.0386716), (-1.7401558, -0.97227937), (-2.5275834, -2.796704), (-2.5920796, -2.863097), (-1.8046522, -1.0386719), (-1.7401556, -0.9722775), (-2.5275822, -2.7967024), (-2.5920796, -2.8630981), (-1.8046556, -1.0386739), (-1.7401601, -0.97227776), (-2.527586, -2.7967005), (-2.5920813, -2.8630955), (-1.8046523, -1.0386726), (-1.7401541, -0.9722782), (-2.5275834, -2.7967024), (-2.592083, -2.8630977), (-1.8046557, -1.0386729), (-1.740157, -0.97227734), (-2.527583, -2.7967021), (-2.592081, -2.863098), (-1.8046548, -1.0386741), (-1.7401576, -0.9722785), (-2.5275838, -2.7967012), (-2.5920808, -2.8630958), (-1.8046538, -1.0386724), (-1.7401555, -0.9722786), (-2.5275815, -2.7967033), (-2.5920768, -2.8630977), (-1.8046519, -1.038674), (-1.7401589, -0.9722792), (-2.5275865, -2.7967017), (-2.5920806, -2.8630953), (-1.8046511, -1.038671), (-1.7401555, -0.9722784), (-2.5275834, -2.7967045), (-2.592078, -2.8630967), (-1.8046508, -1.0386702), (-1.7401576, -0.9722779), (-2.5275862, -2.796704), (-2.5920808, -2.8630965), (-1.8046521, -1.0386705), (-1.7401564, -0.97227794), (-2.527584, -2.796704), (-2.5920796, -2.8630967), (-1.8046534, -1.0386715), (-1.7401588, -0.9722788), (-2.527586, -2.7967038), (-2.59208, -2.8630967), (-1.8046505, -1.0386709), (-1.7401546, -0.9722786), (-2.5275855, -2.7967048), (-2.592083, -2.8630974), (-1.804654, -1.0386704), (-1.7401557, -0.9722768), (-2.527582, -2.7967038), (-2.5920784, -2.8630989), (-1.8046517, -1.0386732), (-1.7401562, -0.97227806), (-2.5275831, -2.7967021), (-2.5920796, -2.8630972), (-1.8046529, -1.0386736), (-1.7401557, -0.9722794), (-2.5275836, -2.7967036), (-2.5920808, -2.8630977), (-1.8046545, -1.0386727), (-1.7401583, -0.9722778), (-2.5275838, -2.7967021), (-2.5920796, -2.8630962), (-1.8046535, -1.0386728), (-1.7401574, -0.9722787), (-2.5275824, -2.796702), (-2.5920782, -2.8630965), (-1.8046534, -1.0386738), (-1.7401595, -0.97227925), (-2.5275855, -2.796701), (-2.5920782, -2.8630939), (-1.80465, -1.0386721), (-1.7401564, -0.9722812), (-2.5275853, -2.796705), (-2.5920808, -2.8630953), (-1.8046529, -1.038669), (-1.740155, -0.97227776), (-2.5275803, -2.7967052), (-2.5920794, -2.8630998), (-1.8046556, -1.0386732), (-1.7401589, -0.9722759), (-2.5275846, -2.7967007), (-2.5920796, -2.863098), (-1.8046528, -1.0386733), (-1.7401563, -0.9722777), (-2.527583, -2.7967024), (-2.5920794, -2.863096), (-1.8046505, -1.0386703), (-1.7401546, -0.9722783), (-2.5275857, -2.7967057), (-2.592083, -2.8630972), (-1.8046507, -1.0386686), (-1.7401519, -0.9722762), (-2.5275848, -2.7967048), (-2.592087, -2.8630986), (-1.8046553, -1.0386697), (-1.7401513, -0.97227454), (-2.52758, -2.7967036), (-2.592082, -2.8631005), (-1.8046553, -1.0386728), (-1.7401555, -0.9722757), (-2.5275826, -2.796702), (-2.5920808, -2.863099), (-1.8046541, -1.0386739), (-1.7401578, -0.97227687), (-2.5275848, -2.7967005), (-2.5920806, -2.8630962), (-1.8046523, -1.0386738), (-1.740156, -0.97227925), (-2.5275824, -2.7967026), (-2.5920775, -2.863097), (-1.8046535, -1.0386734), (-1.7401586, -0.97228026), (-2.5275817, -2.7967036), (-2.5920768, -2.8630958), (-1.8046553, -1.0386728), (-1.740161, -0.9722793), (-2.5275838, -2.7967021), (-2.5920775, -2.8630958), (-1.8046528, -1.0386732), (-1.7401615, -0.9722805), (-2.5275886, -2.796703), (-2.592079, -2.8630946), (-1.8046489, -1.0386705), (-1.7401553, -0.97228), (-2.527585, -2.7967062), (-2.5920794, -2.863098), (-1.8046508, -1.0386701), (-1.7401571, -0.97227716), (-2.5275855, -2.796705), (-2.5920813, -2.8630974), (-1.8046532, -1.0386704), (-1.7401549, -0.97227776), (-2.527582, -2.7967043), (-2.5920796, -2.8630972), (-1.8046523, -1.0386704), (-1.7401553, -0.9722779), (-2.5275831, -2.7967043), (-2.5920794, -2.8630981), (-1.8046526, -1.0386726), (-1.7401563, -0.97227746), (-2.5275826, -2.7967017), (-2.5920804, -2.8630965), (-1.8046526, -1.0386727), (-1.7401534, -0.97227854), (-2.5275846, -2.7967036), (-2.5920858, -2.8630977), (-1.804655, -1.0386709), (-1.7401515, -0.9722754), (-2.5275786, -2.7967026), (-2.592083, -2.863099), (-1.8046591, -1.038673), (-1.7401545, -0.9722748), (-2.5275776, -2.7966995), (-2.5920827, -2.8630998), (-1.80466, -1.0386767), (-1.7401545, -0.97227585), (-2.5275767, -2.796697), (-2.5920818, -2.863098), (-1.8046609, -1.0386778), (-1.7401586, -0.9722788), (-2.5275795, -2.7966986), (-2.592078, -2.8630958), (-1.8046539, -1.038675), (-1.7401551, -0.97227967), (-2.5275805, -2.796703), (-2.5920799, -2.863097), (-1.804655, -1.0386719), (-1.7401574, -0.97227746), (-2.5275824, -2.7967024), (-2.5920794, -2.8630977), (-1.8046529, -1.038674), (-1.740156, -0.9722786), (-2.5275822, -2.796702), (-2.5920773, -2.8630962), (-1.8046533, -1.0386728), (-1.740159, -0.9722794), (-2.527584, -2.7967033), (-2.5920777, -2.8630953), (-1.8046534, -1.0386713), (-1.7401605, -0.97227937), (-2.5275848, -2.7967029), (-2.5920777, -2.8630939), (-1.8046514, -1.0386698), (-1.7401583, -0.9722793), (-2.5275872, -2.7967055), (-2.5920823, -2.863095), (-1.8046532, -1.038666), (-1.7401559, -0.972276), (-2.527583, -2.7967074), (-2.5920794, -2.8631005), (-1.8046516, -1.0386688), (-1.7401563, -0.97227407), (-2.5275838, -2.796703), (-2.59208, -2.8630986), (-1.804654, -1.0386732), (-1.7401555, -0.97227824), (-2.527579, -2.7967029), (-2.592077, -2.8630977), (-1.8046534, -1.0386738), (-1.7401569, -0.97227824), (-2.527583, -2.7967012), (-2.5920782, -2.863096), (-1.8046523, -1.0386735), (-1.740157, -0.9722799), (-2.5275846, -2.796703), (-2.5920823, -2.8630958), (-1.8046516, -1.0386703), (-1.7401528, -0.9722776), (-2.5275848, -2.7967048), (-2.592086, -2.8630977), (-1.8046569, -1.0386691), (-1.7401552, -0.9722735), (-2.5275815, -2.796702), (-2.59208, -2.8631005), (-1.8046534, -1.038675), (-1.7401551, -0.9722773), (-2.5275834, -2.7967012), (-2.592081, -2.8630974), (-1.8046522, -1.038674), (-1.7401543, -0.9722787), (-2.5275838, -2.7967026), (-2.5920837, -2.863097), (-1.8046545, -1.0386721), (-1.7401537, -0.97227895), (-2.5275831, -2.7967043), (-2.5920827, -2.863098), (-1.8046546, -1.038672), (-1.7401563, -0.9722766), (-2.5275824, -2.796702), (-2.5920792, -2.8630981), (-1.8046529, -1.0386741), (-1.7401582, -0.972279), (-2.5275838, -2.7967026), (-2.5920773, -2.8630948), (-1.8046495, -1.0386705), (-1.7401552, -0.9722801), (-2.5275848, -2.7967064), (-2.5920813, -2.8630984), (-1.8046509, -1.0386696), (-1.7401531, -0.97227633), (-2.5275826, -2.796706), (-2.592081, -2.8631), (-1.8046556, -1.0386704), (-1.7401582, -0.97227484), (-2.5275817, -2.7967026), (-2.5920782, -2.8630981), (-1.8046538, -1.0386727), (-1.7401584, -0.9722785), (-2.5275857, -2.7967036), (-2.5920804, -2.8630967), (-1.8046507, -1.0386708), (-1.7401551, -0.9722772), (-2.5275848, -2.7967036), (-2.592081, -2.8630972), (-1.8046528, -1.0386711), (-1.7401563, -0.97227776), (-2.5275848, -2.7967038), (-2.5920844, -2.8630967), (-1.8046548, -1.0386696), (-1.7401534, -0.9722763), (-2.52758, -2.7967045), (-2.5920808, -2.8630986), (-1.8046572, -1.0386709), (-1.7401586, -0.9722761), (-2.5275815, -2.7967021), (-2.592077, -2.863098), (-1.804655, -1.0386746), (-1.7401607, -0.97227865), (-2.5275843, -2.7967002), (-2.5920773, -2.8630953), (-1.8046515, -1.0386744), (-1.7401588, -0.97228175), (-2.5275862, -2.7967038), (-2.5920782, -2.8630946), (-1.8046496, -1.0386709), (-1.7401571, -0.97227985), (-2.527585, -2.7967048), (-2.5920777, -2.863097), (-1.8046498, -1.0386721), (-1.740157, -0.97227967), (-2.5275848, -2.7967043), (-2.5920773, -2.8630967), (-1.8046488, -1.0386717), (-1.7401549, -0.9722795), (-2.5275846, -2.796704), (-2.5920806, -2.8630962), (-1.8046522, -1.0386703), (-1.7401569, -0.97227764), (-2.5275855, -2.796704), (-2.5920806, -2.863097), (-1.8046519, -1.0386711), (-1.7401569, -0.9722774), (-2.527585, -2.7967036), (-2.592081, -2.8630974), (-1.804654, -1.0386715), (-1.7401577, -0.97227746), (-2.5275846, -2.7967029), (-2.5920823, -2.8630972), (-1.8046559, -1.0386722), (-1.7401569, -0.9722768), (-2.5275824, -2.7967012), (-2.59208, -2.8630972), (-1.8046541, -1.0386735), (-1.7401578, -0.97227776), (-2.5275843, -2.7967014), (-2.5920799, -2.863097), (-1.8046523, -1.0386733), (-1.7401555, -0.97227865)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-4.8 -4.8 -4.8 -4.8  0.   0. ]\n",
            "Time predict 11.202545881271362\n",
            "Time model 79.20451307296753\n",
            "Episode reward -4038.0602211076766\n",
            "[(0.0, 0.0), (-3.2358797, -3.1195915), (-6.339973, -6.1121325), (-9.161808, -8.83256), (-11.694877, -11.274597), (-13.973344, -13.487273), (-16.070297, -15.535294), (-18.029266, -17.42969), (-19.833715, -19.166698), (-21.45158, -20.749697), (-22.81872, -22.167974), (-23.83326, -23.425379), (-24.396168, -24.52945), (-24.502956, -25.492422), (-24.270916, -26.347738), (-23.862999, -27.135586), (-23.410172, -27.88375), (-22.985645, -28.60928), (-22.617811, -29.320166), (-22.313604, -30.018927), (-22.069878, -30.70553), (-21.880281, -31.379324), (-21.739292, -32.040188), (-21.64239, -32.6878), (-21.607645, -33.305454), (-21.695353, -33.83614), (-21.927092, -34.23237), (-22.26238, -34.4832), (-22.664297, -34.584454), (-23.108282, -34.540073), (-23.577696, -34.36163), (-24.060762, -34.06593), (-24.550459, -33.67239), (-25.039404, -33.20045), (-25.519955, -32.66795), (-25.98641, -32.090923), (-26.433647, -31.483515), (-26.857037, -30.857592), (-27.251331, -30.223293), (-27.61162, -29.589382), (-27.93347, -28.963356), (-28.213432, -28.351635), (-28.448849, -27.759876), (-28.637236, -27.19335), (-28.776527, -26.656082), (-28.865496, -26.151598), (-28.904493, -25.683498), (-28.895521, -25.254625), (-28.842148, -24.86604), (-28.74867, -24.517763), (-28.619648, -24.209873), (-28.459564, -23.941216), (-28.272451, -23.71079), (-28.062212, -23.517887), (-27.83214, -23.360601), (-27.584614, -23.236301), (-27.32158, -23.142797), (-27.044844, -23.078398), (-26.756714, -23.041056), (-26.459152, -23.028704), (-26.153696, -23.039358), (-25.842896, -23.071157), (-25.529268, -23.122292), (-25.215042, -23.190958), (-24.901848, -23.275345), (-24.59132, -23.37361), (-24.285616, -23.484001), (-23.98565, -23.604816), (-23.692825, -23.73399), (-23.409515, -23.870012), (-23.136625, -24.011877), (-22.876072, -24.158243), (-22.629837, -24.307724), (-22.39897, -24.458826), (-22.184317, -24.610023), (-21.985788, -24.75953), (-21.80353, -24.906137), (-21.637585, -25.049215), (-21.487858, -25.187778), (-21.353846, -25.320997), (-21.23522, -25.448273), (-21.13177, -25.56906), (-21.04262, -25.682789), (-20.966637, -25.789156), (-20.9028, -25.888083), (-20.8502, -25.979448), (-20.808043, -26.063236), (-20.775509, -26.139433), (-20.751715, -26.20811), (-20.735836, -26.269382), (-20.727093, -26.323391), (-20.724798, -26.370337), (-20.728329, -26.410408), (-20.736992, -26.4438), (-20.750172, -26.470726), (-20.76735, -26.491434), (-20.787863, -26.506203), (-20.811176, -26.515303), (-20.836786, -26.51903), (-20.864176, -26.517742), (-20.892895, -26.511776), (-20.922468, -26.501446), (-20.952606, -26.487083), (-20.98283, -26.468992), (-21.012758, -26.447515), (-21.042177, -26.422995), (-21.070822, -26.39577), (-21.098486, -26.366156), (-21.124874, -26.334408), (-21.149828, -26.300817), (-21.17321, -26.265633), (-21.195023, -26.229074), (-21.21514, -26.191341), (-21.233389, -26.1526), (-21.249756, -26.11302), (-21.264174, -26.072765), (-21.276628, -26.031986), (-21.28715, -25.990866), (-21.295877, -25.949507), (-21.302717, -25.90799), (-21.307615, -25.86643), (-21.310638, -25.824942), (-21.311804, -25.783613), (-21.311172, -25.742514), (-21.308847, -25.701723), (-21.304861, -25.661297), (-21.29921, -25.62125), (-21.292046, -25.581642), (-21.283459, -25.542513), (-21.273438, -25.503883), (-21.262087, -25.465782), (-21.249441, -25.428164), (-21.235498, -25.391039), (-21.220394, -25.354483), (-21.204308, -25.318497), (-21.187302, -25.283047), (-21.169336, -25.24812), (-21.150402, -25.213709), (-21.130651, -25.17979), (-21.110226, -25.146353), (-21.08913, -25.113361), (-21.067411, -25.080805), (-21.04509, -25.048635), (-21.02229, -25.01684), (-20.99899, -24.98538), (-20.975231, -24.954182), (-20.951157, -24.923267), (-20.92672, -24.892607), (-20.902039, -24.862152), (-20.877125, -24.831884), (-20.8519, -24.801762), (-20.826515, -24.771746), (-20.800999, -24.74181), (-20.775326, -24.711939), (-20.749573, -24.682076), (-20.723734, -24.65221), (-20.697756, -24.62232), (-20.671618, -24.592403), (-20.645336, -24.562483), (-20.618977, -24.532532), (-20.592579, -24.502548), (-20.566038, -24.472523), (-20.539333, -24.442398), (-20.512606, -24.412163), (-20.485802, -24.381872), (-20.458714, -24.35153), (-20.43145, -24.321129), (-20.40422, -24.290682), (-20.377054, -24.26016), (-20.349869, -24.229485), (-20.322536, -24.198643), (-20.295216, -24.167643), (-20.267923, -24.13646), (-20.240564, -24.105066), (-20.213148, -24.073442), (-20.185663, -24.041574), (-20.15811, -24.009457), (-20.1305, -23.977089), (-20.102844, -23.944464), (-20.07513, -23.911566), (-20.047398, -23.878386), (-20.019611, -23.844902), (-19.991716, -23.811102), (-19.96369, -23.776978), (-19.935633, -23.74253), (-19.907486, -23.707767), (-19.8792, -23.67268), (-19.850847, -23.637249), (-19.822401, -23.601469), (-19.793797, -23.565334), (-19.765083, -23.528862), (-19.73628, -23.492027), (-19.70727, -23.454689), (-19.678095, -23.41691), (-19.648848, -23.378826), (-19.619469, -23.340422), (-19.589888, -23.30167), (-19.559837, -23.262527), (-19.529007, -23.22296), (-19.497194, -23.182983), (-19.46408, -23.142624), (-19.429678, -23.101965), (-19.394264, -23.061127), (-19.357824, -23.020142), (-19.320341, -22.979006), (-19.281849, -22.93763), (-19.242365, -22.896025), (-19.201996, -22.854338), (-19.16065, -22.812578), (-19.1184, -22.770712), (-19.075401, -22.728706), (-19.031557, -22.686556), (-18.986937, -22.644262), (-18.94158, -22.601753), (-18.895472, -22.559004), (-18.848648, -22.515991), (-18.801226, -22.47269), (-18.753231, -22.429073), (-18.704597, -22.385073), (-18.655409, -22.340694), (-18.605694, -22.295935), (-18.555517, -22.250778), (-18.504885, -22.205173), (-18.453747, -22.159088), (-18.401848, -22.112526), (-18.34915, -22.065506), (-18.296051, -22.018085), (-18.242542, -21.970278), (-18.188576, -21.922045), (-18.134195, -21.87338), (-18.079424, -21.824284), (-18.02481, -21.774813), (-17.971273, -21.72506), (-17.919401, -21.674995), (-17.869284, -21.624231), (-17.821032, -21.57259), (-17.774628, -21.520168), (-17.729767, -21.466848), (-17.686401, -21.412436), (-17.64432, -21.35683), (-17.60328, -21.300106), (-17.563253, -21.242292), (-17.52418, -21.183409), (-17.486032, -21.123505), (-17.448784, -21.062613), (-17.412472, -21.000772), (-17.377163, -20.938025), (-17.342844, -20.874306), (-17.309294, -20.809628), (-17.276386, -20.744097), (-17.243982, -20.67776), (-17.21191, -20.610643), (-17.180021, -20.542793), (-17.148174, -20.474277), (-17.116344, -20.404854), (-17.0845, -20.334654), (-17.05255, -20.264135), (-17.02042, -20.19335), (-16.988073, -20.12234), (-16.955341, -20.05113), (-16.92223, -19.979752), (-16.888735, -19.908237), (-16.854832, -19.836613), (-16.820688, -19.764935), (-16.786337, -19.69326), (-16.751842, -19.621584), (-16.717308, -19.54989), (-16.682844, -19.478113), (-16.648342, -19.405779), (-16.61402, -19.332708), (-16.580498, -19.259096), (-16.548004, -19.184767), (-16.516495, -19.109468), (-16.485971, -19.03299), (-16.456121, -18.955126), (-16.426744, -18.875734), (-16.39796, -18.794798), (-16.369684, -18.712307), (-16.341866, -18.628242), (-16.314375, -18.542599), (-16.287096, -18.455404), (-16.259918, -18.366243), (-16.232723, -18.275177), (-16.205517, -18.182783), (-16.178268, -18.089157), (-16.150753, -17.994385), (-16.122612, -17.898691), (-16.093468, -17.802525), (-16.062967, -17.706413), (-16.030825, -17.610775), (-15.997, -17.515966), (-15.961445, -17.42228), (-15.9241295, -17.329617), (-15.885086, -17.238314), (-15.844344, -17.14909), (-15.801953, -17.06223), (-15.757846, -16.977896), (-15.711998, -16.89625), (-15.664431, -16.817495), (-15.615251, -16.741812), (-15.564644, -16.66928), (-15.512737, -16.59988), (-15.459763, -16.533585), (-15.405787, -16.470306), (-15.351136, -16.409632), (-15.2964115, -16.351429), (-15.241901, -16.295761), (-15.187819, -16.242287), (-15.134382, -16.190695), (-15.081578, -16.1406), (-15.029288, -16.091877), (-14.977641, -16.044634), (-14.926713, -15.998786), (-14.876432, -15.954195), (-14.826806, -15.91073), (-14.777948, -15.868341), (-14.72986, -15.826948), (-14.682538, -15.786432), (-14.636062, -15.746689), (-14.590431, -15.707615), (-14.545649, -15.669123), (-14.5017185, -15.631129), (-14.458672, -15.593552), (-14.416258, -15.556308), (-14.374498, -15.519345), (-14.333732, -15.482644), (-14.29394, -15.445975), (-14.255068, -15.409269), (-14.217046, -15.372645), (-14.179823, -15.336069), (-14.143337, -15.299484), (-14.107477, -15.262832), (-14.072191, -15.226073), (-14.037477, -15.189199), (-14.003335, -15.152223), (-13.969734, -15.115122), (-13.936657, -15.077874), (-13.904087, -15.040477), (-13.871982, -15.002928), (-13.840288, -14.965211), (-13.808966, -14.927297), (-13.777992, -14.889205), (-13.747343, -14.850975), (-13.716976, -14.812594), (-13.686911, -14.774069), (-13.6571455, -14.735413), (-13.62761, -14.696614), (-13.59828, -14.657687), (-13.569117, -14.618643), (-13.540139, -14.57949), (-13.511298, -14.540244), (-13.482573, -14.500908), (-13.453895, -14.461501), (-13.425268, -14.42182), (-13.396839, -14.381913), (-13.368657, -14.342075), (-13.340671, -14.302312), (-13.312709, -14.262569), (-13.284821, -14.222837), (-13.25701, -14.183125), (-13.229211, -14.143411), (-13.2014065, -14.1037035), (-13.173404, -14.063989), (-13.144692, -14.024198), (-13.114596, -13.984297), (-13.082682, -13.944339), (-13.048771, -13.904475), (-13.01293, -13.864915), (-12.975269, -13.825799), (-12.935829, -13.787219), (-12.894681, -13.749241), (-12.851932, -13.711889), (-12.807697, -13.67517), (-12.762109, -13.639065), (-12.715248, -13.603539), (-12.667292, -13.568507), (-12.618322, -13.533911), (-12.568383, -13.49975), (-12.517478, -13.465773), (-12.464904, -13.431814), (-12.408942, -13.39785), (-12.348161, -13.3638115), (-12.282056, -13.329871), (-12.21024, -13.296344), (-12.132418, -13.263515), (-12.04837, -13.231617), (-11.95792, -13.200765), (-11.861033, -13.170911), (-11.757734, -13.1419), (-11.64799, -13.11353), (-11.531748, -13.085617), (-11.408896, -13.057997), (-11.278502, -13.030549), (-11.140599, -13.003239), (-10.996109, -12.976083), (-10.845959, -12.949151), (-10.69406, -12.92288), (-10.546553, -12.897751), (-10.408293, -12.873421), (-10.2805605, -12.848593), (-10.163747, -12.821599), (-10.058326, -12.790954), (-9.963377, -12.755492), (-9.877796, -12.714396), (-9.800633, -12.667162), (-9.731228, -12.613462), (-9.6691885, -12.552871), (-9.614275, -12.484882), (-9.566184, -12.408614), (-9.524537, -12.323653), (-9.488982, -12.230138), (-9.458899, -12.127766), (-9.433866, -12.016206), (-9.413761, -11.895193), (-9.398117, -11.764446), (-9.3864765, -11.623673), (-9.378488, -11.47263), (-9.373753, -11.31011), (-9.371965, -11.136006), (-9.372575, -10.951707), (-9.373942, -10.758514), (-9.373586, -10.558518), (-9.36932, -10.354079), (-9.359659, -10.146276), (-9.343726, -9.937222), (-9.321051, -9.729982), (-9.291322, -9.525924), (-9.254314, -9.325869), (-9.209985, -9.129185), (-9.158551, -8.936596), (-9.100325, -8.750141), (-9.035502, -8.570203), (-8.964123, -8.396978), (-8.886078, -8.230066), (-8.801297, -8.070246), (-8.709927, -7.9191837), (-8.61249, -7.7772737), (-8.510071, -7.644569), (-8.404324, -7.5209713), (-8.29636, -7.406155), (-8.187612, -7.2989917), (-8.079821, -7.198902), (-7.9736023, -7.1057906), (-7.8691072, -7.01873), (-7.766431, -6.936763), (-7.6657214, -6.859119), (-7.5671806, -6.7851863), (-7.47098, -6.7144523), (-7.376722, -6.646458), (-7.284657, -6.580841), (-7.19558, -6.5173044), (-7.109457, -6.455487), (-7.026021, -6.3946404), (-6.9450727, -6.334521), (-6.86649, -6.2753835), (-6.79013, -6.2170763), (-6.71586, -6.1593885), (-6.6435575, -6.102156), (-6.573084, -6.045242), (-6.504396, -5.988546), (-6.437448, -5.931983), (-6.3717346, -5.875458), (-6.3072896, -5.818941), (-6.244615, -5.7624297), (-6.1835837, -5.7058415), (-6.1239786, -5.649058), (-6.0656133, -5.59199), (-6.0083313, -5.534599), (-5.952048, -5.4768786), (-5.8965883, -5.4184556), (-5.8414507, -5.3599496), (-5.7858214, -5.302958), (-5.728931, -5.248537), (-5.670275, -5.197462), (-5.609711, -5.150301), (-5.5474086, -5.1074643), (-5.4761763, -5.0495934), (-5.3785386, -4.927812), (-5.265797, -4.746854), (-5.17822, -4.5713906), (-5.1321373, -4.42819), (-5.11216, -4.2940574), (-5.0982614, -4.1432104), (-5.084419, -3.9762995), (-5.0263524, -3.9243543), (-4.8655186, -4.1018534), (-4.630707, -4.3348284), (-4.3943524, -4.4206276), (-4.1899753, -4.4287043), (-4.0158257, -4.514014), (-3.8643637, -4.6490245), (-3.7318256, -4.7081413), (-3.6146758, -4.687951), (-3.541416, -4.588473), (-3.5420141, -4.3757997), (-3.5312939, -4.312987), (-3.5159614, -4.279964), (-3.6030476, -3.8420658), (-3.539783, -3.901408), (-3.3842137, -4.284463), (-3.660822, -3.264678), (-3.6632743, -3.068991), (-3.0219452, -4.81279), (-2.9286284, -4.505625), (-3.5246782, -2.0637553), (-3.495054, -2.0907362), (-2.7323651, -4.5393205), (-2.700457, -4.470161), (-3.4375844, -1.8661673), (-3.4024112, -1.7821451), (-2.5657806, -4.256456), (-2.5713701, -4.1543403), (-2.8869407, -1.452404), (-1.3144269, -1.3934419), (1.6425809, -4.045321), (4.334987, -4.311642), (6.3231254, -2.7370453), (7.944634, -3.550902), (8.290033, -6.0359764), (6.1959434, -6.289314), (3.4764776, -4.0859137), (2.8255596, -1.6738204), (4.318641, -1.3785796), (5.2933474, -3.3101518), (4.2522535, -3.856643), (2.4819925, -2.091584), (1.8005053, -0.16853362), (2.187422, -0.19137119), (2.3985085, -1.4499747), (1.8869504, -1.13153), (1.093342, 0.6295445), (0.7290943, 1.2028618), (0.5605924, 0.21487384), (0.2900549, 0.17219087), (0.0014952874, 1.6305114), (-0.4687378, 2.0894096), (-0.9053312, 1.1389298), (-0.947866, 1.2203964), (-1.2427915, 2.472399), (-2.4246504, 2.7948737), (-3.3465083, 2.724774), (-2.9969845, 3.7419906), (-2.6445563, 4.802052), (-3.6580338, 4.3025208), (-4.735561, 3.6741073), (-4.404283, 4.4968224), (-3.9537559, 5.1441884), (-4.5837293, 4.600397), (-5.293948, 3.8577552), (-4.899888, 4.0196037), (-4.042176, 4.596786), (-4.077728, 4.26125), (-4.563997, 3.4712012), (-4.1554084, 3.5548737), (-3.1821053, 4.1082563), (-2.9841604, 3.8062375), (-3.3186457, 2.9822893), (-2.877679, 2.9670339), (-1.8764547, 3.4964902), (-1.6312907, 3.2591262), (-1.9853898, 2.4532294), (-1.6295222, 2.367721), (-0.68744713, 2.8690686), (-0.48588508, 2.7008584), (-0.96334743, 1.9424076), (-0.7746852, 1.8216376), (0.058315214, 2.3057818), (0.1656075, 2.1978672), (-0.47244865, 1.489678), (-0.4692747, 1.3457919), (0.23920693, 1.8135225), (0.09645108, 1.0789357), (-0.59357226, -0.2697855), (-0.107850276, 0.4283556), (0.5523513, 1.2200248), (-0.3109213, -0.45640728), (-1.2084571, -1.9329768), (-0.7518668, -0.9664744), (-0.38067645, -0.30171934), (-1.0438166, -1.8816177), (-1.9123203, -3.368239), (-2.001067, -2.6513574), (-1.7189229, -1.6377552), (-2.012017, -2.741975), (-2.6865232, -4.560416), (-2.8532178, -4.318821), (-2.5696998, -2.8867767), (-2.6851263, -3.2243469), (-3.127251, -4.7181334), (-3.1562903, -4.624029), (-2.7894173, -3.205288), (-2.8162637, -3.2601461), (-3.2182052, -4.6866875), (-3.220605, -4.7571106), (-2.807788, -3.4310167), (-2.774663, -3.3849678), (-3.1444495, -4.717926), (-3.128539, -4.8190317), (-2.8256662, -3.4224517), (-2.798045, -3.281418), (-2.9176757, -4.705893), (-2.9378526, -4.80861), (-3.0001445, -3.2319415), (-2.8940175, -3.0513227), (-2.5132082, -4.6432743), (-2.483247, -4.934345), (-3.1136408, -3.2731874), (-3.216404, -2.8318803), (-2.322171, -4.3700213), (-1.8413937, -5.0885153), (-2.7292805, -3.7366018), (-3.3801303, -2.7911916), (-2.548768, -3.8417754), (-1.788402, -4.7767196), (-2.365348, -3.937384), (-3.1096344, -2.941417), (-2.7427752, -3.5570488), (-2.124313, -4.337634), (-2.1609337, -3.9182196), (-2.6578124, -3.1820304), (-2.8958595, -3.3422139), (-2.6826952, -3.727976), (-2.4211602, -3.4355075), (-2.553045, -3.0574036), (-2.910652, -3.2538393), (-2.9583395, -3.3461654), (-2.6892672, -2.8837104), (-2.646351, -2.7260978), (-2.9304216, -3.1578364), (-3.0161872, -3.1062503), (-2.7773578, -2.4200695), (-2.7263756, -2.3889182), (-2.9654346, -3.0466802), (-2.9742594, -2.8967164), (-2.7066584, -2.0238876), (-2.7135725, -2.1124246), (-2.97242, -2.955196), (-2.8831723, -2.695508), (-2.544492, -1.6687608), (-2.6187239, -1.8838412), (-2.9374447, -2.8863995), (-2.768988, -2.523574), (-2.347096, -1.3563842), (-2.4815586, -1.6881691), (-2.8798103, -2.8436468), (-2.6536012, -2.3879929), (-2.147167, -1.0697103), (-2.3295317, -1.4675528), (-2.8196316, -2.8031387), (-2.5641325, -2.3354578), (-1.9675477, -0.832063), (-2.1738448, -1.2049797), (-2.7734225, -2.7353237), (-2.5259738, -2.3384328), (-1.8278385, -0.6501565), (-2.0162656, -0.92837435), (-2.731258, -2.641645), (-2.5371702, -2.3685796), (-1.7423718, -0.5259317), (-1.876147, -0.68136877), (-2.6880546, -2.5277662), (-2.5692508, -2.3813896), (-1.7038163, -0.44962367), (-1.7640251, -0.5192881), (-2.6312714, -2.4391737), (-2.5903754, -2.351919), (-1.699949, -0.37301078), (-1.6992391, -0.39917675), (-2.5782835, -2.3781013), (-2.5862656, -2.3582866), (-1.6928846, -0.34544823), (-1.6551309, -0.31493658), (-2.5356426, -2.3067894), (-2.5768037, -2.3413572), (-1.6873486, -0.34354904), (-1.6204079, -0.2852731), (-2.4907498, -2.2680376), (-2.5492542, -2.3316467), (-1.6719595, -0.35642502), (-1.5975455, -0.28903246), (-2.4566212, -2.2597563), (-2.4860623, -2.2593453), (-1.5659401, -0.17986222), (-1.5537207, -0.20312631), (-2.5163393, -2.370887), (-2.5203538, -2.3311472), (-1.5276643, -0.08376594), (-1.4946158, -0.102829225), (-2.482157, -2.3943777), (-2.5152304, -2.4042592), (-1.5300357, -0.11301948), (-1.4874511, -0.10841716), (-2.4548275, -2.4186602), (-2.490453, -2.4459639), (-1.5227746, -0.16092466), (-1.4858027, -0.15887547), (-2.4506757, -2.4733522), (-2.4928656, -2.5146856), (-1.5406609, -0.26300696), (-1.5086651, -0.28071845), (-2.4581482, -2.5833728), (-2.5012038, -2.6364245), (-1.5852323, -0.40806544), (-1.5659186, -0.41263407), (-2.485561, -2.6803722), (-2.5080984, -2.7322512), (-1.6032085, -0.5418074), (-1.5963418, -0.5220899), (-2.5086303, -2.7076979), (-2.5202608, -2.7738369), (-1.6123781, -0.6827055), (-1.6111017, -0.68455136), (-2.5344121, -2.8080013), (-2.576348, -2.8926258), (-1.6828704, -0.879963), (-1.6427356, -0.8407386), (-2.5286415, -2.8560078), (-2.606008, -2.9842238), (-1.7641001, -1.0900685), (-1.6771377, -0.98524207), (-2.4916897, -2.8551755), (-2.5779, -2.9797084), (-1.787498, -1.1677326), (-1.7051061, -1.0762317), (-2.4820073, -2.8934283), (-2.5577297, -2.9951687), (-1.7913681, -1.2077205), (-1.7245793, -1.1334593), (-2.4891343, -2.9331636), (-2.5509214, -3.0131528), (-1.7914808, -1.2287211), (-1.740874, -1.1688802), (-2.5064478, -2.9649878), (-2.5616376, -3.0268095), (-1.8016019, -1.23485), (-1.754736, -1.1837945), (-2.522045, -2.9846628), (-2.5744667, -3.0375085), (-1.8143443, -1.236933), (-1.7720888, -1.1877587), (-2.5414915, -2.991611), (-2.5906272, -3.0399444), (-1.8284007, -1.233893), (-1.7886274, -1.185184), (-2.5601876, -2.9907835), (-2.6069674, -3.0360916), (-1.8414775, -1.225826), (-1.8019689, -1.1771984), (-2.5752099, -2.9846227), (-2.6204917, -3.0282156), (-1.8514147, -1.2143196), (-1.8107431, -1.1651629), (-2.5852113, -2.974463), (-2.6297228, -3.01756), (-1.8572036, -1.2006493), (-1.8146169, -1.1503662), (-2.5901175, -2.9613311), (-2.6345744, -3.0048003), (-1.8590047, -1.1854548), (-1.8141975, -1.1336269), (-2.590746, -2.9459825), (-2.6358333, -2.9903784), (-1.857693, -1.1688603), (-1.8106357, -1.1151545), (-2.5883594, -2.9289339), (-2.6346314, -2.9747682), (-1.8543627, -1.1515474), (-1.805127, -1.095756), (-2.584241, -2.910541), (-2.6322072, -2.958023), (-1.8501143, -1.1334832), (-1.7987107, -1.0756077), (-2.5793445, -2.89131), (-2.629355, -2.94065), (-1.8456464, -1.1150372), (-1.7920502, -1.0550828), (-2.5742326, -2.8716946), (-2.6264422, -2.9228587), (-1.8412707, -1.0963478), (-1.7855501, -1.0347831), (-2.5692227, -2.8524988), (-2.6235487, -2.905414), (-1.8368821, -1.0777835), (-1.7791526, -1.0148151), (-2.564329, -2.834205), (-2.6206114, -2.8890808), (-1.83242, -1.0603094), (-1.7727605, -0.995985), (-2.5593894, -2.8171449), (-2.617524, -2.8741162), (-1.8278533, -1.0444142), (-1.7663099, -0.97884494), (-2.5542526, -2.8017092), (-2.6141627, -2.860809), (-1.8231834, -1.0304277), (-1.7598425, -0.9637398), (-2.5488942, -2.7881584), (-2.610484, -2.8493545), (-1.8184557, -1.018561), (-1.7534782, -0.95088524), (-2.5434196, -2.7766395), (-2.6065688, -2.839826), (-1.8137887, -1.0088763), (-1.747396, -0.94035745), (-2.5380177, -2.7672026), (-2.6025746, -2.8322175), (-1.8093274, -1.0013435), (-1.7417697, -0.93214), (-2.5328896, -2.7598286), (-2.5986826, -2.826458), (-1.8052278, -0.9958415), (-1.7367722, -0.92612094), (-2.5282347, -2.7544324), (-2.595073, -2.822443), (-1.8016217, -0.99222004), (-1.7325177, -0.9221477), (-2.5241828, -2.75089), (-2.5918748, -2.8200438), (-1.798597, -0.9903142), (-1.7290654, -0.92003936), (-2.5208018, -2.7490413), (-2.5891519, -2.8191078), (-1.7961866, -0.98994595), (-1.726426, -0.91960377), (-2.518113, -2.7487128), (-2.5869272, -2.8194723), (-1.7943691, -0.99092615), (-1.7245463, -0.92063475), (-2.5160785, -2.7497234), (-2.5851803, -2.8209734), (-1.7931138, -0.9930695), (-1.7233733, -0.922926), (-2.514649, -2.7518735), (-2.5838687, -2.8234272), (-1.7923481, -0.9961839), (-1.7228155, -0.9262691), (-2.5137627, -2.7549715), (-2.5829544, -2.8266501), (-1.7920135, -1.0000587), (-1.7227962, -0.9304433), (-2.5133595, -2.7588181), (-2.5823958, -2.8304634), (-1.7920531, -1.0044996), (-1.7232305, -0.93523186), (-2.513368, -2.763214), (-2.5821476, -2.834692), (-1.7924118, -1.0093201), (-1.7240567, -0.94042724), (-2.51375, -2.7679644), (-2.5821912, -2.839157), (-1.7930483, -1.014328), (-1.7252018, -0.9458312), (-2.5144439, -2.7728956), (-2.5824857, -2.8437092), (-1.7939104, -1.0193657), (-1.7266016, -0.9512704), (-2.5154018, -2.7778456), (-2.582994, -2.8482046), (-1.7949501, -1.0242851), (-1.7281973, -0.9565893), (-2.516576, -2.782677), (-2.5836923, -2.852527), (-1.796127, -1.0289611), (-1.729919, -0.9616511), (-2.517908, -2.7872705), (-2.5845401, -2.8565822), (-1.7973921, -1.0332986), (-1.731702, -0.9663485), (-2.519335, -2.7915275), (-2.585488, -2.8602898), (-1.7987031, -1.0372224), (-1.7334994, -0.97060055), (-2.52081, -2.7953742), (-2.586496, -2.863596), (-1.8000056, -1.0406822), (-1.7352451, -0.97435564), (-2.5222855, -2.798766), (-2.5875335, -2.8664613), (-1.8012706, -1.0436375), (-1.7369022, -0.97756565), (-2.523715, -2.8016613), (-2.5885603, -2.8688664), (-1.8024684, -1.0460777), (-1.7384387, -0.98021835), (-2.5250688, -2.8040493), (-2.5895503, -2.8708045), (-1.8035641, -1.0480034), (-1.7398162, -0.98231745), (-2.5263143, -2.8059335), (-2.5904865, -2.8722837), (-1.8045547, -1.0494225), (-1.7410257, -0.98386467), (-2.5274274, -2.807318), (-2.5913358, -2.8733222), (-1.8054163, -1.0503721), (-1.7420619, -0.9849025), (-2.5284073, -2.8082333), (-2.592097, -2.8739436), (-1.8061457, -1.0508769), (-1.7429059, -0.9854643), (-2.5292306, -2.8087215), (-2.5927565, -2.8741908), (-1.8067387, -1.0509821), (-1.7435694, -0.9855906), (-2.5299084, -2.8088162), (-2.5933142, -2.8741035), (-1.8071952, -1.0507356), (-1.7440494, -0.98533386), (-2.5304363, -2.8085678), (-2.5937712, -2.8737254), (-1.807524, -1.0501902), (-1.7443621, -0.98475325), (-2.530822, -2.8080256), (-2.5941248, -2.873104), (-1.8077345, -1.0493977), (-1.7445207, -0.98390615), (-2.5310657, -2.8072467), (-2.5943744, -2.872292), (-1.8078369, -1.0484155), (-1.7445414, -0.9828469), (-2.5311794, -2.806273), (-2.5945277, -2.8713307), (-1.8078415, -1.0472964), (-1.7444448, -0.9816379), (-2.5311856, -2.8051624), (-2.594595, -2.8702643), (-1.8077499, -1.0460821), (-1.7442331, -0.9803298), (-2.531093, -2.803968), (-2.5945888, -2.8691406), (-1.8075885, -1.0448176), (-1.7439387, -0.9789643), (-2.5309122, -2.802728), (-2.5945122, -2.8680012), (-1.807369, -1.0435525), (-1.7435824, -0.9775942), (-2.5306652, -2.801481), (-2.5943768, -2.8668702), (-1.8071015, -1.0423144), (-1.7431755, -0.97625417), (-2.530363, -2.800264), (-2.5941975, -2.8657832), (-1.8068032, -1.0411397), (-1.7427374, -0.9749801), (-2.5300248, -2.799105), (-2.5939834, -2.8647592), (-1.8064833, -1.0400442), (-1.7422844, -0.9737936), (-2.5296607, -2.7980304), (-2.593744, -2.8638253), (-1.806156, -1.0390555), (-1.7418364, -0.97271734), (-2.5292935, -2.7970548), (-2.5934918, -2.8629878), (-1.8058298, -1.038182), (-1.7413981, -0.971771), (-2.5289235, -2.796198), (-2.5932336, -2.8622622), (-1.8055128, -1.0374342), (-1.7409807, -0.97095835), (-2.5285602, -2.7954643), (-2.5929737, -2.8616538), (-1.8052175, -1.036817), (-1.7405996, -0.9702856), (-2.5282187, -2.7948573), (-2.5927196, -2.8611627), (-1.804935, -1.036332), (-1.7402496, -0.96975917), (-2.527908, -2.7943838), (-2.5924857, -2.8607848), (-1.8046808, -1.0359666), (-1.7399429, -0.9693652), (-2.5276322, -2.7940347), (-2.5922737, -2.8605218), (-1.804462, -1.0357223), (-1.7396795, -0.9690994), (-2.5273843, -2.7938027), (-2.5920844, -2.8603647), (-1.8042798, -1.0355933), (-1.7394627, -0.9689555), (-2.5271695, -2.793679), (-2.591915, -2.8603027), (-1.8041341, -1.0355668), (-1.739301, -0.96892035), (-2.527, -2.79365), (-2.591772, -2.8603232), (-1.804017, -1.0356303), (-1.739179, -0.9689849), (-2.526865, -2.7937102), (-2.5916524, -2.8604164), (-1.8039308, -1.035767), (-1.7391008, -0.9691321), (-2.5267699, -2.7938473), (-2.5915627, -2.8605697), (-1.8038723, -1.035963), (-1.7390574, -0.9693467), (-2.5267088, -2.7940466), (-2.5914986, -2.8607748), (-1.8038449, -1.0362083), (-1.7390509, -0.96961), (-2.526681, -2.79429), (-2.591467, -2.8610172), (-1.8038491, -1.0364891), (-1.7390736, -0.96991277), (-2.526675, -2.7945704), (-2.5914454, -2.861287), (-1.8038689, -1.0367951), (-1.7391257, -0.97024167), (-2.5266993, -2.7948701), (-2.5914476, -2.8615696), (-1.8039083, -1.0371135), (-1.7391995, -0.9705852), (-2.5267482, -2.7951822), (-2.591471, -2.861857), (-1.8039671, -1.0374324), (-1.7392896, -0.9709299), (-2.526806, -2.7954962), (-2.5915048, -2.8621433), (-1.8040409, -1.0377452), (-1.7393957, -0.9712649), (-2.5268786, -2.7957995), (-2.5915449, -2.8624175), (-1.8041114, -1.0380455), (-1.7395034, -0.97159106), (-2.5269663, -2.7960927), (-2.591599, -2.8626723), (-1.8041885, -1.0383204), (-1.7396172, -0.9718931), (-2.5270607, -2.7963667), (-2.591662, -2.8629084), (-1.804269, -1.0385671), (-1.7397286, -0.9721631), (-2.527154, -2.7966158), (-2.5917246, -2.863122), (-1.8043537, -1.0387862), (-1.7398406, -0.97239953), (-2.5272462, -2.7968307), (-2.5917892, -2.8633065), (-1.8044295, -1.0389774), (-1.7399421, -0.9726055), (-2.527338, -2.7970161), (-2.5918562, -2.8634596), (-1.8045068, -1.0391327), (-1.740041, -0.97277623), (-2.5274239, -2.7971704), (-2.591918, -2.8635852), (-1.8045771, -1.0392569), (-1.7401303, -0.9729079), (-2.527504, -2.7972872), (-2.591979, -2.8636794), (-1.8046415, -1.0393497), (-1.7402065, -0.97300965), (-2.527574, -2.7973769), (-2.5920348, -2.8637455), (-1.8046974, -1.0394112), (-1.7402712, -0.9730778), (-2.5276349, -2.797437), (-2.5920813, -2.8637848), (-1.8047435, -1.0394429), (-1.7403251, -0.97311515), (-2.5276885, -2.7974708), (-2.5921304, -2.8638031), (-1.8047893, -1.0394485), (-1.7403694, -0.97311854), (-2.527727, -2.797474), (-2.5921595, -2.8638017), (-1.8048196, -1.0394411), (-1.7404044, -0.97310555), (-2.5277593, -2.7974555), (-2.592187, -2.8637757), (-1.8048391, -1.0394084), (-1.7404206, -0.9730705), (-2.5277824, -2.797421), (-2.5922089, -2.8637357), (-1.8048505, -1.0393585), (-1.7404308, -0.9730189), (-2.5277994, -2.7973733), (-2.5922258, -2.8636835), (-1.8048593, -1.0392946), (-1.7404351, -0.9729523), (-2.5278091, -2.7973123), (-2.592236, -2.863621), (-1.8048571, -1.039222), (-1.7404261, -0.97287583), (-2.5278113, -2.7972436), (-2.5922456, -2.8635552), (-1.8048537, -1.039145), (-1.7404139, -0.9727917), (-2.5278063, -2.7971683), (-2.592242, -2.8634858), (-1.8048407, -1.039065), (-1.7403964, -0.9727052), (-2.5277941, -2.7970896), (-2.5922358, -2.863412), (-1.8048288, -1.0389853), (-1.7403756, -0.9726193), (-2.5277815, -2.79701), (-2.5922291, -2.863339), (-1.8048066, -1.0389053), (-1.7403431, -0.97253495), (-2.5277605, -2.796936), (-2.5922174, -2.8632717), (-1.8047888, -1.0388288), (-1.7403193, -0.9724517), (-2.5277395, -2.7968616), (-2.592203, -2.8632066), (-1.8047704, -1.0387596), (-1.740292, -0.97237605), (-2.5277164, -2.796791), (-2.5921855, -2.8631463), (-1.8047475, -1.0386988), (-1.7402651, -0.9723089), (-2.527695, -2.7967277), (-2.592172, -2.8630915), (-1.8047314, -1.0386416), (-1.7402397, -0.97224706), (-2.5276709, -2.7966728), (-2.5921519, -2.8630455), (-1.8047069, -1.0385956), (-1.7402107, -0.97219867), (-2.5276465, -2.7966287), (-2.5921352, -2.8630068), (-1.8046869, -1.038554), (-1.7401863, -0.97215307), (-2.5276284, -2.7965887), (-2.5921228, -2.862975), (-1.8046675, -1.0385215), (-1.7401605, -0.9721185), (-2.527607, -2.79656), (-2.5921097, -2.8629513), (-1.8046572, -1.0384958), (-1.7401435, -0.9720902), (-2.527585, -2.796535), (-2.5920897, -2.8629367), (-1.8046418, -1.0384862), (-1.7401295, -0.9720743), (-2.5275698, -2.7965171), (-2.5920784, -2.862925), (-1.8046302, -1.0384787), (-1.740111, -0.9720662), (-2.5275557, -2.7965083), (-2.5920722, -2.8629193), (-1.8046213, -1.0384767), (-1.7400992, -0.97206515), (-2.5275462, -2.7965078), (-2.592066, -2.8629203), (-1.8046187, -1.0384786), (-1.7400948, -0.9720668), (-2.5275362, -2.7965107), (-2.5920548, -2.862927), (-1.8046099, -1.0384884), (-1.7400868, -0.97207737), (-2.527527, -2.7965202), (-2.5920491, -2.8629377), (-1.804608, -1.0385015), (-1.7400854, -0.97209007), (-2.5275252, -2.796531), (-2.5920436, -2.8629491), (-1.804603, -1.0385172), (-1.7400852, -0.9721089), (-2.5275242, -2.7965496), (-2.592039, -2.8629646), (-1.8045981, -1.0385321), (-1.7400848, -0.9721277), (-2.527528, -2.7965693), (-2.5920448, -2.8629816), (-1.8046051, -1.038549), (-1.7400887, -0.97214484), (-2.527524, -2.796586), (-2.5920396, -2.8630028), (-1.804608, -1.0385741), (-1.740096, -0.9721678), (-2.5275285, -2.7966037), (-2.5920403, -2.8630183), (-1.8046091, -1.0385942), (-1.7401028, -0.9721922), (-2.5275393, -2.7966247), (-2.5920453, -2.8630335), (-1.8046103, -1.0386106), (-1.7401062, -0.9722141), (-2.5275414, -2.7966483), (-2.5920484, -2.8630533), (-1.8046199, -1.0386279), (-1.7401159, -0.97223055), (-2.5275428, -2.7966635), (-2.5920482, -2.8630712), (-1.8046242, -1.0386504), (-1.7401226, -0.97225285), (-2.5275493, -2.7966802), (-2.5920508, -2.8630838), (-1.804625, -1.0386648), (-1.7401284, -0.9722719), (-2.527558, -2.7966993), (-2.5920584, -2.8630981), (-1.8046322, -1.0386772), (-1.7401358, -0.9722856), (-2.5275652, -2.7967124), (-2.592062, -2.8631096), (-1.8046346, -1.0386893), (-1.7401443, -0.9722993), (-2.5275738, -2.7967267), (-2.5920653, -2.8631196), (-1.8046386, -1.0386974), (-1.7401495, -0.9723111), (-2.5275776, -2.7967377), (-2.592068, -2.8631282), (-1.8046432, -1.0387049), (-1.7401558, -0.9723164), (-2.5275831, -2.7967417), (-2.5920742, -2.8631322), (-1.804647, -1.0387102), (-1.7401549, -0.9723246), (-2.527583, -2.7967508), (-2.5920799, -2.8631399), (-1.8046569, -1.0387156), (-1.7401626, -0.97232676), (-2.5275874, -2.7967508), (-2.5920823, -2.863142), (-1.8046582, -1.0387204), (-1.7401636, -0.97233063), (-2.5275881, -2.796754), (-2.5920844, -2.8631442), (-1.8046619, -1.0387213), (-1.7401677, -0.97233045), (-2.5275934, -2.7967527), (-2.592087, -2.863143), (-1.8046612, -1.03872), (-1.7401696, -0.97233003), (-2.5275974, -2.7967525), (-2.5920925, -2.8631408), (-1.8046665, -1.0387158), (-1.7401687, -0.9723251), (-2.5275934, -2.7967486), (-2.5920901, -2.8631403), (-1.8046676, -1.0387163), (-1.7401725, -0.972323), (-2.527596, -2.7967448), (-2.5920935, -2.863136), (-1.8046718, -1.0387121), (-1.7401738, -0.97231764), (-2.5275922, -2.796739), (-2.5920863, -2.8631334), (-1.8046671, -1.0387119), (-1.7401762, -0.9723169), (-2.5275993, -2.7967355), (-2.5920877, -2.8631248), (-1.8046633, -1.0387028), (-1.7401757, -0.9723135), (-2.5276017, -2.7967348), (-2.5920885, -2.8631194), (-1.8046594, -1.0386933), (-1.7401712, -0.9723064), (-2.5276022, -2.7967324), (-2.5920932, -2.8631177), (-1.8046587, -1.0386873), (-1.7401643, -0.9722991), (-2.5275981, -2.7967286), (-2.592092, -2.863115), (-1.8046597, -1.0386817), (-1.7401676, -0.9722908), (-2.5275996, -2.796721), (-2.5920908, -2.8631103), (-1.8046564, -1.0386782), (-1.7401632, -0.97228754), (-2.527599, -2.7967176), (-2.592094, -2.863105), (-1.8046579, -1.0386719), (-1.740162, -0.9722804), (-2.5275955, -2.7967114), (-2.592088, -2.863102), (-1.8046539, -1.0386711), (-1.7401605, -0.9722795), (-2.5275948, -2.7967079), (-2.592091, -2.863098), (-1.8046551, -1.0386662), (-1.7401572, -0.97227454), (-2.527592, -2.7967052), (-2.5920892, -2.8630955), (-1.8046544, -1.0386629), (-1.7401533, -0.9722694), (-2.5275857, -2.7967012), (-2.59209, -2.8630958), (-1.8046602, -1.0386628), (-1.7401558, -0.97226447), (-2.5275831, -2.7966943), (-2.5920854, -2.8630936), (-1.8046566, -1.0386658), (-1.7401538, -0.9722663), (-2.5275812, -2.796692), (-2.592083, -2.863089), (-1.8046561, -1.0386627), (-1.7401552, -0.972267), (-2.5275826, -2.7966936), (-2.592083, -2.8630872), (-1.8046547, -1.0386583), (-1.7401541, -0.97226286), (-2.5275834, -2.7966912), (-2.592084, -2.8630881), (-1.8046503, -1.0386609), (-1.7401466, -0.97226447), (-2.5275793, -2.796693), (-2.5920835, -2.8630886), (-1.8046552, -1.0386587), (-1.7401538, -0.97226197), (-2.5275784, -2.7966897), (-2.592077, -2.8630867), (-1.8046516, -1.0386603), (-1.7401521, -0.97226477), (-2.527579, -2.7966921), (-2.5920782, -2.8630872), (-1.8046513, -1.0386599), (-1.7401524, -0.9722649), (-2.527579, -2.7966921), (-2.5920787, -2.8630881), (-1.8046505, -1.0386611), (-1.74015, -0.9722662), (-2.5275786, -2.7966938), (-2.59208, -2.8630893), (-1.8046511, -1.0386622), (-1.7401495, -0.9722654), (-2.5275788, -2.7966924), (-2.5920804, -2.8630886), (-1.8046519, -1.0386626), (-1.7401506, -0.9722666), (-2.5275776, -2.796694), (-2.592078, -2.8630903), (-1.8046517, -1.0386637), (-1.7401513, -0.9722685), (-2.527579, -2.7966945), (-2.5920792, -2.8630908), (-1.8046502, -1.0386652), (-1.7401518, -0.97227067), (-2.5275817, -2.7966974), (-2.5920775, -2.8630927), (-1.8046465, -1.0386665), (-1.7401516, -0.97227323), (-2.5275846, -2.7967012), (-2.5920823, -2.8630936), (-1.804651, -1.0386648), (-1.7401519, -0.9722724), (-2.5275812, -2.7967021), (-2.592079, -2.863097), (-1.8046501, -1.0386695), (-1.7401531, -0.97227573), (-2.527582, -2.7967029), (-2.5920782, -2.8630965), (-1.8046528, -1.0386697), (-1.7401578, -0.9722749), (-2.5275815, -2.796701), (-2.5920746, -2.8630967), (-1.8046477, -1.0386727), (-1.7401527, -0.97227895), (-2.5275826, -2.796704), (-2.592082, -2.8630962), (-1.804653, -1.0386695), (-1.7401525, -0.9722772), (-2.5275786, -2.7967045), (-2.5920794, -2.8631), (-1.8046554, -1.0386745), (-1.7401552, -0.9722776), (-2.5275784, -2.7967017), (-2.592079, -2.8630986), (-1.804657, -1.038677), (-1.7401575, -0.9722815), (-2.527581, -2.7967026), (-2.5920804, -2.8630974), (-1.8046571, -1.0386757), (-1.740157, -0.9722809), (-2.5275795, -2.796704), (-2.5920775, -2.8630996), (-1.8046542, -1.0386771), (-1.7401584, -0.97228247), (-2.5275834, -2.7967052), (-2.5920775, -2.863098), (-1.8046508, -1.0386747), (-1.7401584, -0.97228265), (-2.5275867, -2.7967074), (-2.5920796, -2.8630989), (-1.8046511, -1.0386729), (-1.7401569, -0.9722815), (-2.5275855, -2.7967083), (-2.5920804, -2.8631008), (-1.8046494, -1.0386747), (-1.7401541, -0.9722825), (-2.5275862, -2.7967083), (-2.5920827, -2.8630996), (-1.8046516, -1.0386721), (-1.740155, -0.97227955), (-2.527587, -2.7967074), (-2.592084, -2.8631), (-1.8046533, -1.0386719), (-1.7401569, -0.9722784), (-2.5275855, -2.7967064), (-2.5920815, -2.8631), (-1.8046533, -1.038674), (-1.7401557, -0.97228086), (-2.5275853, -2.7967057), (-2.5920823, -2.8630996), (-1.8046523, -1.038674), (-1.7401552, -0.9722801), (-2.5275853, -2.7967055), (-2.592083, -2.8630993), (-1.8046533, -1.0386742), (-1.7401557, -0.97228026), (-2.5275853, -2.7967052), (-2.5920856, -2.863099), (-1.8046578, -1.0386726), (-1.7401547, -0.9722773), (-2.5275795, -2.796704), (-2.5920815, -2.8631012), (-1.8046572, -1.038675), (-1.740157, -0.97227645), (-2.5275812, -2.7967021), (-2.5920777, -2.8630998), (-1.804651, -1.0386766), (-1.7401576, -0.97228205), (-2.5275874, -2.7967052), (-2.5920804, -2.8630962), (-1.8046514, -1.0386701), (-1.7401571, -0.9722797), (-2.5275862, -2.796707), (-2.5920825, -2.8630981), (-1.8046534, -1.0386698), (-1.7401558, -0.97227687), (-2.5275822, -2.7967048), (-2.5920804, -2.8630989), (-1.8046556, -1.0386729), (-1.7401572, -0.972278), (-2.5275815, -2.7967021), (-2.5920775, -2.8630972), (-1.8046538, -1.0386745), (-1.7401611, -0.9722793), (-2.527588, -2.7967017), (-2.5920806, -2.8630955), (-1.8046501, -1.0386711), (-1.7401551, -0.97227764), (-2.5275843, -2.796704), (-2.5920823, -2.863097), (-1.804653, -1.0386695), (-1.7401513, -0.9722763), (-2.5275798, -2.7967033), (-2.5920813, -2.863098), (-1.8046559, -1.038672), (-1.7401565, -0.97227615), (-2.5275846, -2.7967005), (-2.5920851, -2.863096), (-1.8046558, -1.0386716), (-1.7401537, -0.97227603), (-2.527582, -2.7967014), (-2.5920844, -2.8630984), (-1.8046567, -1.0386729), (-1.7401532, -0.972276), (-2.5275772, -2.796702), (-2.5920784, -2.863099), (-1.8046572, -1.0386741), (-1.7401586, -0.97227615), (-2.5275793, -2.7966993), (-2.592077, -2.863096), (-1.8046565, -1.038674), (-1.7401608, -0.9722794), (-2.527585, -2.7967017), (-2.5920794, -2.863095), (-1.8046526, -1.0386717), (-1.7401571, -0.97227883), (-2.5275846, -2.7967033), (-2.5920815, -2.863096), (-1.8046515, -1.0386701), (-1.7401537, -0.9722777), (-2.5275848, -2.7967045), (-2.592083, -2.863098), (-1.8046515, -1.0386703), (-1.7401531, -0.97227585), (-2.5275836, -2.7967038), (-2.592083, -2.8630993), (-1.8046539, -1.0386726), (-1.7401525, -0.97227556), (-2.5275784, -2.7967014), (-2.5920784, -2.863099), (-1.8046552, -1.0386742), (-1.7401603, -0.9722768), (-2.5275853, -2.7966993), (-2.592078, -2.8630943), (-1.8046501, -1.0386722), (-1.7401565, -0.97227937), (-2.5275848, -2.7967036), (-2.5920792, -2.8630955), (-1.8046517, -1.0386704), (-1.740157, -0.972279), (-2.527584, -2.7967045), (-2.5920806, -2.8630958), (-1.8046528, -1.0386695), (-1.7401527, -0.97227746), (-2.5275815, -2.7967045), (-2.5920815, -2.8630989), (-1.8046538, -1.0386716), (-1.7401547, -0.9722755), (-2.5275817, -2.7967021), (-2.5920813, -2.8630981), (-1.8046551, -1.0386727), (-1.7401555, -0.97227716), (-2.5275824, -2.7967014), (-2.5920825, -2.8630955), (-1.8046553, -1.0386707), (-1.7401553, -0.97227705), (-2.5275822, -2.7967026), (-2.5920827, -2.8630981), (-1.8046571, -1.0386733), (-1.7401549, -0.9722759), (-2.5275784, -2.7967), (-2.5920806, -2.8630984), (-1.8046567, -1.0386751), (-1.7401565, -0.9722774), (-2.5275812, -2.7966993), (-2.5920806, -2.8630962), (-1.8046534, -1.0386745), (-1.7401553, -0.9722801), (-2.5275846, -2.7967033), (-2.5920813, -2.8630953), (-1.8046513, -1.0386693), (-1.7401544, -0.97227806), (-2.5275834, -2.7967055), (-2.5920794, -2.863098), (-1.8046523, -1.0386708), (-1.7401568, -0.9722769), (-2.5275846, -2.7967033), (-2.5920808, -2.8630984), (-1.8046527, -1.0386723), (-1.7401541, -0.97227675), (-2.5275817, -2.796703), (-2.5920835, -2.8630998), (-1.8046558, -1.0386739), (-1.7401525, -0.97227645), (-2.527578, -2.7967014), (-2.5920806, -2.8630996), (-1.8046582, -1.0386755), (-1.7401582, -0.9722775), (-2.5275803, -2.7966995), (-2.5920784, -2.8630955), (-1.8046547, -1.0386739), (-1.7401577, -0.9722794), (-2.5275817, -2.796702), (-2.5920763, -2.8630965), (-1.8046526, -1.038674), (-1.7401594, -0.97227955), (-2.5275874, -2.796702), (-2.5920832, -2.8630955), (-1.8046522, -1.0386711), (-1.7401526, -0.9722773), (-2.5275803, -2.7967038), (-2.5920794, -2.8630993), (-1.8046534, -1.0386738), (-1.740158, -0.9722786), (-2.5275857, -2.796702), (-2.5920804, -2.863094), (-1.8046497, -1.0386709), (-1.7401539, -0.9722802), (-2.5275843, -2.7967055), (-2.5920832, -2.8630974), (-1.8046541, -1.0386707), (-1.7401531, -0.9722776), (-2.5275822, -2.7967038), (-2.592084, -2.863098), (-1.8046565, -1.0386716), (-1.7401539, -0.97227573), (-2.5275788, -2.796702), (-2.5920806, -2.8630989), (-1.8046571, -1.0386746), (-1.7401576, -0.9722773), (-2.527582, -2.7966995), (-2.5920796, -2.8630953), (-1.8046542, -1.0386732), (-1.7401592, -0.97227985), (-2.527586, -2.7967026), (-2.5920804, -2.8630955), (-1.8046505, -1.038671), (-1.7401547, -0.97227794), (-2.527584, -2.7967036), (-2.592081, -2.8630974), (-1.8046533, -1.0386726), (-1.7401537, -0.9722784), (-2.5275793, -2.7967033), (-2.5920787, -2.8630977), (-1.8046536, -1.0386729), (-1.7401547, -0.9722787), (-2.5275822, -2.7967029), (-2.592083, -2.8630962), (-1.8046551, -1.0386715), (-1.7401549, -0.9722783), (-2.5275812, -2.7967036), (-2.59208, -2.863098), (-1.8046553, -1.0386724), (-1.7401574, -0.9722769), (-2.527583, -2.796702), (-2.5920808, -2.8630972), (-1.8046534, -1.0386724), (-1.7401543, -0.97227836), (-2.5275831, -2.7967043), (-2.5920815, -2.8630986), (-1.8046535, -1.0386719), (-1.7401559, -0.9722766), (-2.527584, -2.7967029), (-2.5920837, -2.8630977), (-1.8046542, -1.0386716), (-1.7401531, -0.97227734), (-2.5275838, -2.7967033), (-2.5920854, -2.863097), (-1.8046536, -1.0386705), (-1.7401514, -0.9722762), (-2.52758, -2.796704), (-2.5920806, -2.8631005), (-1.8046556, -1.0386736), (-1.7401589, -0.9722771), (-2.5275857, -2.7967014), (-2.5920818, -2.8630958), (-1.8046532, -1.0386715), (-1.7401552, -0.9722778), (-2.527582, -2.7967036), (-2.5920796, -2.8630981), (-1.8046547, -1.0386727), (-1.7401575, -0.97227705), (-2.5275826, -2.796702), (-2.5920792, -2.8630972), (-1.804651, -1.0386729), (-1.7401547, -0.97227937), (-2.5275853, -2.7967043), (-2.5920846, -2.8630965), (-1.8046561, -1.0386701), (-1.740155, -0.9722764), (-2.52758, -2.7967036), (-2.5920777, -2.8630996), (-1.8046515, -1.038674), (-1.740155, -0.9722778), (-2.527582, -2.796702), (-2.5920796, -2.863098), (-1.8046548, -1.0386735), (-1.7401586, -0.97227746), (-2.5275838, -2.7967002), (-2.592078, -2.8630953), (-1.8046536, -1.0386733), (-1.7401618, -0.9722798), (-2.5275872, -2.7967024), (-2.5920777, -2.8630943), (-1.8046468, -1.0386705), (-1.7401539, -0.9722806), (-2.527586, -2.7967067), (-2.5920818, -2.8630962), (-1.8046511, -1.0386684), (-1.7401549, -0.9722765), (-2.5275857, -2.7967043), (-2.592082, -2.863098), (-1.804652, -1.0386711), (-1.7401541, -0.97227687), (-2.527582, -2.7967033), (-2.592082, -2.8630981), (-1.804656, -1.0386723), (-1.7401558, -0.9722769), (-2.5275805, -2.796702), (-2.5920799, -2.863098), (-1.8046557, -1.038674), (-1.7401555, -0.97227705), (-2.52758, -2.7967), (-2.5920813, -2.8630972), (-1.8046558, -1.0386748), (-1.7401556, -0.9722782), (-2.5275803, -2.796701), (-2.5920787, -2.8630967), (-1.8046541, -1.0386741), (-1.7401586, -0.9722805), (-2.5275862, -2.7967038), (-2.5920837, -2.8630953), (-1.8046563, -1.0386689), (-1.7401553, -0.972276), (-2.5275795, -2.796704), (-2.5920775, -2.8631003), (-1.8046534, -1.0386747), (-1.7401596, -0.97227955), (-2.5275857, -2.796703), (-2.5920792, -2.8630953), (-1.8046484, -1.0386713), (-1.7401522, -0.97227967), (-2.5275855, -2.7967052), (-2.5920863, -2.8630962), (-1.804653, -1.0386678), (-1.7401501, -0.97227615), (-2.5275822, -2.7967055), (-2.592083, -2.8630993), (-1.8046538, -1.038671), (-1.7401532, -0.9722755), (-2.527581, -2.7967024), (-2.5920813, -2.8630989), (-1.8046552, -1.0386738), (-1.7401565, -0.9722773), (-2.5275817, -2.7967005), (-2.5920799, -2.8630955), (-1.8046553, -1.038673), (-1.7401596, -0.9722795), (-2.5275853, -2.7967024), (-2.5920784, -2.8630939), (-1.8046491, -1.0386707), (-1.7401543, -0.97228104), (-2.527585, -2.7967064), (-2.5920808, -2.8630962), (-1.8046502, -1.0386685), (-1.7401546, -0.97227734), (-2.5275855, -2.796705), (-2.592085, -2.8630972), (-1.8046545, -1.0386702), (-1.7401516, -0.97227603), (-2.5275805, -2.7967026), (-2.5920827, -2.863099), (-1.8046557, -1.038674), (-1.7401551, -0.97227734), (-2.5275812, -2.7967017), (-2.5920835, -2.8630977), (-1.8046577, -1.0386733), (-1.7401519, -0.97227764), (-2.527577, -2.796702), (-2.5920827, -2.8630989), (-1.8046579, -1.0386748), (-1.7401541, -0.9722774), (-2.52758, -2.7967012), (-2.5920846, -2.8630981), (-1.8046585, -1.038674), (-1.7401534, -0.9722772), (-2.5275779, -2.796702), (-2.5920818, -2.8630981), (-1.8046597, -1.0386744), (-1.7401562, -0.9722777), (-2.5275772, -2.7966998), (-2.59208, -2.863096), (-1.8046594, -1.0386746), (-1.7401575, -0.9722781), (-2.5275786, -2.796699), (-2.592081, -2.8630962), (-1.8046579, -1.0386755), (-1.7401541, -0.97227824), (-2.5275764, -2.7966993), (-2.5920796, -2.8630972), (-1.8046575, -1.0386764), (-1.7401565, -0.97227865), (-2.5275788, -2.7966995), (-2.592078, -2.8630962), (-1.8046556, -1.0386751), (-1.740158, -0.97227937), (-2.527583, -2.796701), (-2.5920799, -2.8630958), (-1.8046545, -1.0386733), (-1.7401588, -0.97227865), (-2.5275865, -2.796701), (-2.5920808, -2.8630946), (-1.8046498, -1.0386717), (-1.740154, -0.97227997), (-2.5275853, -2.796705), (-2.592084, -2.8630962), (-1.804654, -1.038669), (-1.7401557, -0.97227776), (-2.5275838, -2.796705), (-2.5920804, -2.8630972), (-1.804651, -1.0386698), (-1.7401536, -0.97227764), (-2.527585, -2.7967055), (-2.5920844, -2.8630984), (-1.8046525, -1.0386701), (-1.7401514, -0.9722756), (-2.527581, -2.7967043), (-2.5920806, -2.8630993), (-1.8046552, -1.0386719), (-1.7401563, -0.97227657), (-2.5275812, -2.796702), (-2.5920796, -2.863098), (-1.8046548, -1.0386733), (-1.7401567, -0.9722777), (-2.5275805, -2.7967024), (-2.5920794, -2.863098), (-1.8046558, -1.0386735), (-1.7401572, -0.97227746), (-2.5275807, -2.7967017), (-2.5920784, -2.863098), (-1.804654, -1.0386738), (-1.74016, -0.97227883), (-2.5275874, -2.7967024), (-2.5920796, -2.8630948), (-1.8046484, -1.0386717), (-1.7401549, -0.9722815), (-2.5275877, -2.7967064), (-2.592082, -2.863095), (-1.804649, -1.0386677), (-1.7401531, -0.9722793), (-2.5275836, -2.7967088), (-2.5920796, -2.8630986), (-1.8046521, -1.0386683), (-1.7401578, -0.972276), (-2.5275857, -2.7967045), (-2.5920823, -2.8630981), (-1.8046554, -1.0386707), (-1.7401571, -0.9722759), (-2.5275826, -2.7967024), (-2.5920804, -2.8630986), (-1.8046545, -1.0386735), (-1.7401562, -0.9722782), (-2.5275815, -2.7967024), (-2.5920777, -2.8630967), (-1.8046511, -1.0386722), (-1.7401562, -0.9722788), (-2.527584, -2.796704), (-2.5920813, -2.863096), (-1.8046545, -1.0386695), (-1.7401558, -0.9722768), (-2.5275836, -2.7967038), (-2.5920823, -2.8630986), (-1.8046552, -1.0386727), (-1.7401569, -0.9722774), (-2.5275831, -2.796702), (-2.5920794, -2.8630972), (-1.8046521, -1.0386735), (-1.7401583, -0.9722789), (-2.5275884, -2.7967021), (-2.5920827, -2.8630948), (-1.8046504, -1.0386703), (-1.740153, -0.9722789), (-2.5275857, -2.7967052), (-2.5920856, -2.8630974), (-1.8046516, -1.0386695), (-1.7401501, -0.97227633), (-2.5275822, -2.7967048), (-2.5920832, -2.8630996), (-1.8046534, -1.0386724), (-1.7401513, -0.97227615), (-2.5275788, -2.7967021), (-2.5920787, -2.8630989), (-1.8046534, -1.0386741), (-1.7401588, -0.97227854), (-2.527586, -2.7967021), (-2.5920792, -2.8630958), (-1.8046485, -1.0386715), (-1.7401536, -0.97227925), (-2.527585, -2.7967055), (-2.5920837, -2.8630962), (-1.8046541, -1.0386685), (-1.740154, -0.97227633), (-2.5275812, -2.796705), (-2.5920799, -2.8630993), (-1.8046541, -1.0386723), (-1.7401568, -0.97227716), (-2.5275822, -2.7967021), (-2.592078, -2.8630972), (-1.8046528, -1.0386738), (-1.7401586, -0.9722792), (-2.5275867, -2.7967017), (-2.592081, -2.8630958), (-1.8046511, -1.0386724), (-1.7401541, -0.9722789), (-2.527585, -2.7967029), (-2.5920856, -2.8630967), (-1.8046546, -1.0386711), (-1.7401525, -0.9722767), (-2.5275807, -2.7967026), (-2.5920844, -2.8630981), (-1.8046595, -1.0386732), (-1.7401558, -0.9722769), (-2.5275793, -2.796701), (-2.5920808, -2.863097), (-1.8046569, -1.0386738), (-1.7401539, -0.9722775), (-2.527576, -2.7967007), (-2.5920792, -2.863098), (-1.8046594, -1.0386748), (-1.740159, -0.9722777), (-2.5275803, -2.7966995), (-2.5920784, -2.8630955), (-1.804655, -1.0386744), (-1.7401564, -0.9722801), (-2.5275817, -2.7967021), (-2.5920806, -2.8630958), (-1.8046532, -1.0386722), (-1.7401531, -0.972278), (-2.5275803, -2.7967026), (-2.5920808, -2.8630977), (-1.8046547, -1.0386736), (-1.7401568, -0.9722779), (-2.527584, -2.7967012), (-2.5920804, -2.8630965), (-1.8046508, -1.0386729), (-1.7401527, -0.9722788), (-2.5275836, -2.7967038), (-2.592085, -2.8630962), (-1.804656, -1.0386697), (-1.7401545, -0.9722775), (-2.5275826, -2.7967045), (-2.5920818, -2.8630989), (-1.8046541, -1.038672), (-1.740156, -0.9722768), (-2.5275826, -2.796703), (-2.5920808, -2.8630977), (-1.8046525, -1.038672), (-1.7401546, -0.9722776), (-2.527585, -2.7967033), (-2.5920842, -2.8630977), (-1.804652, -1.038672), (-1.7401518, -0.9722775), (-2.527583, -2.7967043), (-2.5920827, -2.8630981), (-1.804656, -1.0386703), (-1.7401564, -0.97227556), (-2.527582, -2.7967029), (-2.5920799, -2.8630972), (-1.8046535, -1.0386707), (-1.7401559, -0.97227776), (-2.5275815, -2.796704), (-2.592078, -2.8630984), (-1.8046532, -1.0386728), (-1.7401582, -0.97227794), (-2.527584, -2.7967029), (-2.5920784, -2.8630962), (-1.8046517, -1.0386714), (-1.7401575, -0.97227913), (-2.5275838, -2.7967038), (-2.5920808, -2.8630967), (-1.8046553, -1.0386717), (-1.7401576, -0.972277), (-2.5275831, -2.7967024), (-2.5920808, -2.8630977), (-1.8046552, -1.0386734), (-1.7401569, -0.97227913), (-2.5275831, -2.7967033), (-2.5920796, -2.8630974), (-1.804652, -1.038673), (-1.7401551, -0.9722786), (-2.5275836, -2.7967026), (-2.5920808, -2.8630967), (-1.8046527, -1.0386722), (-1.7401557, -0.9722783), (-2.527582, -2.7967033), (-2.5920775, -2.8630977), (-1.8046528, -1.038674), (-1.740162, -0.97227997), (-2.5275908, -2.7967024), (-2.592081, -2.8630943), (-1.8046483, -1.0386705), (-1.740155, -0.97227997), (-2.5275884, -2.796706), (-2.5920844, -2.8630972), (-1.8046516, -1.038669), (-1.740154, -0.97227657), (-2.527584, -2.796705), (-2.5920825, -2.8630981), (-1.8046551, -1.0386707), (-1.7401568, -0.9722759), (-2.5275822, -2.7967024), (-2.592078, -2.8630984), (-1.8046514, -1.0386735), (-1.7401562, -0.9722784), (-2.5275822, -2.7967021), (-2.592076, -2.863097), (-1.804649, -1.0386747), (-1.7401559, -0.97228104), (-2.5275862, -2.7967038), (-2.5920804, -2.8630955), (-1.804649, -1.0386697), (-1.7401534, -0.9722776), (-2.5275831, -2.796705), (-2.5920796, -2.8630984), (-1.8046521, -1.0386708), (-1.7401571, -0.9722776), (-2.527585, -2.7967043), (-2.592081, -2.863096), (-1.804652, -1.0386689), (-1.7401545, -0.97227764), (-2.5275857, -2.7967055), (-2.5920846, -2.8630981), (-1.8046525, -1.0386695), (-1.7401522, -0.9722762), (-2.5275838, -2.7967052), (-2.5920866, -2.863099), (-1.804657, -1.0386697), (-1.7401545, -0.97227335), (-2.5275824, -2.796701), (-2.5920837, -2.8630986), (-1.8046559, -1.0386739), (-1.7401546, -0.97227746), (-2.5275807, -2.7967017), (-2.5920827, -2.8630972), (-1.8046572, -1.0386732), (-1.7401525, -0.97227824), (-2.5275774, -2.7967024), (-2.5920818, -2.8630996), (-1.8046578, -1.0386753), (-1.7401563, -0.9722768), (-2.5275805, -2.7966998), (-2.592081, -2.8630965), (-1.8046554, -1.0386738), (-1.7401537, -0.97227955), (-2.52758, -2.7967036), (-2.5920808, -2.863097), (-1.8046547, -1.0386721), (-1.7401558, -0.97227794), (-2.5275817, -2.7967029), (-2.59208, -2.863097), (-1.8046535, -1.038672), (-1.7401553, -0.97227734), (-2.5275831, -2.7967014), (-2.5920806, -2.8630965), (-1.8046509, -1.0386729), (-1.7401525, -0.97227854), (-2.5275838, -2.7967026), (-2.5920842, -2.8630967), (-1.8046535, -1.0386723), (-1.7401531, -0.9722781), (-2.5275812, -2.7967024), (-2.5920825, -2.863097), (-1.8046577, -1.0386729), (-1.7401583, -0.9722772), (-2.5275831, -2.796701), (-2.5920806, -2.8630965), (-1.804653, -1.0386732), (-1.740156, -0.9722775), (-2.5275843, -2.7967017), (-2.592082, -2.863097), (-1.8046558, -1.0386723), (-1.7401575, -0.97227824), (-2.5275826, -2.796703), (-2.5920804, -2.863097), (-1.8046533, -1.038672), (-1.7401551, -0.97227764), (-2.5275815, -2.7967029), (-2.5920792, -2.8630984), (-1.8046539, -1.0386733), (-1.7401567, -0.972278), (-2.527582, -2.7967024), (-2.5920792, -2.8630972), (-1.8046527, -1.0386734), (-1.740156, -0.97227794), (-2.527582, -2.7967021), (-2.5920768, -2.8630974), (-1.8046521, -1.0386738), (-1.7401578, -0.9722791), (-2.5275826, -2.7967021), (-2.5920765, -2.8630965), (-1.8046522, -1.0386735), (-1.7401615, -0.9722805), (-2.527588, -2.7967038), (-2.592077, -2.8630955), (-1.8046501, -1.0386709), (-1.740161, -0.9722792), (-2.5275905, -2.7967036), (-2.5920818, -2.8630955), (-1.8046491, -1.03867), (-1.7401547, -0.9722793), (-2.5275872, -2.7967072), (-2.5920832, -2.8630977), (-1.8046528, -1.0386677), (-1.7401575, -0.9722754), (-2.527586, -2.7967057), (-2.5920787, -2.8630972), (-1.8046485, -1.0386684), (-1.7401556, -0.972278), (-2.527587, -2.796707), (-2.592082, -2.8630972), (-1.8046489, -1.0386673), (-1.740152, -0.9722768), (-2.5275855, -2.7967076), (-2.5920832, -2.8630989), (-1.8046503, -1.0386677), (-1.7401522, -0.97227573), (-2.5275834, -2.7967067), (-2.5920827, -2.8631008), (-1.8046548, -1.0386708), (-1.7401552, -0.9722737), (-2.5275807, -2.7967017), (-2.592079, -2.8631), (-1.8046534, -1.0386751), (-1.7401571, -0.9722777), (-2.5275853, -2.7967007), (-2.5920815, -2.8630962), (-1.8046519, -1.0386729), (-1.7401534, -0.9722785), (-2.5275817, -2.7967036), (-2.5920794, -2.8630984), (-1.8046534, -1.0386729), (-1.7401571, -0.97227806), (-2.5275834, -2.7967038), (-2.5920792, -2.863098), (-1.8046533, -1.0386715), (-1.740158, -0.972277), (-2.527584, -2.7967024), (-2.5920792, -2.8630972), (-1.8046525, -1.0386735), (-1.7401617, -0.9722795), (-2.52759, -2.796702), (-2.5920792, -2.8630934), (-1.804649, -1.0386693), (-1.7401575, -0.9722804), (-2.5275896, -2.7967074), (-2.5920846, -2.863096), (-1.8046516, -1.0386664), (-1.7401538, -0.97227687), (-2.5275843, -2.7967074), (-2.5920804, -2.863099), (-1.8046511, -1.0386701), (-1.7401558, -0.9722763), (-2.5275843, -2.796704), (-2.5920787, -2.8630986), (-1.80465, -1.0386722), (-1.7401564, -0.97227734), (-2.527585, -2.7967024), (-2.5920784, -2.8630972), (-1.8046503, -1.0386734), (-1.7401571, -0.9722795), (-2.5275838, -2.7967033), (-2.5920775, -2.863096), (-1.8046508, -1.0386713), (-1.7401571, -0.9722791), (-2.527586, -2.796704), (-2.5920799, -2.8630967), (-1.8046486, -1.0386709), (-1.7401528, -0.97227746), (-2.527584, -2.7967036), (-2.5920832, -2.8630984), (-1.8046547, -1.0386724), (-1.7401545, -0.97227645), (-2.5275824, -2.7967012), (-2.5920808, -2.8630977), (-1.8046548, -1.0386728), (-1.7401586, -0.9722773), (-2.5275838, -2.7967021), (-2.5920792, -2.8630972), (-1.8046533, -1.0386721), (-1.740158, -0.9722779), (-2.5275846, -2.796703), (-2.5920818, -2.863097), (-1.8046538, -1.0386714), (-1.7401553, -0.9722773), (-2.527583, -2.7967038), (-2.592081, -2.8630986), (-1.8046546, -1.038673), (-1.740158, -0.9722771), (-2.5275848, -2.796701), (-2.5920806, -2.8630967), (-1.8046525, -1.0386733), (-1.7401545, -0.97227836), (-2.5275812, -2.796702), (-2.5920796, -2.863097), (-1.8046541, -1.0386732), (-1.7401578, -0.9722777), (-2.5275836, -2.7967021), (-2.592078, -2.8630974), (-1.804652, -1.0386739), (-1.7401586, -0.97228026), (-2.5275843, -2.796703), (-2.5920775, -2.8630943), (-1.8046523, -1.0386702), (-1.7401594, -0.9722796), (-2.527586, -2.7967045), (-2.5920792, -2.863096), (-1.8046505, -1.0386702), (-1.7401559, -0.9722782), (-2.5275846, -2.7967045), (-2.5920794, -2.8630974), (-1.8046502, -1.0386716), (-1.740155, -0.97227836), (-2.5275846, -2.7967036), (-2.592082, -2.8630972), (-1.8046548, -1.0386721), (-1.7401565, -0.9722777), (-2.5275826, -2.7967026), (-2.5920796, -2.8630984), (-1.8046532, -1.0386742), (-1.7401581, -0.9722782), (-2.5275855, -2.796701), (-2.59208, -2.8630962), (-1.8046507, -1.038674), (-1.740156, -0.9722805), (-2.527588, -2.7967036), (-2.5920832, -2.8630953), (-1.8046522, -1.0386695), (-1.7401562, -0.972278), (-2.5275838, -2.7967052), (-2.59208, -2.8630974), (-1.8046521, -1.0386709), (-1.7401545, -0.97227776), (-2.5275815, -2.7967043), (-2.592076, -2.8630981), (-1.8046502, -1.0386724), (-1.7401574, -0.9722783), (-2.5275853, -2.7967029), (-2.592082, -2.8630967), (-1.804652, -1.0386708), (-1.7401539, -0.9722777), (-2.5275836, -2.796705), (-2.5920808, -2.8630974), (-1.8046529, -1.0386701), (-1.7401572, -0.9722772), (-2.5275855, -2.796703), (-2.5920825, -2.8630967), (-1.804655, -1.0386717), (-1.7401567, -0.97227764), (-2.527583, -2.7967026), (-2.5920818, -2.8630974), (-1.8046532, -1.0386726), (-1.7401525, -0.97227746), (-2.5275826, -2.7967024), (-2.592085, -2.8630977), (-1.8046534, -1.0386722), (-1.7401496, -0.97227645), (-2.5275822, -2.7967026), (-2.5920877, -2.863099), (-1.8046589, -1.0386717), (-1.7401546, -0.9722735), (-2.5275803, -2.7967), (-2.5920806, -2.863099), (-1.8046553, -1.0386759), (-1.7401574, -0.9722776), (-2.5275817, -2.7967002), (-2.592078, -2.8630962), (-1.8046533, -1.0386738), (-1.7401553, -0.97228026), (-2.5275793, -2.7967036), (-2.592078, -2.8630974), (-1.8046553, -1.0386744), (-1.7401568, -0.97227895), (-2.527578, -2.7967012), (-2.5920765, -2.8630974), (-1.8046567, -1.0386758), (-1.7401621, -0.97227967), (-2.5275846, -2.7966998), (-2.5920746, -2.8630931), (-1.8046483, -1.0386727), (-1.74016, -0.9722836), (-2.527591, -2.796707), (-2.5920806, -2.8630927), (-1.8046486, -1.0386649), (-1.740158, -0.97227883), (-2.5275903, -2.7967088), (-2.5920813, -2.863097), (-1.8046473, -1.0386667), (-1.740156, -0.97227824), (-2.5275893, -2.7967083), (-2.5920794, -2.8630972), (-1.8046465, -1.0386673), (-1.7401556, -0.9722793), (-2.5275898, -2.7967098), (-2.5920823, -2.8630967), (-1.804647, -1.038665), (-1.7401519, -0.972277), (-2.5275853, -2.7967083), (-2.592084, -2.8630993), (-1.8046545, -1.0386695), (-1.7401549, -0.97227544), (-2.5275826, -2.796703), (-2.592083, -2.8630986), (-1.8046559, -1.0386728), (-1.7401536, -0.9722767), (-2.5275788, -2.7967012), (-2.5920827, -2.8630984), (-1.8046594, -1.0386752), (-1.7401551, -0.97227675), (-2.5275788, -2.7966988), (-2.5920818, -2.8630974), (-1.8046579, -1.0386757), (-1.7401569, -0.97227806), (-2.5275793, -2.7967005), (-2.592079, -2.8630958), (-1.8046541, -1.0386722), (-1.7401546, -0.9722781), (-2.5275803, -2.796703), (-2.592078, -2.8630974), (-1.8046521, -1.0386724), (-1.7401556, -0.9722778), (-2.5275824, -2.796702), (-2.592079, -2.8630972), (-1.8046513, -1.0386739), (-1.7401559, -0.9722791), (-2.5275855, -2.796703), (-2.592083, -2.863097), (-1.8046523, -1.0386711), (-1.7401522, -0.9722766), (-2.5275824, -2.7967033), (-2.592084, -2.8630989), (-1.8046561, -1.038672), (-1.7401549, -0.97227615), (-2.5275824, -2.796702), (-2.5920827, -2.8630972), (-1.8046533, -1.0386719), (-1.7401526, -0.9722776), (-2.5275826, -2.7967036), (-2.5920842, -2.863098), (-1.8046573, -1.038672), (-1.740157, -0.9722769), (-2.527582, -2.7967024), (-2.5920804, -2.8630974), (-1.8046547, -1.0386729), (-1.7401568, -0.9722782), (-2.5275826, -2.7967024), (-2.592081, -2.863097), (-1.8046554, -1.0386722), (-1.7401575, -0.9722782), (-2.5275822, -2.796703), (-2.592078, -2.8630974), (-1.8046527, -1.0386728), (-1.7401572, -0.9722791), (-2.5275836, -2.7967038), (-2.5920792, -2.863096), (-1.8046505, -1.0386702), (-1.7401543, -0.9722778), (-2.527583, -2.796705), (-2.5920804, -2.8630981), (-1.8046542, -1.0386703), (-1.7401559, -0.97227573), (-2.5275822, -2.7967026), (-2.592081, -2.863099), (-1.8046551, -1.038674), (-1.7401571, -0.97227746), (-2.5275822, -2.7967012), (-2.592079, -2.863097), (-1.8046526, -1.0386733), (-1.740158, -0.9722786), (-2.5275867, -2.7967021), (-2.5920804, -2.8630958), (-1.8046498, -1.0386715), (-1.7401537, -0.97227836), (-2.5275834, -2.7967038), (-2.5920808, -2.8630974), (-1.804653, -1.0386726), (-1.7401547, -0.97227836), (-2.5275817, -2.7967026), (-2.59208, -2.8630972), (-1.8046533, -1.038673), (-1.7401563, -0.97227734), (-2.5275848, -2.796701), (-2.5920815, -2.8630967), (-1.8046509, -1.0386722), (-1.7401522, -0.972278), (-2.5275836, -2.796704), (-2.5920842, -2.8630984), (-1.8046533, -1.0386717), (-1.7401522, -0.9722763), (-2.5275805, -2.7967029), (-2.592081, -2.8630996), (-1.8046566, -1.0386734), (-1.7401559, -0.972276), (-2.52758, -2.7967014), (-2.5920827, -2.8630993), (-1.8046596, -1.0386747), (-1.7401553, -0.9722765), (-2.5275779, -2.7966998), (-2.5920808, -2.863097), (-1.804658, -1.0386747), (-1.7401593, -0.9722779), (-2.5275826, -2.7966998), (-2.5920796, -2.8630953), (-1.8046534, -1.0386739), (-1.7401562, -0.9722801), (-2.5275822, -2.7967026), (-2.5920799, -2.8630958), (-1.8046573, -1.0386719), (-1.74016, -0.9722775), (-2.527582, -2.7967005), (-2.5920775, -2.8630953), (-1.8046547, -1.038674), (-1.7401597, -0.97228056), (-2.527584, -2.796702), (-2.5920765, -2.8630946), (-1.8046473, -1.0386721), (-1.7401532, -0.97228146), (-2.5275846, -2.796707), (-2.5920806, -2.8630974), (-1.80465, -1.0386698), (-1.7401544, -0.9722769), (-2.5275846, -2.796704), (-2.5920796, -2.863098), (-1.8046503, -1.0386708), (-1.7401547, -0.9722774), (-2.527583, -2.7967045), (-2.5920808, -2.8630972), (-1.8046534, -1.0386703), (-1.7401551, -0.9722777), (-2.5275815, -2.7967043), (-2.59208, -2.8630984), (-1.8046559, -1.0386727), (-1.7401576, -0.9722767), (-2.5275815, -2.7967007), (-2.5920799, -2.8630965), (-1.8046577, -1.0386736), (-1.7401589, -0.972278), (-2.5275803, -2.7967002), (-2.5920794, -2.8630955), (-1.8046583, -1.0386732), (-1.7401589, -0.97227913), (-2.527581, -2.7967021), (-2.5920815, -2.8630962), (-1.8046573, -1.0386723), (-1.7401551, -0.97227764), (-2.5275774, -2.796702), (-2.5920792, -2.8630989), (-1.8046587, -1.0386755), (-1.7401574, -0.9722771), (-2.5275779, -2.796699), (-2.5920799, -2.8630974), (-1.8046577, -1.0386764), (-1.7401568, -0.9722785), (-2.5275784, -2.7966993), (-2.592077, -2.863096), (-1.8046571, -1.0386753), (-1.7401614, -0.97228044), (-2.5275843, -2.7967017), (-2.592077, -2.8630943), (-1.8046478, -1.0386726), (-1.7401538, -0.97228295), (-2.527585, -2.7967079), (-2.5920813, -2.8630958), (-1.8046504, -1.0386667), (-1.7401528, -0.97227776), (-2.5275831, -2.7967083), (-2.5920806, -2.8630996), (-1.8046527, -1.0386691), (-1.7401562, -0.9722745), (-2.527584, -2.7967024), (-2.59208, -2.8630984), (-1.8046534, -1.0386733), (-1.7401592, -0.97227705), (-2.5275867, -2.7967002), (-2.592081, -2.8630958), (-1.804651, -1.0386722), (-1.7401538, -0.9722791), (-2.527585, -2.7967043), (-2.5920866, -2.8630958), (-1.8046548, -1.0386679), (-1.7401513, -0.97227603), (-2.527579, -2.796706), (-2.5920806, -2.8631012), (-1.8046548, -1.038673), (-1.7401553, -0.9722757), (-2.5275824, -2.7967017), (-2.59208, -2.8630986), (-1.8046542, -1.0386739), (-1.740159, -0.9722773), (-2.527586, -2.7967), (-2.5920808, -2.8630939), (-1.8046515, -1.0386711), (-1.7401556, -0.97228), (-2.5275853, -2.7967052), (-2.5920846, -2.8630965), (-1.8046557, -1.0386701), (-1.7401536, -0.9722766), (-2.5275786, -2.7967036), (-2.5920782, -2.863099), (-1.8046544, -1.0386735), (-1.7401558, -0.9722777), (-2.527581, -2.7967017), (-2.5920799, -2.8630974), (-1.8046547, -1.0386729), (-1.7401559, -0.97227734), (-2.5275812, -2.7967021), (-2.5920799, -2.8630974), (-1.8046532, -1.0386733), (-1.7401549, -0.9722777), (-2.5275812, -2.796702), (-2.592079, -2.8630977), (-1.8046525, -1.0386742), (-1.7401552, -0.9722798), (-2.527584, -2.7967036), (-2.5920818, -2.863096), (-1.8046517, -1.0386704), (-1.7401539, -0.972278), (-2.5275836, -2.7967048), (-2.592082, -2.8630974), (-1.8046515, -1.0386696), (-1.7401527, -0.97227585), (-2.5275836, -2.796704), (-2.5920827, -2.8630989), (-1.8046533, -1.038671), (-1.7401541, -0.9722758), (-2.5275846, -2.796703), (-2.592086, -2.8630986), (-1.8046552, -1.0386713), (-1.7401522, -0.972275), (-2.5275817, -2.796702), (-2.592084, -2.8630989), (-1.8046559, -1.038673), (-1.740154, -0.9722757), (-2.5275817, -2.7967012), (-2.5920832, -2.8630986), (-1.8046573, -1.038674), (-1.7401559, -0.97227657), (-2.5275807, -2.7966998), (-2.592082, -2.863097), (-1.8046579, -1.0386747), (-1.7401587, -0.9722781), (-2.527583, -2.7967002), (-2.5920808, -2.8630958), (-1.8046534, -1.0386727), (-1.7401539, -0.9722789), (-2.5275805, -2.7967038), (-2.5920784, -2.8630977), (-1.8046517, -1.0386728), (-1.7401549, -0.9722783), (-2.5275826, -2.7967024), (-2.5920794, -2.8630974), (-1.8046514, -1.0386739), (-1.7401557, -0.97228014), (-2.5275874, -2.7967048), (-2.592083, -2.8630972), (-1.8046489, -1.0386713), (-1.7401515, -0.97227895), (-2.5275843, -2.796706), (-2.5920854, -2.8630974), (-1.804656, -1.0386685), (-1.7401545, -0.97227526), (-2.5275812, -2.796704), (-2.5920815, -2.8631), (-1.8046548, -1.0386738), (-1.740155, -0.9722781), (-2.527581, -2.7967024), (-2.5920806, -2.863097), (-1.8046546, -1.0386722), (-1.7401551, -0.9722774), (-2.5275831, -2.796703), (-2.5920842, -2.8630984), (-1.804656, -1.0386721), (-1.7401546, -0.972276), (-2.5275822, -2.7967014), (-2.5920825, -2.8630977), (-1.804653, -1.0386727), (-1.7401522, -0.97227776), (-2.5275824, -2.7967036), (-2.592084, -2.8630986), (-1.8046558, -1.0386734), (-1.7401532, -0.9722769), (-2.5275784, -2.7967012), (-2.5920835, -2.8630993), (-1.8046607, -1.0386764), (-1.7401557, -0.97227734), (-2.5275803, -2.7966986), (-2.592084, -2.8630972), (-1.8046561, -1.0386748), (-1.740152, -0.97227776), (-2.5275795, -2.7967014), (-2.5920818, -2.8630972), (-1.8046539, -1.0386738), (-1.740152, -0.97227925), (-2.5275817, -2.7967038), (-2.5920837, -2.8630981), (-1.804654, -1.0386721), (-1.7401538, -0.972277), (-2.5275817, -2.7967026), (-2.59208, -2.8630989), (-1.8046536, -1.0386738), (-1.7401581, -0.9722768), (-2.5275853, -2.7967005), (-2.5920799, -2.8630967), (-1.8046514, -1.0386735), (-1.7401534, -0.97227913), (-2.5275826, -2.7967033), (-2.5920832, -2.863097), (-1.8046536, -1.0386722), (-1.7401533, -0.972278), (-2.5275824, -2.796703), (-2.5920832, -2.8630958), (-1.8046573, -1.0386695), (-1.7401586, -0.97227585), (-2.5275834, -2.7967021), (-2.5920804, -2.8630981), (-1.8046544, -1.0386733), (-1.7401596, -0.97227776), (-2.5275874, -2.7967021), (-2.59208, -2.8630955), (-1.804649, -1.0386703), (-1.7401531, -0.9722788), (-2.527587, -2.7967062), (-2.5920866, -2.863098), (-1.8046526, -1.0386682), (-1.740151, -0.972275), (-2.527582, -2.7967057), (-2.5920815, -2.8631008), (-1.8046516, -1.0386714), (-1.7401515, -0.972276), (-2.5275784, -2.7967045), (-2.5920775, -2.8631012), (-1.8046521, -1.0386741), (-1.7401563, -0.9722765), (-2.5275843, -2.7967014), (-2.592081, -2.8630965), (-1.8046526, -1.0386722), (-1.7401543, -0.97227806), (-2.5275826, -2.7967026), (-2.592082, -2.8630977), (-1.8046559, -1.0386728), (-1.7401552, -0.9722767), (-2.527581, -2.7967012), (-2.592084, -2.8630967), (-1.8046582, -1.0386728), (-1.7401527, -0.9722771), (-2.5275755, -2.796701), (-2.592083, -2.8630996), (-1.8046626, -1.0386772), (-1.7401583, -0.97227687), (-2.5275798, -2.796697), (-2.5920808, -2.8630965), (-1.8046557, -1.0386758), (-1.7401531, -0.97227806), (-2.5275798, -2.7967007), (-2.592083, -2.8630965), (-1.8046564, -1.0386734), (-1.7401521, -0.9722784), (-2.527578, -2.7967029), (-2.5920837, -2.8630981), (-1.8046601, -1.0386728), (-1.7401567, -0.9722755), (-2.5275798, -2.7967), (-2.5920808, -2.863098), (-1.8046575, -1.0386739), (-1.7401559, -0.97227645), (-2.5275786, -2.7967005), (-2.5920808, -2.8630977), (-1.8046553, -1.0386735), (-1.7401527, -0.97227746), (-2.5275803, -2.7967014), (-2.5920832, -2.8630972), (-1.8046552, -1.0386732), (-1.7401518, -0.97227734), (-2.5275779, -2.796702), (-2.592082, -2.8630993), (-1.8046587, -1.0386759), (-1.7401567, -0.9722766), (-2.5275805, -2.796698), (-2.592081, -2.863097), (-1.8046563, -1.0386759), (-1.7401565, -0.9722789), (-2.527581, -2.7967007), (-2.5920794, -2.8630955), (-1.8046558, -1.0386732), (-1.7401595, -0.97227854), (-2.5275857, -2.796701), (-2.59208, -2.8630953), (-1.8046514, -1.0386727), (-1.7401552, -0.9722792), (-2.5275812, -2.7967033), (-2.5920787, -2.8630974), (-1.8046533, -1.0386724), (-1.7401555, -0.9722793), (-2.5275834, -2.7967048), (-2.5920815, -2.863097), (-1.8046517, -1.0386692), (-1.7401537, -0.9722768), (-2.5275838, -2.796705), (-2.5920823, -2.863098), (-1.8046547, -1.0386704), (-1.740157, -0.9722762), (-2.5275834, -2.7967036), (-2.592079, -2.863098), (-1.8046522, -1.0386713), (-1.7401568, -0.9722771), (-2.5275843, -2.796703), (-2.5920818, -2.8630977), (-1.8046523, -1.0386728), (-1.7401526, -0.97227836), (-2.5275807, -2.7967033), (-2.592081, -2.863098), (-1.8046566, -1.0386724), (-1.7401587, -0.97227734), (-2.5275831, -2.7967021), (-2.5920792, -2.863098), (-1.804654, -1.0386736), (-1.7401593, -0.97227764), (-2.5275857, -2.7967005), (-2.5920799, -2.8630958), (-1.8046528, -1.0386736), (-1.7401568, -0.9722803), (-2.5275848, -2.7967036), (-2.592082, -2.8630965), (-1.8046522, -1.0386719), (-1.7401546, -0.9722784), (-2.5275822, -2.7967038), (-2.5920775, -2.863098), (-1.8046486, -1.0386733), (-1.7401538, -0.9722798), (-2.5275855, -2.7967048), (-2.5920837, -2.8630972), (-1.8046547, -1.0386703), (-1.7401563, -0.9722768), (-2.5275826, -2.7967038), (-2.5920777, -2.863097), (-1.8046507, -1.0386714), (-1.7401578, -0.9722788), (-2.5275848, -2.7967038), (-2.5920777, -2.8630965), (-1.8046515, -1.0386717), (-1.7401572, -0.9722788), (-2.5275836, -2.796703), (-2.592078, -2.8630967), (-1.8046517, -1.0386733), (-1.7401614, -0.9722796), (-2.5275898, -2.7967021), (-2.5920784, -2.8630934), (-1.8046473, -1.0386703), (-1.7401563, -0.9722809), (-2.527589, -2.7967076), (-2.5920827, -2.863097), (-1.8046511, -1.0386676), (-1.740156, -0.97227657), (-2.527587, -2.7967052), (-2.5920837, -2.8630984), (-1.8046525, -1.0386708), (-1.7401533, -0.9722765), (-2.5275815, -2.7967036), (-2.5920799, -2.8630989), (-1.8046558, -1.0386726), (-1.7401594, -0.9722771), (-2.5275836, -2.7967021), (-2.592078, -2.8630955), (-1.8046514, -1.0386707), (-1.7401583, -0.9722781), (-2.527587, -2.796703), (-2.5920813, -2.8630953), (-1.8046488, -1.0386696), (-1.7401507, -0.97227955), (-2.5275855, -2.7967079), (-2.5920846, -2.8630977), (-1.804649, -1.0386679), (-1.7401481, -0.9722765), (-2.527581, -2.7967072), (-2.5920832, -2.8631012), (-1.8046545, -1.0386705), (-1.7401544, -0.97227347), (-2.527582, -2.7967017), (-2.5920808, -2.8631003), (-1.8046546, -1.0386746), (-1.7401577, -0.9722768), (-2.5275846, -2.7967007), (-2.5920815, -2.863097), (-1.8046554, -1.038673), (-1.7401571, -0.9722775), (-2.5275826, -2.7967014), (-2.5920804, -2.8630972), (-1.8046544, -1.0386734), (-1.7401567, -0.972279), (-2.5275817, -2.7967029), (-2.59208, -2.8630972), (-1.8046559, -1.0386729), (-1.7401576, -0.97227764), (-2.5275824, -2.7967017), (-2.592079, -2.8630974), (-1.8046522, -1.0386739), (-1.7401565, -0.9722786), (-2.5275834, -2.7967014), (-2.5920787, -2.863096), (-1.8046528, -1.0386735), (-1.7401601, -0.972279), (-2.5275884, -2.7967007), (-2.5920794, -2.8630939), (-1.8046485, -1.0386726), (-1.7401567, -0.97228134), (-2.527589, -2.7967055), (-2.592084, -2.8630943), (-1.8046503, -1.0386659), (-1.7401519, -0.9722786), (-2.527584, -2.79671), (-2.5920813, -2.8630996), (-1.8046502, -1.0386685), (-1.7401543, -0.97227645), (-2.5275848, -2.7967052), (-2.5920832, -2.8630986), (-1.8046538, -1.038671), (-1.7401538, -0.97227734), (-2.527583, -2.796704), (-2.592082, -2.8630984), (-1.8046538, -1.0386723), (-1.7401558, -0.9722774), (-2.527583, -2.7967026), (-2.5920804, -2.8630984), (-1.8046529, -1.0386739), (-1.7401582, -0.97227824), (-2.5275862, -2.7967024), (-2.592079, -2.863095), (-1.8046484, -1.0386714), (-1.7401534, -0.9722803), (-2.527584, -2.7967057), (-2.5920808, -2.8630974), (-1.8046517, -1.0386701), (-1.7401551, -0.9722775), (-2.527583, -2.7967043), (-2.5920775, -2.8630974), (-1.8046505, -1.0386722), (-1.7401565, -0.972279), (-2.5275853, -2.7967033), (-2.5920825, -2.863097), (-1.8046547, -1.038671), (-1.7401564, -0.97227645), (-2.5275838, -2.7967024), (-2.5920823, -2.8630962), (-1.804654, -1.0386705), (-1.7401557, -0.9722776), (-2.5275846, -2.7967038), (-2.5920842, -2.8630981), (-1.8046536, -1.0386715), (-1.7401521, -0.9722761), (-2.527583, -2.7967024), (-2.592086, -2.8630984), (-1.8046561, -1.038672), (-1.7401525, -0.9722756), (-2.5275793, -2.7967026), (-2.5920815, -2.8630996), (-1.8046565, -1.0386738), (-1.7401563, -0.9722763), (-2.5275831, -2.7967002), (-2.5920813, -2.8630967), (-1.8046525, -1.0386736), (-1.7401564, -0.9722792), (-2.5275865, -2.796703), (-2.5920815, -2.863096), (-1.8046503, -1.0386702), (-1.7401532, -0.97227824), (-2.527584, -2.7967052), (-2.592082, -2.8630967), (-1.8046525, -1.0386691), (-1.7401539, -0.9722778), (-2.5275817, -2.796706), (-2.5920782, -2.8630989), (-1.8046522, -1.0386709), (-1.740156, -0.97227746), (-2.5275826, -2.7967048), (-2.5920806, -2.8630989), (-1.8046541, -1.0386732), (-1.7401571, -0.9722771), (-2.527583, -2.796701), (-2.592078, -2.8630967), (-1.8046507, -1.038673), (-1.740156, -0.97227937), (-2.5275853, -2.796704), (-2.5920823, -2.8630953), (-1.8046542, -1.0386683), (-1.7401581, -0.97227675), (-2.527586, -2.7967045), (-2.5920818, -2.863097), (-1.8046536, -1.0386697), (-1.740155, -0.97227824), (-2.5275803, -2.7967055), (-2.5920782, -2.8630989), (-1.8046541, -1.038673), (-1.7401586, -0.97227705), (-2.527584, -2.796701), (-2.5920787, -2.8630967), (-1.8046513, -1.038673), (-1.7401563, -0.9722793), (-2.5275853, -2.7967043), (-2.5920796, -2.863097), (-1.804649, -1.0386713), (-1.7401538, -0.9722781), (-2.5275862, -2.796704), (-2.592084, -2.8630974), (-1.804652, -1.0386697), (-1.7401527, -0.9722761), (-2.5275817, -2.7967052), (-2.5920808, -2.863101), (-1.8046544, -1.038673), (-1.7401555, -0.972276), (-2.527583, -2.796702), (-2.5920825, -2.8630977), (-1.8046563, -1.0386722), (-1.7401575, -0.9722767), (-2.5275831, -2.7967017), (-2.5920804, -2.8630977), (-1.8046544, -1.0386742), (-1.7401577, -0.9722787), (-2.5275855, -2.7967017), (-2.5920808, -2.8630958), (-1.8046505, -1.0386715), (-1.7401549, -0.97227913), (-2.527586, -2.7967052), (-2.5920846, -2.863096), (-1.8046547, -1.0386682), (-1.7401546, -0.9722759), (-2.5275826, -2.7967043), (-2.5920818, -2.8630986), (-1.8046551, -1.0386709), (-1.7401547, -0.97227734), (-2.5275788, -2.7967043), (-2.5920763, -2.8630989), (-1.8046511, -1.0386734), (-1.7401559, -0.97227913), (-2.5275838, -2.796704), (-2.5920823, -2.863096), (-1.8046545, -1.0386693), (-1.7401549, -0.97227675), (-2.5275834, -2.7967036), (-2.5920827, -2.8630981), (-1.8046557, -1.0386722), (-1.7401553, -0.9722761), (-2.5275803, -2.7967007), (-2.5920796, -2.863098), (-1.8046534, -1.0386758), (-1.740153, -0.97227937), (-2.5275803, -2.7967017), (-2.5920835, -2.8630967), (-1.804657, -1.0386729), (-1.7401522, -0.972278), (-2.5275776, -2.7967021), (-2.5920835, -2.8630989), (-1.8046595, -1.0386751), (-1.7401549, -0.9722766), (-2.5275788, -2.7966988), (-2.5920837, -2.8630965), (-1.8046597, -1.0386748), (-1.7401543, -0.9722776), (-2.5275755, -2.7966998), (-2.5920782, -2.8630986), (-1.8046583, -1.0386769), (-1.7401586, -0.9722784), (-2.527582, -2.7966993), (-2.5920804, -2.8630965), (-1.8046534, -1.0386753), (-1.7401549, -0.9722795), (-2.5275822, -2.7967021), (-2.5920794, -2.8630962), (-1.804651, -1.0386719), (-1.7401536, -0.97227806), (-2.5275824, -2.7967033), (-2.5920818, -2.8630974), (-1.8046561, -1.0386716), (-1.7401577, -0.9722768), (-2.5275826, -2.7967024), (-2.59208, -2.8630972), (-1.8046547, -1.0386726), (-1.7401567, -0.97227746), (-2.5275826, -2.7967017), (-2.5920794, -2.8630974), (-1.8046538, -1.0386726), (-1.740158, -0.9722771), (-2.5275838, -2.7967021), (-2.5920808, -2.863097), (-1.8046547, -1.0386723), (-1.7401564, -0.97227716), (-2.5275807, -2.7967017), (-2.5920813, -2.8630974), (-1.8046579, -1.0386735), (-1.7401559, -0.972277), (-2.5275793, -2.7967002), (-2.5920823, -2.8630972), (-1.8046583, -1.0386747), (-1.7401528, -0.97227824), (-2.527575, -2.7967007), (-2.5920792, -2.8630972), (-1.8046575, -1.0386747), (-1.7401541, -0.9722785), (-2.5275762, -2.7967007), (-2.5920794, -2.8630981), (-1.80466, -1.038676), (-1.7401608, -0.97227705), (-2.5275812, -2.7966974), (-2.5920773, -2.863096), (-1.8046532, -1.038676), (-1.740157, -0.97228056), (-2.5275846, -2.7967026), (-2.5920806, -2.863096), (-1.804651, -1.0386719), (-1.7401539, -0.97227865), (-2.527582, -2.7967043), (-2.5920787, -2.8630981), (-1.8046532, -1.038672), (-1.7401577, -0.97227675), (-2.5275846, -2.7967021), (-2.592083, -2.8630965), (-1.8046569, -1.0386717), (-1.7401576, -0.9722768), (-2.5275812, -2.796701), (-2.5920796, -2.8630967), (-1.8046567, -1.038674), (-1.7401582, -0.9722794), (-2.5275803, -2.7967017), (-2.592077, -2.863096), (-1.8046529, -1.0386726), (-1.7401564, -0.97227895), (-2.5275817, -2.7967033), (-2.5920782, -2.8630967), (-1.8046523, -1.0386719), (-1.7401558, -0.9722782), (-2.5275824, -2.796703), (-2.5920813, -2.8630967), (-1.8046572, -1.0386716), (-1.7401576, -0.9722765), (-2.527582, -2.796701), (-2.5920815, -2.8630967), (-1.8046559, -1.0386732), (-1.7401563, -0.97227895), (-2.5275824, -2.7967033), (-2.5920806, -2.863097), (-1.8046533, -1.0386721), (-1.740155, -0.97227764), (-2.5275812, -2.7967026), (-2.5920804, -2.8630972), (-1.8046548, -1.0386722), (-1.7401556, -0.97227824), (-2.5275807, -2.7967033), (-2.5920792, -2.863098), (-1.804655, -1.038673), (-1.7401581, -0.97227675), (-2.5275831, -2.796701), (-2.5920782, -2.863097), (-1.8046522, -1.0386742), (-1.7401584, -0.97228044), (-2.5275862, -2.796703), (-2.5920806, -2.8630946), (-1.8046504, -1.0386705), (-1.7401536, -0.9722795), (-2.527584, -2.7967055), (-2.5920837, -2.8630965), (-1.8046545, -1.0386688), (-1.7401544, -0.97227746), (-2.5275838, -2.7967055), (-2.5920835, -2.8630981), (-1.8046528, -1.0386697), (-1.7401514, -0.97227645), (-2.5275805, -2.7967055), (-2.5920825, -2.8631008), (-1.8046547, -1.0386728), (-1.740153, -0.9722754), (-2.52758, -2.796702), (-2.592081, -2.8630993), (-1.8046561, -1.0386746), (-1.7401581, -0.97227716), (-2.5275826, -2.7967005), (-2.5920799, -2.8630965), (-1.8046529, -1.0386735), (-1.7401576, -0.97227913), (-2.5275853, -2.7967024), (-2.5920787, -2.8630958), (-1.804651, -1.0386724), (-1.7401568, -0.9722798), (-2.5275862, -2.7967038), (-2.5920804, -2.8630958), (-1.8046484, -1.03867), (-1.7401528, -0.97227955), (-2.5275862, -2.7967076), (-2.5920832, -2.863098), (-1.8046498, -1.0386676), (-1.7401518, -0.9722749), (-2.5275836, -2.796706), (-2.5920846, -2.863101), (-1.8046556, -1.038671), (-1.7401547, -0.97227395), (-2.527582, -2.7967017), (-2.5920799, -2.8630998), (-1.8046539, -1.0386746), (-1.7401599, -0.972277), (-2.5275884, -2.796699), (-2.5920806, -2.8630946), (-1.8046511, -1.0386729), (-1.7401564, -0.97227937), (-2.5275836, -2.7967026), (-2.5920799, -2.8630965), (-1.8046527, -1.0386732), (-1.7401562, -0.97227955), (-2.5275826, -2.7967026), (-2.5920808, -2.8630965), (-1.8046529, -1.0386728), (-1.7401538, -0.97227865), (-2.527584, -2.7967029), (-2.5920827, -2.863097), (-1.8046508, -1.0386717), (-1.740152, -0.9722777), (-2.527584, -2.7967038), (-2.592085, -2.8630981), (-1.8046538, -1.0386713), (-1.7401516, -0.9722761), (-2.5275803, -2.7967026), (-2.5920835, -2.8630984), (-1.8046578, -1.0386733), (-1.7401545, -0.97227675), (-2.52758, -2.796701), (-2.5920806, -2.8630974), (-1.8046541, -1.0386736), (-1.7401571, -0.972279), (-2.5275846, -2.7967024), (-2.5920794, -2.8630958), (-1.804652, -1.0386723), (-1.740156, -0.9722788), (-2.5275815, -2.796703), (-2.5920775, -2.863097), (-1.8046528, -1.038673), (-1.7401606, -0.9722795), (-2.5275886, -2.7967029), (-2.5920818, -2.8630948), (-1.8046511, -1.0386708), (-1.7401545, -0.9722789), (-2.5275857, -2.7967038), (-2.5920827, -2.8630967), (-1.80465, -1.0386709), (-1.7401515, -0.97227746), (-2.5275843, -2.796703), (-2.5920846, -2.8630977), (-1.804652, -1.0386721), (-1.7401484, -0.972277), (-2.5275786, -2.7967029), (-2.5920823, -2.8630996), (-1.8046561, -1.0386745), (-1.7401553, -0.97227645), (-2.5275822, -2.7966993), (-2.5920825, -2.8630967), (-1.8046539, -1.038674), (-1.7401559, -0.97227883), (-2.5275865, -2.796703), (-2.5920827, -2.863096), (-1.8046515, -1.0386704), (-1.7401539, -0.972278), (-2.5275857, -2.7967048), (-2.5920863, -2.8630977), (-1.8046577, -1.0386701), (-1.7401558, -0.9722755), (-2.5275807, -2.7967024), (-2.5920784, -2.8630993), (-1.8046523, -1.0386752), (-1.7401569, -0.9722789), (-2.527582, -2.796702), (-2.592076, -2.863096), (-1.8046525, -1.0386734), (-1.7401593, -0.9722799), (-2.5275862, -2.7967021), (-2.5920804, -2.8630953), (-1.8046509, -1.0386719), (-1.740154, -0.97227913), (-2.527582, -2.7967038), (-2.5920794, -2.8630972), (-1.8046523, -1.0386716), (-1.7401551, -0.97227764), (-2.5275834, -2.7967036), (-2.5920827, -2.863098), (-1.804653, -1.038671), (-1.7401527, -0.9722766), (-2.5275815, -2.7967045), (-2.592082, -2.8630984), (-1.8046558, -1.0386705), (-1.7401575, -0.9722756), (-2.5275826, -2.7967024), (-2.5920787, -2.8630984), (-1.8046527, -1.0386734), (-1.7401577, -0.9722773), (-2.5275853, -2.7967017), (-2.5920799, -2.8630958), (-1.8046498, -1.0386701), (-1.7401543, -0.9722779), (-2.5275865, -2.7967048), (-2.5920854, -2.8630977), (-1.8046533, -1.0386692), (-1.7401531, -0.97227585), (-2.5275831, -2.7967052), (-2.5920825, -2.8630996), (-1.8046542, -1.0386715), (-1.7401546, -0.9722763), (-2.5275831, -2.7967021), (-2.5920846, -2.863098), (-1.8046571, -1.0386728), (-1.7401536, -0.97227675), (-2.5275788, -2.796702), (-2.5920813, -2.8630984), (-1.8046575, -1.0386745), (-1.7401568, -0.9722787), (-2.5275807, -2.7967017), (-2.5920804, -2.8630967), (-1.8046536, -1.0386733), (-1.7401575, -0.9722789), (-2.5275862, -2.7967026), (-2.5920796, -2.8630965), (-1.8046483, -1.0386722), (-1.7401519, -0.9722789), (-2.527583, -2.7967048), (-2.5920825, -2.8630974), (-1.8046527, -1.0386702), (-1.7401532, -0.9722766), (-2.5275824, -2.796704), (-2.5920784, -2.8630984), (-1.8046505, -1.0386716), (-1.740157, -0.97227854), (-2.527584, -2.7967045), (-2.5920775, -2.863096), (-1.8046516, -1.0386698), (-1.7401586, -0.97227895), (-2.5275874, -2.7967048), (-2.592083, -2.8630962), (-1.8046527, -1.038669), (-1.7401551, -0.97227687), (-2.5275853, -2.796705), (-2.5920851, -2.8630981), (-1.8046564, -1.0386705), (-1.7401551, -0.97227556), (-2.527582, -2.7967017), (-2.5920804, -2.8630981), (-1.8046535, -1.038674), (-1.7401589, -0.97227883), (-2.527586, -2.7967026), (-2.5920794, -2.8630965), (-1.8046513, -1.0386721), (-1.7401557, -0.97227895), (-2.5275815, -2.7967043), (-2.592076, -2.8630977), (-1.8046507, -1.0386734), (-1.7401583, -0.9722794), (-2.5275855, -2.7967026), (-2.592079, -2.8630962), (-1.8046514, -1.038673), (-1.7401558, -0.9722794), (-2.5275831, -2.7967029), (-2.5920794, -2.8630962), (-1.8046534, -1.0386727), (-1.7401581, -0.9722794), (-2.5275838, -2.796703), (-2.5920782, -2.8630965), (-1.8046526, -1.0386727), (-1.7401584, -0.97227895), (-2.5275853, -2.7967024), (-2.5920804, -2.8630943), (-1.8046514, -1.0386705), (-1.7401564, -0.9722789), (-2.5275846, -2.796704), (-2.5920792, -2.863097), (-1.8046526, -1.0386716), (-1.7401583, -0.9722786), (-2.5275855, -2.7967036), (-2.59208, -2.8630967), (-1.8046505, -1.0386707), (-1.7401565, -0.97227705), (-2.5275872, -2.796703), (-2.5920825, -2.8630967), (-1.804653, -1.0386708), (-1.7401567, -0.97227675), (-2.5275848, -2.7967024), (-2.5920804, -2.8630974), (-1.8046522, -1.0386728), (-1.7401552, -0.9722782), (-2.527582, -2.7967024), (-2.5920787, -2.8630977), (-1.8046535, -1.0386735), (-1.7401575, -0.9722787), (-2.5275822, -2.7967026), (-2.5920777, -2.8630972), (-1.8046536, -1.0386745), (-1.7401617, -0.9722793), (-2.527587, -2.7967002), (-2.5920773, -2.8630943), (-1.8046486, -1.0386739), (-1.7401563, -0.97228193), (-2.5275877, -2.7967048), (-2.5920835, -2.8630953), (-1.8046533, -1.0386686), (-1.7401537, -0.9722763), (-2.5275798, -2.7967043), (-2.5920782, -2.8630998), (-1.8046538, -1.0386742), (-1.7401587, -0.97227806), (-2.5275843, -2.7967005), (-2.5920782, -2.8630955), (-1.8046508, -1.0386735), (-1.7401572, -0.97227985), (-2.5275848, -2.796703), (-2.5920784, -2.8630967), (-1.8046515, -1.0386722), (-1.7401564, -0.972279), (-2.5275817, -2.796704), (-2.5920768, -2.8630972), (-1.804653, -1.0386733), (-1.7401603, -0.97227865), (-2.527586, -2.7967014), (-2.592078, -2.863095), (-1.8046529, -1.0386717), (-1.7401602, -0.9722795), (-2.5275862, -2.7967043), (-2.592082, -2.8630953), (-1.8046526, -1.0386683), (-1.7401543, -0.97227705), (-2.5275834, -2.796705), (-2.5920818, -2.863098), (-1.8046547, -1.0386703), (-1.7401564, -0.97227675), (-2.5275826, -2.7967038), (-2.5920804, -2.8630984), (-1.804654, -1.0386724), (-1.740156, -0.9722769), (-2.5275822, -2.7967021), (-2.5920806, -2.8630981), (-1.8046551, -1.0386733), (-1.7401556, -0.972278), (-2.5275784, -2.7967024), (-2.5920746, -2.8630974), (-1.8046514, -1.0386736), (-1.740158, -0.9722797), (-2.5275855, -2.7967038), (-2.5920832, -2.8630953), (-1.8046557, -1.0386689), (-1.7401559, -0.9722767), (-2.5275815, -2.796704), (-2.5920787, -2.8630986), (-1.8046527, -1.038673), (-1.7401564, -0.9722782), (-2.5275826, -2.7967026), (-2.5920804, -2.8630972), (-1.8046535, -1.0386734), (-1.7401559, -0.9722778), (-2.527584, -2.796701), (-2.592081, -2.863096), (-1.8046536, -1.0386724), (-1.7401563, -0.972278), (-2.527583, -2.7967024), (-2.5920813, -2.863097), (-1.8046557, -1.0386728), (-1.7401574, -0.9722784), (-2.5275822, -2.7967024), (-2.5920799, -2.8630967), (-1.8046544, -1.0386729), (-1.7401555, -0.9722785), (-2.5275798, -2.796703), (-2.5920782, -2.863098), (-1.8046558, -1.0386736), (-1.7401589, -0.97227746), (-2.527583, -2.7967), (-2.5920804, -2.8630948), (-1.8046523, -1.038673), (-1.740153, -0.97228014), (-2.5275831, -2.7967038), (-2.5920846, -2.863095), (-1.8046552, -1.0386692), (-1.7401534, -0.9722779), (-2.527581, -2.7967045), (-2.5920796, -2.8630984), (-1.8046536, -1.0386729), (-1.740157, -0.97227806), (-2.5275836, -2.7967021), (-2.59208, -2.863096), (-1.804652, -1.0386715), (-1.7401551, -0.9722781), (-2.5275826, -2.7967036), (-2.59208, -2.8630977), (-1.8046528, -1.0386727), (-1.7401549, -0.9722785), (-2.527585, -2.7967026), (-2.5920837, -2.8630965), (-1.8046523, -1.0386721), (-1.7401524, -0.9722779), (-2.5275824, -2.7967029), (-2.5920854, -2.8630981), (-1.8046582, -1.038673), (-1.7401546, -0.9722757), (-2.527579, -2.7967002), (-2.5920835, -2.8630989), (-1.80466, -1.0386753), (-1.7401562, -0.9722768), (-2.5275788, -2.7966988), (-2.5920815, -2.8630967), (-1.8046582, -1.0386751), (-1.7401537, -0.97227865), (-2.5275753, -2.796701), (-2.5920818, -2.8630986), (-1.8046637, -1.0386765), (-1.740158, -0.9722765), (-2.5275755, -2.796697), (-2.5920765, -2.8630977), (-1.804655, -1.0386791), (-1.7401568, -0.9722807), (-2.5275826, -2.7966998), (-2.5920813, -2.8630953), (-1.8046539, -1.0386732), (-1.7401533, -0.972279), (-2.5275798, -2.7967033), (-2.592079, -2.863097), (-1.8046541, -1.0386728), (-1.7401567, -0.97227925), (-2.527582, -2.7967036), (-2.592079, -2.8630972), (-1.8046516, -1.0386723), (-1.7401547, -0.9722782), (-2.5275824, -2.7967029), (-2.592081, -2.8630967), (-1.8046546, -1.0386716), (-1.7401556, -0.97227776), (-2.5275838, -2.7967033), (-2.5920832, -2.8630977), (-1.8046535, -1.0386708), (-1.7401527, -0.97227615), (-2.5275815, -2.7967036), (-2.5920815, -2.863098), (-1.8046545, -1.0386708), (-1.7401569, -0.972276), (-2.5275843, -2.7967026), (-2.592082, -2.8630967), (-1.8046551, -1.0386701), (-1.7401568, -0.9722763), (-2.5275817, -2.796703), (-2.5920796, -2.863097), (-1.8046545, -1.0386704), (-1.7401569, -0.9722778), (-2.5275834, -2.796704), (-2.592082, -2.8630981), (-1.8046558, -1.0386726), (-1.7401568, -0.9722777), (-2.5275824, -2.7967024), (-2.5920813, -2.8630972), (-1.8046551, -1.0386729), (-1.7401555, -0.9722774), (-2.527581, -2.7967017), (-2.5920827, -2.8630977), (-1.8046576, -1.0386739), (-1.7401541, -0.9722781), (-2.5275798, -2.796702), (-2.592081, -2.8630977), (-1.804653, -1.0386736), (-1.7401546, -0.97227824), (-2.5275831, -2.7967029), (-2.5920799, -2.8630965), (-1.8046515, -1.0386708), (-1.740153, -0.9722789), (-2.527581, -2.7967064), (-2.59208, -2.8630986), (-1.8046544, -1.0386709), (-1.7401577, -0.97227657), (-2.5275834, -2.7967024), (-2.5920784, -2.8630981), (-1.8046519, -1.0386738), (-1.7401575, -0.97227854), (-2.5275838, -2.7967026), (-2.5920768, -2.8630967), (-1.8046498, -1.0386733), (-1.7401572, -0.9722795), (-2.5275867, -2.7967026), (-2.592081, -2.863096), (-1.8046525, -1.0386715), (-1.7401562, -0.9722782), (-2.5275831, -2.7967036), (-2.592079, -2.863096), (-1.804653, -1.038671), (-1.7401581, -0.9722788), (-2.5275846, -2.796704), (-2.5920832, -2.863096), (-1.804657, -1.0386695), (-1.7401565, -0.9722772), (-2.5275817, -2.7967043), (-2.592081, -2.863097), (-1.8046563, -1.0386701), (-1.7401593, -0.9722774), (-2.5275848, -2.7967043), (-2.592079, -2.8630977), (-1.8046497, -1.038672), (-1.7401547, -0.9722786), (-2.5275843, -2.7967038), (-2.5920815, -2.8630974), (-1.8046533, -1.0386726), (-1.7401551, -0.97227836), (-2.52758, -2.7967038), (-2.592076, -2.8630986), (-1.8046508, -1.038673), (-1.7401543, -0.97227794), (-2.5275834, -2.7967026), (-2.5920837, -2.863098), (-1.8046553, -1.0386729), (-1.740156, -0.97227615), (-2.5275838, -2.796701), (-2.5920813, -2.863098), (-1.804653, -1.0386733), (-1.7401555, -0.97227794), (-2.5275822, -2.7967024), (-2.59208, -2.863097), (-1.8046546, -1.0386722), (-1.740157, -0.9722778), (-2.5275846, -2.796703), (-2.592082, -2.8630965), (-1.8046546, -1.0386704), (-1.7401576, -0.97227705), (-2.5275838, -2.7967038), (-2.5920796, -2.8630977), (-1.8046521, -1.0386716), (-1.7401559, -0.9722785), (-2.5275838, -2.7967048), (-2.5920804, -2.863097), (-1.8046526, -1.0386697), (-1.7401569, -0.97227687), (-2.527585, -2.7967036), (-2.5920804, -2.8630974), (-1.8046504, -1.0386714), (-1.7401541, -0.97227913), (-2.5275831, -2.7967057), (-2.5920808, -2.8630967), (-1.8046526, -1.038669), (-1.740155, -0.97227764), (-2.527583, -2.796706), (-2.59208, -2.8630989), (-1.8046542, -1.0386707), (-1.740157, -0.9722765), (-2.5275831, -2.7967036), (-2.5920796, -2.8630974), (-1.8046522, -1.0386714), (-1.740156, -0.97227794), (-2.527583, -2.7967029), (-2.5920794, -2.8630958), (-1.8046527, -1.0386701), (-1.740157, -0.97227806), (-2.5275853, -2.7967048), (-2.5920832, -2.8630972), (-1.8046564, -1.0386707), (-1.7401576, -0.9722766), (-2.5275831, -2.796702), (-2.592079, -2.8630977), (-1.8046519, -1.0386742), (-1.7401572, -0.9722796), (-2.5275853, -2.7967029), (-2.5920804, -2.8630965), (-1.8046521, -1.038672), (-1.7401558, -0.97227865), (-2.527583, -2.7967036), (-2.5920782, -2.8630974), (-1.804652, -1.0386736), (-1.74016, -0.97227967), (-2.5275881, -2.7967021), (-2.5920782, -2.863094), (-1.8046461, -1.0386716), (-1.7401534, -0.9722821), (-2.5275874, -2.7967072), (-2.5920823, -2.8630965), (-1.8046502, -1.0386685), (-1.7401532, -0.97227764), (-2.5275826, -2.7967064), (-2.5920823, -2.8630996), (-1.8046548, -1.0386715), (-1.7401553, -0.9722763), (-2.527583, -2.7967026), (-2.5920825, -2.863099), (-1.8046546, -1.0386728), (-1.7401547, -0.97227615), (-2.5275831, -2.7967017), (-2.5920818, -2.863098), (-1.8046536, -1.0386733), (-1.7401553, -0.9722779), (-2.5275812, -2.7967024), (-2.5920806, -2.8630972), (-1.8046578, -1.0386727), (-1.7401577, -0.97227705), (-2.5275793, -2.7967012), (-2.5920782, -2.863097), (-1.8046556, -1.0386742), (-1.7401571, -0.97227865), (-2.5275815, -2.796701), (-2.5920808, -2.863096), (-1.8046542, -1.0386724), (-1.7401552, -0.9722781), (-2.5275822, -2.7967029), (-2.592081, -2.8630958), (-1.8046533, -1.0386693), (-1.7401553, -0.9722767), (-2.5275855, -2.7967036), (-2.5920825, -2.8630972), (-1.8046501, -1.0386709), (-1.740152, -0.9722767), (-2.527584, -2.7967036), (-2.5920842, -2.8630981), (-1.8046532, -1.0386707), (-1.7401516, -0.9722762), (-2.5275826, -2.7967038), (-2.5920856, -2.863099), (-1.8046565, -1.0386717), (-1.7401543, -0.9722743), (-2.5275807, -2.796701), (-2.5920813, -2.863099), (-1.8046569, -1.0386745), (-1.7401582, -0.9722774), (-2.527583, -2.7966998), (-2.59208, -2.8630948), (-1.8046514, -1.0386734), (-1.7401536, -0.9722815), (-2.5275853, -2.7967052), (-2.5920856, -2.863096), (-1.8046548, -1.0386689), (-1.7401547, -0.972277), (-2.527583, -2.7967052), (-2.5920799, -2.8630981), (-1.8046532, -1.0386711), (-1.7401552, -0.97227776), (-2.5275798, -2.796704), (-2.5920756, -2.8630996), (-1.8046488, -1.0386751), (-1.7401562, -0.9722795), (-2.527587, -2.7967029), (-2.5920823, -2.8630955), (-1.8046509, -1.0386698), (-1.7401533, -0.97227854), (-2.5275862, -2.7967062), (-2.5920856, -2.8630977), (-1.8046536, -1.0386688), (-1.7401545, -0.9722762), (-2.5275846, -2.7967045), (-2.5920813, -2.8630984), (-1.8046513, -1.0386716), (-1.7401547, -0.97227734), (-2.5275836, -2.7967036), (-2.5920806, -2.8630986), (-1.8046529, -1.0386735), (-1.7401557, -0.9722784), (-2.527583, -2.7967024), (-2.59208, -2.8630974), (-1.8046538, -1.0386733), (-1.7401568, -0.9722784), (-2.5275831, -2.7967026), (-2.5920799, -2.8630967), (-1.8046509, -1.0386722), (-1.7401533, -0.9722779), (-2.527584, -2.7967029), (-2.592085, -2.863097), (-1.8046541, -1.0386716), (-1.7401512, -0.97227705), (-2.5275793, -2.7967026), (-2.5920823, -2.8630984), (-1.8046585, -1.038674), (-1.7401572, -0.972277), (-2.5275805, -2.7966998), (-2.5920808, -2.8630972), (-1.8046589, -1.038675), (-1.7401607, -0.97227764), (-2.5275836, -2.7966993), (-2.5920794, -2.8630948), (-1.8046527, -1.0386741), (-1.7401583, -0.97228146), (-2.527588, -2.796704), (-2.5920808, -2.8630948), (-1.8046484, -1.03867), (-1.7401526, -0.97227997), (-2.5275855, -2.796707), (-2.5920827, -2.8630965), (-1.8046488, -1.0386676), (-1.7401524, -0.97227734), (-2.5275862, -2.7967072), (-2.5920837, -2.8630981), (-1.804652, -1.038668), (-1.740154, -0.97227526), (-2.5275838, -2.7967048), (-2.5920818, -2.8630993), (-1.8046532, -1.0386719), (-1.7401544, -0.9722768), (-2.5275815, -2.7967038), (-2.5920784, -2.8630998), (-1.8046519, -1.0386742), (-1.7401553, -0.97227806), (-2.527582, -2.7967021), (-2.5920784, -2.8630974), (-1.804654, -1.0386739), (-1.7401601, -0.972279), (-2.527587, -2.7967014), (-2.5920813, -2.8630939), (-1.804652, -1.0386698), (-1.7401563, -0.9722792), (-2.5275857, -2.7967055), (-2.592082, -2.8630962), (-1.8046523, -1.0386685), (-1.7401569, -0.972277), (-2.5275867, -2.7967048), (-2.5920825, -2.863098), (-1.8046534, -1.0386703), (-1.7401558, -0.97227657), (-2.5275838, -2.7967033), (-2.5920808, -2.8630972), (-1.8046513, -1.0386714), (-1.7401534, -0.9722795), (-2.5275815, -2.7967057), (-2.5920806, -2.863097), (-1.8046541, -1.0386697), (-1.7401545, -0.97227806), (-2.52758, -2.796706), (-2.5920792, -2.863098), (-1.8046551, -1.0386702), (-1.7401569, -0.9722766), (-2.527582, -2.7967033), (-2.5920782, -2.863097), (-1.804651, -1.0386713), (-1.7401567, -0.9722791), (-2.5275862, -2.7967052), (-2.5920827, -2.8630974), (-1.8046545, -1.0386698), (-1.740156, -0.97227746), (-2.5275817, -2.7967052), (-2.5920794, -2.8630974), (-1.8046528, -1.0386704), (-1.7401553, -0.97227836), (-2.5275822, -2.796705), (-2.59208, -2.8630972), (-1.804653, -1.0386703), (-1.7401547, -0.97227734), (-2.5275826, -2.796704), (-2.5920813, -2.863097), (-1.8046552, -1.0386701), (-1.7401576, -0.9722772), (-2.5275831, -2.7967043), (-2.59208, -2.8630972), (-1.8046541, -1.0386704), (-1.7401575, -0.9722772), (-2.527584, -2.796704), (-2.5920815, -2.863097), (-1.804656, -1.0386702), (-1.7401577, -0.9722773), (-2.5275826, -2.7967038), (-2.5920782, -2.8630981), (-1.8046516, -1.0386727), (-1.740156, -0.9722775), (-2.527584, -2.7967024), (-2.59208, -2.8630972), (-1.8046505, -1.0386726), (-1.7401536, -0.9722782), (-2.5275824, -2.7967033), (-2.5920823, -2.8630981), (-1.8046571, -1.0386721), (-1.7401577, -0.9722771), (-2.5275824, -2.7967024), (-2.592079, -2.8630981), (-1.8046538, -1.038674), (-1.7401594, -0.9722778), (-2.527586, -2.7967005), (-2.59208, -2.8630958), (-1.8046514, -1.0386735), (-1.7401564, -0.97228), (-2.5275834, -2.7967033), (-2.5920775, -2.8630967), (-1.8046505, -1.0386733), (-1.7401537, -0.97227967), (-2.527582, -2.7967038), (-2.5920804, -2.8630974), (-1.8046529, -1.0386723), (-1.740156, -0.97227764), (-2.5275836, -2.7967017), (-2.5920815, -2.8630958), (-1.8046558, -1.0386724), (-1.7401584, -0.97227913), (-2.5275843, -2.7967026), (-2.5920813, -2.8630962), (-1.8046532, -1.0386717), (-1.7401549, -0.97227794), (-2.5275815, -2.7967038), (-2.5920796, -2.8630986), (-1.8046557, -1.038673), (-1.7401602, -0.97227675), (-2.5275857, -2.7967002), (-2.59208, -2.8630965), (-1.8046511, -1.0386734), (-1.7401562, -0.97227895), (-2.5275848, -2.796703), (-2.5920808, -2.8630972), (-1.804653, -1.0386721), (-1.7401551, -0.9722774), (-2.5275815, -2.7967024), (-2.5920792, -2.863098), (-1.8046542, -1.0386733), (-1.7401587, -0.97227734), (-2.5275843, -2.7967012), (-2.5920787, -2.863097), (-1.8046525, -1.0386741), (-1.7401567, -0.97227967), (-2.5275817, -2.7967026), (-2.5920782, -2.8630967), (-1.8046538, -1.0386724), (-1.7401577, -0.9722791), (-2.527582, -2.7967038), (-2.5920749, -2.8630955), (-1.8046514, -1.0386711), (-1.7401617, -0.9722794), (-2.527587, -2.796704), (-2.5920799, -2.863095), (-1.8046504, -1.0386696), (-1.7401537, -0.972279), (-2.5275865, -2.7967052), (-2.5920851, -2.8630974), (-1.8046504, -1.0386693), (-1.7401493, -0.9722773), (-2.527582, -2.7967067), (-2.5920835, -2.8631003), (-1.804656, -1.0386697), (-1.7401564, -0.9722723), (-2.5275807, -2.796701), (-2.5920784, -2.8630998), (-1.804657, -1.0386757), (-1.7401624, -0.9722778), (-2.5275855, -2.7966988), (-2.5920813, -2.8630939), (-1.8046545, -1.0386734), (-1.7401563, -0.97228044), (-2.5275831, -2.7967033), (-2.592079, -2.863096), (-1.8046522, -1.0386709), (-1.7401553, -0.9722797), (-2.5275817, -2.7967062), (-2.59208, -2.863098), (-1.8046535, -1.0386713), (-1.7401546, -0.9722776), (-2.5275803, -2.7967036), (-2.5920777, -2.8630984), (-1.8046525, -1.0386729), (-1.7401558, -0.97227806), (-2.527581, -2.7967024), (-2.5920777, -2.863097), (-1.8046538, -1.0386728), (-1.7401576, -0.9722785), (-2.527584, -2.7967024), (-2.5920827, -2.8630955), (-1.8046558, -1.0386708), (-1.7401568, -0.97227716), (-2.5275843, -2.7967026), (-2.592081, -2.8630974), (-1.8046515, -1.0386732), (-1.740154, -0.9722787), (-2.5275848, -2.7967029), (-2.5920837, -2.863097), (-1.8046509, -1.0386709), (-1.7401512, -0.97227657), (-2.5275838, -2.7967038), (-2.5920875, -2.8630974), (-1.8046588, -1.0386683), (-1.7401536, -0.97227407), (-2.527578, -2.7967036), (-2.5920808, -2.863101), (-1.804657, -1.038674), (-1.7401539, -0.97227466), (-2.527578, -2.796699), (-2.5920832, -2.863099), (-1.8046601, -1.0386771), (-1.7401568, -0.9722778), (-2.5275795, -2.7966986), (-2.5920794, -2.8630967), (-1.8046546, -1.0386757), (-1.7401536, -0.97227883), (-2.5275803, -2.7967007), (-2.5920844, -2.863097), (-1.8046575, -1.0386739), (-1.740152, -0.97227687), (-2.5275755, -2.796701), (-2.5920804, -2.863099), (-1.8046596, -1.0386759), (-1.7401583, -0.9722781), (-2.52758, -2.7967), (-2.5920784, -2.8630965), (-1.8046529, -1.0386744), (-1.7401563, -0.97227985), (-2.5275857, -2.7967029), (-2.5920818, -2.863096), (-1.8046505, -1.0386717), (-1.7401537, -0.97227955), (-2.5275853, -2.7967055), (-2.5920844, -2.863096), (-1.8046548, -1.0386683), (-1.7401547, -0.972276), (-2.5275817, -2.7967045), (-2.5920799, -2.8630986), (-1.8046545, -1.0386714), (-1.7401562, -0.97227716), (-2.527582, -2.796703), (-2.592081, -2.8630977), (-1.8046546, -1.0386729), (-1.7401544, -0.9722784), (-2.5275795, -2.7967024), (-2.5920792, -2.8630972), (-1.8046541, -1.0386735), (-1.7401569, -0.97227824), (-2.5275834, -2.7967017), (-2.5920792, -2.8630955), (-1.8046528, -1.0386717), (-1.7401565, -0.9722788), (-2.527581, -2.7967033), (-2.5920773, -2.8630972), (-1.8046552, -1.0386732), (-1.740161, -0.9722784), (-2.527585, -2.796701), (-2.5920792, -2.8630948), (-1.8046523, -1.0386723), (-1.7401555, -0.9722799), (-2.5275836, -2.796704), (-2.5920846, -2.863096), (-1.8046572, -1.0386693), (-1.7401557, -0.9722758), (-2.5275817, -2.7967033), (-2.5920813, -2.8630996), (-1.8046551, -1.038673), (-1.7401558, -0.97227705), (-2.5275817, -2.7967021), (-2.59208, -2.863098), (-1.8046552, -1.0386734), (-1.7401589, -0.9722772), (-2.5275838, -2.7967005), (-2.5920784, -2.8630958), (-1.8046516, -1.0386733), (-1.740156, -0.9722797), (-2.5275838, -2.7967036), (-2.59208, -2.8630958), (-1.8046508, -1.03867), (-1.7401531, -0.97227865), (-2.5275824, -2.7967067), (-2.5920808, -2.8630996), (-1.8046544, -1.0386715), (-1.7401558, -0.9722764), (-2.5275805, -2.796703), (-2.5920792, -2.8630993), (-1.8046551, -1.0386748), (-1.7401569, -0.972278), (-2.527581, -2.7967002), (-2.5920782, -2.8630974), (-1.8046542, -1.0386751), (-1.7401584, -0.97227865), (-2.5275831, -2.796701), (-2.5920768, -2.8630948), (-1.8046509, -1.0386724), (-1.7401587, -0.9722808), (-2.527589, -2.7967043), (-2.5920846, -2.8630948), (-1.8046521, -1.0386674), (-1.740155, -0.9722764), (-2.5275867, -2.7967057), (-2.592084, -2.8630984), (-1.8046507, -1.0386698), (-1.7401512, -0.97227645), (-2.527583, -2.796705), (-2.5920835, -2.8630986), (-1.8046528, -1.0386704), (-1.740152, -0.9722765), (-2.527582, -2.7967048), (-2.5920827, -2.8631), (-1.8046546, -1.0386726), (-1.7401532, -0.97227585), (-2.5275803, -2.7967024), (-2.5920825, -2.8630996), (-1.8046566, -1.0386746), (-1.7401545, -0.9722778), (-2.5275812, -2.7967017), (-2.5920856, -2.8630972), (-1.8046582, -1.0386728), (-1.7401506, -0.9722764), (-2.5275755, -2.7967005), (-2.592085, -2.8630996), (-1.8046632, -1.0386758), (-1.740155, -0.97227454), (-2.5275753, -2.7966971), (-2.5920804, -2.8630993), (-1.804661, -1.0386791), (-1.7401577, -0.97227746), (-2.5275772, -2.7966957), (-2.592077, -2.8630948), (-1.8046559, -1.0386777), (-1.740157, -0.9722828), (-2.5275798, -2.7967017), (-2.5920806, -2.8630943), (-1.8046567, -1.0386723), (-1.7401552, -0.97227895), (-2.5275795, -2.7967026), (-2.5920806, -2.8630972), (-1.804656, -1.0386736), (-1.7401551, -0.9722781), (-2.527579, -2.7967014), (-2.5920806, -2.863098), (-1.8046585, -1.0386745), (-1.7401563, -0.97227687), (-2.5275779, -2.7966998), (-2.592079, -2.863097), (-1.8046575, -1.0386755), (-1.7401602, -0.97227955), (-2.5275831, -2.7967), (-2.5920787, -2.8630931), (-1.8046533, -1.0386719), (-1.7401563, -0.97228056), (-2.5275838, -2.7967043), (-2.5920808, -2.863096), (-1.8046508, -1.0386703), (-1.740154, -0.9722772), (-2.5275834, -2.7967038), (-2.5920794, -2.8630977), (-1.804651, -1.038672), (-1.7401538, -0.9722775), (-2.5275826, -2.796702), (-2.5920823, -2.863097), (-1.8046557, -1.038671), (-1.740156, -0.9722754), (-2.527582, -2.7967021), (-2.5920813, -2.8630989), (-1.8046551, -1.0386739), (-1.7401593, -0.9722769), (-2.5275855, -2.7966993), (-2.5920773, -2.863095), (-1.804648, -1.0386741), (-1.7401551, -0.97228074), (-2.5275872, -2.796704), (-2.5920856, -2.8630955), (-1.8046545, -1.0386682), (-1.7401533, -0.972276), (-2.5275807, -2.7967055), (-2.5920796, -2.8630998), (-1.8046546, -1.0386715), (-1.7401564, -0.9722761), (-2.5275815, -2.7967029), (-2.5920796, -2.8630989), (-1.804655, -1.0386727), (-1.7401568, -0.97227687), (-2.527582, -2.7967017), (-2.5920792, -2.8630977), (-1.8046511, -1.0386744), (-1.7401526, -0.9722789), (-2.5275815, -2.7967021), (-2.5920823, -2.863097), (-1.8046554, -1.038673), (-1.7401564, -0.9722776), (-2.5275817, -2.7967012), (-2.5920794, -2.863097), (-1.8046528, -1.0386734), (-1.7401533, -0.97227895), (-2.5275803, -2.7967036), (-2.5920808, -2.8630981), (-1.8046578, -1.0386728), (-1.7401576, -0.9722767), (-2.5275798, -2.796701), (-2.592082, -2.8630981), (-1.8046592, -1.0386739), (-1.7401558, -0.9722757), (-2.5275786, -2.7967), (-2.592081, -2.8630984), (-1.8046577, -1.0386748), (-1.7401581, -0.97227705), (-2.5275824, -2.7966998), (-2.5920799, -2.8630967), (-1.8046538, -1.0386746), (-1.7401584, -0.9722801), (-2.5275877, -2.7967033), (-2.5920827, -2.8630953), (-1.8046508, -1.0386704), (-1.740153, -0.972279), (-2.5275836, -2.7967055), (-2.5920808, -2.8630974), (-1.8046532, -1.03867), (-1.7401549, -0.97227764), (-2.5275805, -2.7967057), (-2.5920784, -2.8630998), (-1.804651, -1.0386721), (-1.7401528, -0.9722765), (-2.5275812, -2.7967036), (-2.59208, -2.8630993), (-1.8046541, -1.0386733), (-1.7401572, -0.9722768), (-2.527583, -2.7967007), (-2.5920794, -2.8630965), (-1.804652, -1.038673), (-1.7401569, -0.9722784), (-2.527585, -2.796702), (-2.592079, -2.8630958), (-1.8046507, -1.0386714), (-1.7401564, -0.9722783), (-2.5275853, -2.7967036), (-2.5920799, -2.8630962), (-1.8046528, -1.0386711), (-1.7401582, -0.9722789), (-2.5275857, -2.7967036), (-2.592082, -2.8630955), (-1.8046553, -1.0386708), (-1.740157, -0.97227824), (-2.527582, -2.796703), (-2.592082, -2.8630972), (-1.8046577, -1.0386719), (-1.740156, -0.97227585), (-2.5275795, -2.7967012), (-2.5920823, -2.8630993), (-1.8046567, -1.038675), (-1.7401533, -0.9722763), (-2.527578, -2.7967005), (-2.5920792, -2.8630993), (-1.8046563, -1.0386759), (-1.740158, -0.9722789), (-2.5275812, -2.7967007), (-2.592077, -2.8630955), (-1.8046541, -1.0386734), (-1.7401599, -0.972279), (-2.5275836, -2.7967012), (-2.592076, -2.8630946), (-1.8046509, -1.038672), (-1.7401571, -0.9722806), (-2.527584, -2.7967052), (-2.5920796, -2.8630965), (-1.8046508, -1.03867), (-1.7401552, -0.9722785), (-2.5275846, -2.7967057), (-2.5920823, -2.8630977), (-1.8046523, -1.0386693), (-1.7401536, -0.97227603), (-2.5275838, -2.7967052), (-2.5920827, -2.863099), (-1.8046534, -1.0386707), (-1.7401522, -0.9722759), (-2.52758, -2.796703), (-2.592083, -2.8630984), (-1.8046571, -1.0386723), (-1.7401549, -0.9722775), (-2.52758, -2.796703), (-2.5920818, -2.8630984), (-1.8046557, -1.0386723), (-1.7401543, -0.97227615), (-2.527582, -2.7967017), (-2.5920825, -2.863098), (-1.8046538, -1.0386724), (-1.7401533, -0.9722769), (-2.5275812, -2.7967029), (-2.5920823, -2.8630984), (-1.8046573, -1.0386733), (-1.7401563, -0.9722759), (-2.5275815, -2.7966995), (-2.5920825, -2.863097), (-1.8046546, -1.0386742), (-1.7401545, -0.9722781), (-2.527584, -2.7967021), (-2.5920813, -2.8630958), (-1.8046503, -1.0386702), (-1.7401534, -0.9722782), (-2.5275855, -2.7967052), (-2.5920866, -2.863098), (-1.8046571, -1.0386695), (-1.7401552, -0.9722738), (-2.5275812, -2.7967012), (-2.5920806, -2.8630989), (-1.8046554, -1.0386747), (-1.7401565, -0.9722787), (-2.5275815, -2.796702), (-2.5920782, -2.863097), (-1.80465, -1.0386734), (-1.7401518, -0.9722799), (-2.5275815, -2.796705), (-2.592083, -2.8630986), (-1.8046556, -1.0386724), (-1.7401546, -0.9722762), (-2.5275803, -2.7967024), (-2.5920792, -2.8631), (-1.8046538, -1.0386748), (-1.7401556, -0.9722777), (-2.5275812, -2.7967012), (-2.5920792, -2.863097), (-1.8046559, -1.0386741), (-1.7401595, -0.9722795), (-2.5275836, -2.7967014), (-2.5920799, -2.8630943), (-1.804653, -1.0386717), (-1.7401558, -0.97227967), (-2.527584, -2.7967043), (-2.5920808, -2.863097), (-1.8046527, -1.0386711), (-1.740157, -0.9722772), (-2.5275846, -2.796703), (-2.5920813, -2.863097), (-1.8046547, -1.0386708), (-1.7401584, -0.97227645), (-2.5275848, -2.7967026), (-2.5920799, -2.8630974), (-1.8046525, -1.0386716), (-1.7401562, -0.9722782), (-2.5275831, -2.796703), (-2.5920787, -2.8630972), (-1.8046525, -1.0386735), (-1.7401596, -0.9722789), (-2.527588, -2.7967017), (-2.5920804, -2.863096), (-1.8046508, -1.0386729), (-1.7401552, -0.9722794), (-2.527583, -2.7967033), (-2.5920794, -2.863096), (-1.8046539, -1.0386709), (-1.7401584, -0.9722792), (-2.527583, -2.7967043), (-2.592077, -2.8630972), (-1.804651, -1.0386722), (-1.7401569, -0.9722788), (-2.527585, -2.796704), (-2.5920804, -2.863097), (-1.8046519, -1.0386709), (-1.7401556, -0.97227865), (-2.5275848, -2.796705), (-2.5920835, -2.8630972), (-1.8046535, -1.0386708), (-1.7401531, -0.9722782), (-2.5275822, -2.7967048), (-2.592083, -2.8630974), (-1.8046544, -1.0386705), (-1.7401543, -0.9722766), (-2.5275824, -2.7967026), (-2.5920808, -2.8630989), (-1.8046538, -1.0386742), (-1.7401569, -0.9722776), (-2.527583, -2.7967012), (-2.592078, -2.863097), (-1.8046521, -1.0386733), (-1.7401567, -0.97227865), (-2.5275815, -2.7967024), (-2.5920775, -2.8630965), (-1.804654, -1.0386735), (-1.7401596, -0.97227913), (-2.5275853, -2.796702), (-2.592079, -2.8630955), (-1.8046507, -1.0386711), (-1.7401557, -0.97227913), (-2.527586, -2.7967055), (-2.5920842, -2.8630962), (-1.8046539, -1.0386679), (-1.7401559, -0.97227573), (-2.527586, -2.7967052), (-2.5920835, -2.8630986), (-1.8046521, -1.038669), (-1.7401526, -0.972276), (-2.5275817, -2.7967055), (-2.592081, -2.8630993), (-1.8046556, -1.038671), (-1.7401575, -0.9722763), (-2.5275817, -2.7967026), (-2.592077, -2.8630984), (-1.8046517, -1.0386734), (-1.7401576, -0.9722792), (-2.5275836, -2.7967033), (-2.5920777, -2.8630955), (-1.8046517, -1.0386708), (-1.7401586, -0.9722782), (-2.5275862, -2.796703), (-2.5920796, -2.863096), (-1.8046497, -1.0386703), (-1.7401541, -0.97227824), (-2.527586, -2.7967055), (-2.5920844, -2.8630958), (-1.8046538, -1.038667), (-1.7401549, -0.9722778), (-2.5275824, -2.7967083), (-2.592078, -2.8631), (-1.8046516, -1.0386713), (-1.7401572, -0.9722774), (-2.5275853, -2.7967033), (-2.5920804, -2.863097), (-1.8046503, -1.038671), (-1.7401547, -0.97227764), (-2.527585, -2.796704), (-2.5920806, -2.8630981), (-1.804652, -1.0386716), (-1.7401558, -0.9722771), (-2.5275834, -2.7967029), (-2.5920808, -2.863098), (-1.8046559, -1.0386723), (-1.7401589, -0.9722765), (-2.5275838, -2.7967007), (-2.5920794, -2.8630965), (-1.8046535, -1.0386739), (-1.740159, -0.9722793), (-2.5275846, -2.7967026), (-2.5920775, -2.8630958), (-1.8046508, -1.038671), (-1.7401575, -0.97227925), (-2.5275848, -2.7967043), (-2.5920792, -2.8630965), (-1.8046525, -1.0386716), (-1.7401575, -0.9722788), (-2.5275831, -2.796703), (-2.5920777, -2.8630967), (-1.8046519, -1.0386733), (-1.74016, -0.97227955), (-2.5275881, -2.7967029), (-2.5920813, -2.8630953), (-1.8046519, -1.0386705), (-1.7401556, -0.9722787), (-2.5275834, -2.7967052), (-2.59208, -2.863098), (-1.8046541, -1.0386709), (-1.7401578, -0.97227657), (-2.5275831, -2.7967026), (-2.5920782, -2.8630981), (-1.8046519, -1.038673), (-1.740156, -0.97227883), (-2.5275836, -2.796704), (-2.5920804, -2.863097), (-1.8046517, -1.038671), (-1.7401541, -0.9722777), (-2.527582, -2.7967043), (-2.592077, -2.863098), (-1.8046513, -1.038672), (-1.7401583, -0.9722775), (-2.5275853, -2.7967014), (-2.5920796, -2.8630962), (-1.804652, -1.0386736), (-1.7401593, -0.9722799), (-2.5275865, -2.7967024), (-2.5920777, -2.8630953), (-1.8046523, -1.0386729), (-1.740159, -0.97228056), (-2.5275843, -2.7967036), (-2.5920787, -2.8630962), (-1.8046516, -1.038672), (-1.7401565, -0.97227883), (-2.527583, -2.7967038), (-2.592077, -2.8630955), (-1.8046522, -1.038671), (-1.7401612, -0.9722793), (-2.5275886, -2.7967036), (-2.59208, -2.8630958), (-1.8046482, -1.0386697), (-1.7401559, -0.9722793), (-2.527589, -2.7967074), (-2.5920835, -2.8630955), (-1.8046527, -1.0386655), (-1.7401581, -0.9722767), (-2.5275874, -2.7967074), (-2.5920792, -2.8630974), (-1.8046467, -1.0386676), (-1.7401563, -0.9722788), (-2.5275881, -2.7967086), (-2.592077, -2.863097), (-1.8046434, -1.038667), (-1.7401545, -0.9722794), (-2.5275924, -2.796711), (-2.5920844, -2.863097), (-1.8046463, -1.0386628), (-1.7401514, -0.9722767), (-2.527587, -2.7967114), (-2.5920832, -2.8630998), (-1.8046504, -1.0386664), (-1.7401536, -0.97227544), (-2.527585, -2.7967074), (-2.5920827, -2.8631005), (-1.8046525, -1.038669), (-1.7401556, -0.972274), (-2.527585, -2.7967038), (-2.5920832, -2.8630984), (-1.8046546, -1.0386709), (-1.7401546, -0.9722757), (-2.5275824, -2.7967024), (-2.5920806, -2.8630989), (-1.8046534, -1.0386739), (-1.7401575, -0.9722777), (-2.5275836, -2.796702), (-2.5920784, -2.8630967), (-1.804652, -1.0386728), (-1.7401564, -0.9722793), (-2.527583, -2.7967026), (-2.5920799, -2.8630967), (-1.8046526, -1.038673), (-1.7401538, -0.9722786), (-2.5275838, -2.7967026), (-2.5920827, -2.8630967), (-1.8046507, -1.0386715), (-1.7401526, -0.97227746), (-2.5275855, -2.7967036), (-2.592084, -2.863097), (-1.8046521, -1.0386713), (-1.7401527, -0.9722778), (-2.5275836, -2.7967036), (-2.5920832, -2.8630967), (-1.8046527, -1.0386708), (-1.7401532, -0.9722777), (-2.527583, -2.796705), (-2.592083, -2.8630986), (-1.8046546, -1.0386709), (-1.7401546, -0.9722756), (-2.5275824, -2.7967024), (-2.5920818, -2.8630989), (-1.8046554, -1.0386733), (-1.7401577, -0.97227657), (-2.5275846, -2.7967005), (-2.5920823, -2.8630965), (-1.8046536, -1.038673), (-1.7401531, -0.97227806), (-2.5275815, -2.7967021), (-2.5920825, -2.863097), (-1.8046538, -1.0386723), (-1.7401534, -0.97227764), (-2.5275812, -2.7967021), (-2.5920808, -2.863097), (-1.8046541, -1.038673), (-1.7401564, -0.97227776), (-2.5275834, -2.7967021), (-2.5920799, -2.8630974), (-1.8046517, -1.038673), (-1.7401547, -0.97227937), (-2.5275846, -2.796704), (-2.5920818, -2.863097), (-1.8046522, -1.0386709), (-1.7401546, -0.9722776), (-2.527583, -2.796704), (-2.5920813, -2.8630972), (-1.8046551, -1.0386703), (-1.7401575, -0.9722774), (-2.5275836, -2.7967038), (-2.592081, -2.8630984), (-1.8046539, -1.0386721), (-1.7401563, -0.9722776), (-2.5275831, -2.7967036), (-2.5920806, -2.863098), (-1.8046542, -1.0386724), (-1.7401563, -0.9722768), (-2.5275822, -2.7967014), (-2.5920787, -2.8630972), (-1.8046523, -1.0386745), (-1.7401567, -0.97227985), (-2.527583, -2.7967026), (-2.592079, -2.8630967), (-1.8046538, -1.0386732), (-1.7401594, -0.9722787), (-2.5275848, -2.7967021), (-2.592078, -2.8630965), (-1.8046517, -1.038673), (-1.7401575, -0.9722795), (-2.5275824, -2.7967038), (-2.592075, -2.863096), (-1.8046511, -1.0386715), (-1.7401612, -0.9722799), (-2.5275862, -2.7967036), (-2.592077, -2.863095), (-1.8046523, -1.0386703), (-1.7401608, -0.97227913), (-2.5275881, -2.796705), (-2.5920813, -2.8630939), (-1.8046508, -1.0386666), (-1.7401571, -0.9722799), (-2.5275877, -2.7967093), (-2.5920787, -2.8630974), (-1.8046479, -1.0386668), (-1.7401582, -0.97227836), (-2.527589, -2.796709), (-2.5920784, -2.8630974), (-1.8046466, -1.0386667), (-1.740158, -0.97227776), (-2.5275903, -2.7967083), (-2.5920792, -2.8630967), (-1.8046448, -1.0386658), (-1.7401539, -0.9722781), (-2.5275893, -2.7967095), (-2.5920815, -2.863097), (-1.8046472, -1.0386649), (-1.7401555, -0.97227776), (-2.527589, -2.79671), (-2.59208, -2.8630981), (-1.8046471, -1.0386661), (-1.740156, -0.972277), (-2.527589, -2.7967086), (-2.5920799, -2.8630989), (-1.8046473, -1.038668), (-1.7401559, -0.9722781), (-2.5275874, -2.7967079), (-2.5920815, -2.8630967), (-1.8046503, -1.0386672), (-1.7401528, -0.9722765), (-2.5275826, -2.7967055), (-2.592081, -2.8630986), (-1.804654, -1.0386716), (-1.7401568, -0.97227705), (-2.5275836, -2.7967024), (-2.5920813, -2.863098), (-1.8046546, -1.038673), (-1.7401595, -0.97227746), (-2.5275884, -2.796701), (-2.5920813, -2.8630939), (-1.8046491, -1.0386703), (-1.740153, -0.9722793), (-2.5275857, -2.7967057), (-2.5920842, -2.8630972), (-1.8046497, -1.0386683), (-1.7401501, -0.97227675), (-2.5275836, -2.7967062), (-2.592084, -2.8630996), (-1.8046545, -1.0386708), (-1.7401539, -0.9722756), (-2.5275817, -2.7967026), (-2.592082, -2.8630989), (-1.8046558, -1.0386738), (-1.7401563, -0.97227734), (-2.5275805, -2.7967007), (-2.592079, -2.863098), (-1.8046535, -1.0386761), (-1.7401552, -0.9722795), (-2.5275803, -2.796701), (-2.5920799, -2.8630967), (-1.8046556, -1.0386745), (-1.7401565, -0.9722784), (-2.5275815, -2.7967007), (-2.592079, -2.8630953), (-1.8046545, -1.0386727), (-1.7401563, -0.97227836), (-2.5275807, -2.7967021), (-2.592081, -2.8630977), (-1.8046571, -1.038674), (-1.7401541, -0.9722776), (-2.5275788, -2.7967005), (-2.5920844, -2.8630972), (-1.8046598, -1.0386748), (-1.7401537, -0.9722775), (-2.5275776, -2.7966993), (-2.5920832, -2.863098), (-1.8046594, -1.0386751), (-1.7401556, -0.97227645), (-2.5275803, -2.7966993), (-2.592082, -2.8630972), (-1.8046577, -1.0386744), (-1.7401553, -0.97227716), (-2.5275788, -2.7967007), (-2.5920799, -2.8630984), (-1.8046557, -1.0386751), (-1.7401541, -0.9722776), (-2.527579, -2.7967005), (-2.5920813, -2.8630974), (-1.8046557, -1.0386754), (-1.7401549, -0.9722788), (-2.527581, -2.7967005), (-2.5920837, -2.8630965), (-1.8046569, -1.0386736), (-1.7401519, -0.97227776), (-2.5275779, -2.796702), (-2.5920837, -2.863099), (-1.8046596, -1.0386744), (-1.7401541, -0.9722755), (-2.5275764, -2.7967), (-2.5920799, -2.8630986), (-1.8046587, -1.0386754), (-1.7401586, -0.9722777), (-2.5275812, -2.7966995), (-2.5920804, -2.8630955), (-1.8046545, -1.038673), (-1.740155, -0.9722781), (-2.527581, -2.7967024), (-2.5920782, -2.8630972), (-1.8046515, -1.0386726), (-1.7401552, -0.97227937), (-2.5275846, -2.7967048), (-2.5920844, -2.8630955), (-1.8046557, -1.0386678), (-1.7401549, -0.97227687), (-2.527583, -2.7967052), (-2.5920823, -2.8630981), (-1.8046528, -1.0386695), (-1.7401539, -0.97227615), (-2.5275843, -2.7967045), (-2.5920846, -2.863098), (-1.8046558, -1.0386703), (-1.740154, -0.97227556), (-2.5275803, -2.7967029), (-2.592079, -2.8630996), (-1.8046533, -1.0386751), (-1.7401583, -0.9722785), (-2.5275846, -2.7967014), (-2.5920782, -2.863096), (-1.8046507, -1.0386728), (-1.7401568, -0.9722802), (-2.527588, -2.796704), (-2.5920813, -2.8630955), (-1.8046466, -1.0386698), (-1.7401518, -0.9722795), (-2.5275884, -2.796708), (-2.592086, -2.8630974), (-1.8046507, -1.0386655), (-1.7401539, -0.97227556), (-2.5275874, -2.7967083), (-2.5920827, -2.8631), (-1.8046484, -1.0386685), (-1.7401513, -0.9722758), (-2.5275834, -2.7967064), (-2.5920818, -2.8631005), (-1.8046529, -1.0386709), (-1.7401547, -0.9722749), (-2.5275836, -2.7967029), (-2.5920806, -2.8630996), (-1.8046527, -1.0386735), (-1.7401592, -0.97227746), (-2.5275877, -2.7967017), (-2.5920796, -2.8630962), (-1.8046483, -1.0386722), (-1.740152, -0.972279), (-2.5275857, -2.796705), (-2.592087, -2.8630977), (-1.804655, -1.0386688), (-1.7401531, -0.9722751), (-2.527582, -2.7967045), (-2.5920806, -2.8631005), (-1.8046521, -1.0386724), (-1.7401536, -0.972276), (-2.527583, -2.7967029), (-2.5920844, -2.8630986), (-1.804656, -1.0386726), (-1.7401531, -0.9722765), (-2.5275767, -2.7967024), (-2.592079, -2.8630996), (-1.8046602, -1.0386751), (-1.7401606, -0.9722767), (-2.5275793, -2.7966974), (-2.5920765, -2.8630958), (-1.8046559, -1.0386775), (-1.7401601, -0.97228116), (-2.5275824, -2.7966995), (-2.592078, -2.8630939), (-1.8046545, -1.0386736), (-1.7401588, -0.97228), (-2.5275843, -2.7967017), (-2.5920796, -2.8630946), (-1.8046505, -1.0386721), (-1.7401534, -0.9722802), (-2.527582, -2.7967052), (-2.592081, -2.8630972), (-1.8046541, -1.0386704), (-1.7401558, -0.97227657), (-2.527584, -2.7967024), (-2.5920808, -2.8630977), (-1.8046527, -1.0386724), (-1.7401557, -0.9722776), (-2.5275857, -2.796703), (-2.5920842, -2.8630965), (-1.804653, -1.0386702), (-1.7401521, -0.9722769), (-2.5275803, -2.7967045), (-2.5920806, -2.8631), (-1.8046553, -1.0386721), (-1.7401568, -0.9722751), (-2.527582, -2.7967017), (-2.5920808, -2.863098), (-1.8046553, -1.0386724), (-1.7401564, -0.97227746), (-2.5275817, -2.7967024), (-2.5920792, -2.8630967), (-1.8046509, -1.0386723), (-1.7401538, -0.9722792), (-2.5275853, -2.7967045), (-2.592086, -2.8630965), (-1.804654, -1.0386686), (-1.740153, -0.97227585), (-2.5275838, -2.7967055), (-2.5920827, -2.8630998), (-1.8046535, -1.0386714), (-1.740153, -0.9722757), (-2.5275807, -2.7967029), (-2.592081, -2.8631), (-1.8046544, -1.0386746), (-1.7401568, -0.9722772), (-2.5275831, -2.7967012), (-2.5920782, -2.8630972), (-1.8046523, -1.0386745), (-1.7401556, -0.9722797), (-2.5275812, -2.7967029), (-2.5920796, -2.8630972), (-1.8046544, -1.0386727), (-1.7401571, -0.9722778), (-2.5275834, -2.7967024), (-2.592079, -2.8630953), (-1.8046515, -1.0386705), (-1.7401578, -0.97227836), (-2.527587, -2.796704), (-2.5920837, -2.8630955), (-1.804655, -1.0386686), (-1.7401553, -0.97227645), (-2.5275822, -2.796705), (-2.592081, -2.8630993), (-1.8046552, -1.0386715), (-1.7401572, -0.9722765), (-2.5275822, -2.7967021), (-2.5920777, -2.8630972), (-1.8046507, -1.0386728), (-1.7401558, -0.9722795), (-2.5275855, -2.7967043), (-2.5920818, -2.863097), (-1.8046498, -1.0386703), (-1.7401521, -0.97227734), (-2.5275846, -2.7967045), (-2.5920858, -2.8630974), (-1.8046565, -1.0386689), (-1.7401534, -0.9722748), (-2.52758, -2.7967033), (-2.5920799, -2.8631003), (-1.8046542, -1.038675), (-1.7401563, -0.9722768), (-2.527582, -2.7966995), (-2.5920796, -2.863096), (-1.8046542, -1.038674), (-1.7401574, -0.9722795), (-2.5275812, -2.796702), (-2.5920775, -2.8630962), (-1.8046526, -1.0386735), (-1.7401576, -0.9722791), (-2.527585, -2.796702), (-2.59208, -2.8630958), (-1.8046525, -1.0386723), (-1.7401569, -0.9722801), (-2.5275865, -2.796704), (-2.5920835, -2.8630955), (-1.8046519, -1.0386692), (-1.7401539, -0.9722773), (-2.5275834, -2.7967055), (-2.592081, -2.8630984), (-1.8046536, -1.0386709), (-1.7401564, -0.9722766), (-2.5275836, -2.7967029), (-2.5920794, -2.8630965), (-1.8046496, -1.0386705), (-1.7401538, -0.97227854), (-2.5275855, -2.7967057), (-2.5920837, -2.8630981), (-1.804653, -1.0386704), (-1.7401532, -0.9722766), (-2.5275815, -2.7967033), (-2.59208, -2.8630989), (-1.8046538, -1.0386742), (-1.7401571, -0.97227806), (-2.5275843, -2.7967014), (-2.5920808, -2.8630967), (-1.8046534, -1.038673), (-1.7401576, -0.9722774), (-2.527585, -2.7967017), (-2.5920796, -2.863097), (-1.8046509, -1.0386723), (-1.7401553, -0.9722788), (-2.527585, -2.7967036), (-2.5920837, -2.8630972), (-1.8046538, -1.0386722), (-1.7401533, -0.9722784), (-2.5275824, -2.796704), (-2.5920804, -2.8630974), (-1.8046516, -1.0386713), (-1.7401553, -0.97227913), (-2.5275846, -2.7967057), (-2.592084, -2.8630965), (-1.8046567, -1.0386688), (-1.7401562, -0.97227716), (-2.5275836, -2.796705), (-2.5920837, -2.8630981), (-1.8046541, -1.0386705), (-1.7401522, -0.9722772), (-2.5275786, -2.7967045), (-2.5920796, -2.8630996), (-1.8046552, -1.038673), (-1.7401565, -0.9722764), (-2.5275822, -2.7967017), (-2.5920792, -2.8630977), (-1.8046519, -1.0386741), (-1.740153, -0.9722796), (-2.527582, -2.7967036), (-2.5920835, -2.8630972), (-1.8046547, -1.0386721), (-1.7401539, -0.97227806), (-2.5275826, -2.7967033), (-2.5920813, -2.863098), (-1.8046528, -1.0386724), (-1.7401565, -0.97227764), (-2.527585, -2.7967026), (-2.5920818, -2.8630958), (-1.8046529, -1.0386701), (-1.7401558, -0.97227746), (-2.5275843, -2.7967038), (-2.5920827, -2.8630981), (-1.8046566, -1.038672), (-1.7401576, -0.97227675), (-2.5275822, -2.796702), (-2.5920784, -2.8630967), (-1.8046536, -1.0386733), (-1.7401606, -0.97227883), (-2.5275867, -2.7967017), (-2.5920787, -2.8630943), (-1.8046511, -1.0386709), (-1.7401583, -0.9722794), (-2.5275843, -2.7967048), (-2.5920782, -2.8630972), (-1.804653, -1.0386714), (-1.7401578, -0.97227836), (-2.5275834, -2.7967038), (-2.5920777, -2.8630972), (-1.8046519, -1.0386723), (-1.7401571, -0.9722788), (-2.5275822, -2.7967029), (-2.5920765, -2.863097), (-1.8046511, -1.0386734), (-1.740158, -0.97227985), (-2.527585, -2.7967033), (-2.5920768, -2.8630958), (-1.8046498, -1.0386701), (-1.740158, -0.9722778), (-2.5275862, -2.796704), (-2.5920787, -2.863097), (-1.8046497, -1.038671), (-1.7401567, -0.9722787), (-2.527585, -2.7967052), (-2.592081, -2.8630958), (-1.8046525, -1.0386682), (-1.7401545, -0.9722766), (-2.5275855, -2.7967055), (-2.592086, -2.8630984), (-1.8046546, -1.0386682), (-1.7401543, -0.9722744), (-2.527584, -2.7967048), (-2.592082, -2.8630998), (-1.8046534, -1.0386703), (-1.7401545, -0.97227526), (-2.5275822, -2.7967045), (-2.5920792, -2.8631008), (-1.8046521, -1.0386738), (-1.7401558, -0.9722773), (-2.5275836, -2.796702), (-2.5920806, -2.863097), (-1.8046522, -1.0386723), (-1.7401543, -0.97227824), (-2.5275817, -2.7967029), (-2.59208, -2.8630974), (-1.804656, -1.0386728), (-1.7401593, -0.972278), (-2.527584, -2.796702), (-2.5920794, -2.8630965), (-1.8046532, -1.0386739), (-1.7401587, -0.97227937), (-2.5275853, -2.7967017), (-2.5920792, -2.863095), (-1.8046505, -1.0386728), (-1.7401547, -0.9722806), (-2.5275853, -2.796704), (-2.592083, -2.8630958), (-1.8046539, -1.0386701), (-1.7401562, -0.9722777), (-2.527583, -2.7967043), (-2.5920792, -2.8630986), (-1.8046525, -1.038673), (-1.7401563, -0.97227794), (-2.5275826, -2.796702), (-2.592079, -2.863097), (-1.8046541, -1.0386742), (-1.7401594, -0.97227937), (-2.527586, -2.7967012), (-2.5920796, -2.863094), (-1.8046494, -1.0386717), (-1.7401541, -0.97227997), (-2.527584, -2.7967045), (-2.592079, -2.863097), (-1.8046504, -1.0386709), (-1.7401562, -0.97227865), (-2.5275843, -2.7967048), (-2.5920808, -2.8630967), (-1.804654, -1.0386701), (-1.7401577, -0.9722772), (-2.5275846, -2.7967043), (-2.5920806, -2.8630981), (-1.804655, -1.0386717), (-1.7401588, -0.97227687), (-2.5275838, -2.796702), (-2.5920806, -2.8630974), (-1.8046545, -1.0386735), (-1.7401578, -0.97227776), (-2.527584, -2.7967014), (-2.5920794, -2.863097), (-1.804652, -1.0386733), (-1.7401551, -0.97227865), (-2.5275815, -2.7967029), (-2.5920792, -2.8630977), (-1.8046552, -1.0386727), (-1.7401588, -0.97227734), (-2.5275826, -2.7967024), (-2.592078, -2.8630972), (-1.8046513, -1.0386728), (-1.7401563, -0.97227925), (-2.5275853, -2.7967043), (-2.5920823, -2.863096), (-1.8046528, -1.0386695), (-1.7401549, -0.9722771), (-2.527584, -2.7967043), (-2.5920804, -2.863098), (-1.8046521, -1.0386708), (-1.740157, -0.97227633), (-2.527586, -2.7967029), (-2.5920796, -2.8630981), (-1.8046502, -1.0386732), (-1.7401537, -0.97227824), (-2.5275817, -2.796703), (-2.592083, -2.8630984), (-1.8046558, -1.0386724), (-1.7401527, -0.9722766), (-2.5275793, -2.796703), (-2.592083, -2.8630993), (-1.8046583, -1.0386738), (-1.740154, -0.97227633), (-2.527578, -2.7967), (-2.5920808, -2.8630989), (-1.8046575, -1.0386773), (-1.7401575, -0.9722788), (-2.5275793, -2.7966986), (-2.5920787, -2.8630948), (-1.8046573, -1.0386752), (-1.7401593, -0.9722808), (-2.527582, -2.7967017), (-2.5920775, -2.8630943), (-1.8046521, -1.0386721), (-1.7401568, -0.97227997), (-2.5275843, -2.7967029), (-2.5920804, -2.8630958), (-1.8046503, -1.0386714), (-1.7401541, -0.97227794), (-2.5275843, -2.796703), (-2.592082, -2.8630972), (-1.8046521, -1.0386721), (-1.7401524, -0.9722777), (-2.527581, -2.796703), (-2.5920813, -2.8630977), (-1.8046565, -1.0386721), (-1.7401582, -0.97227633), (-2.527583, -2.7967002), (-2.59208, -2.8630965), (-1.8046539, -1.0386732), (-1.7401563, -0.97227883), (-2.5275826, -2.7967026), (-2.5920815, -2.8630967), (-1.8046548, -1.0386717), (-1.7401552, -0.9722768), (-2.5275834, -2.7967021), (-2.5920827, -2.8630958), (-1.8046559, -1.0386701), (-1.7401586, -0.9722777), (-2.5275838, -2.7967036), (-2.5920796, -2.8630967), (-1.8046522, -1.0386717), (-1.7401544, -0.9722779), (-2.527581, -2.7967038), (-2.5920784, -2.8630986), (-1.8046532, -1.0386732), (-1.7401556, -0.97227824), (-2.5275793, -2.7967026), (-2.5920773, -2.8630972), (-1.8046557, -1.0386729), (-1.7401601, -0.9722781), (-2.5275831, -2.7967021), (-2.5920787, -2.8630965), (-1.8046532, -1.0386727), (-1.7401563, -0.9722785), (-2.5275822, -2.7967029), (-2.5920796, -2.8630977), (-1.804654, -1.0386738), (-1.7401577, -0.9722783), (-2.5275846, -2.796701), (-2.5920804, -2.8630958), (-1.8046522, -1.0386722), (-1.7401546, -0.97227806), (-2.5275817, -2.7967026), (-2.5920813, -2.8630974), (-1.8046572, -1.0386733), (-1.7401568, -0.9722768), (-2.5275803, -2.7967002), (-2.5920808, -2.863097), (-1.8046573, -1.0386738), (-1.740157, -0.972278), (-2.5275795, -2.7967012), (-2.5920806, -2.8630977), (-1.8046589, -1.0386739), (-1.7401582, -0.9722773), (-2.5275798, -2.7967007), (-2.592077, -2.8630974), (-1.8046519, -1.0386752), (-1.7401572, -0.97227967), (-2.5275857, -2.7967026), (-2.5920808, -2.863095), (-1.8046494, -1.03867), (-1.740152, -0.9722788), (-2.5275865, -2.7967057), (-2.592085, -2.863098), (-1.8046502, -1.0386692), (-1.740151, -0.97227573), (-2.527582, -2.796705), (-2.5920827, -2.8631008), (-1.8046559, -1.0386727), (-1.740154, -0.97227484), (-2.5275798, -2.7967007), (-2.592083, -2.8630993), (-1.8046576, -1.0386755), (-1.7401534, -0.9722768), (-2.5275767, -2.7966995), (-2.5920813, -2.8630986), (-1.8046608, -1.038677), (-1.7401588, -0.9722784), (-2.5275798, -2.796698), (-2.5920796, -2.8630948), (-1.8046556, -1.0386763), (-1.7401553, -0.97228134), (-2.5275812, -2.7967026), (-2.5920808, -2.8630958), (-1.8046551, -1.0386719), (-1.7401555, -0.97227895), (-2.527581, -2.7967036), (-2.5920806, -2.863098), (-1.8046558, -1.0386723), (-1.7401563, -0.9722769), (-2.5275805, -2.7967021), (-2.5920804, -2.8630977), (-1.8046548, -1.0386738), (-1.7401555, -0.9722785), (-2.5275798, -2.796702), (-2.5920773, -2.8630974), (-1.804654, -1.0386732), (-1.7401593, -0.9722772), (-2.5275843, -2.7967002), (-2.5920768, -2.8630955), (-1.8046522, -1.0386734), (-1.7401625, -0.97227985), (-2.5275881, -2.7967026), (-2.5920787, -2.863094), (-1.8046494, -1.0386708), (-1.7401547, -0.9722802), (-2.5275848, -2.7967055), (-2.592082, -2.8630962), (-1.804653, -1.0386685), (-1.7401536, -0.97227633), (-2.5275826, -2.7967038), (-2.5920823, -2.8630986), (-1.8046552, -1.0386727), (-1.7401565, -0.9722766), (-2.5275824, -2.796701), (-2.59208, -2.8630967), (-1.8046522, -1.0386732), (-1.7401531, -0.972279), (-2.5275803, -2.7967036), (-2.592079, -2.8630974), (-1.8046521, -1.0386726), (-1.740155, -0.9722782), (-2.5275822, -2.7967029), (-2.592082, -2.8630972), (-1.8046577, -1.0386722), (-1.7401574, -0.9722771), (-2.5275807, -2.7967012), (-2.5920794, -2.863097), (-1.8046544, -1.0386732), (-1.7401581, -0.97227764), (-2.5275853, -2.7967005), (-2.592081, -2.8630953), (-1.8046538, -1.0386727), (-1.7401572, -0.9722794), (-2.5275815, -2.7967033), (-2.5920782, -2.8630965), (-1.8046553, -1.0386724), (-1.7401593, -0.9722797), (-2.5275831, -2.7967033), (-2.592079, -2.8630955), (-1.8046536, -1.0386717), (-1.7401574, -0.9722788), (-2.5275817, -2.7967029), (-2.5920775, -2.863097), (-1.8046507, -1.0386732), (-1.7401532, -0.97227865), (-2.5275822, -2.7967029), (-2.5920818, -2.8630977), (-1.8046525, -1.0386732), (-1.7401546, -0.972278), (-2.5275846, -2.7967024), (-2.5920804, -2.8630967), (-1.804652, -1.0386721), (-1.7401555, -0.9722777), (-2.5275822, -2.7967026), (-2.592081, -2.863098), (-1.8046583, -1.0386726), (-1.7401592, -0.9722763), (-2.5275817, -2.7967005), (-2.5920827, -2.8630977), (-1.8046569, -1.0386748), (-1.7401546, -0.9722776), (-2.5275807, -2.7967005), (-2.5920804, -2.8630967), (-1.8046546, -1.0386739), (-1.7401586, -0.9722796), (-2.5275848, -2.796703), (-2.5920782, -2.8630946), (-1.8046511, -1.0386698), (-1.7401568, -0.9722801), (-2.5275862, -2.796706), (-2.592082, -2.863096), (-1.8046497, -1.0386679), (-1.7401522, -0.97227764), (-2.5275846, -2.7967072), (-2.5920813, -2.863099), (-1.8046494, -1.0386705), (-1.7401526, -0.97227705), (-2.527583, -2.796704), (-2.5920799, -2.8630986), (-1.8046528, -1.0386727), (-1.7401562, -0.9722771), (-2.5275838, -2.7967021), (-2.5920808, -2.8630972), (-1.804652, -1.0386728), (-1.7401544, -0.9722784), (-2.5275846, -2.7967026), (-2.5920827, -2.8630972), (-1.8046507, -1.0386722), (-1.7401512, -0.97227716), (-2.5275846, -2.7967029), (-2.592087, -2.863098), (-1.8046561, -1.0386708), (-1.7401539, -0.9722745), (-2.5275815, -2.796702), (-2.5920818, -2.8630998), (-1.8046542, -1.0386739), (-1.7401555, -0.97227585), (-2.5275838, -2.7967014), (-2.592083, -2.8630981), (-1.8046564, -1.0386727), (-1.740157, -0.97227615), (-2.5275822, -2.7967005), (-2.5920815, -2.863097), (-1.8046557, -1.0386733), (-1.7401547, -0.9722776), (-2.5275795, -2.7967017), (-2.592082, -2.8630974), (-1.8046569, -1.0386734), (-1.7401541, -0.9722779), (-2.5275798, -2.7967012), (-2.5920818, -2.8630977), (-1.8046559, -1.0386753), (-1.740155, -0.9722792), (-2.5275815, -2.7967017), (-2.5920804, -2.8630967), (-1.804653, -1.0386732), (-1.7401528, -0.9722792), (-2.5275788, -2.7967045), (-2.5920787, -2.8630977), (-1.8046535, -1.0386711), (-1.7401563, -0.972278), (-2.5275838, -2.7967043), (-2.592082, -2.8630972), (-1.8046528, -1.0386702), (-1.740154, -0.97227734), (-2.5275838, -2.796705), (-2.5920815, -2.8630989), (-1.804653, -1.038671), (-1.7401557, -0.9722767), (-2.527585, -2.796703), (-2.5920825, -2.8630965), (-1.8046529, -1.0386704), (-1.740155, -0.9722781), (-2.5275822, -2.7967048), (-2.5920806, -2.8630984), (-1.8046547, -1.0386722), (-1.7401564, -0.9722774), (-2.5275826, -2.7967029), (-2.5920813, -2.8630981), (-1.8046551, -1.0386729), (-1.7401564, -0.97227716), (-2.5275824, -2.7967024), (-2.5920806, -2.8630981), (-1.8046566, -1.038673), (-1.7401576, -0.97227776), (-2.52758, -2.7967029), (-2.5920796, -2.8630972), (-1.8046548, -1.0386721), (-1.7401559, -0.9722777), (-2.5275824, -2.796703), (-2.5920796, -2.8630965), (-1.8046519, -1.0386698), (-1.7401563, -0.97227746), (-2.527585, -2.796705), (-2.5920813, -2.8630974), (-1.8046521, -1.0386704), (-1.7401553, -0.972278), (-2.5275857, -2.7967048), (-2.592085, -2.863097), (-1.8046535, -1.0386692), (-1.7401507, -0.9722764), (-2.5275779, -2.7967055), (-2.5920799, -2.8630993), (-1.8046561, -1.038671), (-1.7401586, -0.9722765), (-2.5275831, -2.7967024), (-2.592078, -2.8630958), (-1.8046513, -1.0386709), (-1.740157, -0.9722798), (-2.5275853, -2.7967055), (-2.5920823, -2.8630967), (-1.8046547, -1.0386701), (-1.7401551, -0.97227657), (-2.5275826, -2.7967026), (-2.5920827, -2.8630984), (-1.8046547, -1.0386734), (-1.7401538, -0.97227734), (-2.5275803, -2.796702), (-2.5920804, -2.8630977), (-1.8046541, -1.0386742), (-1.7401562, -0.9722788), (-2.527583, -2.7967014), (-2.5920784, -2.8630962), (-1.8046519, -1.0386738), (-1.7401576, -0.9722802), (-2.5275857, -2.7967043), (-2.5920804, -2.863097), (-1.8046517, -1.038671), (-1.7401555, -0.97227764), (-2.5275824, -2.7967036), (-2.592077, -2.8630981), (-1.8046515, -1.0386732), (-1.7401625, -0.9722779), (-2.527592, -2.796701), (-2.5920818, -2.8630939), (-1.8046496, -1.0386705), (-1.7401546, -0.9722801), (-2.5275843, -2.796706), (-2.5920813, -2.8630977), (-1.8046516, -1.0386709), (-1.7401538, -0.9722772), (-2.5275834, -2.796703), (-2.5920799, -2.8630981), (-1.8046538, -1.0386727), (-1.7401581, -0.97227734), (-2.5275838, -2.7967024), (-2.5920784, -2.8630972), (-1.8046521, -1.0386722), (-1.7401582, -0.97227836), (-2.5275853, -2.7967033), (-2.5920796, -2.8630958), (-1.804651, -1.0386701), (-1.740156, -0.9722787), (-2.5275843, -2.7967055), (-2.5920806, -2.8630974), (-1.8046553, -1.0386703), (-1.7401588, -0.9722769), (-2.5275836, -2.7967036), (-2.5920787, -2.8630984), (-1.8046528, -1.0386733), (-1.7401575, -0.9722781), (-2.527583, -2.7967017), (-2.592078, -2.8630962), (-1.8046533, -1.0386735), (-1.7401583, -0.97227997), (-2.5275817, -2.796703), (-2.5920768, -2.8630955), (-1.8046538, -1.0386722), (-1.7401595, -0.9722798), (-2.5275834, -2.796703), (-2.5920768, -2.8630946), (-1.8046521, -1.0386709), (-1.7401586, -0.9722794), (-2.5275831, -2.7967045), (-2.5920777, -2.8630967), (-1.8046522, -1.038671), (-1.7401568, -0.97227836), (-2.5275834, -2.7967036), (-2.5920799, -2.8630974), (-1.8046534, -1.0386727), (-1.7401564, -0.9722785), (-2.5275824, -2.7967029), (-2.592081, -2.8630977), (-1.8046582, -1.0386724), (-1.7401593, -0.9722769), (-2.5275815, -2.796702), (-2.5920799, -2.8630965), (-1.804655, -1.038672), (-1.7401568, -0.9722776), (-2.5275822, -2.796703), (-2.592079, -2.8630962), (-1.8046527, -1.03867), (-1.740157, -0.97227734), (-2.5275846, -2.7967043), (-2.5920808, -2.8630967), (-1.8046528, -1.0386695), (-1.7401557, -0.9722782), (-2.5275834, -2.7967057), (-2.5920796, -2.863098), (-1.8046536, -1.0386708), (-1.7401574, -0.9722765), (-2.5275838, -2.7967024), (-2.5920792, -2.8630974), (-1.804651, -1.038673), (-1.7401549, -0.97227854), (-2.5275824, -2.7967026), (-2.5920808, -2.8630972), (-1.8046553, -1.038673), (-1.7401583, -0.97227716), (-2.5275846, -2.7967007), (-2.5920794, -2.863097), (-1.8046513, -1.038674), (-1.7401563, -0.97227937), (-2.527586, -2.7967029), (-2.592082, -2.863097), (-1.8046521, -1.0386722), (-1.7401545, -0.9722789), (-2.527584, -2.7967043), (-2.5920815, -2.863097), (-1.8046521, -1.038671), (-1.7401541, -0.97227806), (-2.5275826, -2.7967045), (-2.5920794, -2.863098), (-1.8046515, -1.0386711), (-1.7401569, -0.9722778), (-2.527586, -2.7967045), (-2.5920835, -2.863097), (-1.8046535, -1.0386698), (-1.7401521, -0.9722778), (-2.52758, -2.7967062), (-2.5920813, -2.8630993), (-1.8046564, -1.0386707), (-1.7401575, -0.97227544), (-2.5275826, -2.7967026), (-2.5920813, -2.863099), (-1.8046554, -1.0386735), (-1.7401568, -0.9722773), (-2.5275824, -2.796701), (-2.5920784, -2.8630967), (-1.8046527, -1.0386745), (-1.7401593, -0.9722809), (-2.5275865, -2.7967036), (-2.5920799, -2.8630953), (-1.8046525, -1.038671), (-1.7401575, -0.9722795), (-2.527583, -2.7967048), (-2.5920787, -2.8630962), (-1.8046533, -1.0386708), (-1.7401574, -0.972278), (-2.5275834, -2.7967024), (-2.5920775, -2.8630962), (-1.8046504, -1.0386728), (-1.7401574, -0.97227997), (-2.5275846, -2.7967045), (-2.5920808, -2.863096), (-1.8046542, -1.0386705), (-1.7401567, -0.9722778), (-2.5275826, -2.7967033), (-2.592078, -2.8630977), (-1.8046513, -1.0386722), (-1.7401562, -0.97227865), (-2.5275822, -2.7967045), (-2.5920784, -2.8630967), (-1.8046514, -1.03867), (-1.7401551, -0.9722781), (-2.527586, -2.7967057), (-2.5920832, -2.8630984), (-1.804651, -1.0386698), (-1.7401526, -0.97227526), (-2.5275848, -2.7967036), (-2.5920856, -2.8630996), (-1.8046564, -1.0386714), (-1.7401547, -0.9722741), (-2.527581, -2.7967012), (-2.5920813, -2.8630986), (-1.8046566, -1.0386745), (-1.740158, -0.97227716), (-2.527583, -2.7967005), (-2.592081, -2.863097), (-1.8046548, -1.0386733), (-1.7401552, -0.9722776), (-2.5275826, -2.7967014), (-2.592081, -2.8630972), (-1.8046523, -1.0386734), (-1.7401544, -0.9722779), (-2.5275843, -2.7967017), (-2.5920823, -2.8630974), (-1.804651, -1.0386738), (-1.7401532, -0.9722791), (-2.5275857, -2.796703), (-2.5920842, -2.8630958), (-1.8046521, -1.0386695), (-1.7401532, -0.9722775), (-2.5275836, -2.7967057), (-2.5920818, -2.8630986), (-1.8046509, -1.0386702), (-1.7401521, -0.97227633), (-2.527583, -2.7967045), (-2.5920806, -2.8630989), (-1.8046517, -1.0386704), (-1.7401557, -0.9722755), (-2.527585, -2.7967036), (-2.5920835, -2.863099), (-1.804654, -1.0386717), (-1.7401526, -0.9722756), (-2.5275795, -2.7967029), (-2.5920813, -2.8630998), (-1.8046558, -1.0386733), (-1.7401549, -0.9722754), (-2.5275805, -2.7967014), (-2.5920808, -2.863099), (-1.8046556, -1.0386732), (-1.7401569, -0.97227573), (-2.5275836, -2.7967002), (-2.592082, -2.8630967), (-1.8046539, -1.0386738), (-1.7401563, -0.97227824), (-2.5275831, -2.7967012), (-2.592079, -2.8630962), (-1.8046522, -1.0386738), (-1.7401592, -0.9722801), (-2.527588, -2.7967026), (-2.5920806, -2.8630946), (-1.8046511, -1.0386702), (-1.7401565, -0.97227925), (-2.527585, -2.7967052), (-2.5920818, -2.8630965), (-1.8046525, -1.0386702), (-1.7401541, -0.97227746), (-2.5275822, -2.7967045), (-2.5920782, -2.8630993), (-1.8046502, -1.038673), (-1.7401527, -0.9722782), (-2.5275826, -2.7967038), (-2.592082, -2.8630981), (-1.8046538, -1.0386722), (-1.7401558, -0.9722766), (-2.5275836, -2.7967017), (-2.5920813, -2.8630977), (-1.8046508, -1.0386733), (-1.7401533, -0.97227794), (-2.5275855, -2.7967026), (-2.5920837, -2.8630974), (-1.8046542, -1.038672), (-1.7401559, -0.9722767), (-2.5275838, -2.796702), (-2.5920832, -2.8630977), (-1.804654, -1.0386733), (-1.7401558, -0.9722782), (-2.5275846, -2.7967021), (-2.5920796, -2.8630965), (-1.8046507, -1.0386719), (-1.7401555, -0.9722785), (-2.5275862, -2.7967038), (-2.592083, -2.8630965), (-1.8046511, -1.0386709), (-1.7401533, -0.9722775), (-2.5275846, -2.7967048), (-2.5920825, -2.8630981), (-1.8046541, -1.0386698), (-1.7401564, -0.9722764), (-2.5275826, -2.7967043), (-2.5920799, -2.8630981), (-1.8046544, -1.0386704), (-1.7401574, -0.97227687), (-2.5275824, -2.7967038), (-2.5920775, -2.8630981), (-1.8046514, -1.0386726), (-1.7401563, -0.97227746), (-2.5275834, -2.7967021), (-2.5920806, -2.8630974), (-1.8046536, -1.0386733), (-1.7401537, -0.9722789), (-2.5275793, -2.7967033), (-2.5920792, -2.8630972), (-1.8046536, -1.0386724), (-1.7401553, -0.97227824), (-2.527582, -2.7967029), (-2.5920818, -2.8630974), (-1.8046589, -1.0386729), (-1.7401594, -0.9722773), (-2.5275807, -2.7967007), (-2.5920787, -2.8630967), (-1.8046557, -1.0386745), (-1.7401584, -0.9722789), (-2.527584, -2.7967014), (-2.5920804, -2.8630958), (-1.8046522, -1.0386723), (-1.740155, -0.9722785), (-2.5275824, -2.796703), (-2.5920792, -2.8630972), (-1.8046536, -1.0386735), (-1.7401602, -0.97227865), (-2.5275877, -2.7967014), (-2.59208, -2.8630953), (-1.8046514, -1.0386721), (-1.7401578, -0.97227865), (-2.527586, -2.7967029), (-2.5920806, -2.863096), (-1.8046511, -1.0386711), (-1.7401555, -0.97228014), (-2.527587, -2.796706), (-2.592083, -2.8630972), (-1.8046522, -1.0386693), (-1.7401558, -0.97227705), (-2.527584, -2.7967055), (-2.59208, -2.8630986), (-1.804652, -1.0386711), (-1.740154, -0.9722776), (-2.5275817, -2.7967043), (-2.5920787, -2.8630986), (-1.8046511, -1.0386732), (-1.7401559, -0.97227895), (-2.5275843, -2.796704), (-2.5920799, -2.8630972), (-1.8046498, -1.0386711), (-1.7401543, -0.97227776), (-2.5275838, -2.7967038), (-2.5920804, -2.8630972), (-1.8046516, -1.0386711), (-1.7401556, -0.9722776), (-2.527584, -2.7967038), (-2.5920808, -2.8630984), (-1.8046538, -1.0386721), (-1.7401562, -0.9722776), (-2.5275834, -2.7967036), (-2.59208, -2.863097), (-1.8046528, -1.0386708), (-1.7401565, -0.9722774), (-2.5275846, -2.796703), (-2.5920823, -2.8630958), (-1.8046545, -1.03867), (-1.7401547, -0.97227645), (-2.5275831, -2.7967036), (-2.5920832, -2.863098), (-1.8046557, -1.0386709), (-1.7401572, -0.97227615), (-2.527583, -2.7967026), (-2.592081, -2.863098), (-1.8046556, -1.0386724), (-1.7401565, -0.97227794), (-2.5275822, -2.7967026), (-2.5920818, -2.8630972), (-1.8046538, -1.0386723), (-1.7401527, -0.97227794), (-2.5275822, -2.7967038), (-2.5920815, -2.8630984), (-1.8046534, -1.0386724), (-1.7401555, -0.9722771), (-2.5275822, -2.7967026), (-2.5920804, -2.8630984), (-1.8046546, -1.0386733), (-1.7401595, -0.9722777), (-2.5275867, -2.7967017), (-2.5920792, -2.8630962), (-1.8046485, -1.038672), (-1.740155, -0.9722796), (-2.527587, -2.796706), (-2.5920825, -2.8630967), (-1.8046496, -1.0386684), (-1.7401518, -0.9722778), (-2.527584, -2.7967072), (-2.5920808, -2.8630981), (-1.804649, -1.0386701), (-1.7401522, -0.9722776), (-2.527585, -2.7967045), (-2.5920854, -2.8630974), (-1.8046553, -1.0386698), (-1.7401526, -0.9722751), (-2.527579, -2.7967024), (-2.592081, -2.8630996), (-1.8046572, -1.0386744), (-1.7401571, -0.9722776), (-2.5275795, -2.796701), (-2.5920784, -2.8630965), (-1.8046548, -1.038674), (-1.740158, -0.9722795), (-2.5275831, -2.7967026), (-2.5920804, -2.8630962), (-1.8046548, -1.0386723), (-1.7401553, -0.97227824), (-2.527579, -2.796702), (-2.5920765, -2.8630967), (-1.8046528, -1.0386734), (-1.7401578, -0.9722789), (-2.5275853, -2.7967029), (-2.5920815, -2.8630955), (-1.8046519, -1.0386696), (-1.7401556, -0.9722771), (-2.5275846, -2.7967043), (-2.5920827, -2.8630967), (-1.8046534, -1.0386683), (-1.7401537, -0.9722764), (-2.5275848, -2.796705), (-2.5920863, -2.8630981), (-1.8046553, -1.0386692), (-1.7401531, -0.9722743), (-2.527581, -2.7967033), (-2.5920808, -2.8631), (-1.8046564, -1.0386736), (-1.7401584, -0.9722765), (-2.5275831, -2.7967007), (-2.5920804, -2.863097), (-1.8046541, -1.0386733), (-1.7401565, -0.97227883), (-2.5275815, -2.796703), (-2.5920768, -2.8630958), (-1.8046533, -1.0386707), (-1.74016, -0.9722789), (-2.527584, -2.796705), (-2.5920784, -2.8630972), (-1.8046528, -1.0386715), (-1.7401574, -0.97227895), (-2.527582, -2.7967038), (-2.5920758, -2.863097), (-1.8046504, -1.0386728), (-1.7401577, -0.97228), (-2.5275877, -2.796704), (-2.5920818, -2.8630958), (-1.804649, -1.0386702), (-1.7401522, -0.97227794), (-2.5275862, -2.7967057), (-2.592086, -2.8630977), (-1.8046542, -1.0386689), (-1.7401537, -0.97227675), (-2.5275815, -2.7967052), (-2.5920818, -2.8630993), (-1.8046551, -1.0386728), (-1.7401552, -0.9722772), (-2.5275815, -2.7967024), (-2.59208, -2.8630977), (-1.8046536, -1.0386734), (-1.7401551, -0.97227937), (-2.527583, -2.7967038), (-2.5920832, -2.8630958), (-1.8046551, -1.0386698), (-1.740153, -0.9722783), (-2.52758, -2.7967052), (-2.5920832, -2.8630974), (-1.8046566, -1.0386701), (-1.7401547, -0.9722778), (-2.527582, -2.7967052), (-2.592082, -2.863098), (-1.8046556, -1.0386702), (-1.7401556, -0.97227687), (-2.5275815, -2.7967043), (-2.5920808, -2.863099), (-1.8046551, -1.0386732), (-1.7401568, -0.9722778), (-2.5275824, -2.7967024), (-2.5920806, -2.8630967), (-1.8046541, -1.0386721), (-1.7401558, -0.97227836), (-2.5275817, -2.7967036), (-2.5920794, -2.8630974), (-1.804654, -1.0386727), (-1.7401567, -0.9722784), (-2.5275838, -2.7967026), (-2.5920818, -2.8630974), (-1.8046525, -1.0386738), (-1.7401526, -0.9722793), (-2.527583, -2.7967036), (-2.5920846, -2.8630974), (-1.8046569, -1.0386717), (-1.7401559, -0.972277), (-2.5275815, -2.7967029), (-2.5920775, -2.8630981), (-1.8046505, -1.038673), (-1.740154, -0.9722781), (-2.527582, -2.7967026), (-2.5920815, -2.863097), (-1.804656, -1.0386724), (-1.7401574, -0.9722769), (-2.5275822, -2.7967007), (-2.5920815, -2.8630965), (-1.8046554, -1.0386721), (-1.7401556, -0.9722768), (-2.5275826, -2.7967024), (-2.592082, -2.8630977), (-1.8046532, -1.0386722), (-1.7401531, -0.9722766), (-2.5275826, -2.796702), (-2.5920844, -2.8630977), (-1.804657, -1.0386726), (-1.7401536, -0.9722762), (-2.5275803, -2.7967012), (-2.5920856, -2.8630993), (-1.8046594, -1.0386742), (-1.7401532, -0.9722753), (-2.5275784, -2.7967), (-2.592083, -2.8630998), (-1.8046584, -1.0386767), (-1.7401553, -0.9722769), (-2.52758, -2.7966988), (-2.592081, -2.8630977), (-1.8046538, -1.0386761), (-1.7401538, -0.9722784), (-2.527583, -2.7967007), (-2.5920815, -2.8630965), (-1.8046519, -1.038673), (-1.7401527, -0.97227865), (-2.5275846, -2.796703), (-2.5920863, -2.863097), (-1.8046535, -1.0386707), (-1.7401489, -0.97227645), (-2.527578, -2.796704), (-2.5920835, -2.8631005), (-1.8046584, -1.0386728), (-1.7401536, -0.972274), (-2.5275764, -2.7967005), (-2.5920808, -2.8630993), (-1.80466, -1.0386754), (-1.740159, -0.9722774), (-2.5275803, -2.7966998), (-2.5920784, -2.8630958), (-1.804655, -1.0386739), (-1.740158, -0.9722793), (-2.5275836, -2.7967024), (-2.5920792, -2.8630965), (-1.8046525, -1.038673), (-1.7401549, -0.9722797), (-2.527581, -2.7967043), (-2.5920808, -2.863098), (-1.8046567, -1.0386721), (-1.7401568, -0.9722765), (-2.5275805, -2.7967007), (-2.5920796, -2.8630984), (-1.8046554, -1.038676), (-1.7401584, -0.9722782), (-2.5275831, -2.796699), (-2.5920792, -2.8630943), (-1.8046525, -1.0386733), (-1.7401569, -0.9722809), (-2.5275857, -2.796704), (-2.59208, -2.8630958), (-1.804649, -1.0386701), (-1.7401528, -0.9722787), (-2.5275862, -2.7967062), (-2.5920823, -2.863096), (-1.8046478, -1.0386672), (-1.740153, -0.97227734), (-2.5275872, -2.7967067), (-2.5920827, -2.8630981), (-1.8046495, -1.0386683), (-1.7401526, -0.97227633), (-2.527585, -2.7967067), (-2.5920825, -2.8630993), (-1.8046514, -1.0386696), (-1.7401538, -0.972276), (-2.5275857, -2.7967048), (-2.5920868, -2.8630986), (-1.8046546, -1.0386698), (-1.7401503, -0.97227395), (-2.5275798, -2.7967029), (-2.5920844, -2.8631017), (-1.8046582, -1.0386741), (-1.7401544, -0.972274), (-2.5275786, -2.796699), (-2.5920823, -2.8630989), (-1.8046603, -1.0386761), (-1.7401584, -0.9722771), (-2.527579, -2.7966988), (-2.5920784, -2.863097), (-1.8046567, -1.0386751), (-1.7401583, -0.97227824), (-2.527581, -2.7967002), (-2.5920784, -2.8630955), (-1.8046552, -1.0386735), (-1.7401572, -0.9722803), (-2.5275815, -2.7967036), (-2.5920794, -2.8630965), (-1.8046526, -1.0386714), (-1.7401547, -0.972278), (-2.5275815, -2.796704), (-2.5920784, -2.8630984), (-1.8046526, -1.0386723), (-1.740157, -0.9722781), (-2.5275836, -2.7967036), (-2.592079, -2.8630965), (-1.8046516, -1.0386705), (-1.7401567, -0.9722785), (-2.5275855, -2.796705), (-2.5920825, -2.8630962), (-1.8046535, -1.0386689), (-1.740153, -0.9722767), (-2.5275795, -2.7967045), (-2.5920796, -2.8630998), (-1.8046554, -1.0386734), (-1.7401577, -0.9722774), (-2.5275834, -2.7967017), (-2.5920806, -2.863096), (-1.8046529, -1.0386717), (-1.7401546, -0.97227794), (-2.5275836, -2.7967033), (-2.592083, -2.8630965), (-1.8046561, -1.0386705), (-1.7401574, -0.97227794), (-2.527583, -2.796704), (-2.5920794, -2.8630965), (-1.8046513, -1.03867), (-1.7401556, -0.97227836), (-2.5275838, -2.7967057), (-2.5920804, -2.863098), (-1.8046551, -1.0386709), (-1.7401589, -0.9722765), (-2.5275846, -2.7967021), (-2.5920794, -2.863097), (-1.8046511, -1.0386723), (-1.740155, -0.9722777), (-2.527582, -2.7967026), (-2.592081, -2.8630981), (-1.8046561, -1.0386729), (-1.7401568, -0.9722763), (-2.527582, -2.7967007), (-2.5920806, -2.863097), (-1.8046541, -1.0386733), (-1.7401584, -0.97227854), (-2.527588, -2.796702), (-2.5920823, -2.8630946), (-1.8046503, -1.0386708), (-1.7401525, -0.9722797), (-2.5275843, -2.7967057), (-2.5920835, -2.8630981), (-1.8046505, -1.0386696), (-1.7401502, -0.97227633), (-2.5275803, -2.7967064), (-2.592079, -2.8630998), (-1.8046523, -1.0386703), (-1.7401541, -0.9722766), (-2.5275817, -2.796704), (-2.5920792, -2.8630986), (-1.8046521, -1.038673), (-1.7401558, -0.97227794), (-2.5275822, -2.796702), (-2.5920782, -2.863097), (-1.8046527, -1.0386733), (-1.7401572, -0.97227865), (-2.527583, -2.7967021), (-2.5920799, -2.8630967), (-1.8046559, -1.038674), (-1.7401605, -0.97227925), (-2.527586, -2.7967017), (-2.5920815, -2.863095), (-1.8046558, -1.0386716), (-1.7401602, -0.97227865), (-2.5275857, -2.7967036), (-2.5920808, -2.8630965), (-1.8046521, -1.0386709), (-1.7401558, -0.9722788), (-2.527586, -2.7967052), (-2.5920835, -2.8630972), (-1.804655, -1.0386707), (-1.7401552, -0.972277), (-2.5275805, -2.796703), (-2.592078, -2.8630989), (-1.8046523, -1.0386742), (-1.7401581, -0.9722791), (-2.5275862, -2.796703), (-2.5920806, -2.8630958), (-1.8046513, -1.038671), (-1.7401553, -0.9722793), (-2.5275843, -2.7967052), (-2.5920784, -2.8630981), (-1.8046489, -1.0386719), (-1.7401547, -0.97227794), (-2.5275836, -2.796704), (-2.59208, -2.8630974), (-1.8046514, -1.0386717), (-1.7401538, -0.9722779), (-2.5275831, -2.7967029), (-2.592081, -2.8630972), (-1.804654, -1.0386721), (-1.7401571, -0.9722776), (-2.5275836, -2.7967029), (-2.5920794, -2.8630977), (-1.8046501, -1.0386734), (-1.7401549, -0.9722787), (-2.5275846, -2.7967026), (-2.59208, -2.8630967), (-1.8046519, -1.0386721), (-1.7401582, -0.9722784), (-2.5275898, -2.7967033), (-2.592084, -2.8630962), (-1.8046483, -1.0386698), (-1.7401521, -0.9722789), (-2.5275903, -2.7967074), (-2.5920908, -2.8630955), (-1.8046532, -1.0386634), (-1.7401506, -0.97227347), (-2.5275846, -2.7967072), (-2.5920846, -2.863102), (-1.8046513, -1.0386708), (-1.7401507, -0.97227407), (-2.527583, -2.7967024), (-2.5920851, -2.8630998), (-1.8046544, -1.0386735), (-1.7401514, -0.9722756), (-2.527579, -2.796701), (-2.592082, -2.8630993), (-1.8046582, -1.0386758), (-1.7401558, -0.9722769), (-2.5275798, -2.7966983), (-2.5920794, -2.8630967), (-1.8046534, -1.0386759), (-1.7401539, -0.972279), (-2.52758, -2.7967012), (-2.592079, -2.863097), (-1.8046553, -1.0386742), (-1.7401556, -0.97227865), (-2.527579, -2.796701), (-2.5920815, -2.863097), (-1.8046582, -1.0386745), (-1.7401568, -0.9722778), (-2.5275795, -2.7967002), (-2.5920782, -2.8630967), (-1.8046548, -1.0386755), (-1.7401552, -0.9722798), (-2.5275812, -2.796701), (-2.5920825, -2.8630953), (-1.8046569, -1.0386719), (-1.7401578, -0.97227776), (-2.5275822, -2.7967017), (-2.5920787, -2.8630962), (-1.804653, -1.0386728), (-1.7401572, -0.97227865), (-2.5275836, -2.7967021), (-2.592081, -2.863096), (-1.804655, -1.038673), (-1.7401572, -0.9722784), (-2.5275846, -2.796701), (-2.5920813, -2.8630955), (-1.8046532, -1.0386729), (-1.7401555, -0.9722796), (-2.5275824, -2.7967038), (-2.5920777, -2.863096), (-1.8046498, -1.0386704), (-1.7401559, -0.9722793), (-2.527586, -2.7967055), (-2.5920837, -2.8630972), (-1.8046521, -1.038669), (-1.7401522, -0.97227615), (-2.5275834, -2.7967048), (-2.592083, -2.8630981), (-1.8046554, -1.0386703), (-1.7401568, -0.9722765), (-2.5275826, -2.7967036), (-2.5920792, -2.8630972), (-1.8046507, -1.0386713), (-1.7401555, -0.9722789), (-2.5275843, -2.7967052), (-2.5920808, -2.8630974), (-1.8046527, -1.0386709), (-1.7401544, -0.97227824), (-2.5275815, -2.7967043), (-2.5920784, -2.863098), (-1.8046538, -1.0386724), (-1.7401584, -0.9722776), (-2.5275843, -2.7967014), (-2.5920813, -2.863096), (-1.8046558, -1.0386734), (-1.7401607, -0.9722788), (-2.527587, -2.7967014), (-2.5920794, -2.8630946), (-1.80465, -1.038671), (-1.7401551, -0.9722808), (-2.5275865, -2.7967062), (-2.5920842, -2.863096), (-1.8046525, -1.0386683), (-1.7401536, -0.9722774), (-2.5275826, -2.796706), (-2.5920818, -2.8630986), (-1.8046553, -1.0386709), (-1.7401563, -0.9722774), (-2.527581, -2.7967038), (-2.5920792, -2.8630984), (-1.8046538, -1.0386739), (-1.7401565, -0.9722782), (-2.5275822, -2.7967014), (-2.5920775, -2.8630967), (-1.8046514, -1.0386741), (-1.7401578, -0.9722805), (-2.5275874, -2.7967036), (-2.5920825, -2.8630953), (-1.8046511, -1.0386704), (-1.7401532, -0.97227824), (-2.5275834, -2.7967045), (-2.5920815, -2.8630989), (-1.8046534, -1.0386729), (-1.7401555, -0.9722776), (-2.527582, -2.7967026), (-2.5920792, -2.8630974), (-1.8046515, -1.038673), (-1.7401543, -0.97227854), (-2.527582, -2.7967033), (-2.5920799, -2.8630977), (-1.8046527, -1.0386728), (-1.7401549, -0.97227865), (-2.5275836, -2.7967026), (-2.592082, -2.8630967), (-1.8046546, -1.0386721), (-1.7401572, -0.97227764), (-2.5275838, -2.7967021), (-2.5920815, -2.8630965), (-1.8046554, -1.038672), (-1.7401571, -0.9722768), (-2.5275826, -2.7967014), (-2.5920804, -2.8630974), (-1.8046542, -1.0386736), (-1.7401593, -0.97227806), (-2.5275874, -2.7967012), (-2.5920804, -2.8630958), (-1.8046495, -1.0386715), (-1.7401571, -0.97227937), (-2.5275886, -2.796705), (-2.5920823, -2.8630955), (-1.8046504, -1.0386679), (-1.7401532, -0.97227734), (-2.5275836, -2.7967072), (-2.5920806, -2.8630989), (-1.8046521, -1.0386688), (-1.7401568, -0.97227484), (-2.527584, -2.7967043), (-2.5920782, -2.8630993), (-1.8046507, -1.0386728), (-1.7401555, -0.9722779), (-2.5275831, -2.7967024), (-2.592081, -2.8630974), (-1.8046542, -1.0386735), (-1.7401567, -0.97227776), (-2.5275831, -2.7967014), (-2.5920787, -2.8630972), (-1.8046523, -1.0386745), (-1.7401565, -0.9722797), (-2.5275824, -2.796702), (-2.5920777, -2.8630962), (-1.804652, -1.0386728), (-1.7401581, -0.9722791), (-2.527585, -2.796703), (-2.5920787, -2.8630948), (-1.8046516, -1.0386704), (-1.7401577, -0.97227997), (-2.5275853, -2.796706), (-2.5920796, -2.8630962), (-1.8046515, -1.0386684), (-1.7401577, -0.9722766), (-2.5275872, -2.7967045), (-2.5920815, -2.8630974), (-1.8046515, -1.0386707), (-1.7401556, -0.972277), (-2.5275848, -2.796703), (-2.5920813, -2.863097), (-1.8046523, -1.0386708), (-1.7401547, -0.9722785), (-2.5275824, -2.796705), (-2.5920804, -2.8630967), (-1.8046542, -1.03867), (-1.7401569, -0.9722779), (-2.5275836, -2.7967048), (-2.5920806, -2.863097), (-1.8046538, -1.0386704), (-1.7401562, -0.97227657)]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch as th\n",
        "import time\n",
        "\n",
        "MODEL_PATH = f\"models/2gdl8x8framestack-success16/model.zip\"\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = BobinaEnv(duration = 6)\n",
        "\n",
        "# Load the trained agent\n",
        "model = SAC.load(MODEL_PATH, env=env, learning_rate = 0.00001)\n",
        "\n",
        "# Evaluate the agent\n",
        "for i in range(3):\n",
        "    obs, seed = env.reset()\n",
        "    print(obs)\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    velocidad = 0\n",
        "    current = 0\n",
        "    observations = []\n",
        "    noises = []\n",
        "    timepredict = 0\n",
        "    timemodel = 0\n",
        "    distancia11, distancia12, distancia21, distancia22, current1, current2 = obs\n",
        "    while not done:\n",
        "        #noise = random.uniform(-1, 1)\n",
        "        #obs = obs + noise\n",
        "        observations.append(obs)\n",
        "        #noises.append(noise)\n",
        "        t1 = time.time()\n",
        "        action, _states = model.predict(np.array([distancia11, distancia12, distancia21, distancia22, current1, current2]), deterministic=True)\n",
        "        t2 = time.time()\n",
        "        #print(action)\n",
        "        #if env.airgap > 10.1: action = max(action, [-50])\n",
        "        #print(action)\n",
        "        t3 = time.time()\n",
        "        state, reward, terminated, truncated, info = env.step(np.array(action))\n",
        "        t4 = time.time()\n",
        "        distancia11, distancia12, distancia21, distancia22, current1, current2 = state\n",
        "        done = truncated or terminated\n",
        "        episode_reward += reward\n",
        "        timepredict += t2 - t1\n",
        "        timemodel += t4 - t3\n",
        "        noises.append((current1, current2))\n",
        "    print(\"Time predict\", timepredict)\n",
        "    print(\"Time model\", timemodel)\n",
        "    print(\"Episode reward\", episode_reward)\n",
        "    print(noises)\n",
        "    env.render(\"yes\", normalize = True, seed = i+5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.savefig(\"images/floor-2gdl8x8nocrash.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "from stable_baselines3 import SAC\n",
        "\n",
        "#import onnx\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class OnnxablePolicy(th.nn.Module):\n",
        "    def __init__(self, actor: th.nn.Module):\n",
        "        super().__init__()\n",
        "        # Removing the flatten layer because it can't be onnxed\n",
        "        self.actor = th.nn.Sequential(\n",
        "            actor.latent_pi,\n",
        "            actor.mu,\n",
        "            # For gSDE\n",
        "            # th.nn.Hardtanh(min_val=-actor.clip_mean, max_val=actor.clip_mean),\n",
        "            # Squash the output\n",
        "            th.nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, observation: th.Tensor) -> th.Tensor:\n",
        "        # NOTE: You may have to process (normalize) observation in the correct\n",
        "        #       way before using this. See `common.preprocessing.preprocess_obs`\n",
        "        return self.actor(observation)\n",
        "\n",
        "\n",
        "# Example: model = SAC(\"MlpPolicy\", \"Pendulum-v1\")\n",
        "model = SAC.load(f\"models/sac8x8h9.3/model.zip\", device=\"cpu\")\n",
        "onnxable_model = OnnxablePolicy(model.policy.actor)\n",
        "\n",
        "observation_size = model.observation_space.shape\n",
        "dummy_input = th.randn(1, *observation_size)\n",
        "th.onnx.export(\n",
        "    onnxable_model,\n",
        "    dummy_input,\n",
        "    \"./ONNX/1gdlComplexH98x8.onnx\",\n",
        "    opset_version=9,\n",
        "    input_names=[\"input\"],\n",
        ")\n",
        "\n",
        "##### Load and test with onnx\n",
        "\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "onnx_path = \"./ONNX/1gdlComplexH98x8.onnx\"\n",
        "\n",
        "observation = np.zeros((1, *observation_size)).astype(np.float32)\n",
        "ort_sess = ort.InferenceSession(onnx_path)\n",
        "action = ort_sess.run(None, {\"input\": observation})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SACPolicy(\n",
              "  (actor): Actor(\n",
              "    (features_extractor): FlattenExtractor(\n",
              "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    )\n",
              "    (latent_pi): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=8, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (mu): Linear(in_features=8, out_features=1, bias=True)\n",
              "    (log_std): Linear(in_features=8, out_features=1, bias=True)\n",
              "  )\n",
              "  (critic): ContinuousCritic(\n",
              "    (features_extractor): FlattenExtractor(\n",
              "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    )\n",
              "    (qf0): Sequential(\n",
              "      (0): Linear(in_features=5, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    )\n",
              "    (qf1): Sequential(\n",
              "      (0): Linear(in_features=5, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (critic_target): ContinuousCritic(\n",
              "    (features_extractor): FlattenExtractor(\n",
              "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    )\n",
              "    (qf0): Sequential(\n",
              "      (0): Linear(in_features=5, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    )\n",
              "    (qf1): Sequential(\n",
              "      (0): Linear(in_features=5, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): ReLU()\n",
              "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# See \"ONNX export\" for imports and OnnxablePolicy\n",
        "jit_path = \"1gdlComplex.pt\"\n",
        "\n",
        "# Trace and optimize the module\n",
        "traced_module = th.jit.trace(onnxable_model.eval(), dummy_input)\n",
        "frozen_module = th.jit.freeze(traced_module)\n",
        "frozen_module = th.jit.optimize_for_inference(frozen_module)\n",
        "th.jit.save(frozen_module, jit_path)\n",
        "\n",
        "##### Load and test with torch\n",
        "\n",
        "import torch as th\n",
        "\n",
        "dummy_input = th.randn(1, *observation_size)\n",
        "loaded_module = th.jit.load(jit_path)\n",
        "action_jit = loaded_module(dummy_input)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
