Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_75
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 187      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 32       |
|    time_elapsed    | 27       |
|    total_timesteps | 887      |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 7.38     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 9.99     |
|    learning_rate   | 0.0001   |
|    n_updates       | 810685   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 174      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 32       |
|    time_elapsed    | 51       |
|    total_timesteps | 1665     |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 2.83     |
|    learning_rate   | 0.0001   |
|    n_updates       | 811463   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 162      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 31       |
|    time_elapsed    | 73       |
|    total_timesteps | 2322     |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 2.32     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 2.78     |
|    learning_rate   | 0.0001   |
|    n_updates       | 812120   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 177      |
|    ep_rew_mean     | 147      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 30       |
|    time_elapsed    | 92       |
|    total_timesteps | 2827     |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 7.36     |
|    learning_rate   | 0.0001   |
|    n_updates       | 812625   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 29       |
|    time_elapsed    | 111      |
|    total_timesteps | 3305     |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.145   |
|    learning_rate   | 0.0001   |
|    n_updates       | 813103   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 135      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 29       |
|    time_elapsed    | 132      |
|    total_timesteps | 3898     |
| train/             |          |
|    actor_loss      | -46.9    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 4.21     |
|    learning_rate   | 0.0001   |
|    n_updates       | 813696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 162      |
|    ep_rew_mean     | 135      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 29       |
|    time_elapsed    | 154      |
|    total_timesteps | 4526     |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 3.98     |
|    learning_rate   | 0.0001   |
|    n_updates       | 814324   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 172      |
|    ep_rew_mean     | 144      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 30       |
|    time_elapsed    | 181      |
|    total_timesteps | 5500     |
| train/             |          |
|    actor_loss      | -50.7    |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 815298   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 167      |
| time/              |          |
|    episodes        | 36       |
|    fps             | 32       |
|    time_elapsed    | 219      |
|    total_timesteps | 7122     |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.34     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 816920   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 187      |
| time/              |          |
|    episodes        | 40       |
|    fps             | 34       |
|    time_elapsed    | 259      |
|    total_timesteps | 8872     |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 818670   |
---------------------------------
Eval num_timesteps=10000, episode_reward=216.50 +/- 0.00
Episode length: 274.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 274      |
|    mean_reward     | 217      |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 3.39     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 819798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    episodes        | 44       |
|    fps             | 33       |
|    time_elapsed    | 315      |
|    total_timesteps | 10586    |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 3.16     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 820384   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | 198      |
| time/              |          |
|    episodes        | 48       |
|    fps             | 33       |
|    time_elapsed    | 340      |
|    total_timesteps | 11463    |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 2.93     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 821261   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    episodes        | 52       |
|    fps             | 33       |
|    time_elapsed    | 368      |
|    total_timesteps | 12528    |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 2.91     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 822326   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 34       |
|    time_elapsed    | 402      |
|    total_timesteps | 13968    |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 3.43     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 0.496    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 823766   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | 208      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 34       |
|    time_elapsed    | 431      |
|    total_timesteps | 15027    |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | 6.79     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 824825   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | 206      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 34       |
|    time_elapsed    | 456      |
|    total_timesteps | 15854    |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -1.65    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 825652   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    episodes        | 68       |
|    fps             | 34       |
|    time_elapsed    | 479      |
|    total_timesteps | 16544    |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 4.22     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 4.01     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 826342   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 201      |
| time/              |          |
|    episodes        | 72       |
|    fps             | 34       |
|    time_elapsed    | 504      |
|    total_timesteps | 17427    |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 827225   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    episodes        | 76       |
|    fps             | 34       |
|    time_elapsed    | 531      |
|    total_timesteps | 18374    |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 0.16     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 828172   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 200      |
| time/              |          |
|    episodes        | 80       |
|    fps             | 34       |
|    time_elapsed    | 558      |
|    total_timesteps | 19368    |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 3.16     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -0.103   |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 829166   |
---------------------------------
Eval num_timesteps=20000, episode_reward=159.76 +/- 0.00
Episode length: 196.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 196      |
|    mean_reward     | 160      |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 829798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    episodes        | 84       |
|    fps             | 33       |
|    time_elapsed    | 604      |
|    total_timesteps | 20501    |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 0.435    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 830299   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    episodes        | 88       |
|    fps             | 34       |
|    time_elapsed    | 630      |
|    total_timesteps | 21464    |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | -2.38    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 831262   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | 197      |
| time/              |          |
|    episodes        | 92       |
|    fps             | 33       |
|    time_elapsed    | 654      |
|    total_timesteps | 22240    |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | 2.98     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 832038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    episodes        | 96       |
|    fps             | 33       |
|    time_elapsed    | 678      |
|    total_timesteps | 23069    |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 832867   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 194      |
| time/              |          |
|    episodes        | 100      |
|    fps             | 33       |
|    time_elapsed    | 701      |
|    total_timesteps | 23802    |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 833600   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 33       |
|    time_elapsed    | 724      |
|    total_timesteps | 24544    |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | -3.86    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 834342   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 232      |
|    ep_rew_mean     | 191      |
| time/              |          |
|    episodes        | 108      |
|    fps             | 33       |
|    time_elapsed    | 745      |
|    total_timesteps | 25201    |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 5.12     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 834999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 232      |
|    ep_rew_mean     | 191      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 33       |
|    time_elapsed    | 766      |
|    total_timesteps | 25855    |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 13.5     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | -0.879   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 835653   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 193      |
| time/              |          |
|    episodes        | 116      |
|    fps             | 33       |
|    time_elapsed    | 787      |
|    total_timesteps | 26507    |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 3.04     |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | 0.243    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 836305   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 194      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 33       |
|    time_elapsed    | 808      |
|    total_timesteps | 27143    |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | 0.811    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 836941   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | 194      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 33       |
|    time_elapsed    | 829      |
|    total_timesteps | 27812    |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 12       |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 837610   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | 195      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 33       |
|    time_elapsed    | 850      |
|    total_timesteps | 28496    |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 8.05     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | -0.667   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 838294   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 192      |
| time/              |          |
|    episodes        | 132      |
|    fps             | 33       |
|    time_elapsed    | 871      |
|    total_timesteps | 29170    |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 20       |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 838968   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 184      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 33       |
|    time_elapsed    | 892      |
|    total_timesteps | 29833    |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 839631   |
---------------------------------
Eval num_timesteps=30000, episode_reward=205.52 +/- 0.00
Episode length: 263.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 263      |
|    mean_reward     | 206      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 2.75     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | -3.42    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 839798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 214      |
|    ep_rew_mean     | 175      |
| time/              |          |
|    episodes        | 140      |
|    fps             | 32       |
|    time_elapsed    | 932      |
|    total_timesteps | 30590    |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 840388   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 171      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 32       |
|    time_elapsed    | 959      |
|    total_timesteps | 31654    |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 3.53     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 2.34     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 841452   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 33       |
|    time_elapsed    | 986      |
|    total_timesteps | 32665    |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 842463   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 174      |
| time/              |          |
|    episodes        | 152      |
|    fps             | 33       |
|    time_elapsed    | 1015     |
|    total_timesteps | 33850    |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 8.05     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.5      |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 843648   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 168      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 33       |
|    time_elapsed    | 1037     |
|    total_timesteps | 34579    |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 2.39     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.956   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 844377   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 200      |
|    ep_rew_mean     | 165      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 33       |
|    time_elapsed    | 1058     |
|    total_timesteps | 35259    |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.54     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 845057   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 199      |
|    ep_rew_mean     | 164      |
| time/              |          |
|    episodes        | 164      |
|    fps             | 33       |
|    time_elapsed    | 1079     |
|    total_timesteps | 35907    |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.84    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 845705   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 198      |
|    ep_rew_mean     | 163      |
| time/              |          |
|    episodes        | 168      |
|    fps             | 33       |
|    time_elapsed    | 1100     |
|    total_timesteps | 36504    |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 8.23     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.6     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 846302   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 194      |
|    ep_rew_mean     | 160      |
| time/              |          |
|    episodes        | 172      |
|    fps             | 33       |
|    time_elapsed    | 1119     |
|    total_timesteps | 37044    |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 8.08     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 846842   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 158      |
| time/              |          |
|    episodes        | 176      |
|    fps             | 33       |
|    time_elapsed    | 1138     |
|    total_timesteps | 37594    |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.77    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 847392   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 186      |
|    ep_rew_mean     | 154      |
| time/              |          |
|    episodes        | 180      |
|    fps             | 32       |
|    time_elapsed    | 1157     |
|    total_timesteps | 38153    |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 847951   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 152      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 32       |
|    time_elapsed    | 1176     |
|    total_timesteps | 38714    |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 848512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 178      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 32       |
|    time_elapsed    | 1196     |
|    total_timesteps | 39287    |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.34    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 849085   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 148      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 32       |
|    time_elapsed    | 1216     |
|    total_timesteps | 39867    |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 5.82     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 849665   |
---------------------------------
Eval num_timesteps=40000, episode_reward=124.98 +/- 0.00
Episode length: 146.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 146      |
|    mean_reward     | 125      |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 2.47     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 849798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 174      |
|    ep_rew_mean     | 146      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 32       |
|    time_elapsed    | 1255     |
|    total_timesteps | 40601    |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.87     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 850399   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 146      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 32       |
|    time_elapsed    | 1275     |
|    total_timesteps | 41234    |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 4.93     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 851032   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 173      |
|    ep_rew_mean     | 146      |
| time/              |          |
|    episodes        | 204      |
|    fps             | 32       |
|    time_elapsed    | 1297     |
|    total_timesteps | 41939    |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 4.46     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.0632  |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 851737   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 155      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 32       |
|    time_elapsed    | 1335     |
|    total_timesteps | 43640    |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 2.86     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -0.263   |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 853438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | 165      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 33       |
|    time_elapsed    | 1372     |
|    total_timesteps | 45327    |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 855125   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 176      |
| time/              |          |
|    episodes        | 216      |
|    fps             | 33       |
|    time_elapsed    | 1411     |
|    total_timesteps | 47177    |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -0.058   |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 856975   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 188      |
| time/              |          |
|    episodes        | 220      |
|    fps             | 33       |
|    time_elapsed    | 1455     |
|    total_timesteps | 49248    |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 2.75     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 0.304    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 859046   |
---------------------------------
Eval num_timesteps=50000, episode_reward=195.86 +/- 0.00
Episode length: 242.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 196      |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 2.67     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 859798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 190      |
| time/              |          |
|    episodes        | 224      |
|    fps             | 33       |
|    time_elapsed    | 1498     |
|    total_timesteps | 50259    |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 860057   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 229      |
|    ep_rew_mean     | 196      |
| time/              |          |
|    episodes        | 228      |
|    fps             | 33       |
|    time_elapsed    | 1531     |
|    total_timesteps | 51624    |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 2.34     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 861422   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 211      |
| time/              |          |
|    episodes        | 232      |
|    fps             | 34       |
|    time_elapsed    | 1579     |
|    total_timesteps | 54007    |
| train/             |          |
|    actor_loss      | -53.2    |
|    critic_loss     | 2.06     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.75     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 863805   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 265      |
|    ep_rew_mean     | 229      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 34       |
|    time_elapsed    | 1629     |
|    total_timesteps | 56544    |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 2.1      |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -2.61    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 866342   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 246      |
| time/              |          |
|    episodes        | 240      |
|    fps             | 35       |
|    time_elapsed    | 1682     |
|    total_timesteps | 59210    |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 0.411    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 869008   |
---------------------------------
Eval num_timesteps=60000, episode_reward=443.24 +/- 0.00
Episode length: 526.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 443      |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 2.59     |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 869798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 295      |
|    ep_rew_mean     | 256      |
| time/              |          |
|    episodes        | 244      |
|    fps             | 35       |
|    time_elapsed    | 1748     |
|    total_timesteps | 61588    |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 6.83     |
|    ent_coef        | 0.0201   |
|    ent_coef_loss   | -0.225   |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 871386   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 248      |
|    fps             | 35       |
|    time_elapsed    | 1791     |
|    total_timesteps | 63611    |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.0208   |
|    ent_coef_loss   | 0.396    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 873409   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 312      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 35       |
|    time_elapsed    | 1830     |
|    total_timesteps | 65412    |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0213   |
|    ent_coef_loss   | 0.878    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 875210   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 35       |
|    time_elapsed    | 1870     |
|    total_timesteps | 67316    |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 3.33     |
|    ent_coef        | 0.0215   |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 877114   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | 287      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 36       |
|    time_elapsed    | 1906     |
|    total_timesteps | 68979    |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 4        |
|    ent_coef        | 0.0206   |
|    ent_coef_loss   | -0.247   |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 878777   |
---------------------------------
Eval num_timesteps=70000, episode_reward=325.25 +/- 0.00
Episode length: 383.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | 325      |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 7.04     |
|    ent_coef        | 0.0202   |
|    ent_coef_loss   | 0.884    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 879798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 295      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 36       |
|    time_elapsed    | 1962     |
|    total_timesteps | 70759    |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 2.83     |
|    ent_coef        | 0.0201   |
|    ent_coef_loss   | 0.41     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 880557   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 36       |
|    time_elapsed    | 1998     |
|    total_timesteps | 72398    |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0203   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 882196   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 366      |
|    ep_rew_mean     | 316      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 36       |
|    time_elapsed    | 2038     |
|    total_timesteps | 74276    |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -0.461   |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 884074   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 328      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 36       |
|    time_elapsed    | 2080     |
|    total_timesteps | 76265    |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 886063   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 339      |
| time/              |          |
|    episodes        | 280      |
|    fps             | 36       |
|    time_elapsed    | 2118     |
|    total_timesteps | 78067    |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -1.36    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 887865   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 403      |
|    ep_rew_mean     | 347      |
| time/              |          |
|    episodes        | 284      |
|    fps             | 36       |
|    time_elapsed    | 2152     |
|    total_timesteps | 79594    |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 889392   |
---------------------------------
Eval num_timesteps=80000, episode_reward=385.64 +/- 0.00
Episode length: 444.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 444      |
|    mean_reward     | 386      |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -0.794   |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 889798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 416      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 36       |
|    time_elapsed    | 2217     |
|    total_timesteps | 81929    |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 0.463    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 891727   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 292      |
|    fps             | 37       |
|    time_elapsed    | 2260     |
|    total_timesteps | 83971    |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 6.84     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 1.84     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 893769   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 383      |
| time/              |          |
|    episodes        | 296      |
|    fps             | 37       |
|    time_elapsed    | 2302     |
|    total_timesteps | 85940    |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -0.282   |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 895738   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    episodes        | 300      |
|    fps             | 37       |
|    time_elapsed    | 2334     |
|    total_timesteps | 87368    |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 897166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 393      |
| time/              |          |
|    episodes        | 304      |
|    fps             | 37       |
|    time_elapsed    | 2362     |
|    total_timesteps | 88481    |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 0.502    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 898279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 386      |
| time/              |          |
|    episodes        | 308      |
|    fps             | 37       |
|    time_elapsed    | 2386     |
|    total_timesteps | 89377    |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -1.56    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 899175   |
---------------------------------
Eval num_timesteps=90000, episode_reward=172.07 +/- 0.00
Episode length: 214.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 214      |
|    mean_reward     | 172      |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 899798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    episodes        | 312      |
|    fps             | 37       |
|    time_elapsed    | 2430     |
|    total_timesteps | 90455    |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 0.469    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 900253   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 37       |
|    time_elapsed    | 2456     |
|    total_timesteps | 91488    |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -0.247   |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 901286   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 361      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 37       |
|    time_elapsed    | 2483     |
|    total_timesteps | 92577    |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -0.251   |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 902375   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 428      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 37       |
|    time_elapsed    | 2516     |
|    total_timesteps | 94002    |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 903800   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 367      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 37       |
|    time_elapsed    | 2550     |
|    total_timesteps | 95511    |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 12.5     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.905   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 905309   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 421      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 37       |
|    time_elapsed    | 2584     |
|    total_timesteps | 97031    |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 0.264    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 906829   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 37       |
|    time_elapsed    | 2629     |
|    total_timesteps | 99042    |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 908840   |
---------------------------------
Eval num_timesteps=100000, episode_reward=435.79 +/- 0.00
Episode length: 525.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 525      |
|    mean_reward     | 436      |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 8.51     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 909798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 411      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 37       |
|    time_elapsed    | 2703     |
|    total_timesteps | 101668   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -0.551   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 911466   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 415      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 37       |
|    time_elapsed    | 2755     |
|    total_timesteps | 104203   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 914001   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 38       |
|    time_elapsed    | 2801     |
|    total_timesteps | 106495   |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 9.39     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -0.753   |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 916293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 38       |
|    time_elapsed    | 2849     |
|    total_timesteps | 108934   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -0.846   |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 918732   |
---------------------------------
Eval num_timesteps=110000, episode_reward=517.69 +/- 0.00
Episode length: 609.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 609      |
|    mean_reward     | 518      |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 3.24     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 0.794    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 919798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 364      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 38       |
|    time_elapsed    | 2922     |
|    total_timesteps | 111708   |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.909    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 921506   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 38       |
|    time_elapsed    | 2967     |
|    total_timesteps | 113913   |
| train/             |          |
|    actor_loss      | -54.1    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -2.19    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 923711   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 38       |
|    time_elapsed    | 3011     |
|    total_timesteps | 116094   |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 4.21     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 925892   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 376      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 38       |
|    time_elapsed    | 3052     |
|    total_timesteps | 118033   |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 927831   |
---------------------------------
Eval num_timesteps=120000, episode_reward=425.20 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 425      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 5.97     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 1.81     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 929798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 443      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 38       |
|    time_elapsed    | 3120     |
|    total_timesteps | 120483   |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -0.947   |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 930281   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 443      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 38       |
|    time_elapsed    | 3162     |
|    total_timesteps | 122515   |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -0.913   |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 932313   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 38       |
|    time_elapsed    | 3203     |
|    total_timesteps | 124454   |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 6.38     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 2.35     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 934252   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 381      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 38       |
|    time_elapsed    | 3245     |
|    total_timesteps | 126420   |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 3.53     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 936218   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 381      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 39       |
|    time_elapsed    | 3287     |
|    total_timesteps | 128409   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 2.27     |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 938207   |
---------------------------------
Eval num_timesteps=130000, episode_reward=424.85 +/- 0.00
Episode length: 500.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 500      |
|    mean_reward     | 425      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 0.0223   |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 939798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 381      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 38       |
|    time_elapsed    | 3348     |
|    total_timesteps | 130504   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 940302   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 383      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 39       |
|    time_elapsed    | 3393     |
|    total_timesteps | 132720   |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.959   |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 942518   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 392      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 39       |
|    time_elapsed    | 3443     |
|    total_timesteps | 135218   |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 7.38     |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 945016   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 477      |
|    ep_rew_mean     | 405      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 39       |
|    time_elapsed    | 3494     |
|    total_timesteps | 137789   |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.36    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 947587   |
---------------------------------
Eval num_timesteps=140000, episode_reward=625.21 +/- 0.00
Episode length: 728.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 728      |
|    mean_reward     | 625      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 4.74     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 0.459    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 949798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 496      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 39       |
|    time_elapsed    | 3567     |
|    total_timesteps | 140612   |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.0441  |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 950410   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 513      |
|    ep_rew_mean     | 438      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 39       |
|    time_elapsed    | 3618     |
|    total_timesteps | 143216   |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 953014   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 527      |
|    ep_rew_mean     | 451      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 39       |
|    time_elapsed    | 3667     |
|    total_timesteps | 145661   |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 2.54     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 955459   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 544      |
|    ep_rew_mean     | 466      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 39       |
|    time_elapsed    | 3722     |
|    total_timesteps | 148423   |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 958221   |
---------------------------------
Eval num_timesteps=150000, episode_reward=551.18 +/- 0.00
Episode length: 637.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | 551      |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 959798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 559      |
|    ep_rew_mean     | 479      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 39       |
|    time_elapsed    | 3796     |
|    total_timesteps | 151408   |
| train/             |          |
|    actor_loss      | -50.8    |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 0.955    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 961206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 570      |
|    ep_rew_mean     | 489      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 40       |
|    time_elapsed    | 3847     |
|    total_timesteps | 154029   |
| train/             |          |
|    actor_loss      | -52      |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 963827   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 583      |
|    ep_rew_mean     | 500      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 40       |
|    time_elapsed    | 3901     |
|    total_timesteps | 156838   |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 2.57     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 966636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 591      |
|    ep_rew_mean     | 508      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 40       |
|    time_elapsed    | 3956     |
|    total_timesteps | 159724   |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -3.42    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 969522   |
---------------------------------
Eval num_timesteps=160000, episode_reward=462.58 +/- 0.00
Episode length: 526.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 526      |
|    mean_reward     | 463      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 3.63     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.426    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 969798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 597      |
|    ep_rew_mean     | 513      |
| time/              |          |
|    episodes        | 440      |
|    fps             | 40       |
|    time_elapsed    | 4034     |
|    total_timesteps | 162812   |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 3.89     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 972610   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 601      |
|    ep_rew_mean     | 516      |
| time/              |          |
|    episodes        | 444      |
|    fps             | 40       |
|    time_elapsed    | 4090     |
|    total_timesteps | 165731   |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 21.5     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 2.72     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 975529   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 607      |
|    ep_rew_mean     | 522      |
| time/              |          |
|    episodes        | 448      |
|    fps             | 40       |
|    time_elapsed    | 4145     |
|    total_timesteps | 168642   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 2.53     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -3.43    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 978440   |
---------------------------------
Eval num_timesteps=170000, episode_reward=608.15 +/- 0.00
Episode length: 709.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 709      |
|    mean_reward     | 608      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.806    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 979798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 612      |
|    ep_rew_mean     | 528      |
| time/              |          |
|    episodes        | 452      |
|    fps             | 40       |
|    time_elapsed    | 4232     |
|    total_timesteps | 172340   |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 5.01     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 2.17     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 982138   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 621      |
|    ep_rew_mean     | 536      |
| time/              |          |
|    episodes        | 456      |
|    fps             | 40       |
|    time_elapsed    | 4292     |
|    total_timesteps | 175471   |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 0.52     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 985269   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 625      |
|    ep_rew_mean     | 539      |
| time/              |          |
|    episodes        | 460      |
|    fps             | 41       |
|    time_elapsed    | 4341     |
|    total_timesteps | 178041   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.0838   |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 987839   |
---------------------------------
Eval num_timesteps=180000, episode_reward=667.29 +/- 0.00
Episode length: 764.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 764      |
|    mean_reward     | 667      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.00602 |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 989798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 632      |
|    ep_rew_mean     | 545      |
| time/              |          |
|    episodes        | 464      |
|    fps             | 41       |
|    time_elapsed    | 4427     |
|    total_timesteps | 181588   |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 5.43     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 991386   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 638      |
|    ep_rew_mean     | 551      |
| time/              |          |
|    episodes        | 468      |
|    fps             | 41       |
|    time_elapsed    | 4477     |
|    total_timesteps | 184142   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 3.11     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 993940   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 650      |
|    ep_rew_mean     | 561      |
| time/              |          |
|    episodes        | 472      |
|    fps             | 41       |
|    time_elapsed    | 4537     |
|    total_timesteps | 187278   |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 2.84     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 997076   |
---------------------------------
Eval num_timesteps=190000, episode_reward=608.97 +/- 0.00
Episode length: 711.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 711      |
|    mean_reward     | 609      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.388   |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 999798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 657      |
|    ep_rew_mean     | 568      |
| time/              |          |
|    episodes        | 476      |
|    fps             | 41       |
|    time_elapsed    | 4623     |
|    total_timesteps | 190759   |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1000557  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 663      |
|    ep_rew_mean     | 574      |
| time/              |          |
|    episodes        | 480      |
|    fps             | 41       |
|    time_elapsed    | 4672     |
|    total_timesteps | 193231   |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1003029  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 484      |
|    fps             | 41       |
|    time_elapsed    | 4724     |
|    total_timesteps | 195838   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.709   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1005636  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 676      |
|    ep_rew_mean     | 586      |
| time/              |          |
|    episodes        | 488      |
|    fps             | 41       |
|    time_elapsed    | 4777     |
|    total_timesteps | 198510   |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 2.6      |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -0.443   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1008308  |
---------------------------------
Eval num_timesteps=200000, episode_reward=654.72 +/- 0.00
Episode length: 753.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 753      |
|    mean_reward     | 655      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 5.49     |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1009798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 686      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 492      |
|    fps             | 41       |
|    time_elapsed    | 4863     |
|    total_timesteps | 202162   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 3.29     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1011960  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 691      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 496      |
|    fps             | 41       |
|    time_elapsed    | 4918     |
|    total_timesteps | 204941   |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1014739  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 692      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 500      |
|    fps             | 41       |
|    time_elapsed    | 4969     |
|    total_timesteps | 207521   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1017319  |
---------------------------------
Eval num_timesteps=210000, episode_reward=907.62 +/- 0.00
Episode length: 1043.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.04e+03 |
|    mean_reward     | 908      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1019798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 697      |
|    ep_rew_mean     | 605      |
| time/              |          |
|    episodes        | 504      |
|    fps             | 41       |
|    time_elapsed    | 5054     |
|    total_timesteps | 210972   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 0.393    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1020770  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 508      |
|    fps             | 41       |
|    time_elapsed    | 5111     |
|    total_timesteps | 213962   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 2.78     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 1.85     |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1023760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 701      |
|    ep_rew_mean     | 608      |
| time/              |          |
|    episodes        | 512      |
|    fps             | 41       |
|    time_elapsed    | 5166     |
|    total_timesteps | 216839   |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -2.67    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1026637  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 706      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 42       |
|    time_elapsed    | 5222     |
|    total_timesteps | 219743   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -0.29    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1029541  |
---------------------------------
Eval num_timesteps=220000, episode_reward=824.48 +/- 0.00
Episode length: 966.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 966      |
|    mean_reward     | 824      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 0.299    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1029798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 616      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 42       |
|    time_elapsed    | 5308     |
|    total_timesteps | 223235   |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1033033  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 524      |
|    fps             | 42       |
|    time_elapsed    | 5377     |
|    total_timesteps | 227004   |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1036802  |
---------------------------------
Eval num_timesteps=230000, episode_reward=866.19 +/- 0.00
Episode length: 996.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 996      |
|    mean_reward     | 866      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1039798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 528      |
|    fps             | 42       |
|    time_elapsed    | 5467     |
|    total_timesteps | 230825   |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1040623  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 730      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 532      |
|    fps             | 42       |
|    time_elapsed    | 5524     |
|    total_timesteps | 233812   |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 0.0588   |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1043610  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 42       |
|    time_elapsed    | 5575     |
|    total_timesteps | 236452   |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 8.71     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1046250  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 627      |
| time/              |          |
|    episodes        | 540      |
|    fps             | 42       |
|    time_elapsed    | 5619     |
|    total_timesteps | 238653   |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1048451  |
---------------------------------
Eval num_timesteps=240000, episode_reward=895.25 +/- 0.00
Episode length: 1033.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 895      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 2.46     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.83     |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1049798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 544      |
|    fps             | 42       |
|    time_elapsed    | 5701     |
|    total_timesteps | 241860   |
| train/             |          |
|    actor_loss      | -53.2    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1051658  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 629      |
| time/              |          |
|    episodes        | 548      |
|    fps             | 42       |
|    time_elapsed    | 5765     |
|    total_timesteps | 245315   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.05     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 0.806    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1055113  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 42       |
|    time_elapsed    | 5833     |
|    total_timesteps | 249041   |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1058839  |
---------------------------------
Eval num_timesteps=250000, episode_reward=749.88 +/- 0.00
Episode length: 884.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 884      |
|    mean_reward     | 750      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1059798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 737      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 556      |
|    fps             | 42       |
|    time_elapsed    | 5922     |
|    total_timesteps | 252741   |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 11.9     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | -0.254   |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1062539  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 560      |
|    fps             | 42       |
|    time_elapsed    | 5978     |
|    total_timesteps | 255663   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1065461  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 564      |
|    fps             | 42       |
|    time_elapsed    | 6037     |
|    total_timesteps | 258863   |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 22.2     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1068661  |
---------------------------------
Eval num_timesteps=260000, episode_reward=813.33 +/- 0.00
Episode length: 933.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 933      |
|    mean_reward     | 813      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 2.23     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.632    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1069798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 755      |
|    ep_rew_mean     | 656      |
| time/              |          |
|    episodes        | 568      |
|    fps             | 42       |
|    time_elapsed    | 6130     |
|    total_timesteps | 262832   |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 4.08     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1072630  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 572      |
|    fps             | 43       |
|    time_elapsed    | 6206     |
|    total_timesteps | 266981   |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1076779  |
---------------------------------
Eval num_timesteps=270000, episode_reward=803.29 +/- 0.00
Episode length: 923.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 923      |
|    mean_reward     | 803      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 2.24     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1079798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 576      |
|    fps             | 43       |
|    time_elapsed    | 6316     |
|    total_timesteps | 271960   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 36.2     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1081758  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 780      |
|    ep_rew_mean     | 679      |
| time/              |          |
|    episodes        | 580      |
|    fps             | 43       |
|    time_elapsed    | 6366     |
|    total_timesteps | 274493   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 8.25     |
|    ent_coef        | 0.0241   |
|    ent_coef_loss   | 11.1     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1084291  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 762      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 584      |
|    fps             | 43       |
|    time_elapsed    | 6388     |
|    total_timesteps | 275250   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0269   |
|    ent_coef_loss   | 15.5     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1085048  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 588      |
|    fps             | 43       |
|    time_elapsed    | 6408     |
|    total_timesteps | 275849   |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 11.8     |
|    ent_coef        | 0.0292   |
|    ent_coef_loss   | 16.3     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1085647  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 713      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 592      |
|    fps             | 42       |
|    time_elapsed    | 6421     |
|    total_timesteps | 276037   |
| train/             |          |
|    actor_loss      | -67.8    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.0298   |
|    ent_coef_loss   | 18.5     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1085835  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 687      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 596      |
|    fps             | 42       |
|    time_elapsed    | 6434     |
|    total_timesteps | 276215   |
| train/             |          |
|    actor_loss      | -69.5    |
|    critic_loss     | 7.57     |
|    ent_coef        | 0.0304   |
|    ent_coef_loss   | 17.7     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086013  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 663      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 600      |
|    fps             | 42       |
|    time_elapsed    | 6448     |
|    total_timesteps | 276403   |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 8.22     |
|    ent_coef        | 0.031    |
|    ent_coef_loss   | 12.2     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086201  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 634      |
|    ep_rew_mean     | 553      |
| time/              |          |
|    episodes        | 604      |
|    fps             | 42       |
|    time_elapsed    | 6461     |
|    total_timesteps | 276580   |
| train/             |          |
|    actor_loss      | -72.9    |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0315   |
|    ent_coef_loss   | 14.1     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086378  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 606      |
|    ep_rew_mean     | 529      |
| time/              |          |
|    episodes        | 608      |
|    fps             | 42       |
|    time_elapsed    | 6474     |
|    total_timesteps | 276759   |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 10.3     |
|    ent_coef        | 0.032    |
|    ent_coef_loss   | 14.4     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086557  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 579      |
|    ep_rew_mean     | 506      |
| time/              |          |
|    episodes        | 612      |
|    fps             | 42       |
|    time_elapsed    | 6487     |
|    total_timesteps | 276962   |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0326   |
|    ent_coef_loss   | 15.4     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 552      |
|    ep_rew_mean     | 482      |
| time/              |          |
|    episodes        | 616      |
|    fps             | 42       |
|    time_elapsed    | 6500     |
|    total_timesteps | 277146   |
| train/             |          |
|    actor_loss      | -74.7    |
|    critic_loss     | 19.8     |
|    ent_coef        | 0.0331   |
|    ent_coef_loss   | 13.4     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1086944  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 522      |
|    ep_rew_mean     | 455      |
| time/              |          |
|    episodes        | 620      |
|    fps             | 42       |
|    time_elapsed    | 6514     |
|    total_timesteps | 277340   |
| train/             |          |
|    actor_loss      | -72.8    |
|    critic_loss     | 18.1     |
|    ent_coef        | 0.0338   |
|    ent_coef_loss   | 16.3     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087138  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 486      |
|    ep_rew_mean     | 424      |
| time/              |          |
|    episodes        | 624      |
|    fps             | 42       |
|    time_elapsed    | 6527     |
|    total_timesteps | 277549   |
| train/             |          |
|    actor_loss      | -73.2    |
|    critic_loss     | 21.4     |
|    ent_coef        | 0.0344   |
|    ent_coef_loss   | 16.3     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087347  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 395      |
| time/              |          |
|    episodes        | 628      |
|    fps             | 42       |
|    time_elapsed    | 6541     |
|    total_timesteps | 277759   |
| train/             |          |
|    actor_loss      | -73.4    |
|    critic_loss     | 8.4      |
|    ent_coef        | 0.0351   |
|    ent_coef_loss   | 14.2     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087557  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 632      |
|    fps             | 42       |
|    time_elapsed    | 6555     |
|    total_timesteps | 277979   |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.0358   |
|    ent_coef_loss   | 13       |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087777  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 401      |
|    ep_rew_mean     | 350      |
| time/              |          |
|    episodes        | 636      |
|    fps             | 42       |
|    time_elapsed    | 6568     |
|    total_timesteps | 278189   |
| train/             |          |
|    actor_loss      | -72.9    |
|    critic_loss     | 12.9     |
|    ent_coef        | 0.0366   |
|    ent_coef_loss   | 14.1     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087987  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 333      |
| time/              |          |
|    episodes        | 640      |
|    fps             | 42       |
|    time_elapsed    | 6581     |
|    total_timesteps | 278391   |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 8.04     |
|    ent_coef        | 0.0373   |
|    ent_coef_loss   | 13.8     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1088189  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 311      |
| time/              |          |
|    episodes        | 644      |
|    fps             | 42       |
|    time_elapsed    | 6595     |
|    total_timesteps | 278585   |
| train/             |          |
|    actor_loss      | -75      |
|    critic_loss     | 52.3     |
|    ent_coef        | 0.038    |
|    ent_coef_loss   | 11.4     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1088383  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 323      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    episodes        | 648      |
|    fps             | 42       |
|    time_elapsed    | 6608     |
|    total_timesteps | 278764   |
| train/             |          |
|    actor_loss      | -75.5    |
|    critic_loss     | 16.2     |
|    ent_coef        | 0.0386   |
|    ent_coef_loss   | 12.2     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1088562  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 288      |
|    ep_rew_mean     | 252      |
| time/              |          |
|    episodes        | 652      |
|    fps             | 42       |
|    time_elapsed    | 6620     |
|    total_timesteps | 278928   |
| train/             |          |
|    actor_loss      | -78.8    |
|    critic_loss     | 16.2     |
|    ent_coef        | 0.0392   |
|    ent_coef_loss   | 11.8     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1088726  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 254      |
|    ep_rew_mean     | 223      |
| time/              |          |
|    episodes        | 656      |
|    fps             | 42       |
|    time_elapsed    | 6634     |
|    total_timesteps | 279105   |
| train/             |          |
|    actor_loss      | -77.5    |
|    critic_loss     | 23.9     |
|    ent_coef        | 0.0398   |
|    ent_coef_loss   | 9.52     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1088903  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | 199      |
| time/              |          |
|    episodes        | 660      |
|    fps             | 42       |
|    time_elapsed    | 6646     |
|    total_timesteps | 279274   |
| train/             |          |
|    actor_loss      | -79.9    |
|    critic_loss     | 16.3     |
|    ent_coef        | 0.0404   |
|    ent_coef_loss   | 13.4     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089072  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 196      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    episodes        | 664      |
|    fps             | 41       |
|    time_elapsed    | 6659     |
|    total_timesteps | 279464   |
| train/             |          |
|    actor_loss      | -83.2    |
|    critic_loss     | 16       |
|    ent_coef        | 0.041    |
|    ent_coef_loss   | 10.2     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089262  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 141      |
| time/              |          |
|    episodes        | 668      |
|    fps             | 41       |
|    time_elapsed    | 6672     |
|    total_timesteps | 279635   |
| train/             |          |
|    actor_loss      | -82.5    |
|    critic_loss     | 28.5     |
|    ent_coef        | 0.0416   |
|    ent_coef_loss   | 13.7     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089433  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 121      |
|    ep_rew_mean     | 107      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 41       |
|    time_elapsed    | 6686     |
|    total_timesteps | 279835   |
| train/             |          |
|    actor_loss      | -81.5    |
|    critic_loss     | 43.5     |
|    ent_coef        | 0.0423   |
|    ent_coef_loss   | 7.23     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089633  |
---------------------------------
Eval num_timesteps=280000, episode_reward=35.94 +/- 0.00
Episode length: 40.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 40       |
|    mean_reward     | 35.9     |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -84.5    |
|    critic_loss     | 18.3     |
|    ent_coef        | 0.0428   |
|    ent_coef_loss   | 8.28     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.6     |
|    ep_rew_mean     | 71.5     |
| time/              |          |
|    episodes        | 676      |
|    fps             | 41       |
|    time_elapsed    | 6715     |
|    total_timesteps | 280059   |
| train/             |          |
|    actor_loss      | -82.6    |
|    critic_loss     | 15.2     |
|    ent_coef        | 0.043    |
|    ent_coef_loss   | 7.8      |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089857  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 57       |
|    ep_rew_mean     | 50.6     |
| time/              |          |
|    episodes        | 680      |
|    fps             | 41       |
|    time_elapsed    | 6728     |
|    total_timesteps | 280230   |
| train/             |          |
|    actor_loss      | -77.8    |
|    critic_loss     | 48.4     |
|    ent_coef        | 0.0436   |
|    ent_coef_loss   | 10.3     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090028  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 51.2     |
|    ep_rew_mean     | 45.3     |
| time/              |          |
|    episodes        | 684      |
|    fps             | 41       |
|    time_elapsed    | 6740     |
|    total_timesteps | 280408   |
| train/             |          |
|    actor_loss      | -81.1    |
|    critic_loss     | 38.1     |
|    ent_coef        | 0.0442   |
|    ent_coef_loss   | 9.92     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090206  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47       |
|    ep_rew_mean     | 41.5     |
| time/              |          |
|    episodes        | 688      |
|    fps             | 41       |
|    time_elapsed    | 6754     |
|    total_timesteps | 280588   |
| train/             |          |
|    actor_loss      | -85.6    |
|    critic_loss     | 25.2     |
|    ent_coef        | 0.0448   |
|    ent_coef_loss   | 6.34     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090386  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47       |
|    ep_rew_mean     | 41.5     |
| time/              |          |
|    episodes        | 692      |
|    fps             | 41       |
|    time_elapsed    | 6767     |
|    total_timesteps | 280770   |
| train/             |          |
|    actor_loss      | -78      |
|    critic_loss     | 20.9     |
|    ent_coef        | 0.0455   |
|    ent_coef_loss   | 7.15     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090568  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47.1     |
|    ep_rew_mean     | 41.7     |
| time/              |          |
|    episodes        | 696      |
|    fps             | 41       |
|    time_elapsed    | 6780     |
|    total_timesteps | 280965   |
| train/             |          |
|    actor_loss      | -82.5    |
|    critic_loss     | 11.1     |
|    ent_coef        | 0.0462   |
|    ent_coef_loss   | 7.77     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090763  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47       |
|    ep_rew_mean     | 41.6     |
| time/              |          |
|    episodes        | 700      |
|    fps             | 41       |
|    time_elapsed    | 6793     |
|    total_timesteps | 281137   |
| train/             |          |
|    actor_loss      | -83.9    |
|    critic_loss     | 14.2     |
|    ent_coef        | 0.0468   |
|    ent_coef_loss   | 7.16     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1090935  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47       |
|    ep_rew_mean     | 41.6     |
| time/              |          |
|    episodes        | 704      |
|    fps             | 41       |
|    time_elapsed    | 6806     |
|    total_timesteps | 281316   |
| train/             |          |
|    actor_loss      | -81.7    |
|    critic_loss     | 14.1     |
|    ent_coef        | 0.0474   |
|    ent_coef_loss   | 7.78     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1091114  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47.1     |
|    ep_rew_mean     | 41.8     |
| time/              |          |
|    episodes        | 708      |
|    fps             | 41       |
|    time_elapsed    | 6819     |
|    total_timesteps | 281509   |
| train/             |          |
|    actor_loss      | -80.3    |
|    critic_loss     | 17.4     |
|    ent_coef        | 0.0481   |
|    ent_coef_loss   | 10.6     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1091307  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | 44.2     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 41       |
|    time_elapsed    | 6837     |
|    total_timesteps | 282001   |
| train/             |          |
|    actor_loss      | -78.2    |
|    critic_loss     | 11.9     |
|    ent_coef        | 0.0498   |
|    ent_coef_loss   | 3.89     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1091799  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 56.1     |
|    ep_rew_mean     | 49.3     |
| time/              |          |
|    episodes        | 716      |
|    fps             | 41       |
|    time_elapsed    | 6860     |
|    total_timesteps | 282795   |
| train/             |          |
|    actor_loss      | -84.3    |
|    critic_loss     | 12.3     |
|    ent_coef        | 0.0524   |
|    ent_coef_loss   | 3.65     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1092593  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 71.4     |
|    ep_rew_mean     | 62.1     |
| time/              |          |
|    episodes        | 720      |
|    fps             | 41       |
|    time_elapsed    | 6897     |
|    total_timesteps | 284522   |
| train/             |          |
|    actor_loss      | -82      |
|    critic_loss     | 33.3     |
|    ent_coef        | 0.0578   |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1094320  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.6     |
|    ep_rew_mean     | 74.1     |
| time/              |          |
|    episodes        | 724      |
|    fps             | 41       |
|    time_elapsed    | 6934     |
|    total_timesteps | 286148   |
| train/             |          |
|    actor_loss      | -76.1    |
|    critic_loss     | 15.3     |
|    ent_coef        | 0.059    |
|    ent_coef_loss   | -1.41    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1095946  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | 87.6     |
| time/              |          |
|    episodes        | 728      |
|    fps             | 41       |
|    time_elapsed    | 6973     |
|    total_timesteps | 287986   |
| train/             |          |
|    actor_loss      | -75.2    |
|    critic_loss     | 22.5     |
|    ent_coef        | 0.0552   |
|    ent_coef_loss   | -0.799   |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1097784  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 114      |
|    ep_rew_mean     | 97.8     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 41       |
|    time_elapsed    | 7007     |
|    total_timesteps | 289450   |
| train/             |          |
|    actor_loss      | -74.3    |
|    critic_loss     | 13.1     |
|    ent_coef        | 0.0495   |
|    ent_coef_loss   | -1.78    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1099248  |
---------------------------------
Eval num_timesteps=290000, episode_reward=381.35 +/- 0.00
Episode length: 425.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 425      |
|    mean_reward     | 381      |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -75      |
|    critic_loss     | 11.8     |
|    ent_coef        | 0.0472   |
|    ent_coef_loss   | -0.533   |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1099798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    episodes        | 736      |
|    fps             | 41       |
|    time_elapsed    | 7067     |
|    total_timesteps | 291511   |
| train/             |          |
|    actor_loss      | -72.1    |
|    critic_loss     | 18.6     |
|    ent_coef        | 0.0418   |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1101309  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 136      |
| time/              |          |
|    episodes        | 740      |
|    fps             | 41       |
|    time_elapsed    | 7121     |
|    total_timesteps | 294261   |
| train/             |          |
|    actor_loss      | -69.3    |
|    critic_loss     | 7.16     |
|    ent_coef        | 0.0361   |
|    ent_coef_loss   | 0.915    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1104059  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 178      |
| time/              |          |
|    episodes        | 744      |
|    fps             | 41       |
|    time_elapsed    | 7207     |
|    total_timesteps | 299049   |
| train/             |          |
|    actor_loss      | -68.6    |
|    critic_loss     | 12.6     |
|    ent_coef        | 0.0346   |
|    ent_coef_loss   | 0.171    |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 1108847  |
---------------------------------
Eval num_timesteps=300000, episode_reward=1041.20 +/- 0.00
Episode length: 1179.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -69.9    |
|    critic_loss     | 10.9     |
|    ent_coef        | 0.0346   |
|    ent_coef_loss   | 0.472    |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 1109798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 257      |
|    ep_rew_mean     | 226      |
| time/              |          |
|    episodes        | 748      |
|    fps             | 41       |
|    time_elapsed    | 7343     |
|    total_timesteps | 305609   |
| train/             |          |
|    actor_loss      | -71.2    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0304   |
|    ent_coef_loss   | -0.00977 |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1115407  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 254      |
| time/              |          |
|    episodes        | 752      |
|    fps             | 41       |
|    time_elapsed    | 7406     |
|    total_timesteps | 308964   |
| train/             |          |
|    actor_loss      | -67.6    |
|    critic_loss     | 6.67     |
|    ent_coef        | 0.028    |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1118762  |
---------------------------------
Eval num_timesteps=310000, episode_reward=831.34 +/- 0.00
Episode length: 948.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 948      |
|    mean_reward     | 831      |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -74.3    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0275   |
|    ent_coef_loss   | -2.84    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1119798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 329      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    episodes        | 756      |
|    fps             | 41       |
|    time_elapsed    | 7505     |
|    total_timesteps | 313241   |
| train/             |          |
|    actor_loss      | -69.8    |
|    critic_loss     | 5.91     |
|    ent_coef        | 0.0258   |
|    ent_coef_loss   | 0.825    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1123039  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 364      |
|    ep_rew_mean     | 319      |
| time/              |          |
|    episodes        | 760      |
|    fps             | 41       |
|    time_elapsed    | 7574     |
|    total_timesteps | 316910   |
| train/             |          |
|    actor_loss      | -67.3    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0248   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1126708  |
---------------------------------
Eval num_timesteps=320000, episode_reward=807.23 +/- 0.00
Episode length: 924.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 924      |
|    mean_reward     | 807      |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0234   |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1129798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 394      |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 764      |
|    fps             | 41       |
|    time_elapsed    | 7666     |
|    total_timesteps | 320747   |
| train/             |          |
|    actor_loss      | -67.3    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0231   |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1130545  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 768      |
|    fps             | 41       |
|    time_elapsed    | 7726     |
|    total_timesteps | 323863   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 4.69     |
|    ent_coef        | 0.0223   |
|    ent_coef_loss   | -3.49    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1133661  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 395      |
| time/              |          |
|    episodes        | 772      |
|    fps             | 41       |
|    time_elapsed    | 7784     |
|    total_timesteps | 326881   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0216   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1136679  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 478      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 776      |
|    fps             | 42       |
|    time_elapsed    | 7838     |
|    total_timesteps | 329690   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 8.42     |
|    ent_coef        | 0.0218   |
|    ent_coef_loss   | 0.605    |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1139488  |
---------------------------------
Eval num_timesteps=330000, episode_reward=888.07 +/- 0.00
Episode length: 1031.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 888      |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -67.1    |
|    critic_loss     | 5.95     |
|    ent_coef        | 0.0217   |
|    ent_coef_loss   | -0.702   |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1139798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 503      |
|    ep_rew_mean     | 439      |
| time/              |          |
|    episodes        | 780      |
|    fps             | 42       |
|    time_elapsed    | 7918     |
|    total_timesteps | 332682   |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.0213   |
|    ent_coef_loss   | 1.89     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1142480  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 461      |
| time/              |          |
|    episodes        | 784      |
|    fps             | 42       |
|    time_elapsed    | 7971     |
|    total_timesteps | 335384   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0202   |
|    ent_coef_loss   | -0.249   |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1145182  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 552      |
|    ep_rew_mean     | 482      |
| time/              |          |
|    episodes        | 788      |
|    fps             | 42       |
|    time_elapsed    | 8023     |
|    total_timesteps | 337944   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | -0.643   |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1147742  |
---------------------------------
Eval num_timesteps=340000, episode_reward=636.17 +/- 0.00
Episode length: 730.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 730      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1149798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 576      |
|    ep_rew_mean     | 503      |
| time/              |          |
|    episodes        | 792      |
|    fps             | 42       |
|    time_elapsed    | 8096     |
|    total_timesteps | 340738   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1150536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 597      |
|    ep_rew_mean     | 521      |
| time/              |          |
|    episodes        | 796      |
|    fps             | 42       |
|    time_elapsed    | 8142     |
|    total_timesteps | 343011   |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -3.36    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1152809  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 620      |
|    ep_rew_mean     | 540      |
| time/              |          |
|    episodes        | 800      |
|    fps             | 42       |
|    time_elapsed    | 8192     |
|    total_timesteps | 345446   |
| train/             |          |
|    actor_loss      | -64.1    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | 0.265    |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1155244  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 646      |
|    ep_rew_mean     | 563      |
| time/              |          |
|    episodes        | 804      |
|    fps             | 42       |
|    time_elapsed    | 8247     |
|    total_timesteps | 348237   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1158035  |
---------------------------------
Eval num_timesteps=350000, episode_reward=602.85 +/- 0.00
Episode length: 701.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 701      |
|    mean_reward     | 603      |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 7.18     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -4.7     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1159798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 668      |
|    ep_rew_mean     | 582      |
| time/              |          |
|    episodes        | 808      |
|    fps             | 42       |
|    time_elapsed    | 8322     |
|    total_timesteps | 351194   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.69     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1160992  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 812      |
|    fps             | 42       |
|    time_elapsed    | 8372     |
|    total_timesteps | 353692   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 5.82     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1163490  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 614      |
| time/              |          |
|    episodes        | 816      |
|    fps             | 42       |
|    time_elapsed    | 8424     |
|    total_timesteps | 356219   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.31     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1166017  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 820      |
|    fps             | 42       |
|    time_elapsed    | 8480     |
|    total_timesteps | 359103   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 5.29     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -0.432   |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1168901  |
---------------------------------
Eval num_timesteps=360000, episode_reward=835.73 +/- 0.00
Episode length: 968.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 968      |
|    mean_reward     | 836      |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 9.26     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -3.3     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1169798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 824      |
|    fps             | 42       |
|    time_elapsed    | 8568     |
|    total_timesteps | 362696   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.62     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1172494  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | 661      |
| time/              |          |
|    episodes        | 828      |
|    fps             | 42       |
|    time_elapsed    | 8646     |
|    total_timesteps | 366950   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1176748  |
---------------------------------
Eval num_timesteps=370000, episode_reward=1198.68 +/- 0.00
Episode length: 1338.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.34e+03 |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1179798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 782      |
|    ep_rew_mean     | 685      |
| time/              |          |
|    episodes        | 832      |
|    fps             | 42       |
|    time_elapsed    | 8744     |
|    total_timesteps | 371025   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 5.35     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1180823  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 704      |
| time/              |          |
|    episodes        | 836      |
|    fps             | 42       |
|    time_elapsed    | 8821     |
|    total_timesteps | 375176   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 9.76     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.581   |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1184974  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 807      |
|    ep_rew_mean     | 705      |
| time/              |          |
|    episodes        | 840      |
|    fps             | 42       |
|    time_elapsed    | 8879     |
|    total_timesteps | 378131   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 7.93     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 5.7      |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1187929  |
---------------------------------
Eval num_timesteps=380000, episode_reward=652.15 +/- 0.00
Episode length: 751.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 751      |
|    mean_reward     | 652      |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1189798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 691      |
| time/              |          |
|    episodes        | 844      |
|    fps             | 42       |
|    time_elapsed    | 8980     |
|    total_timesteps | 382579   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1192377  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 760      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 848      |
|    fps             | 42       |
|    time_elapsed    | 9030     |
|    total_timesteps | 385042   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 9.07     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 4.6      |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1194840  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 852      |
|    fps             | 42       |
|    time_elapsed    | 9075     |
|    total_timesteps | 387188   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -0.209   |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1196986  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 729      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 856      |
|    fps             | 42       |
|    time_elapsed    | 9121     |
|    total_timesteps | 389435   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 7.65     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.6      |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1199233  |
---------------------------------
Eval num_timesteps=390000, episode_reward=452.66 +/- 0.00
Episode length: 539.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 539      |
|    mean_reward     | 453      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 6        |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1199798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 714      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 860      |
|    fps             | 42       |
|    time_elapsed    | 9193     |
|    total_timesteps | 392212   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 6.01     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -2.22    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1202010  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 607      |
| time/              |          |
|    episodes        | 864      |
|    fps             | 42       |
|    time_elapsed    | 9230     |
|    total_timesteps | 393923   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.91     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.747   |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1203721  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 685      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 868      |
|    fps             | 42       |
|    time_elapsed    | 9268     |
|    total_timesteps | 395673   |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 5.32     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.158   |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1205471  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 677      |
|    ep_rew_mean     | 587      |
| time/              |          |
|    episodes        | 872      |
|    fps             | 42       |
|    time_elapsed    | 9314     |
|    total_timesteps | 397833   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 6        |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -0.776   |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1207631  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 876      |
|    fps             | 42       |
|    time_elapsed    | 9357     |
|    total_timesteps | 399878   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1209676  |
---------------------------------
Eval num_timesteps=400000, episode_reward=542.85 +/- 0.00
Episode length: 629.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 629      |
|    mean_reward     | 543      |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1209798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 880      |
|    fps             | 42       |
|    time_elapsed    | 9432     |
|    total_timesteps | 402405   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 7.16     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1212203  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 577      |
| time/              |          |
|    episodes        | 884      |
|    fps             | 42       |
|    time_elapsed    | 9487     |
|    total_timesteps | 405044   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1214842  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 888      |
|    fps             | 42       |
|    time_elapsed    | 9543     |
|    total_timesteps | 407653   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.39     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -0.615   |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1217451  |
---------------------------------
Eval num_timesteps=410000, episode_reward=793.76 +/- 0.00
Episode length: 896.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 896      |
|    mean_reward     | 794      |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1219798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 673      |
|    ep_rew_mean     | 584      |
| time/              |          |
|    episodes        | 892      |
|    fps             | 42       |
|    time_elapsed    | 9639     |
|    total_timesteps | 411372   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 0.9      |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1221170  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 678      |
|    ep_rew_mean     | 588      |
| time/              |          |
|    episodes        | 896      |
|    fps             | 42       |
|    time_elapsed    | 9696     |
|    total_timesteps | 414062   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1223860  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 687      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 900      |
|    fps             | 42       |
|    time_elapsed    | 9765     |
|    total_timesteps | 417447   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -0.623   |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1227245  |
---------------------------------
Eval num_timesteps=420000, episode_reward=566.27 +/- 0.00
Episode length: 652.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 652      |
|    mean_reward     | 566      |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 3.2      |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -0.0604  |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1229798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 689      |
|    ep_rew_mean     | 597      |
| time/              |          |
|    episodes        | 904      |
|    fps             | 42       |
|    time_elapsed    | 9858     |
|    total_timesteps | 421217   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 1.9      |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1231015  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 908      |
|    fps             | 42       |
|    time_elapsed    | 9926     |
|    total_timesteps | 424607   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 11.6     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -3.44    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1234405  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 616      |
| time/              |          |
|    episodes        | 912      |
|    fps             | 42       |
|    time_elapsed    | 10000    |
|    total_timesteps | 428306   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -0.473   |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1238104  |
---------------------------------
Eval num_timesteps=430000, episode_reward=765.75 +/- 0.00
Episode length: 882.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 882      |
|    mean_reward     | 766      |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.33     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -3.21    |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1239798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 916      |
|    fps             | 42       |
|    time_elapsed    | 10096    |
|    total_timesteps | 432469   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 0.0803   |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1242267  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 920      |
|    fps             | 42       |
|    time_elapsed    | 10172    |
|    total_timesteps | 436590   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 3.09     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 0.872    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1246388  |
---------------------------------
Eval num_timesteps=440000, episode_reward=1068.82 +/- 0.00
Episode length: 1189.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.19e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -0.398   |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1249798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 638      |
| time/              |          |
|    episodes        | 924      |
|    fps             | 42       |
|    time_elapsed    | 10275    |
|    total_timesteps | 441031   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 3.92     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -1.67    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1250829  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 746      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 928      |
|    fps             | 43       |
|    time_elapsed    | 10369    |
|    total_timesteps | 446318   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 1256116  |
---------------------------------
Eval num_timesteps=450000, episode_reward=1633.20 +/- 0.00
Episode length: 1843.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.84e+03 |
|    mean_reward     | 1.63e+03 |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 1259798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 752      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 932      |
|    fps             | 43       |
|    time_elapsed    | 10484    |
|    total_timesteps | 451320   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 3.4      |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 1261118  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 936      |
|    fps             | 43       |
|    time_elapsed    | 10582    |
|    total_timesteps | 456937   |
| train/             |          |
|    actor_loss      | -66.6    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1266735  |
---------------------------------
Eval num_timesteps=460000, episode_reward=2194.16 +/- 0.00
Episode length: 2454.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.45e+03 |
|    mean_reward     | 2.19e+03 |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -4.3     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1269798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 940      |
|    fps             | 43       |
|    time_elapsed    | 10692    |
|    total_timesteps | 461402   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 5.03     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 1.95     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1271200  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 692      |
| time/              |          |
|    episodes        | 944      |
|    fps             | 43       |
|    time_elapsed    | 10781    |
|    total_timesteps | 466342   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1276140  |
---------------------------------
Eval num_timesteps=470000, episode_reward=1177.10 +/- 0.00
Episode length: 1342.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.34e+03 |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 5.14     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.483    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1279798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 716      |
| time/              |          |
|    episodes        | 948      |
|    fps             | 43       |
|    time_elapsed    | 10894    |
|    total_timesteps | 471427   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 3.26     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1281225  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 734      |
| time/              |          |
|    episodes        | 952      |
|    fps             | 43       |
|    time_elapsed    | 10970    |
|    total_timesteps | 475617   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 2.75     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.63     |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 1285415  |
---------------------------------
Eval num_timesteps=480000, episode_reward=941.10 +/- 0.00
Episode length: 1083.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 941      |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 8.58     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.0538  |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 1289798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 880      |
|    ep_rew_mean     | 767      |
| time/              |          |
|    episodes        | 956      |
|    fps             | 43       |
|    time_elapsed    | 11106    |
|    total_timesteps | 482213   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 1292011  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 780      |
| time/              |          |
|    episodes        | 960      |
|    fps             | 43       |
|    time_elapsed    | 11177    |
|    total_timesteps | 485939   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.8     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1295737  |
---------------------------------
Eval num_timesteps=490000, episode_reward=1251.55 +/- 0.00
Episode length: 1450.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.45e+03 |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1299798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 805      |
| time/              |          |
|    episodes        | 964      |
|    fps             | 43       |
|    time_elapsed    | 11296    |
|    total_timesteps | 491288   |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1301086  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 820      |
| time/              |          |
|    episodes        | 968      |
|    fps             | 43       |
|    time_elapsed    | 11360    |
|    total_timesteps | 494645   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.18     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1304443  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 969      |
|    ep_rew_mean     | 847      |
| time/              |          |
|    episodes        | 972      |
|    fps             | 43       |
|    time_elapsed    | 11454    |
|    total_timesteps | 499823   |
| train/             |          |
|    actor_loss      | -67.3    |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 1309621  |
---------------------------------
Eval num_timesteps=500000, episode_reward=1063.21 +/- 0.00
Episode length: 1195.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 3.38     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.36    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 1309798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 867      |
| time/              |          |
|    episodes        | 976      |
|    fps             | 43       |
|    time_elapsed    | 11556    |
|    total_timesteps | 504189   |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 2.24     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -3.27    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 1313987  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 885      |
| time/              |          |
|    episodes        | 980      |
|    fps             | 43       |
|    time_elapsed    | 11635    |
|    total_timesteps | 508564   |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 3.57     |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1318362  |
---------------------------------
Eval num_timesteps=510000, episode_reward=834.01 +/- 0.00
Episode length: 949.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 949      |
|    mean_reward     | 834      |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.996   |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1319798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 984      |
|    fps             | 43       |
|    time_elapsed    | 11735    |
|    total_timesteps | 512872   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -0.369   |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1322670  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 915      |
| time/              |          |
|    episodes        | 988      |
|    fps             | 43       |
|    time_elapsed    | 11813    |
|    total_timesteps | 517126   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.687    |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1326924  |
---------------------------------
Eval num_timesteps=520000, episode_reward=844.40 +/- 0.00
Episode length: 938.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 938      |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -65.3    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1329798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 992      |
|    fps             | 43       |
|    time_elapsed    | 11922    |
|    total_timesteps | 522019   |
| train/             |          |
|    actor_loss      | -68.6    |
|    critic_loss     | 3.29     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -5.36    |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1331817  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    episodes        | 996      |
|    fps             | 43       |
|    time_elapsed    | 12002    |
|    total_timesteps | 526427   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -3.44    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1336225  |
---------------------------------
Eval num_timesteps=530000, episode_reward=845.45 +/- 0.00
Episode length: 948.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 948      |
|    mean_reward     | 845      |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.53    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1339798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 43       |
|    time_elapsed    | 12103    |
|    total_timesteps | 530778   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 5.46     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 0.772    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1340576  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 955      |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 43       |
|    time_elapsed    | 12186    |
|    total_timesteps | 535394   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 3.09     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1345192  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 957      |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 43       |
|    time_elapsed    | 12254    |
|    total_timesteps | 539000   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 3.37     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 2.19     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1348798  |
---------------------------------
Eval num_timesteps=540000, episode_reward=675.90 +/- 0.00
Episode length: 779.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 779      |
|    mean_reward     | 676      |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.08     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.793   |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1349798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 952      |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 43       |
|    time_elapsed    | 12337    |
|    total_timesteps | 542314   |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 5.26     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.594   |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1352112  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 964      |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 44       |
|    time_elapsed    | 12423    |
|    total_timesteps | 547104   |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 4.96     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1356902  |
---------------------------------
Eval num_timesteps=550000, episode_reward=824.79 +/- 0.00
Episode length: 936.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 936      |
|    mean_reward     | 825      |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -66.6    |
|    critic_loss     | 2.87     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -4.81    |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1359798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 966      |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 44       |
|    time_elapsed    | 12532    |
|    total_timesteps | 551925   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -2.5     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1361723  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 974      |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 44       |
|    time_elapsed    | 12608    |
|    total_timesteps | 556132   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1365930  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 958      |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 44       |
|    time_elapsed    | 12674    |
|    total_timesteps | 559626   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -2.46    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1369424  |
---------------------------------
Eval num_timesteps=560000, episode_reward=1074.43 +/- 0.00
Episode length: 1214.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 2.04     |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1369798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 951      |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 44       |
|    time_elapsed    | 12772    |
|    total_timesteps | 563729   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 6.58     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 0.896    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1373527  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 942      |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 44       |
|    time_elapsed    | 12853    |
|    total_timesteps | 568289   |
| train/             |          |
|    actor_loss      | -67.5    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -0.491   |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1378087  |
---------------------------------
Eval num_timesteps=570000, episode_reward=620.14 +/- 0.00
Episode length: 715.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 715      |
|    mean_reward     | 620      |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 2        |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -1.61    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1379798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 44       |
|    time_elapsed    | 12948    |
|    total_timesteps | 572354   |
| train/             |          |
|    actor_loss      | -67.6    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1382152  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 927      |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 44       |
|    time_elapsed    | 13017    |
|    total_timesteps | 576018   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 1385816  |
---------------------------------
Eval num_timesteps=580000, episode_reward=1243.37 +/- 0.00
Episode length: 1420.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.24e+03 |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 5.17     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -0.464   |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 1389798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 44       |
|    time_elapsed    | 13129    |
|    total_timesteps | 581006   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 1390804  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 916      |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 44       |
|    time_elapsed    | 13203    |
|    total_timesteps | 585004   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 2.5      |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 0.892    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1394802  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 900      |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 44       |
|    time_elapsed    | 13277    |
|    total_timesteps | 588960   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1398758  |
---------------------------------
Eval num_timesteps=590000, episode_reward=4486.62 +/- 0.00
Episode length: 5000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5e+03    |
|    mean_reward     | 4.49e+03 |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -67.5    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -0.0986  |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1399798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 898      |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 44       |
|    time_elapsed    | 13403    |
|    total_timesteps | 593511   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1403309  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 891      |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 44       |
|    time_elapsed    | 13473    |
|    total_timesteps | 597223   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1407021  |
---------------------------------
Eval num_timesteps=600000, episode_reward=841.78 +/- 0.00
Episode length: 961.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 961      |
|    mean_reward     | 842      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -69      |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -5.78    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1409798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 890      |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 44       |
|    time_elapsed    | 13560    |
|    total_timesteps | 600763   |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 2.37     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1410561  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 873      |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 44       |
|    time_elapsed    | 13624    |
|    total_timesteps | 604094   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 2.54     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1413892  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 987      |
|    ep_rew_mean     | 870      |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 44       |
|    time_elapsed    | 13697    |
|    total_timesteps | 607947   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 2.96     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1417745  |
---------------------------------
Eval num_timesteps=610000, episode_reward=3101.83 +/- 0.00
Episode length: 3444.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.44e+03 |
|    mean_reward     | 3.1e+03  |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 0.503    |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1419798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 976      |
|    ep_rew_mean     | 860      |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 44       |
|    time_elapsed    | 13798    |
|    total_timesteps | 611518   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -1.64    |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1421316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 968      |
|    ep_rew_mean     | 852      |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 44       |
|    time_elapsed    | 13862    |
|    total_timesteps | 614862   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1424660  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 968      |
|    ep_rew_mean     | 853      |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 44       |
|    time_elapsed    | 13942    |
|    total_timesteps | 619201   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 5.09     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 3.55     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 1428999  |
---------------------------------
Eval num_timesteps=620000, episode_reward=888.83 +/- 0.00
Episode length: 1009.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 889      |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 3        |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.435    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 1429798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | 845      |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 44       |
|    time_elapsed    | 14027    |
|    total_timesteps | 622602   |
| train/             |          |
|    actor_loss      | -64.1    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 1432400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 954      |
|    ep_rew_mean     | 839      |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 44       |
|    time_elapsed    | 14099    |
|    total_timesteps | 626402   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 8.75     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.89     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1436200  |
---------------------------------
Eval num_timesteps=630000, episode_reward=1309.11 +/- 0.00
Episode length: 1467.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 1.31e+03 |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -0.554   |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1439798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 958      |
|    ep_rew_mean     | 843      |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 44       |
|    time_elapsed    | 14203    |
|    total_timesteps | 630853   |
| train/             |          |
|    actor_loss      | -66.5    |
|    critic_loss     | 3.32     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1440651  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 829      |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 44       |
|    time_elapsed    | 14264    |
|    total_timesteps | 633927   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 5.36     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1443725  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 824      |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 44       |
|    time_elapsed    | 14324    |
|    total_timesteps | 637021   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 5.38     |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1446819  |
---------------------------------
Eval num_timesteps=640000, episode_reward=1039.87 +/- 0.00
Episode length: 1201.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -0.533   |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1449798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 935      |
|    ep_rew_mean     | 822      |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 44       |
|    time_elapsed    | 14416    |
|    total_timesteps | 640792   |
| train/             |          |
|    actor_loss      | -66.8    |
|    critic_loss     | 2.84     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1450590  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 807      |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 44       |
|    time_elapsed    | 14477    |
|    total_timesteps | 643967   |
| train/             |          |
|    actor_loss      | -66.8    |
|    critic_loss     | 3.09     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 0.648    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1453765  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 800      |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 44       |
|    time_elapsed    | 14544    |
|    total_timesteps | 647504   |
| train/             |          |
|    actor_loss      | -65.3    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -0.955   |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1457302  |
---------------------------------
Eval num_timesteps=650000, episode_reward=875.51 +/- 0.00
Episode length: 1005.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 876      |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -2.92    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1459798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 796      |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 44       |
|    time_elapsed    | 14646    |
|    total_timesteps | 651949   |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 7.88     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -1.47    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1461747  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 791      |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 44       |
|    time_elapsed    | 14704    |
|    total_timesteps | 654937   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -0.0564  |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1464735  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 894      |
|    ep_rew_mean     | 783      |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 44       |
|    time_elapsed    | 14761    |
|    total_timesteps | 657810   |
| train/             |          |
|    actor_loss      | -67.2    |
|    critic_loss     | 5.93     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -0.753   |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 1467608  |
---------------------------------
Eval num_timesteps=660000, episode_reward=979.12 +/- 0.00
Episode length: 1132.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 979      |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.821   |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 1469798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 775      |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 44       |
|    time_elapsed    | 14857    |
|    total_timesteps | 661858   |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -2.17    |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 1471656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 44       |
|    time_elapsed    | 14920    |
|    total_timesteps | 665134   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 2.65     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1474932  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 769      |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 44       |
|    time_elapsed    | 14992    |
|    total_timesteps | 668906   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 2.98     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -3.22    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1478704  |
---------------------------------
Eval num_timesteps=670000, episode_reward=900.62 +/- 0.00
Episode length: 1018.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 901      |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 2.55     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1479798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 880      |
|    ep_rew_mean     | 771      |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 44       |
|    time_elapsed    | 15109    |
|    total_timesteps | 674339   |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 6.04     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1484137  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 758      |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 44       |
|    time_elapsed    | 15160    |
|    total_timesteps | 676890   |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 5.43     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 3.18     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1486688  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 44       |
|    time_elapsed    | 15212    |
|    total_timesteps | 679409   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 0.0594   |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1489207  |
---------------------------------
Eval num_timesteps=680000, episode_reward=568.61 +/- 0.00
Episode length: 641.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 641      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 6.66     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 3.54     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1489798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 851      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 44       |
|    time_elapsed    | 15307    |
|    total_timesteps | 683486   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 2.91     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1493284  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 44       |
|    time_elapsed    | 15371    |
|    total_timesteps | 686868   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 14.8     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -3.72    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1496666  |
---------------------------------
Eval num_timesteps=690000, episode_reward=1741.54 +/- 0.00
Episode length: 1932.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.93e+03 |
|    mean_reward     | 1.74e+03 |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.732   |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1499798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 748      |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 44       |
|    time_elapsed    | 15486    |
|    total_timesteps | 691687   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 3.72     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1501485  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 759      |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 44       |
|    time_elapsed    | 15571    |
|    total_timesteps | 696320   |
| train/             |          |
|    actor_loss      | -67      |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -0.372   |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1506118  |
---------------------------------
Eval num_timesteps=700000, episode_reward=650.64 +/- 0.00
Episode length: 739.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 739      |
|    mean_reward     | 651      |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 8.52     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -0.433   |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1509798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 44       |
|    time_elapsed    | 15683    |
|    total_timesteps | 701508   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1511306  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 765      |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 44       |
|    time_elapsed    | 15739    |
|    total_timesteps | 704382   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -1.57    |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1514180  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 763      |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 44       |
|    time_elapsed    | 15801    |
|    total_timesteps | 707526   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 3.55     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 0.012    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1517324  |
---------------------------------
Eval num_timesteps=710000, episode_reward=2371.58 +/- 0.00
Episode length: 2657.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.66e+03 |
|    mean_reward     | 2.37e+03 |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 2.28     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1519798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 757      |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 44       |
|    time_elapsed    | 15918    |
|    total_timesteps | 712170   |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 2.72     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1521968  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 765      |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 44       |
|    time_elapsed    | 15995    |
|    total_timesteps | 716354   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.147    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1526152  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 862      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 44       |
|    time_elapsed    | 16050    |
|    total_timesteps | 719095   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 5.96     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1528893  |
---------------------------------
Eval num_timesteps=720000, episode_reward=1115.05 +/- 0.00
Episode length: 1276.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.28e+03 |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -66.5    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1529798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 44       |
|    time_elapsed    | 16158    |
|    total_timesteps | 723842   |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -3.53    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1533640  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 44       |
|    time_elapsed    | 16209    |
|    total_timesteps | 726380   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 5.61     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -3.02    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1536178  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 44       |
|    time_elapsed    | 16270    |
|    total_timesteps | 729459   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -3.79    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1539257  |
---------------------------------
Eval num_timesteps=730000, episode_reward=599.58 +/- 0.00
Episode length: 683.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 683      |
|    mean_reward     | 600      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -2.46    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1539798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 44       |
|    time_elapsed    | 16356    |
|    total_timesteps | 733073   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1542871  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 858      |
|    ep_rew_mean     | 752      |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 44       |
|    time_elapsed    | 16421    |
|    total_timesteps | 736372   |
| train/             |          |
|    actor_loss      | -67.2    |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1546170  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 856      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 44       |
|    time_elapsed    | 16485    |
|    total_timesteps | 739693   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1549491  |
---------------------------------
Eval num_timesteps=740000, episode_reward=674.13 +/- 0.00
Episode length: 767.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 767      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 7.99     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 4.69     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1549798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 44       |
|    time_elapsed    | 16579    |
|    total_timesteps | 743662   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -3.26    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1553460  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 44       |
|    time_elapsed    | 16647    |
|    total_timesteps | 747165   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 3.27     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1556963  |
---------------------------------
Eval num_timesteps=750000, episode_reward=613.28 +/- 0.00
Episode length: 686.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 613      |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.897   |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1559798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 861      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 44       |
|    time_elapsed    | 16733    |
|    total_timesteps | 750739   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.0731   |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1560537  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 748      |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 44       |
|    time_elapsed    | 16787    |
|    total_timesteps | 753518   |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.21     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1563316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 748      |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 44       |
|    time_elapsed    | 16850    |
|    total_timesteps | 756759   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 3.16     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -1.47    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1566557  |
---------------------------------
Eval num_timesteps=760000, episode_reward=562.97 +/- 0.00
Episode length: 635.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 563      |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 0.763    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1569798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 44       |
|    time_elapsed    | 16941    |
|    total_timesteps | 760557   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1570355  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 823      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 44       |
|    time_elapsed    | 16993    |
|    total_timesteps | 763153   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 2.95     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -3.37    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1572951  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 44       |
|    time_elapsed    | 17055    |
|    total_timesteps | 766299   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 6.84     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.216    |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1576097  |
---------------------------------
Eval num_timesteps=770000, episode_reward=597.67 +/- 0.00
Episode length: 679.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 679      |
|    mean_reward     | 598      |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 6.21     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1579798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 847      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 44       |
|    time_elapsed    | 17165    |
|    total_timesteps | 771281   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1581079  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 738      |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 44       |
|    time_elapsed    | 17222    |
|    total_timesteps | 774198   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1583996  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 738      |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 44       |
|    time_elapsed    | 17288    |
|    total_timesteps | 777680   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 3.48     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1587478  |
---------------------------------
Eval num_timesteps=780000, episode_reward=893.19 +/- 0.00
Episode length: 1023.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 893      |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.469    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1589798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 44       |
|    time_elapsed    | 17373    |
|    total_timesteps | 781071   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1590869  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 44       |
|    time_elapsed    | 17443    |
|    total_timesteps | 784761   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -3.89    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1594559  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 808      |
|    ep_rew_mean     | 708      |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 45       |
|    time_elapsed    | 17512    |
|    total_timesteps | 788390   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 4.96     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.698   |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1598188  |
---------------------------------
Eval num_timesteps=790000, episode_reward=864.90 +/- 0.00
Episode length: 987.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 987      |
|    mean_reward     | 865      |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.921   |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1599798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 44       |
|    time_elapsed    | 17594    |
|    total_timesteps | 791526   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1601324  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 713      |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 45       |
|    time_elapsed    | 17661    |
|    total_timesteps | 795014   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.246   |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1604812  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 813      |
|    ep_rew_mean     | 712      |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 45       |
|    time_elapsed    | 17729    |
|    total_timesteps | 798527   |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 3.84     |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1608325  |
---------------------------------
Eval num_timesteps=800000, episode_reward=533.63 +/- 0.00
Episode length: 619.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 534      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.144   |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1609798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 705      |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 45       |
|    time_elapsed    | 17821    |
|    total_timesteps | 802508   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1612306  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 709      |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 45       |
|    time_elapsed    | 17882    |
|    total_timesteps | 805642   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.551   |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1615440  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 706      |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 45       |
|    time_elapsed    | 17949    |
|    total_timesteps | 809159   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 8.5      |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.976   |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1618957  |
---------------------------------
Eval num_timesteps=810000, episode_reward=1107.20 +/- 0.00
Episode length: 1251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 23.3     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1619798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 816      |
|    ep_rew_mean     | 714      |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 45       |
|    time_elapsed    | 18051    |
|    total_timesteps | 813520   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -5.59    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1623318  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 717      |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 45       |
|    time_elapsed    | 18114    |
|    total_timesteps | 816796   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 5.93     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1626594  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 45       |
|    time_elapsed    | 18174    |
|    total_timesteps | 819932   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 2.67     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1629730  |
---------------------------------
Eval num_timesteps=820000, episode_reward=939.32 +/- 0.00
Episode length: 1066.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.07e+03 |
|    mean_reward     | 939      |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.338    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1629798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 726      |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 45       |
|    time_elapsed    | 18273    |
|    total_timesteps | 824157   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1633955  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 726      |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 45       |
|    time_elapsed    | 18337    |
|    total_timesteps | 827465   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 8.84     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.76     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1637263  |
---------------------------------
Eval num_timesteps=830000, episode_reward=658.89 +/- 0.00
Episode length: 746.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 746      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 7.41     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.2     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1639798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 720      |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 45       |
|    time_elapsed    | 18418    |
|    total_timesteps | 830678   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -3.46    |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1640476  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 815      |
|    ep_rew_mean     | 715      |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 45       |
|    time_elapsed    | 18476    |
|    total_timesteps | 833686   |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.316   |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1643484  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 817      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 45       |
|    time_elapsed    | 18538    |
|    total_timesteps | 836898   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 7.85     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1646696  |
---------------------------------
Eval num_timesteps=840000, episode_reward=872.20 +/- 0.00
Episode length: 989.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 989      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.348   |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1649798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 725      |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 45       |
|    time_elapsed    | 18636    |
|    total_timesteps | 841038   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1650836  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 823      |
|    ep_rew_mean     | 723      |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 45       |
|    time_elapsed    | 18694    |
|    total_timesteps | 844069   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.356    |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1653867  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 45       |
|    time_elapsed    | 18753    |
|    total_timesteps | 847103   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.54    |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1656901  |
---------------------------------
Eval num_timesteps=850000, episode_reward=674.79 +/- 0.00
Episode length: 759.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 759      |
|    mean_reward     | 675      |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 2.62     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.0508   |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1659798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 832      |
|    ep_rew_mean     | 731      |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 45       |
|    time_elapsed    | 18844    |
|    total_timesteps | 850889   |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 8.9      |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1660687  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 45       |
|    time_elapsed    | 18914    |
|    total_timesteps | 854643   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 8.32     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 0.644    |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1664441  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 45       |
|    time_elapsed    | 18993    |
|    total_timesteps | 858942   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.121    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 1668740  |
---------------------------------
Eval num_timesteps=860000, episode_reward=622.31 +/- 0.00
Episode length: 711.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 711      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.102   |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 1669798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 45       |
|    time_elapsed    | 19084    |
|    total_timesteps | 862703   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 7.77     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.0103  |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 1672501  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 45       |
|    time_elapsed    | 19145    |
|    total_timesteps | 865913   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.614   |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1675711  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 45       |
|    time_elapsed    | 19215    |
|    total_timesteps | 869676   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 5.53     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.84     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1679474  |
---------------------------------
Eval num_timesteps=870000, episode_reward=658.54 +/- 0.00
Episode length: 755.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 755      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 2.03     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1679798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 45       |
|    time_elapsed    | 19309    |
|    total_timesteps | 873741   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.492    |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1683539  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 45       |
|    time_elapsed    | 19385    |
|    total_timesteps | 877791   |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1687589  |
---------------------------------
Eval num_timesteps=880000, episode_reward=602.51 +/- 0.00
Episode length: 689.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | 603      |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 7.71     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.956   |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1689798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 45       |
|    time_elapsed    | 19467    |
|    total_timesteps | 881056   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 2.84     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1690854  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 45       |
|    time_elapsed    | 19533    |
|    total_timesteps | 884578   |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 7.18     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1694376  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 45       |
|    time_elapsed    | 19607    |
|    total_timesteps | 888440   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 5.49     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 1698238  |
---------------------------------
Eval num_timesteps=890000, episode_reward=825.02 +/- 0.00
Episode length: 934.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 934      |
|    mean_reward     | 825      |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -2.95    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 1699798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 45       |
|    time_elapsed    | 19717    |
|    total_timesteps | 893385   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 11.5     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -3.11    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 1703183  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 884      |
|    ep_rew_mean     | 778      |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 45       |
|    time_elapsed    | 19794    |
|    total_timesteps | 897609   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.66     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 1707407  |
---------------------------------
Eval num_timesteps=900000, episode_reward=927.37 +/- 0.00
Episode length: 1056.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.06e+03 |
|    mean_reward     | 927      |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 0.354    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 1709798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 773      |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 45       |
|    time_elapsed    | 19887    |
|    total_timesteps | 901376   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 1711174  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 887      |
|    ep_rew_mean     | 780      |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 45       |
|    time_elapsed    | 19965    |
|    total_timesteps | 905673   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 2.79     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -2.68    |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 1715471  |
---------------------------------
Eval num_timesteps=910000, episode_reward=2873.43 +/- 0.00
Episode length: 3190.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.19e+03 |
|    mean_reward     | 2.87e+03 |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -3.4     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 1719798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 800      |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 45       |
|    time_elapsed    | 20130    |
|    total_timesteps | 913198   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.209   |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 1722996  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 933      |
|    ep_rew_mean     | 822      |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 45       |
|    time_elapsed    | 20231    |
|    total_timesteps | 918809   |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 2.08     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 1728607  |
---------------------------------
Eval num_timesteps=920000, episode_reward=1036.02 +/- 0.00
Episode length: 1175.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 1729798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 951      |
|    ep_rew_mean     | 839      |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 45       |
|    time_elapsed    | 20364    |
|    total_timesteps | 925034   |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.79    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1734832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 956      |
|    ep_rew_mean     | 843      |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 45       |
|    time_elapsed    | 20434    |
|    total_timesteps | 928823   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1738621  |
---------------------------------
Eval num_timesteps=930000, episode_reward=2181.85 +/- 0.00
Episode length: 2428.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.43e+03 |
|    mean_reward     | 2.18e+03 |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 3.32     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1739798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 962      |
|    ep_rew_mean     | 847      |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 45       |
|    time_elapsed    | 20535    |
|    total_timesteps | 932608   |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.192    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1742406  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 989      |
|    ep_rew_mean     | 871      |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 45       |
|    time_elapsed    | 20634    |
|    total_timesteps | 938303   |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 1748101  |
---------------------------------
Eval num_timesteps=940000, episode_reward=1948.14 +/- 0.00
Episode length: 2186.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.19e+03 |
|    mean_reward     | 1.95e+03 |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.18     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.297    |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 1749798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 886      |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 45       |
|    time_elapsed    | 20779    |
|    total_timesteps | 944876   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 4.98     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 4.05     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 1754674  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 894      |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 45       |
|    time_elapsed    | 20861    |
|    total_timesteps | 949411   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 5.25     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 1759209  |
---------------------------------
Eval num_timesteps=950000, episode_reward=1022.36 +/- 0.00
Episode length: 1154.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.15e+03 |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 5.15     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.629    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 1759798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 905      |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 45       |
|    time_elapsed    | 20971    |
|    total_timesteps | 954268   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.227   |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 1764066  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 907      |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 45       |
|    time_elapsed    | 21035    |
|    total_timesteps | 957542   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 1767340  |
---------------------------------
Eval num_timesteps=960000, episode_reward=854.28 +/- 0.00
Episode length: 974.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 974      |
|    mean_reward     | 854      |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.114    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 1769798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 921      |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 45       |
|    time_elapsed    | 21180    |
|    total_timesteps | 964720   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 3.55     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 1774518  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 920      |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 45       |
|    time_elapsed    | 21247    |
|    total_timesteps | 968325   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.09     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 1778123  |
---------------------------------
Eval num_timesteps=970000, episode_reward=2242.75 +/- 0.00
Episode length: 2524.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.52e+03 |
|    mean_reward     | 2.24e+03 |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 1779798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 911      |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 45       |
|    time_elapsed    | 21350    |
|    total_timesteps | 972295   |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.589    |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 1782093  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 45       |
|    time_elapsed    | 21431    |
|    total_timesteps | 976673   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 2.51     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.0452  |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 1786471  |
---------------------------------
Eval num_timesteps=980000, episode_reward=1996.04 +/- 0.00
Episode length: 2247.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.25e+03 |
|    mean_reward     | 2e+03    |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 3.42     |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 1789798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 935      |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 45       |
|    time_elapsed    | 21558    |
|    total_timesteps | 982308   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 4.08     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.808   |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 1792106  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 45       |
|    time_elapsed    | 21652    |
|    total_timesteps | 987462   |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -0.94    |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 1797260  |
---------------------------------
Eval num_timesteps=990000, episode_reward=4519.03 +/- 0.00
Episode length: 5000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 5e+03    |
|    mean_reward     | 4.52e+03 |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 2.04     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 1799798  |
---------------------------------
New best mean reward!
Stopping training because the mean reward 4519.03  is above the threshold 4500