Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_88
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 575      |
|    ep_rew_mean     | 514      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 78       |
|    time_elapsed    | 29       |
|    total_timesteps | 2300     |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 19.9     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 0.0001   |
|    n_updates       | 2739800  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 112      |
|    time_elapsed    | 52       |
|    total_timesteps | 5951     |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 12.9     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.169   |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 2739804  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 689      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 123      |
|    time_elapsed    | 74       |
|    total_timesteps | 9236     |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 7.28     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 4.31     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 2739808  |
---------------------------------
Eval num_timesteps=10000, episode_reward=1015.92 +/- 0.00
Episode length: 1116.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 5.51     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 2739809  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 107      |
|    time_elapsed    | 127      |
|    total_timesteps | 13629    |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.28     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 2739812  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 752      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 118      |
|    time_elapsed    | 148      |
|    total_timesteps | 17586    |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 6.03     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 9.07     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 2739816  |
---------------------------------
Eval num_timesteps=20000, episode_reward=1006.48 +/- 0.00
Episode length: 1115.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.186   |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 2739819  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 107      |
|    time_elapsed    | 203      |
|    total_timesteps | 21970    |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 7.08     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 7.56     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 2739820  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | 771      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 113      |
|    time_elapsed    | 225      |
|    total_timesteps | 25564    |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 5.96     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 2739824  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 774      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 118      |
|    time_elapsed    | 246      |
|    total_timesteps | 29128    |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 2739828  |
---------------------------------
Eval num_timesteps=30000, episode_reward=976.72 +/- 0.00
Episode length: 1086.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 977      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 1.23     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 2739829  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 765      |
| time/              |          |
|    episodes        | 36       |
|    fps             | 111      |
|    time_elapsed    | 297      |
|    total_timesteps | 33127    |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.58     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 2739832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 762      |
| time/              |          |
|    episodes        | 40       |
|    fps             | 114      |
|    time_elapsed    | 317      |
|    total_timesteps | 36495    |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 10.2     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 2739836  |
---------------------------------
Eval num_timesteps=40000, episode_reward=2221.76 +/- 0.00
Episode length: 2397.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.4e+03  |
|    mean_reward     | 2.22e+03 |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.07     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.928    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 2739840  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 788      |
| time/              |          |
|    episodes        | 44       |
|    fps             | 109      |
|    time_elapsed    | 376      |
|    total_timesteps | 41278    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 905      |
|    ep_rew_mean     | 805      |
| time/              |          |
|    episodes        | 48       |
|    fps             | 114      |
|    time_elapsed    | 398      |
|    total_timesteps | 45741    |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.65     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 2739844  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 811      |
| time/              |          |
|    episodes        | 52       |
|    fps             | 118      |
|    time_elapsed    | 420      |
|    total_timesteps | 49788    |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.376    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 2739848  |
---------------------------------
Eval num_timesteps=50000, episode_reward=1911.73 +/- 0.00
Episode length: 2065.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.06e+03 |
|    mean_reward     | 1.91e+03 |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.51     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.16     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 2739849  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 916      |
|    ep_rew_mean     | 812      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 112      |
|    time_elapsed    | 478      |
|    total_timesteps | 53792    |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.48     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 2739852  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 807      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 114      |
|    time_elapsed    | 497      |
|    total_timesteps | 57223    |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.695    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 2739856  |
---------------------------------
Eval num_timesteps=60000, episode_reward=2050.51 +/- 0.00
Episode length: 2218.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.22e+03 |
|    mean_reward     | 2.05e+03 |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.483    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 2739860  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 813      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 110      |
|    time_elapsed    | 555      |
|    total_timesteps | 61322    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 813      |
| time/              |          |
|    episodes        | 68       |
|    fps             | 113      |
|    time_elapsed    | 575      |
|    total_timesteps | 64997    |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.233    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 2739864  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 817      |
| time/              |          |
|    episodes        | 72       |
|    fps             | 116      |
|    time_elapsed    | 595      |
|    total_timesteps | 69116    |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 2739868  |
---------------------------------
Eval num_timesteps=70000, episode_reward=1938.37 +/- 0.00
Episode length: 2186.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.19e+03 |
|    mean_reward     | 1.94e+03 |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.768   |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 2739869  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 929      |
|    ep_rew_mean     | 821      |
| time/              |          |
|    episodes        | 76       |
|    fps             | 113      |
|    time_elapsed    | 652      |
|    total_timesteps | 74028    |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 2739872  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 920      |
|    ep_rew_mean     | 813      |
| time/              |          |
|    episodes        | 80       |
|    fps             | 114      |
|    time_elapsed    | 671      |
|    total_timesteps | 77003    |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 2739876  |
---------------------------------
Eval num_timesteps=80000, episode_reward=1071.38 +/- 0.00
Episode length: 1206.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 5.29     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.428    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 2739880  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 919      |
|    ep_rew_mean     | 812      |
| time/              |          |
|    episodes        | 84       |
|    fps             | 112      |
|    time_elapsed    | 719      |
|    total_timesteps | 80911    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 815      |
| time/              |          |
|    episodes        | 88       |
|    fps             | 114      |
|    time_elapsed    | 738      |
|    total_timesteps | 84712    |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.8      |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 2739884  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 922      |
|    ep_rew_mean     | 816      |
| time/              |          |
|    episodes        | 92       |
|    fps             | 116      |
|    time_elapsed    | 758      |
|    total_timesteps | 88511    |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 2739888  |
---------------------------------
Eval num_timesteps=90000, episode_reward=1420.16 +/- 0.00
Episode length: 1532.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.42e+03 |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.769   |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 2739890  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 926      |
|    ep_rew_mean     | 820      |
| time/              |          |
|    episodes        | 96       |
|    fps             | 114      |
|    time_elapsed    | 809      |
|    total_timesteps | 92951    |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.44     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 2739892  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 926      |
|    ep_rew_mean     | 820      |
| time/              |          |
|    episodes        | 100      |
|    fps             | 116      |
|    time_elapsed    | 828      |
|    total_timesteps | 96635    |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.35    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 2739896  |
---------------------------------
Eval num_timesteps=100000, episode_reward=2480.10 +/- 0.00
Episode length: 2644.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.64e+03 |
|    mean_reward     | 2.48e+03 |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 5.88     |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 2739900  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 835      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 113      |
|    time_elapsed    | 888      |
|    total_timesteps | 100876   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 830      |
| time/              |          |
|    episodes        | 108      |
|    fps             | 114      |
|    time_elapsed    | 906      |
|    total_timesteps | 104023   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 2.67     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.35    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 2739904  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 944      |
|    ep_rew_mean     | 836      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 116      |
|    time_elapsed    | 925      |
|    total_timesteps | 107954   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 2739908  |
---------------------------------
Eval num_timesteps=110000, episode_reward=4554.80 +/- 0.00
Episode length: 4807.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.81e+03 |
|    mean_reward     | 4.55e+03 |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.209   |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 2739911  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 834      |
| time/              |          |
|    episodes        | 116      |
|    fps             | 111      |
|    time_elapsed    | 1000     |
|    total_timesteps | 111466   |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 2739912  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 832      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 112      |
|    time_elapsed    | 1019     |
|    total_timesteps | 115117   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 2739916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 937      |
|    ep_rew_mean     | 830      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 114      |
|    time_elapsed    | 1038     |
|    total_timesteps | 118777   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.818    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 2739920  |
---------------------------------
Eval num_timesteps=120000, episode_reward=1125.35 +/- 0.00
Episode length: 1259.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.17    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 2739922  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 831      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 113      |
|    time_elapsed    | 1087     |
|    total_timesteps | 123061   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.3      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 2739924  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 935      |
|    ep_rew_mean     | 829      |
| time/              |          |
|    episodes        | 132      |
|    fps             | 114      |
|    time_elapsed    | 1104     |
|    total_timesteps | 126328   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.734    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 2739928  |
---------------------------------
Eval num_timesteps=130000, episode_reward=1110.52 +/- 0.00
Episode length: 1220.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 2.83     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 2739932  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 940      |
|    ep_rew_mean     | 833      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 113      |
|    time_elapsed    | 1154     |
|    total_timesteps | 130922   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 948      |
|    ep_rew_mean     | 841      |
| time/              |          |
|    episodes        | 140      |
|    fps             | 114      |
|    time_elapsed    | 1174     |
|    total_timesteps | 135065   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 2.33     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -5.56    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 2739936  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 938      |
|    ep_rew_mean     | 832      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 116      |
|    time_elapsed    | 1192     |
|    total_timesteps | 138737   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.46    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 2739940  |
---------------------------------
Eval num_timesteps=140000, episode_reward=1213.62 +/- 0.00
Episode length: 1330.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.33e+03 |
|    mean_reward     | 1.21e+03 |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 2739942  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 820      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 114      |
|    time_elapsed    | 1241     |
|    total_timesteps | 142282   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 5.05     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.57    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 2739944  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 921      |
|    ep_rew_mean     | 817      |
| time/              |          |
|    episodes        | 152      |
|    fps             | 115      |
|    time_elapsed    | 1260     |
|    total_timesteps | 145977   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.358   |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 2739948  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 913      |
|    ep_rew_mean     | 811      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 116      |
|    time_elapsed    | 1278     |
|    total_timesteps | 149049   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.357   |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 2739952  |
---------------------------------
Eval num_timesteps=150000, episode_reward=3193.56 +/- 0.00
Episode length: 3374.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.37e+03 |
|    mean_reward     | 3.19e+03 |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 2.88     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 2739953  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 918      |
|    ep_rew_mean     | 816      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 114      |
|    time_elapsed    | 1343     |
|    total_timesteps | 153909   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 3.53     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.24    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 2739956  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 917      |
|    ep_rew_mean     | 816      |
| time/              |          |
|    episodes        | 164      |
|    fps             | 115      |
|    time_elapsed    | 1363     |
|    total_timesteps | 157863   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 2739960  |
---------------------------------
Eval num_timesteps=160000, episode_reward=962.51 +/- 0.00
Episode length: 1077.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 963      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.907   |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 2739963  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 914      |
|    ep_rew_mean     | 813      |
| time/              |          |
|    episodes        | 168      |
|    fps             | 114      |
|    time_elapsed    | 1410     |
|    total_timesteps | 161650   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.33     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.17    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 2739964  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 908      |
|    ep_rew_mean     | 809      |
| time/              |          |
|    episodes        | 172      |
|    fps             | 115      |
|    time_elapsed    | 1429     |
|    total_timesteps | 165174   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 9.12     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.954   |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 2739968  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 802      |
| time/              |          |
|    episodes        | 176      |
|    fps             | 116      |
|    time_elapsed    | 1446     |
|    total_timesteps | 168401   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.45    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 2739972  |
---------------------------------
Eval num_timesteps=170000, episode_reward=1565.78 +/- 0.00
Episode length: 1736.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.74e+03 |
|    mean_reward     | 1.57e+03 |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 2739975  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 903      |
|    ep_rew_mean     | 804      |
| time/              |          |
|    episodes        | 180      |
|    fps             | 114      |
|    time_elapsed    | 1497     |
|    total_timesteps | 171690   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.41    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 2739976  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 900      |
|    ep_rew_mean     | 802      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 115      |
|    time_elapsed    | 1514     |
|    total_timesteps | 175048   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.18    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 2739980  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 891      |
|    ep_rew_mean     | 793      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 116      |
|    time_elapsed    | 1531     |
|    total_timesteps | 177966   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.79    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 2739984  |
---------------------------------
Eval num_timesteps=180000, episode_reward=959.49 +/- 0.00
Episode length: 1049.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.05e+03 |
|    mean_reward     | 959      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.99    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 2739987  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 788      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 115      |
|    time_elapsed    | 1575     |
|    total_timesteps | 181702   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.88    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 2739988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 881      |
|    ep_rew_mean     | 784      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 116      |
|    time_elapsed    | 1594     |
|    total_timesteps | 185312   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 2739992  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 782      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 117      |
|    time_elapsed    | 1612     |
|    total_timesteps | 188681   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -4.98    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 2739996  |
---------------------------------
Eval num_timesteps=190000, episode_reward=927.87 +/- 0.00
Episode length: 1016.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 928      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.582   |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 2739998  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 779      |
| time/              |          |
|    episodes        | 204      |
|    fps             | 116      |
|    time_elapsed    | 1658     |
|    total_timesteps | 192697   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.92    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 2740000  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 881      |
|    ep_rew_mean     | 785      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 117      |
|    time_elapsed    | 1677     |
|    total_timesteps | 196464   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -6.4     |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 2740004  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 781      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 117      |
|    time_elapsed    | 1695     |
|    total_timesteps | 199949   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 2.37     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 2740008  |
---------------------------------
Eval num_timesteps=200000, episode_reward=727.60 +/- 0.00
Episode length: 806.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 806      |
|    mean_reward     | 728      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 2.39     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -3.91    |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 2740009  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 779      |
| time/              |          |
|    episodes        | 216      |
|    fps             | 116      |
|    time_elapsed    | 1739     |
|    total_timesteps | 203158   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 2.33     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.963   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 2740012  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 775      |
| time/              |          |
|    episodes        | 220      |
|    fps             | 117      |
|    time_elapsed    | 1757     |
|    total_timesteps | 206406   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.69    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2740016  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 773      |
| time/              |          |
|    episodes        | 224      |
|    fps             | 118      |
|    time_elapsed    | 1775     |
|    total_timesteps | 209811   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 2.57     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2740020  |
---------------------------------
Eval num_timesteps=210000, episode_reward=814.41 +/- 0.00
Episode length: 905.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 905      |
|    mean_reward     | 814      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.3      |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.54    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2740021  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 228      |
|    fps             | 117      |
|    time_elapsed    | 1819     |
|    total_timesteps | 212953   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.94     |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2740024  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 770      |
| time/              |          |
|    episodes        | 232      |
|    fps             | 117      |
|    time_elapsed    | 1837     |
|    total_timesteps | 216607   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.45     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2740028  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 118      |
|    time_elapsed    | 1855     |
|    total_timesteps | 219780   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 6.12     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.613   |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2740032  |
---------------------------------
Eval num_timesteps=220000, episode_reward=3856.70 +/- 0.00
Episode length: 4135.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.14e+03 |
|    mean_reward     | 3.86e+03 |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.91    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2740033  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 240      |
|    fps             | 116      |
|    time_elapsed    | 1920     |
|    total_timesteps | 223022   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2740036  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 746      |
| time/              |          |
|    episodes        | 244      |
|    fps             | 116      |
|    time_elapsed    | 1938     |
|    total_timesteps | 225813   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2740040  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 248      |
|    fps             | 117      |
|    time_elapsed    | 1956     |
|    total_timesteps | 229221   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -7.17    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2740044  |
---------------------------------
Eval num_timesteps=230000, episode_reward=1006.46 +/- 0.00
Episode length: 1129.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.2     |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2740045  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 116      |
|    time_elapsed    | 2002     |
|    total_timesteps | 233305   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 3.63     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -3.23    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2740048  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 117      |
|    time_elapsed    | 2020     |
|    total_timesteps | 236931   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -3.28    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2740052  |
---------------------------------
Eval num_timesteps=240000, episode_reward=985.34 +/- 0.00
Episode length: 1092.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 985      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.128   |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2740056  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 835      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 116      |
|    time_elapsed    | 2066     |
|    total_timesteps | 240738   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 117      |
|    time_elapsed    | 2086     |
|    total_timesteps | 244593   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 5.04     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -5.22    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2740060  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 117      |
|    time_elapsed    | 2104     |
|    total_timesteps | 247621   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.185   |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2740064  |
---------------------------------
Eval num_timesteps=250000, episode_reward=2411.28 +/- 0.00
Episode length: 2634.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.63e+03 |
|    mean_reward     | 2.41e+03 |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 2.64     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -6.26    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2740067  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 116      |
|    time_elapsed    | 2163     |
|    total_timesteps | 251559   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 2.67     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.51    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2740068  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 116      |
|    time_elapsed    | 2180     |
|    total_timesteps | 254642   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 7.45     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2740072  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 735      |
| time/              |          |
|    episodes        | 280      |
|    fps             | 117      |
|    time_elapsed    | 2199     |
|    total_timesteps | 257846   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.29    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2740076  |
---------------------------------
Eval num_timesteps=260000, episode_reward=713.94 +/- 0.00
Episode length: 815.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 815      |
|    mean_reward     | 714      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.401    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2740079  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 735      |
| time/              |          |
|    episodes        | 284      |
|    fps             | 116      |
|    time_elapsed    | 2242     |
|    total_timesteps | 261814   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.63    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2740080  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 117      |
|    time_elapsed    | 2262     |
|    total_timesteps | 265405   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 5.96     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2740084  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 828      |
|    ep_rew_mean     | 733      |
| time/              |          |
|    episodes        | 292      |
|    fps             | 117      |
|    time_elapsed    | 2279     |
|    total_timesteps | 267841   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.09    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2740088  |
---------------------------------
Eval num_timesteps=270000, episode_reward=1092.28 +/- 0.00
Episode length: 1211.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2740091  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 296      |
|    fps             | 116      |
|    time_elapsed    | 2324     |
|    total_timesteps | 271253   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2740092  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 300      |
|    fps             | 117      |
|    time_elapsed    | 2342     |
|    total_timesteps | 274145   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 2.61     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.66    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2740096  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 817      |
|    ep_rew_mean     | 721      |
| time/              |          |
|    episodes        | 304      |
|    fps             | 117      |
|    time_elapsed    | 2360     |
|    total_timesteps | 277705   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -6.59    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2740100  |
---------------------------------
Eval num_timesteps=280000, episode_reward=739.01 +/- 0.00
Episode length: 841.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 841      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2740104  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 308      |
|    fps             | 116      |
|    time_elapsed    | 2403     |
|    total_timesteps | 280544   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 312      |
|    fps             | 117      |
|    time_elapsed    | 2421     |
|    total_timesteps | 284068   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.48    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2740108  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 712      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 117      |
|    time_elapsed    | 2440     |
|    total_timesteps | 287569   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.57    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2740112  |
---------------------------------
Eval num_timesteps=290000, episode_reward=785.29 +/- 0.00
Episode length: 896.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 896      |
|    mean_reward     | 785      |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.56     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.933    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2740115  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 713      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 117      |
|    time_elapsed    | 2485     |
|    total_timesteps | 291801   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -5.13    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2740116  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 815      |
|    ep_rew_mean     | 716      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 118      |
|    time_elapsed    | 2503     |
|    total_timesteps | 295556   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2740120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 118      |
|    time_elapsed    | 2521     |
|    total_timesteps | 298840   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 4.07     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.524   |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2740124  |
---------------------------------
Eval num_timesteps=300000, episode_reward=693.20 +/- 0.00
Episode length: 785.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 785      |
|    mean_reward     | 693      |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -6.43    |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2740126  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 712      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 117      |
|    time_elapsed    | 2565     |
|    total_timesteps | 302261   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2740128  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 821      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 118      |
|    time_elapsed    | 2584     |
|    total_timesteps | 306430   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.83    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2740132  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 725      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 119      |
|    time_elapsed    | 2602     |
|    total_timesteps | 309735   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 2.56     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.96    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2740136  |
---------------------------------
Eval num_timesteps=310000, episode_reward=822.04 +/- 0.00
Episode length: 928.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 928      |
|    mean_reward     | 822      |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.89    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2740137  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 730      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 118      |
|    time_elapsed    | 2647     |
|    total_timesteps | 313398   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.96    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2740140  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 733      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 118      |
|    time_elapsed    | 2666     |
|    total_timesteps | 317094   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.01     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2740144  |
---------------------------------
Eval num_timesteps=320000, episode_reward=4373.64 +/- 0.00
Episode length: 4640.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.64e+03 |
|    mean_reward     | 4.37e+03 |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2740147  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 117      |
|    time_elapsed    | 2740     |
|    total_timesteps | 321625   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.23    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2740148  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 117      |
|    time_elapsed    | 2758     |
|    total_timesteps | 325093   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 2.51     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.2     |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2740152  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 118      |
|    time_elapsed    | 2777     |
|    total_timesteps | 328727   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.36     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -3.8     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2740156  |
---------------------------------
Eval num_timesteps=330000, episode_reward=773.71 +/- 0.00
Episode length: 910.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 910      |
|    mean_reward     | 774      |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -6.38    |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2740158  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 735      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 117      |
|    time_elapsed    | 2820     |
|    total_timesteps | 332553   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -6.2     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2740160  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 734      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 118      |
|    time_elapsed    | 2838     |
|    total_timesteps | 335434   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -5.17    |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2740164  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 832      |
|    ep_rew_mean     | 729      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 118      |
|    time_elapsed    | 2855     |
|    total_timesteps | 338669   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 2.46     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -5.24    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2740168  |
---------------------------------
Eval num_timesteps=340000, episode_reward=689.44 +/- 0.00
Episode length: 793.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 793      |
|    mean_reward     | 689      |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2740170  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 730      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 118      |
|    time_elapsed    | 2898     |
|    total_timesteps | 342321   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 5.24     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2740172  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 732      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 118      |
|    time_elapsed    | 2916     |
|    total_timesteps | 345708   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.527   |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2740176  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 119      |
|    time_elapsed    | 2935     |
|    total_timesteps | 349681   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -4.63    |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2740180  |
---------------------------------
Eval num_timesteps=350000, episode_reward=871.74 +/- 0.00
Episode length: 997.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 997      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.029   |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2740181  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 118      |
|    time_elapsed    | 2980     |
|    total_timesteps | 353927   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 2.09     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.95    |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2740184  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 119      |
|    time_elapsed    | 3000     |
|    total_timesteps | 358570   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.07    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2740188  |
---------------------------------
Eval num_timesteps=360000, episode_reward=1130.76 +/- 0.00
Episode length: 1296.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.3e+03  |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.3     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2740190  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 118      |
|    time_elapsed    | 3048     |
|    total_timesteps | 362185   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.407    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2740192  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 119      |
|    time_elapsed    | 3066     |
|    total_timesteps | 365343   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.94    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2740196  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 119      |
|    time_elapsed    | 3084     |
|    total_timesteps | 368801   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2740200  |
---------------------------------
Eval num_timesteps=370000, episode_reward=779.26 +/- 0.00
Episode length: 916.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 916      |
|    mean_reward     | 779      |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.395    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2740202  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 119      |
|    time_elapsed    | 3129     |
|    total_timesteps | 372683   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -4.84    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2740204  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 765      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 119      |
|    time_elapsed    | 3148     |
|    total_timesteps | 376285   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2740208  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 878      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 119      |
|    time_elapsed    | 3166     |
|    total_timesteps | 379867   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 2.34     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.95    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2740212  |
---------------------------------
Eval num_timesteps=380000, episode_reward=619.08 +/- 0.00
Episode length: 729.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 729      |
|    mean_reward     | 619      |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.32     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2740213  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 764      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 119      |
|    time_elapsed    | 3208     |
|    total_timesteps | 383164   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2740216  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 119      |
|    time_elapsed    | 3225     |
|    total_timesteps | 386163   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2740220  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 120      |
|    time_elapsed    | 3243     |
|    total_timesteps | 389344   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.512   |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2740224  |
---------------------------------
Eval num_timesteps=390000, episode_reward=599.86 +/- 0.00
Episode length: 728.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 728      |
|    mean_reward     | 600      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1        |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2740225  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 119      |
|    time_elapsed    | 3286     |
|    total_timesteps | 393157   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.0955  |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2740228  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 119      |
|    time_elapsed    | 3303     |
|    total_timesteps | 396151   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.69    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2740232  |
---------------------------------
Eval num_timesteps=400000, episode_reward=855.16 +/- 0.00
Episode length: 996.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 996      |
|    mean_reward     | 855      |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.16     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.54    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2740236  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 861      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 440      |
|    fps             | 119      |
|    time_elapsed    | 3349     |
|    total_timesteps | 400677   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 444      |
|    fps             | 119      |
|    time_elapsed    | 3368     |
|    total_timesteps | 403893   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -7.43    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2740240  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 858      |
|    ep_rew_mean     | 739      |
| time/              |          |
|    episodes        | 448      |
|    fps             | 120      |
|    time_elapsed    | 3386     |
|    total_timesteps | 407534   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2740244  |
---------------------------------
Eval num_timesteps=410000, episode_reward=1136.23 +/- 0.00
Episode length: 1289.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.49     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2740247  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 737      |
| time/              |          |
|    episodes        | 452      |
|    fps             | 119      |
|    time_elapsed    | 3433     |
|    total_timesteps | 411599   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.85     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2740248  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 862      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 456      |
|    fps             | 120      |
|    time_elapsed    | 3453     |
|    total_timesteps | 415508   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2740252  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 858      |
|    ep_rew_mean     | 738      |
| time/              |          |
|    episodes        | 460      |
|    fps             | 120      |
|    time_elapsed    | 3472     |
|    total_timesteps | 418800   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.652   |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2740256  |
---------------------------------
Eval num_timesteps=420000, episode_reward=649.99 +/- 0.00
Episode length: 778.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 778      |
|    mean_reward     | 650      |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 1.91     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.02    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2740258  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 734      |
| time/              |          |
|    episodes        | 464      |
|    fps             | 120      |
|    time_elapsed    | 3516     |
|    total_timesteps | 422210   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2740260  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 468      |
|    fps             | 120      |
|    time_elapsed    | 3536     |
|    total_timesteps | 425773   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.93    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2740264  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 746      |
| time/              |          |
|    episodes        | 472      |
|    fps             | 120      |
|    time_elapsed    | 3555     |
|    total_timesteps | 429683   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.85     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 7.19     |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2740268  |
---------------------------------
Eval num_timesteps=430000, episode_reward=620.48 +/- 0.00
Episode length: 758.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 758      |
|    mean_reward     | 620      |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.1      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.989   |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2740269  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 476      |
|    fps             | 120      |
|    time_elapsed    | 3597     |
|    total_timesteps | 432939   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 6.98     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2740272  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 747      |
| time/              |          |
|    episodes        | 480      |
|    fps             | 120      |
|    time_elapsed    | 3617     |
|    total_timesteps | 436818   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 2.26     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2740276  |
---------------------------------
Eval num_timesteps=440000, episode_reward=868.96 +/- 0.00
Episode length: 1003.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 869      |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2740280  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 484      |
|    fps             | 120      |
|    time_elapsed    | 3664     |
|    total_timesteps | 440790   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 488      |
|    fps             | 120      |
|    time_elapsed    | 3683     |
|    total_timesteps | 444585   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.76    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2740284  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 492      |
|    fps             | 121      |
|    time_elapsed    | 3703     |
|    total_timesteps | 448748   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.46     |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2740288  |
---------------------------------
Eval num_timesteps=450000, episode_reward=931.06 +/- 0.00
Episode length: 1076.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 931      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 6.31     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.23    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2740290  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 863      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 496      |
|    fps             | 120      |
|    time_elapsed    | 3749     |
|    total_timesteps | 452620   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.69    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2740292  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 500      |
|    fps             | 121      |
|    time_elapsed    | 3768     |
|    total_timesteps | 456391   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2740296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 504      |
|    fps             | 121      |
|    time_elapsed    | 3786     |
|    total_timesteps | 459759   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.54    |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2740300  |
---------------------------------
Eval num_timesteps=460000, episode_reward=678.68 +/- 0.00
Episode length: 789.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 789      |
|    mean_reward     | 679      |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.362   |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2740301  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 871      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 508      |
|    fps             | 121      |
|    time_elapsed    | 3830     |
|    total_timesteps | 463668   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.12    |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2740304  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 512      |
|    fps             | 121      |
|    time_elapsed    | 3848     |
|    total_timesteps | 467167   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.411    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2740308  |
---------------------------------
Eval num_timesteps=470000, episode_reward=764.04 +/- 0.00
Episode length: 908.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 908      |
|    mean_reward     | 764      |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.98     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -4.34    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2740311  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 873      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 121      |
|    time_elapsed    | 3895     |
|    total_timesteps | 471846   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.39    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2740312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 875      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 121      |
|    time_elapsed    | 3912     |
|    total_timesteps | 475252   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.11     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.28    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2740316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 879      |
|    ep_rew_mean     | 744      |
| time/              |          |
|    episodes        | 524      |
|    fps             | 121      |
|    time_elapsed    | 3930     |
|    total_timesteps | 478611   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.0949   |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2740320  |
---------------------------------
Eval num_timesteps=480000, episode_reward=1555.70 +/- 0.00
Episode length: 1751.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.75e+03 |
|    mean_reward     | 1.56e+03 |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2740322  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 882      |
|    ep_rew_mean     | 747      |
| time/              |          |
|    episodes        | 528      |
|    fps             | 121      |
|    time_elapsed    | 3984     |
|    total_timesteps | 482694   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3.75    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2740324  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 532      |
|    fps             | 121      |
|    time_elapsed    | 4002     |
|    total_timesteps | 486228   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 5.26     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2740328  |
---------------------------------
Eval num_timesteps=490000, episode_reward=1171.29 +/- 0.00
Episode length: 1300.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.3e+03  |
|    mean_reward     | 1.17e+03 |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.57     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2740332  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 763      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 121      |
|    time_elapsed    | 4053     |
|    total_timesteps | 491209   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 907      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 540      |
|    fps             | 121      |
|    time_elapsed    | 4072     |
|    total_timesteps | 495344   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.349    |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2740336  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 767      |
| time/              |          |
|    episodes        | 544      |
|    fps             | 121      |
|    time_elapsed    | 4090     |
|    total_timesteps | 498399   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 3.05     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2740340  |
---------------------------------
Eval num_timesteps=500000, episode_reward=1284.64 +/- 0.00
Episode length: 1448.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.45e+03 |
|    mean_reward     | 1.28e+03 |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 6.68     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3.15    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2740342  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 906      |
|    ep_rew_mean     | 767      |
| time/              |          |
|    episodes        | 548      |
|    fps             | 121      |
|    time_elapsed    | 4140     |
|    total_timesteps | 502865   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.431   |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2740344  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 764      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 121      |
|    time_elapsed    | 4159     |
|    total_timesteps | 506219   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.18     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2740348  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 556      |
|    fps             | 121      |
|    time_elapsed    | 4176     |
|    total_timesteps | 509315   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.185   |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2740352  |
---------------------------------
Eval num_timesteps=510000, episode_reward=1103.94 +/- 0.00
Episode length: 1288.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 3.07     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.572    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2740353  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 560      |
|    fps             | 121      |
|    time_elapsed    | 4223     |
|    total_timesteps | 512976   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2740356  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 893      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 564      |
|    fps             | 121      |
|    time_elapsed    | 4241     |
|    total_timesteps | 516021   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.789   |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2740360  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 744      |
| time/              |          |
|    episodes        | 568      |
|    fps             | 121      |
|    time_elapsed    | 4258     |
|    total_timesteps | 518883   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 4.16     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.55     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2740364  |
---------------------------------
Eval num_timesteps=520000, episode_reward=1150.88 +/- 0.00
Episode length: 1326.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.33e+03 |
|    mean_reward     | 1.15e+03 |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 7.26     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.28    |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2740366  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 882      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 572      |
|    fps             | 121      |
|    time_elapsed    | 4306     |
|    total_timesteps | 522670   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 2.24     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2740368  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 885      |
|    ep_rew_mean     | 744      |
| time/              |          |
|    episodes        | 576      |
|    fps             | 121      |
|    time_elapsed    | 4324     |
|    total_timesteps | 525949   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 5.87     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.501   |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2740372  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 880      |
|    ep_rew_mean     | 738      |
| time/              |          |
|    episodes        | 580      |
|    fps             | 121      |
|    time_elapsed    | 4342     |
|    total_timesteps | 529297   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 2.55     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.0155   |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2740376  |
---------------------------------
Eval num_timesteps=530000, episode_reward=939.78 +/- 0.00
Episode length: 1073.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.07e+03 |
|    mean_reward     | 940      |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2740377  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 735      |
| time/              |          |
|    episodes        | 584      |
|    fps             | 121      |
|    time_elapsed    | 4389     |
|    total_timesteps | 533161   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2740380  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 588      |
|    fps             | 121      |
|    time_elapsed    | 4408     |
|    total_timesteps | 537102   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 7.29     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2740384  |
---------------------------------
Eval num_timesteps=540000, episode_reward=596.71 +/- 0.00
Episode length: 764.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 764      |
|    mean_reward     | 597      |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 5.72     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2740388  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 724      |
| time/              |          |
|    episodes        | 592      |
|    fps             | 121      |
|    time_elapsed    | 4451     |
|    total_timesteps | 540714   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 720      |
| time/              |          |
|    episodes        | 596      |
|    fps             | 121      |
|    time_elapsed    | 4470     |
|    total_timesteps | 543934   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.07     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.0463  |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2740392  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 862      |
|    ep_rew_mean     | 717      |
| time/              |          |
|    episodes        | 600      |
|    fps             | 121      |
|    time_elapsed    | 4488     |
|    total_timesteps | 547495   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.941   |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2740396  |
---------------------------------
Eval num_timesteps=550000, episode_reward=525.49 +/- 0.00
Episode length: 642.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 642      |
|    mean_reward     | 525      |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.82     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2740400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 714      |
| time/              |          |
|    episodes        | 604      |
|    fps             | 121      |
|    time_elapsed    | 4528     |
|    total_timesteps | 550985   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 608      |
|    fps             | 121      |
|    time_elapsed    | 4546     |
|    total_timesteps | 554179   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -5.44    |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2740404  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 704      |
| time/              |          |
|    episodes        | 612      |
|    fps             | 122      |
|    time_elapsed    | 4563     |
|    total_timesteps | 557023   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3.93    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2740408  |
---------------------------------
Eval num_timesteps=560000, episode_reward=576.03 +/- 0.00
Episode length: 754.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 754      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.106    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2740412  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 699      |
| time/              |          |
|    episodes        | 616      |
|    fps             | 121      |
|    time_elapsed    | 4606     |
|    total_timesteps | 561038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 704      |
| time/              |          |
|    episodes        | 620      |
|    fps             | 122      |
|    time_elapsed    | 4625     |
|    total_timesteps | 564963   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 2.61     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2740416  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 624      |
|    fps             | 122      |
|    time_elapsed    | 4644     |
|    total_timesteps | 568898   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.79     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.63    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2740420  |
---------------------------------
Eval num_timesteps=570000, episode_reward=1336.40 +/- 0.00
Episode length: 1531.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.34e+03 |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 4.37     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.902   |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2740422  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 708      |
| time/              |          |
|    episodes        | 628      |
|    fps             | 121      |
|    time_elapsed    | 4692     |
|    total_timesteps | 572438   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 7.77     |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2740424  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 704      |
| time/              |          |
|    episodes        | 632      |
|    fps             | 122      |
|    time_elapsed    | 4711     |
|    total_timesteps | 575486   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -4.37    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2740428  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 686      |
| time/              |          |
|    episodes        | 636      |
|    fps             | 122      |
|    time_elapsed    | 4728     |
|    total_timesteps | 578295   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 5.25     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 4.23     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2740432  |
---------------------------------
Eval num_timesteps=580000, episode_reward=1149.10 +/- 0.00
Episode length: 1331.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.33e+03 |
|    mean_reward     | 1.15e+03 |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 2.36     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2740435  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 640      |
|    fps             | 121      |
|    time_elapsed    | 4775     |
|    total_timesteps | 581695   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3       |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2740436  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 644      |
|    fps             | 122      |
|    time_elapsed    | 4795     |
|    total_timesteps | 585741   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2740440  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 826      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 648      |
|    fps             | 122      |
|    time_elapsed    | 4813     |
|    total_timesteps | 589166   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2740444  |
---------------------------------
Eval num_timesteps=590000, episode_reward=613.80 +/- 0.00
Episode length: 778.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 778      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.305    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2740445  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 652      |
|    fps             | 122      |
|    time_elapsed    | 4857     |
|    total_timesteps | 593251   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.685    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2740448  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 656      |
|    fps             | 122      |
|    time_elapsed    | 4876     |
|    total_timesteps | 596762   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 3.18     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2740452  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 660      |
|    fps             | 122      |
|    time_elapsed    | 4894     |
|    total_timesteps | 599861   |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.592    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2740456  |
---------------------------------
Eval num_timesteps=600000, episode_reward=563.48 +/- 0.00
Episode length: 719.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 719      |
|    mean_reward     | 563      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2740457  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 832      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 664      |
|    fps             | 122      |
|    time_elapsed    | 4937     |
|    total_timesteps | 603225   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.462   |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2740460  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 690      |
| time/              |          |
|    episodes        | 668      |
|    fps             | 122      |
|    time_elapsed    | 4956     |
|    total_timesteps | 607092   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 3.13     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2740464  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 683      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 122      |
|    time_elapsed    | 4973     |
|    total_timesteps | 609940   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 2.89     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2740468  |
---------------------------------
Eval num_timesteps=610000, episode_reward=596.90 +/- 0.00
Episode length: 772.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 772      |
|    mean_reward     | 597      |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 7.96     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.53     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2740469  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 679      |
| time/              |          |
|    episodes        | 676      |
|    fps             | 122      |
|    time_elapsed    | 5015     |
|    total_timesteps | 613138   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 18.6     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2740472  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 672      |
| time/              |          |
|    episodes        | 680      |
|    fps             | 122      |
|    time_elapsed    | 5031     |
|    total_timesteps | 615793   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2740476  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 684      |
|    fps             | 122      |
|    time_elapsed    | 5048     |
|    total_timesteps | 618405   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -3.13    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2740480  |
---------------------------------
Eval num_timesteps=620000, episode_reward=525.70 +/- 0.00
Episode length: 635.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 635      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2740483  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 807      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 688      |
|    fps             | 122      |
|    time_elapsed    | 5089     |
|    total_timesteps | 621395   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 5.92     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2740484  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 692      |
|    fps             | 122      |
|    time_elapsed    | 5107     |
|    total_timesteps | 624153   |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 4.36     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2740488  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 801      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 696      |
|    fps             | 122      |
|    time_elapsed    | 5123     |
|    total_timesteps | 627011   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.77    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2740492  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 700      |
|    fps             | 122      |
|    time_elapsed    | 5141     |
|    total_timesteps | 629991   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.51     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.868    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2740496  |
---------------------------------
Eval num_timesteps=630000, episode_reward=593.76 +/- 0.00
Episode length: 729.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 729      |
|    mean_reward     | 594      |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 4.15     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2740497  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 704      |
|    fps             | 122      |
|    time_elapsed    | 5182     |
|    total_timesteps | 632887   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.03     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.133   |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2740500  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 708      |
|    fps             | 122      |
|    time_elapsed    | 5199     |
|    total_timesteps | 635992   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 5.25     |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2740504  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 712      |
|    fps             | 122      |
|    time_elapsed    | 5218     |
|    total_timesteps | 639884   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 5.01     |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2740508  |
---------------------------------
Eval num_timesteps=640000, episode_reward=528.79 +/- 0.00
Episode length: 644.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 644      |
|    mean_reward     | 529      |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.257    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2740509  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 716      |
|    fps             | 122      |
|    time_elapsed    | 5259     |
|    total_timesteps | 642969   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.433   |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2740512  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 787      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 720      |
|    fps             | 122      |
|    time_elapsed    | 5277     |
|    total_timesteps | 645803   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 6.05     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 5.78     |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2740516  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    episodes        | 724      |
|    fps             | 122      |
|    time_elapsed    | 5295     |
|    total_timesteps | 649181   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 6.05     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.314    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2740520  |
---------------------------------
Eval num_timesteps=650000, episode_reward=568.83 +/- 0.00
Episode length: 742.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 742      |
|    mean_reward     | 569      |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2740522  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 776      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 728      |
|    fps             | 122      |
|    time_elapsed    | 5337     |
|    total_timesteps | 652134   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.204    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2740524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 780      |
|    ep_rew_mean     | 624      |
| time/              |          |
|    episodes        | 732      |
|    fps             | 122      |
|    time_elapsed    | 5356     |
|    total_timesteps | 655577   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 6.33     |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2740528  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 736      |
|    fps             | 122      |
|    time_elapsed    | 5374     |
|    total_timesteps | 659248   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.96     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2740532  |
---------------------------------
Eval num_timesteps=660000, episode_reward=559.59 +/- 0.00
Episode length: 723.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 723      |
|    mean_reward     | 560      |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 4.37     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2740533  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 740      |
|    fps             | 122      |
|    time_elapsed    | 5418     |
|    total_timesteps | 663157   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2740536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 624      |
| time/              |          |
|    episodes        | 744      |
|    fps             | 122      |
|    time_elapsed    | 5437     |
|    total_timesteps | 666343   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 7.4      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.78     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2740540  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 773      |
|    ep_rew_mean     | 617      |
| time/              |          |
|    episodes        | 748      |
|    fps             | 122      |
|    time_elapsed    | 5454     |
|    total_timesteps | 668958   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 3.76     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.259   |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2740544  |
---------------------------------
Eval num_timesteps=670000, episode_reward=681.70 +/- 0.00
Episode length: 859.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 859      |
|    mean_reward     | 682      |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 11.8     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.26     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2740546  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 772      |
|    ep_rew_mean     | 616      |
| time/              |          |
|    episodes        | 752      |
|    fps             | 122      |
|    time_elapsed    | 5498     |
|    total_timesteps | 672543   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.07     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2740548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 756      |
|    fps             | 122      |
|    time_elapsed    | 5515     |
|    total_timesteps | 675318   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2740552  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 760      |
|    fps             | 122      |
|    time_elapsed    | 5533     |
|    total_timesteps | 678702   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 4.96     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.04     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2740556  |
---------------------------------
Eval num_timesteps=680000, episode_reward=774.71 +/- 0.00
Episode length: 990.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 990      |
|    mean_reward     | 775      |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2740558  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 764      |
|    fps             | 122      |
|    time_elapsed    | 5579     |
|    total_timesteps | 682572   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 4.11     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2740560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 602      |
| time/              |          |
|    episodes        | 768      |
|    fps             | 122      |
|    time_elapsed    | 5595     |
|    total_timesteps | 685279   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 5.25     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.35    |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2740564  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 772      |
|    fps             | 122      |
|    time_elapsed    | 5612     |
|    total_timesteps | 687767   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 6.52     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 5.54     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2740568  |
---------------------------------
Eval num_timesteps=690000, episode_reward=545.95 +/- 0.00
Episode length: 697.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 697      |
|    mean_reward     | 546      |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 6.39     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.64     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2740571  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 602      |
| time/              |          |
|    episodes        | 776      |
|    fps             | 122      |
|    time_elapsed    | 5655     |
|    total_timesteps | 691709   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 6.41     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2740572  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 608      |
| time/              |          |
|    episodes        | 780      |
|    fps             | 122      |
|    time_elapsed    | 5673     |
|    total_timesteps | 695101   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 4.38     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2740576  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 784      |
|    fps             | 122      |
|    time_elapsed    | 5691     |
|    total_timesteps | 698180   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2740580  |
---------------------------------
Eval num_timesteps=700000, episode_reward=523.04 +/- 0.00
Episode length: 633.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 633      |
|    mean_reward     | 523      |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.0638  |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2740583  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 788      |
|    fps             | 122      |
|    time_elapsed    | 5733     |
|    total_timesteps | 701915   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.251   |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2740584  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 787      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    episodes        | 792      |
|    fps             | 122      |
|    time_elapsed    | 5752     |
|    total_timesteps | 705239   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2740588  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 786      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    episodes        | 796      |
|    fps             | 122      |
|    time_elapsed    | 5769     |
|    total_timesteps | 708031   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 5.37     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.82     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2740592  |
---------------------------------
Eval num_timesteps=710000, episode_reward=623.14 +/- 0.00
Episode length: 744.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 744      |
|    mean_reward     | 623      |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 6.41     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 4.59     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2740595  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 800      |
|    fps             | 122      |
|    time_elapsed    | 5811     |
|    total_timesteps | 711786   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 9.19     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2740596  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 804      |
|    fps             | 122      |
|    time_elapsed    | 5829     |
|    total_timesteps | 714947   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2740600  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 808      |
|    fps             | 122      |
|    time_elapsed    | 5847     |
|    total_timesteps | 718380   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 2.91     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2740604  |
---------------------------------
Eval num_timesteps=720000, episode_reward=497.58 +/- 0.00
Episode length: 616.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 616      |
|    mean_reward     | 498      |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.82     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 5.77     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2740606  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 812      |
|    fps             | 122      |
|    time_elapsed    | 5889     |
|    total_timesteps | 722256   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.915    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2740608  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 816      |
|    fps             | 122      |
|    time_elapsed    | 5907     |
|    total_timesteps | 725322   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.418    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2740612  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 820      |
|    fps             | 122      |
|    time_elapsed    | 5924     |
|    total_timesteps | 728415   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 2.63     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.624   |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2740616  |
---------------------------------
Eval num_timesteps=730000, episode_reward=597.44 +/- 0.00
Episode length: 752.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 752      |
|    mean_reward     | 597      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.368    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2740619  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 824      |
|    fps             | 122      |
|    time_elapsed    | 5967     |
|    total_timesteps | 731772   |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2740620  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 828      |
|    fps             | 122      |
|    time_elapsed    | 5985     |
|    total_timesteps | 735279   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 5.25     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2740624  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 832      |
|    fps             | 123      |
|    time_elapsed    | 6003     |
|    total_timesteps | 738501   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2740628  |
---------------------------------
Eval num_timesteps=740000, episode_reward=631.39 +/- 0.00
Episode length: 814.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 814      |
|    mean_reward     | 631      |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 5.76     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.29    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2740630  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 836      |
|    fps             | 122      |
|    time_elapsed    | 6048     |
|    total_timesteps | 742685   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 8.07     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 7.06     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2740632  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 840      |
|    fps             | 122      |
|    time_elapsed    | 6065     |
|    total_timesteps | 745794   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 6.61     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.572   |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2740636  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 627      |
| time/              |          |
|    episodes        | 844      |
|    fps             | 123      |
|    time_elapsed    | 6083     |
|    total_timesteps | 748429   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.675   |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2740640  |
---------------------------------
Eval num_timesteps=750000, episode_reward=479.70 +/- 0.00
Episode length: 615.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 615      |
|    mean_reward     | 480      |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 9.61     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.341    |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2740643  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 848      |
|    fps             | 122      |
|    time_elapsed    | 6125     |
|    total_timesteps | 751773   |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 2.35     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2740644  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 852      |
|    fps             | 122      |
|    time_elapsed    | 6142     |
|    total_timesteps | 754768   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 5.42     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 7.35     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2740648  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 856      |
|    fps             | 123      |
|    time_elapsed    | 6160     |
|    total_timesteps | 758117   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 5.11     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2740652  |
---------------------------------
Eval num_timesteps=760000, episode_reward=609.03 +/- 0.00
Episode length: 764.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 764      |
|    mean_reward     | 609      |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 12.3     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2740655  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 860      |
|    fps             | 122      |
|    time_elapsed    | 6203     |
|    total_timesteps | 761480   |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 2.45     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 4.33     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2740656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 864      |
|    fps             | 122      |
|    time_elapsed    | 6222     |
|    total_timesteps | 765285   |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 5.21     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.12     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2740660  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 799      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 868      |
|    fps             | 123      |
|    time_elapsed    | 6238     |
|    total_timesteps | 767709   |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.07     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 2.52     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2740664  |
---------------------------------
Eval num_timesteps=770000, episode_reward=720.55 +/- 0.00
Episode length: 924.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 924      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 6.67     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2740668  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 801      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 872      |
|    fps             | 122      |
|    time_elapsed    | 6282     |
|    total_timesteps | 770889   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 799      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 876      |
|    fps             | 122      |
|    time_elapsed    | 6300     |
|    total_timesteps | 774100   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 2.98     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.43     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2740672  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 880      |
|    fps             | 123      |
|    time_elapsed    | 6318     |
|    total_timesteps | 777317   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 8.36     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2740676  |
---------------------------------
Eval num_timesteps=780000, episode_reward=659.98 +/- 0.00
Episode length: 840.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 840      |
|    mean_reward     | 660      |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 4.51     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.59     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2740680  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 884      |
|    fps             | 122      |
|    time_elapsed    | 6362     |
|    total_timesteps | 780936   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 888      |
|    fps             | 122      |
|    time_elapsed    | 6381     |
|    total_timesteps | 784654   |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2740684  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 892      |
|    fps             | 123      |
|    time_elapsed    | 6400     |
|    total_timesteps | 788292   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.48     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2740688  |
---------------------------------
Eval num_timesteps=790000, episode_reward=757.89 +/- 0.00
Episode length: 964.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 964      |
|    mean_reward     | 758      |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.82     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2740691  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 803      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 896      |
|    fps             | 122      |
|    time_elapsed    | 6444     |
|    total_timesteps | 791598   |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 1.66     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2740692  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    episodes        | 900      |
|    fps             | 123      |
|    time_elapsed    | 6463     |
|    total_timesteps | 795366   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 5.27     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 5.09     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2740696  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 638      |
| time/              |          |
|    episodes        | 904      |
|    fps             | 123      |
|    time_elapsed    | 6480     |
|    total_timesteps | 798434   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 2.36     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.526    |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2740700  |
---------------------------------
Eval num_timesteps=800000, episode_reward=492.51 +/- 0.00
Episode length: 619.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 493      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.65     |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2740702  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 908      |
|    fps             | 123      |
|    time_elapsed    | 6525     |
|    total_timesteps | 803368   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 6.25     |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2740704  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 912      |
|    fps             | 123      |
|    time_elapsed    | 6543     |
|    total_timesteps | 806217   |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 27.5     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 6.26     |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2740708  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 812      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 916      |
|    fps             | 123      |
|    time_elapsed    | 6561     |
|    total_timesteps | 809471   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.75     |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2740712  |
---------------------------------
Eval num_timesteps=810000, episode_reward=647.82 +/- 0.00
Episode length: 825.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 825      |
|    mean_reward     | 648      |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2740713  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 920      |
|    fps             | 123      |
|    time_elapsed    | 6606     |
|    total_timesteps | 813064   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2740716  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 924      |
|    fps             | 123      |
|    time_elapsed    | 6623     |
|    total_timesteps | 816078   |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.45     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2740720  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 928      |
|    fps             | 123      |
|    time_elapsed    | 6642     |
|    total_timesteps | 819523   |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 4.98     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 6.93     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2740724  |
---------------------------------
Eval num_timesteps=820000, episode_reward=765.60 +/- 0.00
Episode length: 962.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 962      |
|    mean_reward     | 766      |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 5.62     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.821    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2740725  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 932      |
|    fps             | 123      |
|    time_elapsed    | 6685     |
|    total_timesteps | 823089   |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2740728  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 936      |
|    fps             | 123      |
|    time_elapsed    | 6704     |
|    total_timesteps | 825906   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 6.46     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2740732  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 940      |
|    fps             | 123      |
|    time_elapsed    | 6721     |
|    total_timesteps | 829017   |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 6.01     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 4.61     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2740736  |
---------------------------------
Eval num_timesteps=830000, episode_reward=534.23 +/- 0.00
Episode length: 686.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 534      |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 5.72     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 4.9      |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2740738  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    episodes        | 944      |
|    fps             | 123      |
|    time_elapsed    | 6764     |
|    total_timesteps | 832299   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 4.3      |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2740740  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 807      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 948      |
|    fps             | 123      |
|    time_elapsed    | 6783     |
|    total_timesteps | 835714   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 9.31     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2740744  |
---------------------------------
Eval num_timesteps=840000, episode_reward=796.14 +/- 0.00
Episode length: 948.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 948      |
|    mean_reward     | 796      |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 7.42     |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2740748  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 655      |
| time/              |          |
|    episodes        | 952      |
|    fps             | 123      |
|    time_elapsed    | 6831     |
|    total_timesteps | 841185   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 658      |
| time/              |          |
|    episodes        | 956      |
|    fps             | 123      |
|    time_elapsed    | 6850     |
|    total_timesteps | 844627   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 7.04     |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2740752  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 659      |
| time/              |          |
|    episodes        | 960      |
|    fps             | 123      |
|    time_elapsed    | 6868     |
|    total_timesteps | 847731   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 3.04     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2740756  |
---------------------------------
Eval num_timesteps=850000, episode_reward=634.51 +/- 0.00
Episode length: 823.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 823      |
|    mean_reward     | 635      |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 5.9      |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2740759  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 818      |
|    ep_rew_mean     | 653      |
| time/              |          |
|    episodes        | 964      |
|    fps             | 123      |
|    time_elapsed    | 6912     |
|    total_timesteps | 851527   |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 7.25     |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2740760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 832      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 968      |
|    fps             | 123      |
|    time_elapsed    | 6931     |
|    total_timesteps | 855271   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 6.93     |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2740764  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 972      |
|    fps             | 123      |
|    time_elapsed    | 6950     |
|    total_timesteps | 858857   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2740768  |
---------------------------------
Eval num_timesteps=860000, episode_reward=632.56 +/- 0.00
Episode length: 803.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 803      |
|    mean_reward     | 633      |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 5.18     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.254    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2740770  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 976      |
|    fps             | 123      |
|    time_elapsed    | 6994     |
|    total_timesteps | 862459   |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.206    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2740772  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 980      |
|    fps             | 123      |
|    time_elapsed    | 7012     |
|    total_timesteps | 865490   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 5.76     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.575    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2740776  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 672      |
| time/              |          |
|    episodes        | 984      |
|    fps             | 123      |
|    time_elapsed    | 7030     |
|    total_timesteps | 868882   |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.55     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2740780  |
---------------------------------
Eval num_timesteps=870000, episode_reward=526.25 +/- 0.00
Episode length: 669.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 669      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 8.79     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2740782  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 835      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 988      |
|    fps             | 123      |
|    time_elapsed    | 7072     |
|    total_timesteps | 872276   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 5.13     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2740784  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 992      |
|    fps             | 123      |
|    time_elapsed    | 7091     |
|    total_timesteps | 875687   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 6.43     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 7.27     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2740788  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 996      |
|    fps             | 123      |
|    time_elapsed    | 7110     |
|    total_timesteps | 878884   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 3.43     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 3.18     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2740792  |
---------------------------------
Eval num_timesteps=880000, episode_reward=603.53 +/- 0.00
Episode length: 773.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 773      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2740794  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 835      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 123      |
|    time_elapsed    | 7154     |
|    total_timesteps | 883005   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 6.82     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2740796  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 123      |
|    time_elapsed    | 7173     |
|    total_timesteps | 886650   |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2740800  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 658      |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 123      |
|    time_elapsed    | 7191     |
|    total_timesteps | 889581   |
| train/             |          |
|    actor_loss      | -54.1    |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 4.68     |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2740804  |
---------------------------------
Eval num_timesteps=890000, episode_reward=613.66 +/- 0.00
Episode length: 733.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 733      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 5.4      |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2740805  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 123      |
|    time_elapsed    | 7234     |
|    total_timesteps | 893407   |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 4.12     |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2740808  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 123      |
|    time_elapsed    | 7253     |
|    total_timesteps | 896872   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.66     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2740812  |
---------------------------------
Eval num_timesteps=900000, episode_reward=597.68 +/- 0.00
Episode length: 762.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 762      |
|    mean_reward     | 598      |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 4.16     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 6.86     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2740816  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 123      |
|    time_elapsed    | 7298     |
|    total_timesteps | 901057   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 846      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 123      |
|    time_elapsed    | 7317     |
|    total_timesteps | 904737   |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 2.01     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2740820  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 123      |
|    time_elapsed    | 7333     |
|    total_timesteps | 907184   |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 6.47     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 4.77     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2740824  |
---------------------------------
Eval num_timesteps=910000, episode_reward=614.07 +/- 0.00
Episode length: 794.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 794      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.86     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2740828  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 123      |
|    time_elapsed    | 7378     |
|    total_timesteps | 911421   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 123      |
|    time_elapsed    | 7397     |
|    total_timesteps | 914901   |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.69     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2740832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 679      |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 123      |
|    time_elapsed    | 7415     |
|    total_timesteps | 917814   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 2.65     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 0.39     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2740836  |
---------------------------------
Eval num_timesteps=920000, episode_reward=495.47 +/- 0.00
Episode length: 624.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 624      |
|    mean_reward     | 495      |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2740839  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 851      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 123      |
|    time_elapsed    | 7456     |
|    total_timesteps | 921276   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2740840  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 851      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 123      |
|    time_elapsed    | 7474     |
|    total_timesteps | 924734   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2740844  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 123      |
|    time_elapsed    | 7493     |
|    total_timesteps | 928549   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 5.51     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 6.01     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2740848  |
---------------------------------
Eval num_timesteps=930000, episode_reward=667.65 +/- 0.00
Episode length: 842.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 842      |
|    mean_reward     | 668      |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 4.39     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 6.09     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2740851  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 123      |
|    time_elapsed    | 7535     |
|    total_timesteps | 931414   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 8.49     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 7.34     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2740852  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 123      |
|    time_elapsed    | 7553     |
|    total_timesteps | 934514   |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 8.06     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2740856  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 123      |
|    time_elapsed    | 7570     |
|    total_timesteps | 937577   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2740860  |
---------------------------------
Eval num_timesteps=940000, episode_reward=642.98 +/- 0.00
Episode length: 819.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 819      |
|    mean_reward     | 643      |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | -54.1    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 4.87     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2740863  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 123      |
|    time_elapsed    | 7615     |
|    total_timesteps | 941369   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 3.11     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2740864  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 123      |
|    time_elapsed    | 7635     |
|    total_timesteps | 945726   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 7.1      |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2740868  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 124      |
|    time_elapsed    | 7654     |
|    total_timesteps | 949288   |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 7.63     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2740872  |
---------------------------------
Eval num_timesteps=950000, episode_reward=572.20 +/- 0.00
Episode length: 720.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 720      |
|    mean_reward     | 572      |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 4.02     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 5.15     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2740873  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 123      |
|    time_elapsed    | 7697     |
|    total_timesteps | 953614   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2740876  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 124      |
|    time_elapsed    | 7715     |
|    total_timesteps | 956956   |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 3.97     |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2740880  |
---------------------------------
Eval num_timesteps=960000, episode_reward=610.86 +/- 0.00
Episode length: 768.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 768      |
|    mean_reward     | 611      |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 6.83     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.69     |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2740884  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 123      |
|    time_elapsed    | 7758     |
|    total_timesteps | 960891   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 679      |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 124      |
|    time_elapsed    | 7778     |
|    total_timesteps | 964772   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.21     |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2740888  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 685      |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 124      |
|    time_elapsed    | 7797     |
|    total_timesteps | 968677   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.24     |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2740892  |
---------------------------------
Eval num_timesteps=970000, episode_reward=903.83 +/- 0.00
Episode length: 1114.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 904      |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 5.55     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 7.08     |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2740894  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 685      |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 124      |
|    time_elapsed    | 7845     |
|    total_timesteps | 972905   |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 3.57     |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2740896  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 865      |
|    ep_rew_mean     | 684      |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 124      |
|    time_elapsed    | 7863     |
|    total_timesteps | 976330   |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 8.01     |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2740900  |
---------------------------------
Eval num_timesteps=980000, episode_reward=778.48 +/- 0.00
Episode length: 966.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 966      |
|    mean_reward     | 778      |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.01     |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2740904  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 692      |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 123      |
|    time_elapsed    | 7911     |
|    total_timesteps | 980965   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 694      |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 124      |
|    time_elapsed    | 7931     |
|    total_timesteps | 984667   |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 4.18     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.83     |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2740908  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 869      |
|    ep_rew_mean     | 688      |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 124      |
|    time_elapsed    | 7948     |
|    total_timesteps | 987377   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 5.82     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 5.79     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2740912  |
---------------------------------
Eval num_timesteps=990000, episode_reward=630.20 +/- 0.00
Episode length: 791.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 791      |
|    mean_reward     | 630      |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 5.4      |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 7.32     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2740916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 684      |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 123      |
|    time_elapsed    | 7991     |
|    total_timesteps | 990590   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 124      |
|    time_elapsed    | 8009     |
|    total_timesteps | 993900   |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 8.26     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 5.61     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2740920  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 868      |
|    ep_rew_mean     | 687      |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 124      |
|    time_elapsed    | 8027     |
|    total_timesteps | 997181   |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 7.11     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 7.63     |
|    learning_rate   | 9e-05    |
|    n_updates       | 2740924  |
---------------------------------
Eval num_timesteps=1000000, episode_reward=788.66 +/- 0.00
Episode length: 991.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 991      |
|    mean_reward     | 789      |
| time/              |          |
|    total_timesteps | 1000000  |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 8.38     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 6.87     |
|    learning_rate   | 9e-05    |
|    n_updates       | 2740928  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 856      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 123      |
|    time_elapsed    | 8074     |
|    total_timesteps | 1000797  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 124      |
|    time_elapsed    | 8092     |
|    total_timesteps | 1003976  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 3.57     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 9e-05    |
|    n_updates       | 2740932  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 856      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 124      |
|    time_elapsed    | 8109     |
|    total_timesteps | 1007137  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 3.38     |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2740936  |
---------------------------------
Eval num_timesteps=1010000, episode_reward=849.20 +/- 0.00
Episode length: 1082.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 849      |
| time/              |          |
|    total_timesteps | 1010000  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 5.59     |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2740940  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 124      |
|    time_elapsed    | 8150     |
|    total_timesteps | 1010802  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 124      |
|    time_elapsed    | 8167     |
|    total_timesteps | 1013996  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2740944  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 124      |
|    time_elapsed    | 8183     |
|    total_timesteps | 1017084  |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2740948  |
---------------------------------
Eval num_timesteps=1020000, episode_reward=627.83 +/- 0.00
Episode length: 785.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 785      |
|    mean_reward     | 628      |
| time/              |          |
|    total_timesteps | 1020000  |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 5.46     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2740952  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 124      |
|    time_elapsed    | 8222     |
|    total_timesteps | 1020940  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 855      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 124      |
|    time_elapsed    | 8238     |
|    total_timesteps | 1024315  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 7.63     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 6.56     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2740956  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 124      |
|    time_elapsed    | 8254     |
|    total_timesteps | 1027856  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 5.43     |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2740960  |
---------------------------------
Eval num_timesteps=1030000, episode_reward=940.99 +/- 0.00
Episode length: 1165.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 941      |
| time/              |          |
|    total_timesteps | 1030000  |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 4.37     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 7.4      |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2740963  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 860      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 124      |
|    time_elapsed    | 8296     |
|    total_timesteps | 1031573  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 6.6      |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 4.5      |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2740964  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 850      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 124      |
|    time_elapsed    | 8311     |
|    total_timesteps | 1034946  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 5.65     |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2740968  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 124      |
|    time_elapsed    | 8328     |
|    total_timesteps | 1038313  |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 7.95     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 10.5     |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2740972  |
---------------------------------
Eval num_timesteps=1040000, episode_reward=621.84 +/- 0.00
Episode length: 780.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 780      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 1040000  |
| train/             |          |
|    actor_loss      | -50.7    |
|    critic_loss     | 4.75     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 6.24     |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2740975  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 124      |
|    time_elapsed    | 8367     |
|    total_timesteps | 1042168  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 2.8      |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2740976  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 124      |
|    time_elapsed    | 8384     |
|    total_timesteps | 1046282  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 7.12     |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2740980  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 856      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 124      |
|    time_elapsed    | 8401     |
|    total_timesteps | 1049948  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 8.16     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 2.89     |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2740984  |
---------------------------------
Eval num_timesteps=1050000, episode_reward=623.45 +/- 0.00
Episode length: 783.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 783      |
|    mean_reward     | 623      |
| time/              |          |
|    total_timesteps | 1050000  |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 4.51     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 5.9      |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2740985  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 846      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 124      |
|    time_elapsed    | 8439     |
|    total_timesteps | 1052802  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 4.9      |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 9.31     |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2740988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 124      |
|    time_elapsed    | 8455     |
|    total_timesteps | 1055756  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 6.24     |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2740992  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 828      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 124      |
|    time_elapsed    | 8472     |
|    total_timesteps | 1058892  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 6.46     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2740996  |
---------------------------------
Eval num_timesteps=1060000, episode_reward=595.70 +/- 0.00
Episode length: 737.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 737      |
|    mean_reward     | 596      |
| time/              |          |
|    total_timesteps | 1060000  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 5.87     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 6.47     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2740998  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 822      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 124      |
|    time_elapsed    | 8509     |
|    total_timesteps | 1062078  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 4.82     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2741000  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 124      |
|    time_elapsed    | 8525     |
|    total_timesteps | 1064668  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 3.11     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2741004  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 124      |
|    time_elapsed    | 8540     |
|    total_timesteps | 1067284  |
| train/             |          |
|    actor_loss      | -50.7    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 5.42     |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2741008  |
---------------------------------
Eval num_timesteps=1070000, episode_reward=601.15 +/- 0.00
Episode length: 755.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 755      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 1070000  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2741011  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 124      |
|    time_elapsed    | 8579     |
|    total_timesteps | 1071462  |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 3.82     |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2741012  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 124      |
|    time_elapsed    | 8594     |
|    total_timesteps | 1074207  |
| train/             |          |
|    actor_loss      | -49.7    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 7.36     |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2741016  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 125      |
|    time_elapsed    | 8610     |
|    total_timesteps | 1077345  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 6.35     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 4.08     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2741020  |
---------------------------------
Eval num_timesteps=1080000, episode_reward=611.58 +/- 0.00
Episode length: 769.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 769      |
|    mean_reward     | 612      |
| time/              |          |
|    total_timesteps | 1080000  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 5.58     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2741023  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 125      |
|    time_elapsed    | 8650     |
|    total_timesteps | 1081515  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 6.25     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2741024  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 794      |
|    ep_rew_mean     | 630      |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 125      |
|    time_elapsed    | 8666     |
|    total_timesteps | 1084395  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 5.65     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.8      |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2741028  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 125      |
|    time_elapsed    | 8681     |
|    total_timesteps | 1087351  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 7.39     |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2741032  |
---------------------------------
Eval num_timesteps=1090000, episode_reward=526.98 +/- 0.00
Episode length: 662.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 527      |
| time/              |          |
|    total_timesteps | 1090000  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 7.29     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2741036  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 125      |
|    time_elapsed    | 8720     |
|    total_timesteps | 1090902  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 798      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 125      |
|    time_elapsed    | 8737     |
|    total_timesteps | 1094451  |
| train/             |          |
|    actor_loss      | -49.8    |
|    critic_loss     | 7.51     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 10.1     |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2741040  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 801      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 125      |
|    time_elapsed    | 8754     |
|    total_timesteps | 1097881  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2741044  |
---------------------------------
Eval num_timesteps=1100000, episode_reward=520.26 +/- 0.00
Episode length: 662.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 520      |
| time/              |          |
|    total_timesteps | 1100000  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2741047  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 125      |
|    time_elapsed    | 8792     |
|    total_timesteps | 1101764  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 5.41     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 8.09     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2741048  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 125      |
|    time_elapsed    | 8809     |
|    total_timesteps | 1105080  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 6.61     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2741052  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 803      |
|    ep_rew_mean     | 638      |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 125      |
|    time_elapsed    | 8826     |
|    total_timesteps | 1108560  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 7.02     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2741056  |
---------------------------------
Eval num_timesteps=1110000, episode_reward=592.87 +/- 0.00
Episode length: 741.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 741      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 1110000  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 7.25     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2741059  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 125      |
|    time_elapsed    | 8864     |
|    total_timesteps | 1111572  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 5.38     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2741060  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 125      |
|    time_elapsed    | 8879     |
|    total_timesteps | 1114603  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 5.71     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2741064  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 125      |
|    time_elapsed    | 8895     |
|    total_timesteps | 1117539  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 15.4     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 8.55     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2741068  |
---------------------------------
Eval num_timesteps=1120000, episode_reward=755.93 +/- 0.00
Episode length: 940.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 940      |
|    mean_reward     | 756      |
| time/              |          |
|    total_timesteps | 1120000  |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 6.63     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 6.71     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2741072  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 125      |
|    time_elapsed    | 8935     |
|    total_timesteps | 1120876  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 790      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 125      |
|    time_elapsed    | 8952     |
|    total_timesteps | 1124681  |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 3.38     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2741076  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 776      |
|    ep_rew_mean     | 617      |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 125      |
|    time_elapsed    | 8967     |
|    total_timesteps | 1127389  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.46     |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2741080  |
---------------------------------
Eval num_timesteps=1130000, episode_reward=625.95 +/- 0.00
Episode length: 782.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 782      |
|    mean_reward     | 626      |
| time/              |          |
|    total_timesteps | 1130000  |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 5.22     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 4.27     |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2741084  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 125      |
|    time_elapsed    | 9007     |
|    total_timesteps | 1130652  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 773      |
|    ep_rew_mean     | 614      |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 125      |
|    time_elapsed    | 9022     |
|    total_timesteps | 1133783  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.13     |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2741088  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 125      |
|    time_elapsed    | 9038     |
|    total_timesteps | 1136482  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 11.6     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 8.08     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2741092  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 125      |
|    time_elapsed    | 9054     |
|    total_timesteps | 1139547  |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 4.73     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 7.28     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2741096  |
---------------------------------
Eval num_timesteps=1140000, episode_reward=504.84 +/- 0.00
Episode length: 637.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 637      |
|    mean_reward     | 505      |
| time/              |          |
|    total_timesteps | 1140000  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.8      |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2741097  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 125      |
|    time_elapsed    | 9091     |
|    total_timesteps | 1142645  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.72     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2741100  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 125      |
|    time_elapsed    | 9107     |
|    total_timesteps | 1145392  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 7.99     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 6.33     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2741104  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 125      |
|    time_elapsed    | 9122     |
|    total_timesteps | 1148074  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 7.98     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 8.01     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2741108  |
---------------------------------
Eval num_timesteps=1150000, episode_reward=511.17 +/- 0.00
Episode length: 638.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 638      |
|    mean_reward     | 511      |
| time/              |          |
|    total_timesteps | 1150000  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 8.17     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2741111  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 763      |
|    ep_rew_mean     | 607      |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 125      |
|    time_elapsed    | 9160     |
|    total_timesteps | 1151115  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 4.16     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2741112  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 125      |
|    time_elapsed    | 9176     |
|    total_timesteps | 1154383  |
| train/             |          |
|    actor_loss      | -50.2    |
|    critic_loss     | 6.93     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 7.85     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2741116  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 125      |
|    time_elapsed    | 9191     |
|    total_timesteps | 1157460  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 5.82     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 5.9      |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2741120  |
---------------------------------
Eval num_timesteps=1160000, episode_reward=742.09 +/- 0.00
Episode length: 929.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 929      |
|    mean_reward     | 742      |
| time/              |          |
|    total_timesteps | 1160000  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 7.58     |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2741123  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 125      |
|    time_elapsed    | 9233     |
|    total_timesteps | 1161514  |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 7.55     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 9.14     |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2741124  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 125      |
|    time_elapsed    | 9249     |
|    total_timesteps | 1164312  |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 7.93     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 5.22     |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2741128  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 125      |
|    time_elapsed    | 9265     |
|    total_timesteps | 1167377  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 5.79     |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2741132  |
---------------------------------
Eval num_timesteps=1170000, episode_reward=727.27 +/- 0.00
Episode length: 894.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 894      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 1170000  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 9.78     |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2741136  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 608      |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 125      |
|    time_elapsed    | 9303     |
|    total_timesteps | 1170549  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 609      |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 125      |
|    time_elapsed    | 9321     |
|    total_timesteps | 1174264  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 10.7     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 8.27     |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2741140  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 760      |
|    ep_rew_mean     | 604      |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 126      |
|    time_elapsed    | 9336     |
|    total_timesteps | 1176980  |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 13.2     |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2741144  |
---------------------------------
Eval num_timesteps=1180000, episode_reward=522.84 +/- 0.00
Episode length: 667.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 667      |
|    mean_reward     | 523      |
| time/              |          |
|    total_timesteps | 1180000  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 7.38     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 8.02     |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2741148  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 755      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 125      |
|    time_elapsed    | 9374     |
|    total_timesteps | 1180593  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 126      |
|    time_elapsed    | 9391     |
|    total_timesteps | 1183837  |
| train/             |          |
|    actor_loss      | -48.4    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 12.3     |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2741152  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 755      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 126      |
|    time_elapsed    | 9407     |
|    total_timesteps | 1187378  |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 4.15     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 6.1      |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2741156  |
---------------------------------
Eval num_timesteps=1190000, episode_reward=395.74 +/- 0.00
Episode length: 494.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 396      |
| time/              |          |
|    total_timesteps | 1190000  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 10.3     |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2741160  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 126      |
|    time_elapsed    | 9444     |
|    total_timesteps | 1190623  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 126      |
|    time_elapsed    | 9460     |
|    total_timesteps | 1193798  |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 9.01     |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2741164  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 601      |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 126      |
|    time_elapsed    | 9477     |
|    total_timesteps | 1196903  |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 7.07     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 9.89     |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2741168  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 755      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 126      |
|    time_elapsed    | 9493     |
|    total_timesteps | 1199904  |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 5.22     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 6.45     |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2741172  |
---------------------------------
Eval num_timesteps=1200000, episode_reward=693.65 +/- 0.00
Episode length: 876.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 876      |
|    mean_reward     | 694      |
| time/              |          |
|    total_timesteps | 1200000  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 8.21     |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2741173  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 592      |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 126      |
|    time_elapsed    | 9532     |
|    total_timesteps | 1202797  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 8.73     |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2741176  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 751      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 126      |
|    time_elapsed    | 9548     |
|    total_timesteps | 1206053  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 5.37     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 6.01     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2741180  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 597      |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 126      |
|    time_elapsed    | 9564     |
|    total_timesteps | 1209274  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 8.72     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2741184  |
---------------------------------
Eval num_timesteps=1210000, episode_reward=566.78 +/- 0.00
Episode length: 704.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 704      |
|    mean_reward     | 567      |
| time/              |          |
|    total_timesteps | 1210000  |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2741185  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 755      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 126      |
|    time_elapsed    | 9604     |
|    total_timesteps | 1213348  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 5.71     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2741188  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 763      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 126      |
|    time_elapsed    | 9620     |
|    total_timesteps | 1216865  |
| train/             |          |
|    actor_loss      | -49.1    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 8.51     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2741192  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 759      |
|    ep_rew_mean     | 603      |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 126      |
|    time_elapsed    | 9636     |
|    total_timesteps | 1219489  |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 13.5     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2741196  |
---------------------------------
Eval num_timesteps=1220000, episode_reward=371.24 +/- 0.00
Episode length: 460.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 460      |
|    mean_reward     | 371      |
| time/              |          |
|    total_timesteps | 1220000  |
| train/             |          |
|    actor_loss      | -49.7    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 9.86     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2741197  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 602      |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 126      |
|    time_elapsed    | 9672     |
|    total_timesteps | 1222569  |
| train/             |          |
|    actor_loss      | -49.6    |
|    critic_loss     | 4.73     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2741200  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 770      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 126      |
|    time_elapsed    | 9689     |
|    total_timesteps | 1226477  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 8.21     |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 2741204  |
---------------------------------
Eval num_timesteps=1230000, episode_reward=729.09 +/- 0.00
Episode length: 916.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 916      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 1230000  |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 3.38     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 8.9      |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 2741208  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 618      |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 126      |
|    time_elapsed    | 9730     |
|    total_timesteps | 1230727  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | 622      |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 126      |
|    time_elapsed    | 9746     |
|    total_timesteps | 1233592  |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 11       |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 2741212  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 785      |
|    ep_rew_mean     | 622      |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 126      |
|    time_elapsed    | 9762     |
|    total_timesteps | 1236889  |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 8        |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 6.84     |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 2741216  |
---------------------------------
Eval num_timesteps=1240000, episode_reward=494.40 +/- 0.00
Episode length: 623.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 623      |
|    mean_reward     | 494      |
| time/              |          |
|    total_timesteps | 1240000  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 4.7      |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 7.32     |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 2741220  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 788      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 126      |
|    time_elapsed    | 9800     |
|    total_timesteps | 1240785  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 788      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 126      |
|    time_elapsed    | 9816     |
|    total_timesteps | 1243924  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 5.97     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 9.67     |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 2741224  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 126      |
|    time_elapsed    | 9833     |
|    total_timesteps | 1247150  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 7.94     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2741228  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 790      |
|    ep_rew_mean     | 626      |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 126      |
|    time_elapsed    | 9848     |
|    total_timesteps | 1249987  |
| train/             |          |
|    actor_loss      | -49.7    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 14       |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2741232  |
---------------------------------
Eval num_timesteps=1250000, episode_reward=371.25 +/- 0.00
Episode length: 461.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 461      |
|    mean_reward     | 371      |
| time/              |          |
|    total_timesteps | 1250000  |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 14.3     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2741233  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 630      |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 126      |
|    time_elapsed    | 9885     |
|    total_timesteps | 1253375  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 5.95     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 11.6     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2741236  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 126      |
|    time_elapsed    | 9902     |
|    total_timesteps | 1256838  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 6.48     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 12       |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 2741240  |
---------------------------------
Eval num_timesteps=1260000, episode_reward=660.87 +/- 0.00
Episode length: 822.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 822      |
|    mean_reward     | 661      |
| time/              |          |
|    total_timesteps | 1260000  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 6.23     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 7.74     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 2741244  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 630      |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 126      |
|    time_elapsed    | 9942     |
|    total_timesteps | 1260766  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 126      |
|    time_elapsed    | 9957     |
|    total_timesteps | 1263463  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 4.68     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 14.7     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 2741248  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 126      |
|    time_elapsed    | 9972     |
|    total_timesteps | 1266360  |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 11.5     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2741252  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 787      |
|    ep_rew_mean     | 624      |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 127      |
|    time_elapsed    | 9989     |
|    total_timesteps | 1269701  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 13.6     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2741256  |
---------------------------------
Eval num_timesteps=1270000, episode_reward=540.07 +/- 0.00
Episode length: 677.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 677      |
|    mean_reward     | 540      |
| time/              |          |
|    total_timesteps | 1270000  |
| train/             |          |
|    actor_loss      | -47      |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 13.3     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2741257  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 126      |
|    time_elapsed    | 10031    |
|    total_timesteps | 1273113  |
| train/             |          |
|    actor_loss      | -51.1    |
|    critic_loss     | 5.23     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 9.54     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2741260  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 126      |
|    time_elapsed    | 10047    |
|    total_timesteps | 1275806  |
| train/             |          |
|    actor_loss      | -48.7    |
|    critic_loss     | 3.37     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 13       |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2741264  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 781      |
|    ep_rew_mean     | 620      |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 127      |
|    time_elapsed    | 10064    |
|    total_timesteps | 1278630  |
| train/             |          |
|    actor_loss      | -46.9    |
|    critic_loss     | 6.04     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 12.9     |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2741268  |
---------------------------------
Eval num_timesteps=1280000, episode_reward=488.24 +/- 0.00
Episode length: 619.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 619      |
|    mean_reward     | 488      |
| time/              |          |
|    total_timesteps | 1280000  |
| train/             |          |
|    actor_loss      | -50.1    |
|    critic_loss     | 7.09     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 6.06     |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2741271  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 776      |
|    ep_rew_mean     | 616      |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 126      |
|    time_elapsed    | 10102    |
|    total_timesteps | 1281356  |
| train/             |          |
|    actor_loss      | -50.1    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 7.01     |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2741272  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 771      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 126      |
|    time_elapsed    | 10118    |
|    total_timesteps | 1283641  |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 6.69     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 4.3      |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2741276  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 610      |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 126      |
|    time_elapsed    | 10135    |
|    total_timesteps | 1286700  |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 4.69     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 9.59     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2741280  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 605      |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 127      |
|    time_elapsed    | 10151    |
|    total_timesteps | 1289365  |
| train/             |          |
|    actor_loss      | -50.6    |
|    critic_loss     | 19.3     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 9.76     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2741284  |
---------------------------------
Eval num_timesteps=1290000, episode_reward=554.98 +/- 0.00
Episode length: 687.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 687      |
|    mean_reward     | 555      |
| time/              |          |
|    total_timesteps | 1290000  |
| train/             |          |
|    actor_loss      | -47.8    |
|    critic_loss     | 7.16     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 5.08     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2741286  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 598      |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 126      |
|    time_elapsed    | 10189    |
|    total_timesteps | 1291769  |
| train/             |          |
|    actor_loss      | -49.3    |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 7.62     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2741288  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 760      |
|    ep_rew_mean     | 602      |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 126      |
|    time_elapsed    | 10209    |
|    total_timesteps | 1295865  |
| train/             |          |
|    actor_loss      | -48.3    |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 8.44     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2741292  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 769      |
|    ep_rew_mean     | 609      |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 127      |
|    time_elapsed    | 10226    |
|    total_timesteps | 1299405  |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 11.8     |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2741296  |
---------------------------------
Eval num_timesteps=1300000, episode_reward=711.86 +/- 0.00
Episode length: 878.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 878      |
|    mean_reward     | 712      |
| time/              |          |
|    total_timesteps | 1300000  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 3.32     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 12.9     |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2741297  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 126      |
|    time_elapsed    | 10266    |
|    total_timesteps | 1302134  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 7.78     |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2741300  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 126      |
|    time_elapsed    | 10284    |
|    total_timesteps | 1305948  |
| train/             |          |
|    actor_loss      | -47.2    |
|    critic_loss     | 5.42     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 13.6     |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2741304  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 759      |
|    ep_rew_mean     | 603      |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 127      |
|    time_elapsed    | 10300    |
|    total_timesteps | 1309103  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 6.26     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 8.97     |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2741308  |
---------------------------------
Eval num_timesteps=1310000, episode_reward=580.31 +/- 0.00
Episode length: 722.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 722      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 1310000  |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 8.59     |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2741310  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 607      |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 126      |
|    time_elapsed    | 10340    |
|    total_timesteps | 1312731  |
| train/             |          |
|    actor_loss      | -47.3    |
|    critic_loss     | 8.83     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 12       |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2741312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 126      |
|    time_elapsed    | 10355    |
|    total_timesteps | 1314940  |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 5.08     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 8.78     |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2741316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 127      |
|    time_elapsed    | 10372    |
|    total_timesteps | 1318068  |
| train/             |          |
|    actor_loss      | -50.6    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 6.34     |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2741320  |
---------------------------------
Eval num_timesteps=1320000, episode_reward=722.43 +/- 0.00
Episode length: 898.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 898      |
|    mean_reward     | 722      |
| time/              |          |
|    total_timesteps | 1320000  |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 5.55     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 14.3     |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2741323  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 592      |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 126      |
|    time_elapsed    | 10412    |
|    total_timesteps | 1321293  |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 5.51     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 11       |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2741324  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 593      |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 127      |
|    time_elapsed    | 10429    |
|    total_timesteps | 1324629  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 3.82     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2741328  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 592      |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 127      |
|    time_elapsed    | 10445    |
|    total_timesteps | 1327326  |
| train/             |          |
|    actor_loss      | -48.7    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 13.3     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2741332  |
---------------------------------
Eval num_timesteps=1330000, episode_reward=362.11 +/- 0.00
Episode length: 442.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 442      |
|    mean_reward     | 362      |
| time/              |          |
|    total_timesteps | 1330000  |
| train/             |          |
|    actor_loss      | -47.6    |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 15.1     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2741335  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 127      |
|    time_elapsed    | 10485    |
|    total_timesteps | 1332027  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 12.8     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2741336  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 746      |
|    ep_rew_mean     | 594      |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 127      |
|    time_elapsed    | 10501    |
|    total_timesteps | 1335234  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 3.33     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 10.3     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2741340  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 127      |
|    time_elapsed    | 10518    |
|    total_timesteps | 1338395  |
| train/             |          |
|    actor_loss      | -48.2    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 12.5     |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2741344  |
---------------------------------
Eval num_timesteps=1340000, episode_reward=496.59 +/- 0.00
Episode length: 628.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 628      |
|    mean_reward     | 497      |
| time/              |          |
|    total_timesteps | 1340000  |
| train/             |          |
|    actor_loss      | -48.4    |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 12.9     |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2741346  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 597      |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 127      |
|    time_elapsed    | 10557    |
|    total_timesteps | 1342095  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 11.7     |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2741348  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 127      |
|    time_elapsed    | 10573    |
|    total_timesteps | 1344725  |
| train/             |          |
|    actor_loss      | -47.9    |
|    critic_loss     | 4.92     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 11.1     |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2741352  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 590      |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 127      |
|    time_elapsed    | 10589    |
|    total_timesteps | 1347376  |
| train/             |          |
|    actor_loss      | -47.9    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 12.5     |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2741356  |
---------------------------------
Eval num_timesteps=1350000, episode_reward=350.22 +/- 0.00
Episode length: 433.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | 350      |
| time/              |          |
|    total_timesteps | 1350000  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 15       |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2741360  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 735      |
|    ep_rew_mean     | 586      |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 127      |
|    time_elapsed    | 10626    |
|    total_timesteps | 1350611  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 127      |
|    time_elapsed    | 10640    |
|    total_timesteps | 1352555  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 13.7     |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2741364  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 127      |
|    time_elapsed    | 10656    |
|    total_timesteps | 1355193  |
| train/             |          |
|    actor_loss      | -48.4    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 12.1     |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2741368  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 589      |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 127      |
|    time_elapsed    | 10673    |
|    total_timesteps | 1359043  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 9.02     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2741372  |
---------------------------------
Eval num_timesteps=1360000, episode_reward=797.87 +/- 0.00
Episode length: 1006.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 798      |
| time/              |          |
|    total_timesteps | 1360000  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 11.9     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2741374  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 591      |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 127      |
|    time_elapsed    | 10714    |
|    total_timesteps | 1361736  |
| train/             |          |
|    actor_loss      | -47.7    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 9.38     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2741376  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 588      |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 127      |
|    time_elapsed    | 10730    |
|    total_timesteps | 1364340  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 8.31     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 12.4     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2741380  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 590      |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 127      |
|    time_elapsed    | 10746    |
|    total_timesteps | 1367295  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 5.29     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 11.3     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2741384  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 589      |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 127      |
|    time_elapsed    | 10761    |
|    total_timesteps | 1369576  |
| train/             |          |
|    actor_loss      | -48.4    |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 12.4     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2741388  |
---------------------------------
Eval num_timesteps=1370000, episode_reward=394.32 +/- 0.00
Episode length: 494.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 494      |
|    mean_reward     | 394      |
| time/              |          |
|    total_timesteps | 1370000  |
| train/             |          |
|    actor_loss      | -46.2    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 14.1     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2741389  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 576      |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 127      |
|    time_elapsed    | 10797    |
|    total_timesteps | 1372345  |
| train/             |          |
|    actor_loss      | -46.4    |
|    critic_loss     | 5.92     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 16.3     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2741392  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 714      |
|    ep_rew_mean     | 571      |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 127      |
|    time_elapsed    | 10813    |
|    total_timesteps | 1375247  |
| train/             |          |
|    actor_loss      | -47.2    |
|    critic_loss     | 5.15     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 13.2     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2741396  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 723      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 127      |
|    time_elapsed    | 10829    |
|    total_timesteps | 1378309  |
| train/             |          |
|    actor_loss      | -45.8    |
|    critic_loss     | 6.45     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 12       |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2741400  |
---------------------------------
Eval num_timesteps=1380000, episode_reward=523.24 +/- 0.00
Episode length: 661.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 661      |
|    mean_reward     | 523      |
| time/              |          |
|    total_timesteps | 1380000  |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 7.43     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2741403  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 568      |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 127      |
|    time_elapsed    | 10867    |
|    total_timesteps | 1381246  |
| train/             |          |
|    actor_loss      | -46.7    |
|    critic_loss     | 5.51     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 15.7     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2741404  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 708      |
|    ep_rew_mean     | 565      |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 127      |
|    time_elapsed    | 10882    |
|    total_timesteps | 1383994  |
| train/             |          |
|    actor_loss      | -48      |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 11.7     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2741408  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 558      |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 127      |
|    time_elapsed    | 10897    |
|    total_timesteps | 1386454  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 15.1     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741412  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 558      |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 127      |
|    time_elapsed    | 10912    |
|    total_timesteps | 1388645  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 14.1     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741416  |
---------------------------------
Eval num_timesteps=1390000, episode_reward=572.89 +/- 0.00
Episode length: 710.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 710      |
|    mean_reward     | 573      |
| time/              |          |
|    total_timesteps | 1390000  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 6.86     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741419  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 550      |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 127      |
|    time_elapsed    | 10949    |
|    total_timesteps | 1390942  |
| train/             |          |
|    actor_loss      | -46.5    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 15.3     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741420  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 685      |
|    ep_rew_mean     | 548      |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 127      |
|    time_elapsed    | 10964    |
|    total_timesteps | 1393196  |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 14.3     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741424  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 674      |
|    ep_rew_mean     | 539      |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 127      |
|    time_elapsed    | 10978    |
|    total_timesteps | 1395420  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.49     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 19.9     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2741428  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 672      |
|    ep_rew_mean     | 538      |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 127      |
|    time_elapsed    | 10993    |
|    total_timesteps | 1397939  |
| train/             |          |
|    actor_loss      | -45.7    |
|    critic_loss     | 6.37     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 10.4     |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2741432  |
---------------------------------
Eval num_timesteps=1400000, episode_reward=707.80 +/- 0.00
Episode length: 880.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 880      |
|    mean_reward     | 708      |
| time/              |          |
|    total_timesteps | 1400000  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 5.27     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 12.7     |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2741436  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 529      |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 126      |
|    time_elapsed    | 11032    |
|    total_timesteps | 1400908  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 657      |
|    ep_rew_mean     | 527      |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 127      |
|    time_elapsed    | 11048    |
|    total_timesteps | 1403769  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 14.5     |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2741440  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 651      |
|    ep_rew_mean     | 522      |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 127      |
|    time_elapsed    | 11064    |
|    total_timesteps | 1406336  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 11       |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2741444  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 651      |
|    ep_rew_mean     | 522      |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 127      |
|    time_elapsed    | 11079    |
|    total_timesteps | 1409166  |
| train/             |          |
|    actor_loss      | -48.2    |
|    critic_loss     | 10.9     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2741448  |
---------------------------------
Eval num_timesteps=1410000, episode_reward=582.03 +/- 0.00
Episode length: 732.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 732      |
|    mean_reward     | 582      |
| time/              |          |
|    total_timesteps | 1410000  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 12.6     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 12.7     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2741450  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 648      |
|    ep_rew_mean     | 519      |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 126      |
|    time_elapsed    | 11117    |
|    total_timesteps | 1411822  |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 7.05     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2741452  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 652      |
|    ep_rew_mean     | 522      |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 127      |
|    time_elapsed    | 11133    |
|    total_timesteps | 1414935  |
| train/             |          |
|    actor_loss      | -44.7    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 13.3     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2741456  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 651      |
|    ep_rew_mean     | 522      |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 127      |
|    time_elapsed    | 11148    |
|    total_timesteps | 1417434  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 8.27     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 14.1     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2741460  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 655      |
|    ep_rew_mean     | 525      |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 127      |
|    time_elapsed    | 11163    |
|    total_timesteps | 1419744  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 8.66     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 15.9     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2741464  |
---------------------------------
Eval num_timesteps=1420000, episode_reward=593.04 +/- 0.00
Episode length: 738.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 738      |
|    mean_reward     | 593      |
| time/              |          |
|    total_timesteps | 1420000  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 5.23     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 13.1     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2741465  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 652      |
|    ep_rew_mean     | 524      |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 126      |
|    time_elapsed    | 11200    |
|    total_timesteps | 1422403  |
| train/             |          |
|    actor_loss      | -47.2    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 15.5     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2741468  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 634      |
|    ep_rew_mean     | 509      |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 127      |
|    time_elapsed    | 11215    |
|    total_timesteps | 1424415  |
| train/             |          |
|    actor_loss      | -48.7    |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2741472  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 636      |
|    ep_rew_mean     | 511      |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 127      |
|    time_elapsed    | 11230    |
|    total_timesteps | 1427034  |
| train/             |          |
|    actor_loss      | -47      |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 8.54     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741476  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 637      |
|    ep_rew_mean     | 511      |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 127      |
|    time_elapsed    | 11245    |
|    total_timesteps | 1429746  |
| train/             |          |
|    actor_loss      | -50.5    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 6.27     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741480  |
---------------------------------
Eval num_timesteps=1430000, episode_reward=724.31 +/- 0.00
Episode length: 894.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 894      |
|    mean_reward     | 724      |
| time/              |          |
|    total_timesteps | 1430000  |
| train/             |          |
|    actor_loss      | -48.3    |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 10.3     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741481  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 625      |
|    ep_rew_mean     | 502      |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 126      |
|    time_elapsed    | 11283    |
|    total_timesteps | 1431778  |
| train/             |          |
|    actor_loss      | -46.4    |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 9.45     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741484  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 620      |
|    ep_rew_mean     | 498      |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 126      |
|    time_elapsed    | 11297    |
|    total_timesteps | 1433527  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 11.5     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741488  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 615      |
|    ep_rew_mean     | 494      |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 126      |
|    time_elapsed    | 11312    |
|    total_timesteps | 1435435  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2741492  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 615      |
|    ep_rew_mean     | 494      |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 126      |
|    time_elapsed    | 11327    |
|    total_timesteps | 1438274  |
| train/             |          |
|    actor_loss      | -46.2    |
|    critic_loss     | 7.54     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 16       |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2741496  |
---------------------------------
Eval num_timesteps=1440000, episode_reward=302.41 +/- 0.00
Episode length: 371.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 371      |
|    mean_reward     | 302      |
| time/              |          |
|    total_timesteps | 1440000  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 7.47     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 11.7     |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2741500  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 603      |
|    ep_rew_mean     | 485      |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 126      |
|    time_elapsed    | 11361    |
|    total_timesteps | 1440438  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 593      |
|    ep_rew_mean     | 477      |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 126      |
|    time_elapsed    | 11375    |
|    total_timesteps | 1442139  |
| train/             |          |
|    actor_loss      | -45.8    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 16.3     |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2741504  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 592      |
|    ep_rew_mean     | 476      |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 126      |
|    time_elapsed    | 11390    |
|    total_timesteps | 1444747  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 8.18     |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2741508  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 588      |
|    ep_rew_mean     | 473      |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 126      |
|    time_elapsed    | 11405    |
|    total_timesteps | 1446804  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 4.36     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 12.1     |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2741512  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 590      |
|    ep_rew_mean     | 475      |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 126      |
|    time_elapsed    | 11420    |
|    total_timesteps | 1449211  |
| train/             |          |
|    actor_loss      | -48.5    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 9.67     |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2741516  |
---------------------------------
Eval num_timesteps=1450000, episode_reward=304.40 +/- 0.00
Episode length: 376.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 376      |
|    mean_reward     | 304      |
| time/              |          |
|    total_timesteps | 1450000  |
| train/             |          |
|    actor_loss      | -48.1    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 12.7     |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2741518  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 592      |
|    ep_rew_mean     | 476      |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 126      |
|    time_elapsed    | 11454    |
|    total_timesteps | 1451590  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 8.43     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 14.2     |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2741520  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 589      |
|    ep_rew_mean     | 474      |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 126      |
|    time_elapsed    | 11468    |
|    total_timesteps | 1453558  |
| train/             |          |
|    actor_loss      | -48.3    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 11       |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2741524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 587      |
|    ep_rew_mean     | 472      |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 126      |
|    time_elapsed    | 11482    |
|    total_timesteps | 1455575  |
| train/             |          |
|    actor_loss      | -47.8    |
|    critic_loss     | 6.58     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 6.25     |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2741528  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 583      |
|    ep_rew_mean     | 469      |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 126      |
|    time_elapsed    | 11496    |
|    total_timesteps | 1457684  |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 4.73     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 9.72     |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2741532  |
---------------------------------
Eval num_timesteps=1460000, episode_reward=363.45 +/- 0.00
Episode length: 450.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 1460000  |
| train/             |          |
|    actor_loss      | -48      |
|    critic_loss     | 6.42     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 8.66     |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2741536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 577      |
|    ep_rew_mean     | 464      |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 126      |
|    time_elapsed    | 11531    |
|    total_timesteps | 1460446  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 458      |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 126      |
|    time_elapsed    | 11546    |
|    total_timesteps | 1462540  |
| train/             |          |
|    actor_loss      | -47.7    |
|    critic_loss     | 5.71     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 7.66     |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2741540  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 571      |
|    ep_rew_mean     | 460      |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 126      |
|    time_elapsed    | 11561    |
|    total_timesteps | 1465300  |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 4.73     |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2741544  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 565      |
|    ep_rew_mean     | 455      |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 126      |
|    time_elapsed    | 11576    |
|    total_timesteps | 1467529  |
| train/             |          |
|    actor_loss      | -42.3    |
|    critic_loss     | 5.36     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 14.4     |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2741548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 560      |
|    ep_rew_mean     | 451      |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 126      |
|    time_elapsed    | 11590    |
|    total_timesteps | 1469384  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 6.79     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 15       |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2741552  |
---------------------------------
Eval num_timesteps=1470000, episode_reward=361.44 +/- 0.00
Episode length: 447.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 447      |
|    mean_reward     | 361      |
| time/              |          |
|    total_timesteps | 1470000  |
| train/             |          |
|    actor_loss      | -48.1    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 10       |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2741554  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 556      |
|    ep_rew_mean     | 448      |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 126      |
|    time_elapsed    | 11626    |
|    total_timesteps | 1472290  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 5.04     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 8.64     |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2741556  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 554      |
|    ep_rew_mean     | 447      |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 126      |
|    time_elapsed    | 11641    |
|    total_timesteps | 1474614  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 11.6     |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2741560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 553      |
|    ep_rew_mean     | 446      |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 126      |
|    time_elapsed    | 11656    |
|    total_timesteps | 1476792  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 4.7      |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 12.1     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741564  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 550      |
|    ep_rew_mean     | 443      |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 126      |
|    time_elapsed    | 11671    |
|    total_timesteps | 1478869  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 11.4     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741568  |
---------------------------------
Eval num_timesteps=1480000, episode_reward=362.24 +/- 0.00
Episode length: 448.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 448      |
|    mean_reward     | 362      |
| time/              |          |
|    total_timesteps | 1480000  |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 5.15     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 15.3     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741571  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 548      |
|    ep_rew_mean     | 442      |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 126      |
|    time_elapsed    | 11705    |
|    total_timesteps | 1480909  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 7.94     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741572  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 546      |
|    ep_rew_mean     | 441      |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 126      |
|    time_elapsed    | 11720    |
|    total_timesteps | 1483340  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 10.8     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741576  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 537      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 126      |
|    time_elapsed    | 11733    |
|    total_timesteps | 1485130  |
| train/             |          |
|    actor_loss      | -45.9    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 9.14     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2741580  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 544      |
|    ep_rew_mean     | 440      |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 126      |
|    time_elapsed    | 11749    |
|    total_timesteps | 1487623  |
| train/             |          |
|    actor_loss      | -47.3    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 12.7     |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2741584  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 546      |
|    ep_rew_mean     | 441      |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 126      |
|    time_elapsed    | 11763    |
|    total_timesteps | 1489512  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 16       |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2741588  |
---------------------------------
Eval num_timesteps=1490000, episode_reward=362.53 +/- 0.00
Episode length: 450.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 450      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 1490000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 8.28     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 14.3     |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2741589  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 546      |
|    ep_rew_mean     | 441      |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 126      |
|    time_elapsed    | 11798    |
|    total_timesteps | 1491925  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 7        |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 10.2     |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2741592  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 536      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 126      |
|    time_elapsed    | 11812    |
|    total_timesteps | 1493788  |
| train/             |          |
|    actor_loss      | -46.5    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 10.3     |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2741596  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 538      |
|    ep_rew_mean     | 436      |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 126      |
|    time_elapsed    | 11826    |
|    total_timesteps | 1495929  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 10.4     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741600  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 539      |
|    ep_rew_mean     | 436      |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 126      |
|    time_elapsed    | 11840    |
|    total_timesteps | 1497717  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 7.34     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741604  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 531      |
|    ep_rew_mean     | 430      |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 126      |
|    time_elapsed    | 11854    |
|    total_timesteps | 1499516  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 15.3     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741608  |
---------------------------------
Eval num_timesteps=1500000, episode_reward=308.83 +/- 0.00
Episode length: 381.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 381      |
|    mean_reward     | 309      |
| time/              |          |
|    total_timesteps | 1500000  |
| train/             |          |
|    actor_loss      | -49.3    |
|    critic_loss     | 3.76     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 8.65     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741609  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 533      |
|    ep_rew_mean     | 432      |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 126      |
|    time_elapsed    | 11889    |
|    total_timesteps | 1502265  |
| train/             |          |
|    actor_loss      | -48.3    |
|    critic_loss     | 4.46     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 7.66     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741612  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 537      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 126      |
|    time_elapsed    | 11904    |
|    total_timesteps | 1505002  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 12.8     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2741616  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 542      |
|    ep_rew_mean     | 439      |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 126      |
|    time_elapsed    | 11919    |
|    total_timesteps | 1507826  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 6.87     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 12.8     |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2741620  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 539      |
|    ep_rew_mean     | 436      |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 126      |
|    time_elapsed    | 11933    |
|    total_timesteps | 1509548  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 13.3     |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2741624  |
---------------------------------
Eval num_timesteps=1510000, episode_reward=363.53 +/- 0.00
Episode length: 452.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 452      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 1510000  |
| train/             |          |
|    actor_loss      | -45.6    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 18       |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2741625  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 538      |
|    ep_rew_mean     | 435      |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 126      |
|    time_elapsed    | 11968    |
|    total_timesteps | 1511864  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 5.44     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 6.5      |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2741628  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 536      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 126      |
|    time_elapsed    | 11983    |
|    total_timesteps | 1513750  |
| train/             |          |
|    actor_loss      | -42.3    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 14.5     |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2741632  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 533      |
|    ep_rew_mean     | 431      |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 126      |
|    time_elapsed    | 11997    |
|    total_timesteps | 1515593  |
| train/             |          |
|    actor_loss      | -47.3    |
|    critic_loss     | 7.32     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 11.7     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2741636  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 537      |
|    ep_rew_mean     | 435      |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 126      |
|    time_elapsed    | 12012    |
|    total_timesteps | 1518047  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 5.53     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2741640  |
---------------------------------
Eval num_timesteps=1520000, episode_reward=307.92 +/- 0.00
Episode length: 383.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | 308      |
| time/              |          |
|    total_timesteps | 1520000  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 8.97     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2741644  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 526      |
|    ep_rew_mean     | 426      |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 126      |
|    time_elapsed    | 12048    |
|    total_timesteps | 1520451  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 521      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 126      |
|    time_elapsed    | 12061    |
|    total_timesteps | 1522165  |
| train/             |          |
|    actor_loss      | -46.7    |
|    critic_loss     | 7.48     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 9.75     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2741648  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 521      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 126      |
|    time_elapsed    | 12075    |
|    total_timesteps | 1523975  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 8.02     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2741652  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 516      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 126      |
|    time_elapsed    | 12090    |
|    total_timesteps | 1526148  |
| train/             |          |
|    actor_loss      | -47.2    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 10.1     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2741656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 510      |
|    ep_rew_mean     | 414      |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 126      |
|    time_elapsed    | 12104    |
|    total_timesteps | 1527933  |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 12.1     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2741660  |
---------------------------------
Eval num_timesteps=1530000, episode_reward=305.25 +/- 0.00
Episode length: 375.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 375      |
|    mean_reward     | 305      |
| time/              |          |
|    total_timesteps | 1530000  |
| train/             |          |
|    actor_loss      | -44.5    |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 13.9     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2741664  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 507      |
|    ep_rew_mean     | 410      |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 126      |
|    time_elapsed    | 12139    |
|    total_timesteps | 1530452  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 505      |
|    ep_rew_mean     | 409      |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 126      |
|    time_elapsed    | 12154    |
|    total_timesteps | 1532337  |
| train/             |          |
|    actor_loss      | -48.1    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 10.5     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2741668  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 510      |
|    ep_rew_mean     | 413      |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 126      |
|    time_elapsed    | 12168    |
|    total_timesteps | 1534712  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 7.37     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 12.4     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2741672  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 511      |
|    ep_rew_mean     | 414      |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 126      |
|    time_elapsed    | 12183    |
|    total_timesteps | 1537289  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2741676  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 513      |
|    ep_rew_mean     | 415      |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 126      |
|    time_elapsed    | 12198    |
|    total_timesteps | 1539267  |
| train/             |          |
|    actor_loss      | -42.7    |
|    critic_loss     | 6.06     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 12.1     |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2741680  |
---------------------------------
Eval num_timesteps=1540000, episode_reward=369.12 +/- 0.00
Episode length: 458.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 458      |
|    mean_reward     | 369      |
| time/              |          |
|    total_timesteps | 1540000  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2741681  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 520      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 126      |
|    time_elapsed    | 12236    |
|    total_timesteps | 1543128  |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 9.51     |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2741684  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 519      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 126      |
|    time_elapsed    | 12250    |
|    total_timesteps | 1544981  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 11.6     |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2741688  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 525      |
|    ep_rew_mean     | 424      |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 126      |
|    time_elapsed    | 12265    |
|    total_timesteps | 1547476  |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 7.01     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 8.22     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2741692  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 126      |
|    time_elapsed    | 12280    |
|    total_timesteps | 1549644  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 8.92     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2741696  |
---------------------------------
Eval num_timesteps=1550000, episode_reward=367.98 +/- 0.00
Episode length: 456.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 456      |
|    mean_reward     | 368      |
| time/              |          |
|    total_timesteps | 1550000  |
| train/             |          |
|    actor_loss      | -48.1    |
|    critic_loss     | 5.07     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 7.92     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2741697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 525      |
|    ep_rew_mean     | 424      |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 126      |
|    time_elapsed    | 12315    |
|    total_timesteps | 1551852  |
| train/             |          |
|    actor_loss      | -44      |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 15.1     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2741700  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 532      |
|    ep_rew_mean     | 430      |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 126      |
|    time_elapsed    | 12330    |
|    total_timesteps | 1554341  |
| train/             |          |
|    actor_loss      | -45.8    |
|    critic_loss     | 6.86     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 11.3     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2741704  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 532      |
|    ep_rew_mean     | 430      |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 126      |
|    time_elapsed    | 12344    |
|    total_timesteps | 1556151  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 5.24     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 11.4     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2741708  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 532      |
|    ep_rew_mean     | 429      |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 126      |
|    time_elapsed    | 12359    |
|    total_timesteps | 1558382  |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 13       |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2741712  |
---------------------------------
Eval num_timesteps=1560000, episode_reward=365.65 +/- 0.00
Episode length: 455.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 366      |
| time/              |          |
|    total_timesteps | 1560000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 14.8     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2741716  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 523      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 125      |
|    time_elapsed    | 12393    |
|    total_timesteps | 1560457  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 526      |
|    ep_rew_mean     | 425      |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 125      |
|    time_elapsed    | 12410    |
|    total_timesteps | 1563627  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 5.35     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 11.9     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2741720  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 126      |
|    time_elapsed    | 12424    |
|    total_timesteps | 1565522  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 9.57     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741724  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 126      |
|    time_elapsed    | 12438    |
|    total_timesteps | 1567357  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 7.79     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741728  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 527      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 126      |
|    time_elapsed    | 12452    |
|    total_timesteps | 1569226  |
| train/             |          |
|    actor_loss      | -45.9    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 7        |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741732  |
---------------------------------
Eval num_timesteps=1570000, episode_reward=307.34 +/- 0.00
Episode length: 373.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 373      |
|    mean_reward     | 307      |
| time/              |          |
|    total_timesteps | 1570000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 9.73     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741734  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 526      |
|    ep_rew_mean     | 426      |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 125      |
|    time_elapsed    | 12485    |
|    total_timesteps | 1571289  |
| train/             |          |
|    actor_loss      | -46.9    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 5.44     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741736  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 520      |
|    ep_rew_mean     | 421      |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 125      |
|    time_elapsed    | 12499    |
|    total_timesteps | 1573123  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 11.2     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741740  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 524      |
|    ep_rew_mean     | 424      |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 125      |
|    time_elapsed    | 12514    |
|    total_timesteps | 1575202  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 3.57     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 8.9      |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2741744  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 523      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 125      |
|    time_elapsed    | 12528    |
|    total_timesteps | 1576863  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 5.07     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 9.11     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2741748  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 523      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 125      |
|    time_elapsed    | 12542    |
|    total_timesteps | 1578626  |
| train/             |          |
|    actor_loss      | -44.5    |
|    critic_loss     | 5.56     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 6.81     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2741752  |
---------------------------------
Eval num_timesteps=1580000, episode_reward=308.35 +/- 0.00
Episode length: 380.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | 308      |
| time/              |          |
|    total_timesteps | 1580000  |
| train/             |          |
|    actor_loss      | -44      |
|    critic_loss     | 4.67     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 8.07     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2741756  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 519      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 1960     |
|    fps             | 125      |
|    time_elapsed    | 12576    |
|    total_timesteps | 1580449  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 518      |
|    ep_rew_mean     | 419      |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 125      |
|    time_elapsed    | 12589    |
|    total_timesteps | 1582130  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 5.93     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2741760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 518      |
|    ep_rew_mean     | 419      |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 125      |
|    time_elapsed    | 12603    |
|    total_timesteps | 1583920  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 7.61     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2741764  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 521      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 125      |
|    time_elapsed    | 12618    |
|    total_timesteps | 1586144  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 11.8     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 6.92     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741768  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 514      |
|    ep_rew_mean     | 416      |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 125      |
|    time_elapsed    | 12632    |
|    total_timesteps | 1587805  |
| train/             |          |
|    actor_loss      | -47.6    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 7.53     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741772  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 508      |
|    ep_rew_mean     | 411      |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 125      |
|    time_elapsed    | 12646    |
|    total_timesteps | 1589733  |
| train/             |          |
|    actor_loss      | -44.7    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 9.18     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741776  |
---------------------------------
Eval num_timesteps=1590000, episode_reward=304.42 +/- 0.00
Episode length: 366.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 366      |
|    mean_reward     | 304      |
| time/              |          |
|    total_timesteps | 1590000  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 8.77     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.85     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741777  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 505      |
|    ep_rew_mean     | 409      |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 125      |
|    time_elapsed    | 12680    |
|    total_timesteps | 1591749  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 10.2     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741780  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 399      |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 125      |
|    time_elapsed    | 12694    |
|    total_timesteps | 1593582  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 5.84     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741784  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 491      |
|    ep_rew_mean     | 398      |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 125      |
|    time_elapsed    | 12708    |
|    total_timesteps | 1595242  |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 10.6     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2741788  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 391      |
| time/              |          |
|    episodes        | 1996     |
|    fps             | 125      |
|    time_elapsed    | 12722    |
|    total_timesteps | 1596885  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 4.85     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741792  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 387      |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 125      |
|    time_elapsed    | 12736    |
|    total_timesteps | 1598476  |
| train/             |          |
|    actor_loss      | -44.5    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.95     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741796  |
---------------------------------
Eval num_timesteps=1600000, episode_reward=299.72 +/- 0.00
Episode length: 364.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 364      |
|    mean_reward     | 300      |
| time/              |          |
|    total_timesteps | 1600000  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 7.08     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741800  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 385      |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 125      |
|    time_elapsed    | 12770    |
|    total_timesteps | 1600384  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 379      |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 125      |
|    time_elapsed    | 12784    |
|    total_timesteps | 1602131  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 11       |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741804  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 125      |
|    time_elapsed    | 12798    |
|    total_timesteps | 1603707  |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741808  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 125      |
|    time_elapsed    | 12812    |
|    total_timesteps | 1605445  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 5.66     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2741812  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 125      |
|    time_elapsed    | 12826    |
|    total_timesteps | 1606990  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 7.9      |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741816  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 125      |
|    time_elapsed    | 12840    |
|    total_timesteps | 1608636  |
| train/             |          |
|    actor_loss      | -46.5    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.21     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741820  |
---------------------------------
Eval num_timesteps=1610000, episode_reward=302.09 +/- 0.00
Episode length: 368.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 368      |
|    mean_reward     | 302      |
| time/              |          |
|    total_timesteps | 1610000  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 5.1      |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.2      |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741823  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 440      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 125      |
|    time_elapsed    | 12874    |
|    total_timesteps | 1610825  |
| train/             |          |
|    actor_loss      | -44      |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.61     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741824  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    episodes        | 2032     |
|    fps             | 125      |
|    time_elapsed    | 12887    |
|    total_timesteps | 1612303  |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 10.6     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741828  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 2036     |
|    fps             | 125      |
|    time_elapsed    | 12901    |
|    total_timesteps | 1613888  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 5.05     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 8.28     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2741832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2040     |
|    fps             | 125      |
|    time_elapsed    | 12915    |
|    total_timesteps | 1615478  |
| train/             |          |
|    actor_loss      | -46.5    |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 7.71     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741836  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2044     |
|    fps             | 125      |
|    time_elapsed    | 12929    |
|    total_timesteps | 1617295  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 4        |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 8.13     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741840  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 125      |
|    time_elapsed    | 12943    |
|    total_timesteps | 1618865  |
| train/             |          |
|    actor_loss      | -41.8    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 10.1     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741844  |
---------------------------------
Eval num_timesteps=1620000, episode_reward=312.17 +/- 0.00
Episode length: 380.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 380      |
|    mean_reward     | 312      |
| time/              |          |
|    total_timesteps | 1620000  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 5.1      |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 9.76     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741847  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 428      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 124      |
|    time_elapsed    | 12977    |
|    total_timesteps | 1620835  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 12.8     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 5.72     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741848  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 124      |
|    time_elapsed    | 12991    |
|    total_timesteps | 1622557  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 7.79     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741852  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 124      |
|    time_elapsed    | 13005    |
|    total_timesteps | 1624229  |
| train/             |          |
|    actor_loss      | -44.7    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 5.84     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2741856  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 124      |
|    time_elapsed    | 13019    |
|    total_timesteps | 1626013  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 7.14     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 7.9      |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741860  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 124      |
|    time_elapsed    | 13033    |
|    total_timesteps | 1627778  |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 4.36     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 4.27     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741864  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 2072     |
|    fps             | 124      |
|    time_elapsed    | 13047    |
|    total_timesteps | 1629592  |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 8.85     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 4.74     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741868  |
---------------------------------
Eval num_timesteps=1630000, episode_reward=300.02 +/- 0.00
Episode length: 364.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 364      |
|    mean_reward     | 300      |
| time/              |          |
|    total_timesteps | 1630000  |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 4.51     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 11.7     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741870  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 423      |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 2076     |
|    fps             | 124      |
|    time_elapsed    | 13080    |
|    total_timesteps | 1631293  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 9.3      |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741872  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 124      |
|    time_elapsed    | 13094    |
|    total_timesteps | 1632996  |
| train/             |          |
|    actor_loss      | -42.6    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 5.7      |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741876  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 124      |
|    time_elapsed    | 13108    |
|    total_timesteps | 1634725  |
| train/             |          |
|    actor_loss      | -45.6    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 4.83     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2741880  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 2088     |
|    fps             | 124      |
|    time_elapsed    | 13122    |
|    total_timesteps | 1636444  |
| train/             |          |
|    actor_loss      | -44.7    |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 6.19     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741884  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 342      |
| time/              |          |
|    episodes        | 2092     |
|    fps             | 124      |
|    time_elapsed    | 13136    |
|    total_timesteps | 1638032  |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 8.61     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741888  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 124      |
|    time_elapsed    | 13149    |
|    total_timesteps | 1639736  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 8.31     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 10.5     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741892  |
---------------------------------
Eval num_timesteps=1640000, episode_reward=306.69 +/- 0.00
Episode length: 368.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 368      |
|    mean_reward     | 307      |
| time/              |          |
|    total_timesteps | 1640000  |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 10.6     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741893  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 420      |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 2100     |
|    fps             | 124      |
|    time_elapsed    | 13183    |
|    total_timesteps | 1641692  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 6.45     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 10       |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741896  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2104     |
|    fps             | 124      |
|    time_elapsed    | 13197    |
|    total_timesteps | 1643819  |
| train/             |          |
|    actor_loss      | -44.5    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 6.2      |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2741900  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2108     |
|    fps             | 124      |
|    time_elapsed    | 13212    |
|    total_timesteps | 1645583  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 8.89     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741904  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2112     |
|    fps             | 124      |
|    time_elapsed    | 13226    |
|    total_timesteps | 1647298  |
| train/             |          |
|    actor_loss      | -45.5    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 8.33     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741908  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 124      |
|    time_elapsed    | 13239    |
|    total_timesteps | 1648811  |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 7.46     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741912  |
---------------------------------
Eval num_timesteps=1650000, episode_reward=320.24 +/- 0.00
Episode length: 389.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | 320      |
| time/              |          |
|    total_timesteps | 1650000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 9.43     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741915  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 425      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2120     |
|    fps             | 124      |
|    time_elapsed    | 13273    |
|    total_timesteps | 1650769  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 8.68     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 350      |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 124      |
|    time_elapsed    | 13288    |
|    total_timesteps | 1652659  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 5.7      |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741920  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 2128     |
|    fps             | 124      |
|    time_elapsed    | 13302    |
|    total_timesteps | 1654320  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 10.2     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2741924  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 427      |
|    ep_rew_mean     | 349      |
| time/              |          |
|    episodes        | 2132     |
|    fps             | 124      |
|    time_elapsed    | 13315    |
|    total_timesteps | 1655933  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 10.5     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741928  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 428      |
|    ep_rew_mean     | 350      |
| time/              |          |
|    episodes        | 2136     |
|    fps             | 124      |
|    time_elapsed    | 13329    |
|    total_timesteps | 1657624  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 5.03     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 8.71     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741932  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 355      |
| time/              |          |
|    episodes        | 2140     |
|    fps             | 124      |
|    time_elapsed    | 13344    |
|    total_timesteps | 1659813  |
| train/             |          |
|    actor_loss      | -44      |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 6.06     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741936  |
---------------------------------
Eval num_timesteps=1660000, episode_reward=292.81 +/- 0.00
Episode length: 358.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 358      |
|    mean_reward     | 293      |
| time/              |          |
|    total_timesteps | 1660000  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 8.91     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741937  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 2144     |
|    fps             | 124      |
|    time_elapsed    | 13378    |
|    total_timesteps | 1661737  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 9.53     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741940  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 355      |
| time/              |          |
|    episodes        | 2148     |
|    fps             | 124      |
|    time_elapsed    | 13392    |
|    total_timesteps | 1663388  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 9.03     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741944  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2152     |
|    fps             | 124      |
|    time_elapsed    | 13406    |
|    total_timesteps | 1664852  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 7.48     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 9.03     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2741948  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 2156     |
|    fps             | 124      |
|    time_elapsed    | 13420    |
|    total_timesteps | 1666525  |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 6.03     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741952  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 2160     |
|    fps             | 124      |
|    time_elapsed    | 13434    |
|    total_timesteps | 1668161  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 3.37     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 3.45     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741956  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 124      |
|    time_elapsed    | 13448    |
|    total_timesteps | 1669982  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 6.85     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741960  |
---------------------------------
Eval num_timesteps=1670000, episode_reward=312.72 +/- 0.00
Episode length: 378.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 378      |
|    mean_reward     | 313      |
| time/              |          |
|    total_timesteps | 1670000  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 5        |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 7.63     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741961  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 2168     |
|    fps             | 123      |
|    time_elapsed    | 13482    |
|    total_timesteps | 1671746  |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 4.15     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 6.34     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741964  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 2172     |
|    fps             | 123      |
|    time_elapsed    | 13496    |
|    total_timesteps | 1673516  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 7.84     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741968  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2176     |
|    fps             | 123      |
|    time_elapsed    | 13510    |
|    total_timesteps | 1675251  |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 8.73     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2741972  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 2180     |
|    fps             | 124      |
|    time_elapsed    | 13524    |
|    total_timesteps | 1677018  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 4.12     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741976  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2184     |
|    fps             | 123      |
|    time_elapsed    | 13538    |
|    total_timesteps | 1678713  |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 7.68     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741980  |
---------------------------------
Eval num_timesteps=1680000, episode_reward=319.48 +/- 0.00
Episode length: 386.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 319      |
| time/              |          |
|    total_timesteps | 1680000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 8.26     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 5.08     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741983  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2188     |
|    fps             | 123      |
|    time_elapsed    | 13572    |
|    total_timesteps | 1680847  |
| train/             |          |
|    actor_loss      | -38.4    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 11.8     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741984  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 355      |
| time/              |          |
|    episodes        | 2192     |
|    fps             | 123      |
|    time_elapsed    | 13586    |
|    total_timesteps | 1682593  |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 7.28     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 9.6      |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    episodes        | 2196     |
|    fps             | 123      |
|    time_elapsed    | 13600    |
|    total_timesteps | 1684430  |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.24     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2741992  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 434      |
|    ep_rew_mean     | 355      |
| time/              |          |
|    episodes        | 2200     |
|    fps             | 123      |
|    time_elapsed    | 13614    |
|    total_timesteps | 1686081  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 4.49     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 2.8      |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2741996  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2204     |
|    fps             | 123      |
|    time_elapsed    | 13628    |
|    total_timesteps | 1687948  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742000  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 2208     |
|    fps             | 123      |
|    time_elapsed    | 13642    |
|    total_timesteps | 1689769  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 5.72     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 3.96     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742004  |
---------------------------------
Eval num_timesteps=1690000, episode_reward=322.30 +/- 0.00
Episode length: 389.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 389      |
|    mean_reward     | 322      |
| time/              |          |
|    total_timesteps | 1690000  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742005  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 354      |
| time/              |          |
|    episodes        | 2212     |
|    fps             | 123      |
|    time_elapsed    | 13676    |
|    total_timesteps | 1691716  |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 3.88     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742008  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    episodes        | 2216     |
|    fps             | 123      |
|    time_elapsed    | 13690    |
|    total_timesteps | 1693546  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742012  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 357      |
| time/              |          |
|    episodes        | 2220     |
|    fps             | 123      |
|    time_elapsed    | 13704    |
|    total_timesteps | 1695225  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.19     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2742016  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    episodes        | 2224     |
|    fps             | 123      |
|    time_elapsed    | 13717    |
|    total_timesteps | 1696958  |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 5.2      |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742020  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 357      |
| time/              |          |
|    episodes        | 2228     |
|    fps             | 123      |
|    time_elapsed    | 13731    |
|    total_timesteps | 1698761  |
| train/             |          |
|    actor_loss      | -45.7    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 2.9      |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742024  |
---------------------------------
Eval num_timesteps=1700000, episode_reward=318.93 +/- 0.00
Episode length: 383.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 383      |
|    mean_reward     | 319      |
| time/              |          |
|    total_timesteps | 1700000  |
| train/             |          |
|    actor_loss      | -38.7    |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 10       |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742027  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 358      |
| time/              |          |
|    episodes        | 2232     |
|    fps             | 123      |
|    time_elapsed    | 13766    |
|    total_timesteps | 1700902  |
| train/             |          |
|    actor_loss      | -42.7    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.55     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742028  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 439      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 2236     |
|    fps             | 123      |
|    time_elapsed    | 13780    |
|    total_timesteps | 1702711  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.63     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742032  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 357      |
| time/              |          |
|    episodes        | 2240     |
|    fps             | 123      |
|    time_elapsed    | 13794    |
|    total_timesteps | 1704587  |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.47     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2742036  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 2244     |
|    fps             | 123      |
|    time_elapsed    | 13810    |
|    total_timesteps | 1707746  |
| train/             |          |
|    actor_loss      | -39.8    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 13.5     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2742040  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 2248     |
|    fps             | 123      |
|    time_elapsed    | 13824    |
|    total_timesteps | 1709485  |
| train/             |          |
|    actor_loss      | -42.7    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 7.38     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2742044  |
---------------------------------
Eval num_timesteps=1710000, episode_reward=377.87 +/- 0.00
Episode length: 455.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 455      |
|    mean_reward     | 378      |
| time/              |          |
|    total_timesteps | 1710000  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 9.41     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2742046  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 2252     |
|    fps             | 123      |
|    time_elapsed    | 13861    |
|    total_timesteps | 1711990  |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 8.78     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2742048  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 462      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    episodes        | 2256     |
|    fps             | 123      |
|    time_elapsed    | 13875    |
|    total_timesteps | 1713807  |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 8.11     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2742052  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 461      |
|    ep_rew_mean     | 378      |
| time/              |          |
|    episodes        | 2260     |
|    fps             | 123      |
|    time_elapsed    | 13889    |
|    total_timesteps | 1715400  |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 5.64     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742056  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 458      |
|    ep_rew_mean     | 376      |
| time/              |          |
|    episodes        | 2264     |
|    fps             | 123      |
|    time_elapsed    | 13903    |
|    total_timesteps | 1716936  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 5.82     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742060  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 2268     |
|    fps             | 123      |
|    time_elapsed    | 13917    |
|    total_timesteps | 1718514  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 5.5      |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742064  |
---------------------------------
Eval num_timesteps=1720000, episode_reward=294.80 +/- 0.00
Episode length: 361.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 361      |
|    mean_reward     | 295      |
| time/              |          |
|    total_timesteps | 1720000  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 8.08     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 9.37     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742068  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 457      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 2272     |
|    fps             | 123      |
|    time_elapsed    | 13950    |
|    total_timesteps | 1720463  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 375      |
| time/              |          |
|    episodes        | 2276     |
|    fps             | 123      |
|    time_elapsed    | 13964    |
|    total_timesteps | 1722345  |
| train/             |          |
|    actor_loss      | -41.9    |
|    critic_loss     | 5.71     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 8.38     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742072  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 2280     |
|    fps             | 123      |
|    time_elapsed    | 13978    |
|    total_timesteps | 1723875  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 6.61     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2742076  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 2284     |
|    fps             | 123      |
|    time_elapsed    | 13992    |
|    total_timesteps | 1725551  |
| train/             |          |
|    actor_loss      | -38.1    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 6.3      |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742080  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 454      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2288     |
|    fps             | 123      |
|    time_elapsed    | 14006    |
|    total_timesteps | 1727072  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 6.77     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 5.64     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742084  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2292     |
|    fps             | 123      |
|    time_elapsed    | 14020    |
|    total_timesteps | 1728769  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 8.92     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742088  |
---------------------------------
Eval num_timesteps=1730000, episode_reward=377.00 +/- 0.00
Episode length: 454.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 454      |
|    mean_reward     | 377      |
| time/              |          |
|    total_timesteps | 1730000  |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 4.36     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 5.4      |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742091  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 2296     |
|    fps             | 123      |
|    time_elapsed    | 14055    |
|    total_timesteps | 1730912  |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 6.12     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742092  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 454      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2300     |
|    fps             | 123      |
|    time_elapsed    | 14069    |
|    total_timesteps | 1732683  |
| train/             |          |
|    actor_loss      | -40.4    |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 6.73     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742096  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2304     |
|    fps             | 123      |
|    time_elapsed    | 14083    |
|    total_timesteps | 1734362  |
| train/             |          |
|    actor_loss      | -41      |
|    critic_loss     | 4        |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 4.67     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2742100  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2308     |
|    fps             | 123      |
|    time_elapsed    | 14097    |
|    total_timesteps | 1736183  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 4.15     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 7.71     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742104  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 2312     |
|    fps             | 123      |
|    time_elapsed    | 14112    |
|    total_timesteps | 1738025  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 0.545    |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742108  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2316     |
|    fps             | 123      |
|    time_elapsed    | 14126    |
|    total_timesteps | 1739659  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742112  |
---------------------------------
Eval num_timesteps=1740000, episode_reward=380.39 +/- 0.00
Episode length: 457.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 457      |
|    mean_reward     | 380      |
| time/              |          |
|    total_timesteps | 1740000  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 7.16     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742113  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2320     |
|    fps             | 122      |
|    time_elapsed    | 14160    |
|    total_timesteps | 1741697  |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 4.01     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 4.98     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742116  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2324     |
|    fps             | 122      |
|    time_elapsed    | 14174    |
|    total_timesteps | 1743462  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 4.66     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2328     |
|    fps             | 122      |
|    time_elapsed    | 14189    |
|    total_timesteps | 1745225  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 6.02     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2742124  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2332     |
|    fps             | 122      |
|    time_elapsed    | 14202    |
|    total_timesteps | 1746966  |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 4.46     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2742128  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 2336     |
|    fps             | 123      |
|    time_elapsed    | 14216    |
|    total_timesteps | 1748746  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 3.63     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2742132  |
---------------------------------
Eval num_timesteps=1750000, episode_reward=321.43 +/- 0.00
Episode length: 388.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 388      |
|    mean_reward     | 321      |
| time/              |          |
|    total_timesteps | 1750000  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2742136  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 2340     |
|    fps             | 122      |
|    time_elapsed    | 14250    |
|    total_timesteps | 1750447  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 435      |
|    ep_rew_mean     | 357      |
| time/              |          |
|    episodes        | 2344     |
|    fps             | 122      |
|    time_elapsed    | 14265    |
|    total_timesteps | 1752209  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 9.14     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 3.27     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2742140  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 358      |
| time/              |          |
|    episodes        | 2348     |
|    fps             | 122      |
|    time_elapsed    | 14279    |
|    total_timesteps | 1754047  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 3.82     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 2.74     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2742144  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 353      |
| time/              |          |
|    episodes        | 2352     |
|    fps             | 122      |
|    time_elapsed    | 14293    |
|    total_timesteps | 1755816  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 4.7      |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 5.11     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742148  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 432      |
|    ep_rew_mean     | 355      |
| time/              |          |
|    episodes        | 2356     |
|    fps             | 122      |
|    time_elapsed    | 14307    |
|    total_timesteps | 1757864  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 5.32     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742152  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 356      |
| time/              |          |
|    episodes        | 2360     |
|    fps             | 122      |
|    time_elapsed    | 14322    |
|    total_timesteps | 1759565  |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 6.42     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 7.62     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742156  |
---------------------------------
Eval num_timesteps=1760000, episode_reward=319.00 +/- 0.00
Episode length: 394.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 394      |
|    mean_reward     | 319      |
| time/              |          |
|    total_timesteps | 1760000  |
| train/             |          |
|    actor_loss      | -46.2    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 4.77     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742157  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 359      |
| time/              |          |
|    episodes        | 2364     |
|    fps             | 122      |
|    time_elapsed    | 14356    |
|    total_timesteps | 1761862  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 5.73     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742160  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 438      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    episodes        | 2368     |
|    fps             | 122      |
|    time_elapsed    | 14370    |
|    total_timesteps | 1763625  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 4.01     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.91     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742164  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 360      |
| time/              |          |
|    episodes        | 2372     |
|    fps             | 122      |
|    time_elapsed    | 14384    |
|    total_timesteps | 1765375  |
| train/             |          |
|    actor_loss      | -44.7    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 4.94     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2742168  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 437      |
|    ep_rew_mean     | 361      |
| time/              |          |
|    episodes        | 2376     |
|    fps             | 122      |
|    time_elapsed    | 14398    |
|    total_timesteps | 1767239  |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 4.64     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 3.69     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742172  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 441      |
|    ep_rew_mean     | 364      |
| time/              |          |
|    episodes        | 2380     |
|    fps             | 122      |
|    time_elapsed    | 14413    |
|    total_timesteps | 1769181  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 7.59     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742176  |
---------------------------------
Eval num_timesteps=1770000, episode_reward=322.77 +/- 0.00
Episode length: 386.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 323      |
| time/              |          |
|    total_timesteps | 1770000  |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 4.89     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742178  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 444      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    episodes        | 2384     |
|    fps             | 122      |
|    time_elapsed    | 14448    |
|    total_timesteps | 1771461  |
| train/             |          |
|    actor_loss      | -41.1    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.04     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742180  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 446      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 2388     |
|    fps             | 122      |
|    time_elapsed    | 14462    |
|    total_timesteps | 1773212  |
| train/             |          |
|    actor_loss      | -39.7    |
|    critic_loss     | 6.04     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.71     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742184  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 447      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 2392     |
|    fps             | 122      |
|    time_elapsed    | 14477    |
|    total_timesteps | 1775011  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -0.433   |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2742188  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2396     |
|    fps             | 122      |
|    time_elapsed    | 14493    |
|    total_timesteps | 1777026  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.9      |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742192  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2400     |
|    fps             | 122      |
|    time_elapsed    | 14509    |
|    total_timesteps | 1778809  |
| train/             |          |
|    actor_loss      | -38.4    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 10.6     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742196  |
---------------------------------
Eval num_timesteps=1780000, episode_reward=412.91 +/- 0.00
Episode length: 499.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 499      |
|    mean_reward     | 413      |
| time/              |          |
|    total_timesteps | 1780000  |
| train/             |          |
|    actor_loss      | -41.4    |
|    critic_loss     | 13.6     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 7.71     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742199  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 451      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2404     |
|    fps             | 122      |
|    time_elapsed    | 14549    |
|    total_timesteps | 1780882  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 4.79     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 1.81     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742200  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 2408     |
|    fps             | 122      |
|    time_elapsed    | 14563    |
|    total_timesteps | 1782574  |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742204  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 371      |
| time/              |          |
|    episodes        | 2412     |
|    fps             | 122      |
|    time_elapsed    | 14578    |
|    total_timesteps | 1784391  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 7.35     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2742208  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 450      |
|    ep_rew_mean     | 372      |
| time/              |          |
|    episodes        | 2416     |
|    fps             | 122      |
|    time_elapsed    | 14592    |
|    total_timesteps | 1786140  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742212  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 2420     |
|    fps             | 122      |
|    time_elapsed    | 14606    |
|    total_timesteps | 1788015  |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 3.01     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742216  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 375      |
| time/              |          |
|    episodes        | 2424     |
|    fps             | 122      |
|    time_elapsed    | 14620    |
|    total_timesteps | 1789906  |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 5.87     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 3.73     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742220  |
---------------------------------
Eval num_timesteps=1790000, episode_reward=321.13 +/- 0.00
Episode length: 386.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 386      |
|    mean_reward     | 321      |
| time/              |          |
|    total_timesteps | 1790000  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 7.45     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742221  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 454      |
|    ep_rew_mean     | 376      |
| time/              |          |
|    episodes        | 2428     |
|    fps             | 122      |
|    time_elapsed    | 14655    |
|    total_timesteps | 1791841  |
| train/             |          |
|    actor_loss      | -45.4    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 1.32     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742224  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 2432     |
|    fps             | 122      |
|    time_elapsed    | 14669    |
|    total_timesteps | 1793746  |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 3.07     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2742228  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 377      |
| time/              |          |
|    episodes        | 2436     |
|    fps             | 122      |
|    time_elapsed    | 14683    |
|    total_timesteps | 1795551  |
| train/             |          |
|    actor_loss      | -44      |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 5.14     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742232  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 379      |
| time/              |          |
|    episodes        | 2440     |
|    fps             | 122      |
|    time_elapsed    | 14697    |
|    total_timesteps | 1797498  |
| train/             |          |
|    actor_loss      | -40.8    |
|    critic_loss     | 12.8     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 9.02     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742236  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 380      |
| time/              |          |
|    episodes        | 2444     |
|    fps             | 122      |
|    time_elapsed    | 14712    |
|    total_timesteps | 1799386  |
| train/             |          |
|    actor_loss      | -40.5    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 4.92     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742240  |
---------------------------------
Eval num_timesteps=1800000, episode_reward=313.08 +/- 0.00
Episode length: 381.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 381      |
|    mean_reward     | 313      |
| time/              |          |
|    total_timesteps | 1800000  |
| train/             |          |
|    actor_loss      | -41.1    |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 0.323    |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742242  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 380      |
| time/              |          |
|    episodes        | 2448     |
|    fps             | 122      |
|    time_elapsed    | 14746    |
|    total_timesteps | 1801371  |
| train/             |          |
|    actor_loss      | -39.3    |
|    critic_loss     | 10       |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.82     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742244  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 459      |
|    ep_rew_mean     | 380      |
| time/              |          |
|    episodes        | 2452     |
|    fps             | 122      |
|    time_elapsed    | 14760    |
|    total_timesteps | 1803107  |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 3.76     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2742248  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 383      |
| time/              |          |
|    episodes        | 2456     |
|    fps             | 122      |
|    time_elapsed    | 14775    |
|    total_timesteps | 1805478  |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 6.71     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742252  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 384      |
| time/              |          |
|    episodes        | 2460     |
|    fps             | 122      |
|    time_elapsed    | 14789    |
|    total_timesteps | 1807342  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 5.17     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 7.78     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742256  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 466      |
|    ep_rew_mean     | 386      |
| time/              |          |
|    episodes        | 2464     |
|    fps             | 122      |
|    time_elapsed    | 14804    |
|    total_timesteps | 1809415  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 10.1     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742260  |
---------------------------------
Eval num_timesteps=1810000, episode_reward=324.72 +/- 0.00
Episode length: 391.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 391      |
|    mean_reward     | 325      |
| time/              |          |
|    total_timesteps | 1810000  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 11.7     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 7.47     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742262  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 388      |
| time/              |          |
|    episodes        | 2468     |
|    fps             | 122      |
|    time_elapsed    | 14839    |
|    total_timesteps | 1811475  |
| train/             |          |
|    actor_loss      | -40.9    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.79     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742264  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 388      |
| time/              |          |
|    episodes        | 2472     |
|    fps             | 122      |
|    time_elapsed    | 14853    |
|    total_timesteps | 1813250  |
| train/             |          |
|    actor_loss      | -44.5    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 5.28     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742268  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 387      |
| time/              |          |
|    episodes        | 2476     |
|    fps             | 122      |
|    time_elapsed    | 14867    |
|    total_timesteps | 1814956  |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -0.829   |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2742272  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 386      |
| time/              |          |
|    episodes        | 2480     |
|    fps             | 122      |
|    time_elapsed    | 14881    |
|    total_timesteps | 1816860  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 0.203    |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2742276  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 463      |
|    ep_rew_mean     | 383      |
| time/              |          |
|    episodes        | 2484     |
|    fps             | 122      |
|    time_elapsed    | 14895    |
|    total_timesteps | 1818437  |
| train/             |          |
|    actor_loss      | -46      |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2742280  |
---------------------------------
Eval num_timesteps=1820000, episode_reward=317.32 +/- 0.00
Episode length: 379.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 379      |
|    mean_reward     | 317      |
| time/              |          |
|    total_timesteps | 1820000  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 2.62     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2742284  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 384      |
| time/              |          |
|    episodes        | 2488     |
|    fps             | 121      |
|    time_elapsed    | 14929    |
|    total_timesteps | 1820492  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 465      |
|    ep_rew_mean     | 385      |
| time/              |          |
|    episodes        | 2492     |
|    fps             | 121      |
|    time_elapsed    | 14943    |
|    total_timesteps | 1822346  |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.32     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2742288  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 388      |
| time/              |          |
|    episodes        | 2496     |
|    fps             | 121      |
|    time_elapsed    | 14958    |
|    total_timesteps | 1824716  |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 6.69     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 5.37     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2742292  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 389      |
| time/              |          |
|    episodes        | 2500     |
|    fps             | 121      |
|    time_elapsed    | 14972    |
|    total_timesteps | 1826663  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 474      |
|    ep_rew_mean     | 392      |
| time/              |          |
|    episodes        | 2504     |
|    fps             | 122      |
|    time_elapsed    | 14987    |
|    total_timesteps | 1828749  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 6.72     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 4.94     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742300  |
---------------------------------
Eval num_timesteps=1830000, episode_reward=412.24 +/- 0.00
Episode length: 499.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 499      |
|    mean_reward     | 412      |
| time/              |          |
|    total_timesteps | 1830000  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 2.81     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742302  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    episodes        | 2508     |
|    fps             | 121      |
|    time_elapsed    | 15023    |
|    total_timesteps | 1831553  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 6.5      |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742304  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    episodes        | 2512     |
|    fps             | 121      |
|    time_elapsed    | 15038    |
|    total_timesteps | 1833406  |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 3.45     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 7.4      |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742308  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    episodes        | 2516     |
|    fps             | 121      |
|    time_elapsed    | 15051    |
|    total_timesteps | 1835063  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 6.05     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 4.74     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2742312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 400      |
| time/              |          |
|    episodes        | 2520     |
|    fps             | 121      |
|    time_elapsed    | 15066    |
|    total_timesteps | 1836964  |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 5.04     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 399      |
| time/              |          |
|    episodes        | 2524     |
|    fps             | 121      |
|    time_elapsed    | 15080    |
|    total_timesteps | 1838856  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 5.95     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742320  |
---------------------------------
Eval num_timesteps=1840000, episode_reward=403.12 +/- 0.00
Episode length: 495.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | 403      |
| time/              |          |
|    total_timesteps | 1840000  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 8.57     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 6.09     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742323  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 483      |
|    ep_rew_mean     | 399      |
| time/              |          |
|    episodes        | 2528     |
|    fps             | 121      |
|    time_elapsed    | 15114    |
|    total_timesteps | 1840821  |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 6.39     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 6.76     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742324  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 486      |
|    ep_rew_mean     | 401      |
| time/              |          |
|    episodes        | 2532     |
|    fps             | 121      |
|    time_elapsed    | 15129    |
|    total_timesteps | 1842993  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 7        |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.45     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742328  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 402      |
| time/              |          |
|    episodes        | 2536     |
|    fps             | 121      |
|    time_elapsed    | 15143    |
|    total_timesteps | 1844942  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -0.248   |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2742332  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 487      |
|    ep_rew_mean     | 402      |
| time/              |          |
|    episodes        | 2540     |
|    fps             | 121      |
|    time_elapsed    | 15157    |
|    total_timesteps | 1846853  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.64     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2742336  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 406      |
| time/              |          |
|    episodes        | 2544     |
|    fps             | 121      |
|    time_elapsed    | 15173    |
|    total_timesteps | 1849270  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 2.72     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2742340  |
---------------------------------
Eval num_timesteps=1850000, episode_reward=402.60 +/- 0.00
Episode length: 493.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 493      |
|    mean_reward     | 403      |
| time/              |          |
|    total_timesteps | 1850000  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 4.34     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2742342  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 497      |
|    ep_rew_mean     | 410      |
| time/              |          |
|    episodes        | 2548     |
|    fps             | 121      |
|    time_elapsed    | 15208    |
|    total_timesteps | 1851861  |
| train/             |          |
|    actor_loss      | -39.7    |
|    critic_loss     | 6.05     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2742344  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 421      |
| time/              |          |
|    episodes        | 2552     |
|    fps             | 121      |
|    time_elapsed    | 15225    |
|    total_timesteps | 1855064  |
| train/             |          |
|    actor_loss      | -41.1    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 4.34     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2742348  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 508      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 2556     |
|    fps             | 121      |
|    time_elapsed    | 15239    |
|    total_timesteps | 1857061  |
| train/             |          |
|    actor_loss      | -39.2    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 9.73     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742352  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 509      |
|    ep_rew_mean     | 419      |
| time/              |          |
|    episodes        | 2560     |
|    fps             | 121      |
|    time_elapsed    | 15253    |
|    total_timesteps | 1859054  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.33     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 3.33     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742356  |
---------------------------------
Eval num_timesteps=1860000, episode_reward=422.57 +/- 0.00
Episode length: 507.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 507      |
|    mean_reward     | 423      |
| time/              |          |
|    total_timesteps | 1860000  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 6.25     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742358  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 507      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 2564     |
|    fps             | 121      |
|    time_elapsed    | 15289    |
|    total_timesteps | 1861394  |
| train/             |          |
|    actor_loss      | -38.5    |
|    critic_loss     | 6.53     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | 5.34     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742360  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 509      |
|    ep_rew_mean     | 419      |
| time/              |          |
|    episodes        | 2568     |
|    fps             | 121      |
|    time_elapsed    | 15304    |
|    total_timesteps | 1863497  |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742364  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 510      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 2572     |
|    fps             | 121      |
|    time_elapsed    | 15318    |
|    total_timesteps | 1865394  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 4.74     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 5.2      |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2742368  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 514      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 2576     |
|    fps             | 121      |
|    time_elapsed    | 15333    |
|    total_timesteps | 1867480  |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 5.82     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2742372  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 519      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 2580     |
|    fps             | 121      |
|    time_elapsed    | 15348    |
|    total_timesteps | 1869964  |
| train/             |          |
|    actor_loss      | -45.5    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.44     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2742376  |
---------------------------------
Eval num_timesteps=1870000, episode_reward=298.89 +/- 0.00
Episode length: 358.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 358      |
|    mean_reward     | 299      |
| time/              |          |
|    total_timesteps | 1870000  |
| train/             |          |
|    actor_loss      | -40.9    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 5.52     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2742377  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 522      |
|    ep_rew_mean     | 429      |
| time/              |          |
|    episodes        | 2584     |
|    fps             | 121      |
|    time_elapsed    | 15381    |
|    total_timesteps | 1871883  |
| train/             |          |
|    actor_loss      | -42.8    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 5.23     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2742380  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 524      |
|    ep_rew_mean     | 431      |
| time/              |          |
|    episodes        | 2588     |
|    fps             | 121      |
|    time_elapsed    | 15395    |
|    total_timesteps | 1873935  |
| train/             |          |
|    actor_loss      | -44.3    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 6.8      |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2742384  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 527      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 2592     |
|    fps             | 121      |
|    time_elapsed    | 15410    |
|    total_timesteps | 1876155  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.95     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742388  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 524      |
|    ep_rew_mean     | 431      |
| time/              |          |
|    episodes        | 2596     |
|    fps             | 121      |
|    time_elapsed    | 15424    |
|    total_timesteps | 1878175  |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742392  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 521      |
|    ep_rew_mean     | 429      |
| time/              |          |
|    episodes        | 2600     |
|    fps             | 121      |
|    time_elapsed    | 15439    |
|    total_timesteps | 1879891  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 5.68     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742396  |
---------------------------------
Eval num_timesteps=1880000, episode_reward=371.38 +/- 0.00
Episode length: 445.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 445      |
|    mean_reward     | 371      |
| time/              |          |
|    total_timesteps | 1880000  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 4.46     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 7.02     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742397  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 519      |
|    ep_rew_mean     | 427      |
| time/              |          |
|    episodes        | 2604     |
|    fps             | 121      |
|    time_elapsed    | 15473    |
|    total_timesteps | 1881849  |
| train/             |          |
|    actor_loss      | -41.7    |
|    critic_loss     | 21.8     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 2608     |
|    fps             | 121      |
|    time_elapsed    | 15487    |
|    total_timesteps | 1883806  |
| train/             |          |
|    actor_loss      | -43.1    |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -0.511   |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2742404  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 2612     |
|    fps             | 121      |
|    time_elapsed    | 15502    |
|    total_timesteps | 1885692  |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742408  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 514      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 2616     |
|    fps             | 121      |
|    time_elapsed    | 15516    |
|    total_timesteps | 1887509  |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 3.28     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742412  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 511      |
|    ep_rew_mean     | 421      |
| time/              |          |
|    episodes        | 2620     |
|    fps             | 121      |
|    time_elapsed    | 15530    |
|    total_timesteps | 1889081  |
| train/             |          |
|    actor_loss      | -39.5    |
|    critic_loss     | 5.09     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.9      |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742416  |
---------------------------------
Eval num_timesteps=1890000, episode_reward=293.71 +/- 0.00
Episode length: 350.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 350      |
|    mean_reward     | 294      |
| time/              |          |
|    total_timesteps | 1890000  |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 6.41     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 0.264    |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742418  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 511      |
|    ep_rew_mean     | 421      |
| time/              |          |
|    episodes        | 2624     |
|    fps             | 121      |
|    time_elapsed    | 15565    |
|    total_timesteps | 1891421  |
| train/             |          |
|    actor_loss      | -39      |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742420  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 520      |
|    ep_rew_mean     | 428      |
| time/              |          |
|    episodes        | 2628     |
|    fps             | 121      |
|    time_elapsed    | 15580    |
|    total_timesteps | 1894105  |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2742424  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 515      |
|    ep_rew_mean     | 425      |
| time/              |          |
|    episodes        | 2632     |
|    fps             | 121      |
|    time_elapsed    | 15594    |
|    total_timesteps | 1895826  |
| train/             |          |
|    actor_loss      | -45.3    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 0.876    |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742428  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 2636     |
|    fps             | 121      |
|    time_elapsed    | 15608    |
|    total_timesteps | 1897442  |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 4.07     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.81     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742432  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 509      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 2640     |
|    fps             | 121      |
|    time_elapsed    | 15621    |
|    total_timesteps | 1899045  |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 4.73     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.7      |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742436  |
---------------------------------
Eval num_timesteps=1900000, episode_reward=282.64 +/- 0.00
Episode length: 334.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 334      |
|    mean_reward     | 283      |
| time/              |          |
|    total_timesteps | 1900000  |
| train/             |          |
|    actor_loss      | -38.7    |
|    critic_loss     | 5.85     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.92     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742438  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 502      |
|    ep_rew_mean     | 414      |
| time/              |          |
|    episodes        | 2644     |
|    fps             | 121      |
|    time_elapsed    | 15656    |
|    total_timesteps | 1901180  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 3.65     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742440  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 2648     |
|    fps             | 121      |
|    time_elapsed    | 15672    |
|    total_timesteps | 1903887  |
| train/             |          |
|    actor_loss      | -41.9    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.46     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2742444  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 413      |
| time/              |          |
|    episodes        | 2652     |
|    fps             | 121      |
|    time_elapsed    | 15687    |
|    total_timesteps | 1906443  |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1        |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2742448  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 502      |
|    ep_rew_mean     | 415      |
| time/              |          |
|    episodes        | 2656     |
|    fps             | 121      |
|    time_elapsed    | 15702    |
|    total_timesteps | 1908727  |
| train/             |          |
|    actor_loss      | -41      |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -0.234   |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2742452  |
---------------------------------
Eval num_timesteps=1910000, episode_reward=361.52 +/- 0.00
Episode length: 435.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 435      |
|    mean_reward     | 362      |
| time/              |          |
|    total_timesteps | 1910000  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 3.38     |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2742455  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | 418      |
| time/              |          |
|    episodes        | 2660     |
|    fps             | 121      |
|    time_elapsed    | 15737    |
|    total_timesteps | 1911392  |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.59     |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2742456  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 506      |
|    ep_rew_mean     | 419      |
| time/              |          |
|    episodes        | 2664     |
|    fps             | 121      |
|    time_elapsed    | 15751    |
|    total_timesteps | 1913363  |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 14.1     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.74     |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2742460  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 508      |
|    ep_rew_mean     | 420      |
| time/              |          |
|    episodes        | 2668     |
|    fps             | 121      |
|    time_elapsed    | 15766    |
|    total_timesteps | 1915643  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2742464  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 510      |
|    ep_rew_mean     | 422      |
| time/              |          |
|    episodes        | 2672     |
|    fps             | 121      |
|    time_elapsed    | 15781    |
|    total_timesteps | 1917748  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2742468  |
---------------------------------
Eval num_timesteps=1920000, episode_reward=279.02 +/- 0.00
Episode length: 330.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 330      |
|    mean_reward     | 279      |
| time/              |          |
|    total_timesteps | 1920000  |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2742472  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 512      |
|    ep_rew_mean     | 423      |
| time/              |          |
|    episodes        | 2676     |
|    fps             | 121      |
|    time_elapsed    | 15819    |
|    total_timesteps | 1920447  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 515      |
|    ep_rew_mean     | 426      |
| time/              |          |
|    episodes        | 2680     |
|    fps             | 121      |
|    time_elapsed    | 15837    |
|    total_timesteps | 1923206  |
| train/             |          |
|    actor_loss      | -41.4    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2742476  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 520      |
|    ep_rew_mean     | 430      |
| time/              |          |
|    episodes        | 2684     |
|    fps             | 121      |
|    time_elapsed    | 15854    |
|    total_timesteps | 1925552  |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 2.84     |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2742480  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 524      |
|    ep_rew_mean     | 433      |
| time/              |          |
|    episodes        | 2688     |
|    fps             | 121      |
|    time_elapsed    | 15871    |
|    total_timesteps | 1927989  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 3.11     |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2742484  |
---------------------------------
Eval num_timesteps=1930000, episode_reward=361.50 +/- 0.00
Episode length: 434.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 434      |
|    mean_reward     | 362      |
| time/              |          |
|    total_timesteps | 1930000  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 5.1      |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2742488  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 525      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 2692     |
|    fps             | 121      |
|    time_elapsed    | 15917    |
|    total_timesteps | 1930487  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 525      |
|    ep_rew_mean     | 433      |
| time/              |          |
|    episodes        | 2696     |
|    fps             | 121      |
|    time_elapsed    | 15934    |
|    total_timesteps | 1932443  |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2742492  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 530      |
|    ep_rew_mean     | 437      |
| time/              |          |
|    episodes        | 2700     |
|    fps             | 121      |
|    time_elapsed    | 15952    |
|    total_timesteps | 1934665  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 9.49     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.4      |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2742496  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 536      |
|    ep_rew_mean     | 442      |
| time/              |          |
|    episodes        | 2704     |
|    fps             | 121      |
|    time_elapsed    | 15972    |
|    total_timesteps | 1937125  |
| train/             |          |
|    actor_loss      | -38.2    |
|    critic_loss     | 4.86     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 5.49     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2742500  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 540      |
|    ep_rew_mean     | 445      |
| time/              |          |
|    episodes        | 2708     |
|    fps             | 121      |
|    time_elapsed    | 15992    |
|    total_timesteps | 1939464  |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 5.15     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 6.88     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2742504  |
---------------------------------
Eval num_timesteps=1940000, episode_reward=292.92 +/- 0.00
Episode length: 347.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 347      |
|    mean_reward     | 293      |
| time/              |          |
|    total_timesteps | 1940000  |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.215    |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2742505  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 540      |
|    ep_rew_mean     | 445      |
| time/              |          |
|    episodes        | 2712     |
|    fps             | 121      |
|    time_elapsed    | 16034    |
|    total_timesteps | 1941905  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.93     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2742508  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 543      |
|    ep_rew_mean     | 448      |
| time/              |          |
|    episodes        | 2716     |
|    fps             | 121      |
|    time_elapsed    | 16053    |
|    total_timesteps | 1944052  |
| train/             |          |
|    actor_loss      | -43.8    |
|    critic_loss     | 4.79     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2742512  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 551      |
|    ep_rew_mean     | 454      |
| time/              |          |
|    episodes        | 2720     |
|    fps             | 121      |
|    time_elapsed    | 16070    |
|    total_timesteps | 1946380  |
| train/             |          |
|    actor_loss      | -43.6    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742516  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 554      |
|    ep_rew_mean     | 457      |
| time/              |          |
|    episodes        | 2724     |
|    fps             | 121      |
|    time_elapsed    | 16088    |
|    total_timesteps | 1948659  |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 5.32     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 6.07     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742520  |
---------------------------------
Eval num_timesteps=1950000, episode_reward=364.49 +/- 0.00
Episode length: 439.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 439      |
|    mean_reward     | 364      |
| time/              |          |
|    total_timesteps | 1950000  |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.35     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742523  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 550      |
|    ep_rew_mean     | 453      |
| time/              |          |
|    episodes        | 2728     |
|    fps             | 120      |
|    time_elapsed    | 16133    |
|    total_timesteps | 1951234  |
| train/             |          |
|    actor_loss      | -40      |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 6.34     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 552      |
|    ep_rew_mean     | 454      |
| time/              |          |
|    episodes        | 2732     |
|    fps             | 120      |
|    time_elapsed    | 16149    |
|    total_timesteps | 1953161  |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 4.02     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -0.378   |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742528  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 553      |
|    ep_rew_mean     | 455      |
| time/              |          |
|    episodes        | 2736     |
|    fps             | 120      |
|    time_elapsed    | 16167    |
|    total_timesteps | 1954889  |
| train/             |          |
|    actor_loss      | -39.1    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 9.58     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2742532  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 555      |
|    ep_rew_mean     | 457      |
| time/              |          |
|    episodes        | 2740     |
|    fps             | 120      |
|    time_elapsed    | 16184    |
|    total_timesteps | 1956687  |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.72     |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2742536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 557      |
|    ep_rew_mean     | 458      |
| time/              |          |
|    episodes        | 2744     |
|    fps             | 120      |
|    time_elapsed    | 16203    |
|    total_timesteps | 1958556  |
| train/             |          |
|    actor_loss      | -39.9    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 6.33     |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2742540  |
---------------------------------
Eval num_timesteps=1960000, episode_reward=740.19 +/- 0.00
Episode length: 918.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 918      |
|    mean_reward     | 740      |
| time/              |          |
|    total_timesteps | 1960000  |
| train/             |          |
|    actor_loss      | -38.5    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.95     |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2742542  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 561      |
|    ep_rew_mean     | 461      |
| time/              |          |
|    episodes        | 2748     |
|    fps             | 120      |
|    time_elapsed    | 16256    |
|    total_timesteps | 1962339  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2742544  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 555      |
|    ep_rew_mean     | 457      |
| time/              |          |
|    episodes        | 2752     |
|    fps             | 120      |
|    time_elapsed    | 16274    |
|    total_timesteps | 1964321  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.69     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.9      |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2742548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 556      |
|    ep_rew_mean     | 458      |
| time/              |          |
|    episodes        | 2756     |
|    fps             | 120      |
|    time_elapsed    | 16291    |
|    total_timesteps | 1966674  |
| train/             |          |
|    actor_loss      | -41.7    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -0.566   |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2742552  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 561      |
|    ep_rew_mean     | 462      |
| time/              |          |
|    episodes        | 2760     |
|    fps             | 120      |
|    time_elapsed    | 16309    |
|    total_timesteps | 1969535  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.16     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2742556  |
---------------------------------
Eval num_timesteps=1970000, episode_reward=363.37 +/- 0.00
Episode length: 433.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 433      |
|    mean_reward     | 363      |
| time/              |          |
|    total_timesteps | 1970000  |
| train/             |          |
|    actor_loss      | -39.2    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 3.3      |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2742557  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 571      |
|    ep_rew_mean     | 470      |
| time/              |          |
|    episodes        | 2764     |
|    fps             | 120      |
|    time_elapsed    | 16351    |
|    total_timesteps | 1973024  |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.71     |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2742560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 572      |
|    ep_rew_mean     | 471      |
| time/              |          |
|    episodes        | 2768     |
|    fps             | 120      |
|    time_elapsed    | 16367    |
|    total_timesteps | 1975379  |
| train/             |          |
|    actor_loss      | -40.8    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.96     |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2742564  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 573      |
|    ep_rew_mean     | 471      |
| time/              |          |
|    episodes        | 2772     |
|    fps             | 120      |
|    time_elapsed    | 16385    |
|    total_timesteps | 1977543  |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 3.55     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2742568  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 468      |
| time/              |          |
|    episodes        | 2776     |
|    fps             | 120      |
|    time_elapsed    | 16403    |
|    total_timesteps | 1979485  |
| train/             |          |
|    actor_loss      | -41.4    |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.715    |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2742572  |
---------------------------------
Eval num_timesteps=1980000, episode_reward=358.62 +/- 0.00
Episode length: 432.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 432      |
|    mean_reward     | 359      |
| time/              |          |
|    total_timesteps | 1980000  |
| train/             |          |
|    actor_loss      | -41.7    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.54     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2742574  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 564      |
|    ep_rew_mean     | 464      |
| time/              |          |
|    episodes        | 2780     |
|    fps             | 120      |
|    time_elapsed    | 16448    |
|    total_timesteps | 1981736  |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.0768   |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2742576  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 563      |
|    ep_rew_mean     | 464      |
| time/              |          |
|    episodes        | 2784     |
|    fps             | 120      |
|    time_elapsed    | 16466    |
|    total_timesteps | 1984010  |
| train/             |          |
|    actor_loss      | -38.7    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 6.74     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2742580  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 562      |
|    ep_rew_mean     | 462      |
| time/              |          |
|    episodes        | 2788     |
|    fps             | 120      |
|    time_elapsed    | 16485    |
|    total_timesteps | 1986284  |
| train/             |          |
|    actor_loss      | -38.4    |
|    critic_loss     | 4.3      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2742584  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 556      |
|    ep_rew_mean     | 458      |
| time/              |          |
|    episodes        | 2792     |
|    fps             | 120      |
|    time_elapsed    | 16502    |
|    total_timesteps | 1988118  |
| train/             |          |
|    actor_loss      | -35.9    |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 2.68     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2742588  |
---------------------------------
Eval num_timesteps=1990000, episode_reward=472.97 +/- 0.00
Episode length: 573.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 573      |
|    mean_reward     | 473      |
| time/              |          |
|    total_timesteps | 1990000  |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.96     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2742592  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 555      |
|    ep_rew_mean     | 457      |
| time/              |          |
|    episodes        | 2796     |
|    fps             | 120      |
|    time_elapsed    | 16547    |
|    total_timesteps | 1990441  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 557      |
|    ep_rew_mean     | 458      |
| time/              |          |
|    episodes        | 2800     |
|    fps             | 120      |
|    time_elapsed    | 16566    |
|    total_timesteps | 1992830  |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 3.03     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2742596  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 561      |
|    ep_rew_mean     | 462      |
| time/              |          |
|    episodes        | 2804     |
|    fps             | 120      |
|    time_elapsed    | 16586    |
|    total_timesteps | 1995701  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 5.83     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2742600  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 564      |
|    ep_rew_mean     | 464      |
| time/              |          |
|    episodes        | 2808     |
|    fps             | 120      |
|    time_elapsed    | 16603    |
|    total_timesteps | 1998372  |
| train/             |          |
|    actor_loss      | -36.5    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 9.43     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2742604  |
---------------------------------
Eval num_timesteps=2000000, episode_reward=557.81 +/- 0.00
Episode length: 686.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 558      |
| time/              |          |
|    total_timesteps | 2000000  |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 5.83     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2742608  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 468      |
| time/              |          |
|    episodes        | 2812     |
|    fps             | 120      |
|    time_elapsed    | 16644    |
|    total_timesteps | 2000938  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 575      |
|    ep_rew_mean     | 473      |
| time/              |          |
|    episodes        | 2816     |
|    fps             | 120      |
|    time_elapsed    | 16663    |
|    total_timesteps | 2003693  |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 4.35     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2742612  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 580      |
|    ep_rew_mean     | 477      |
| time/              |          |
|    episodes        | 2820     |
|    fps             | 120      |
|    time_elapsed    | 16682    |
|    total_timesteps | 2006488  |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 3.83     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2742616  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 578      |
|    ep_rew_mean     | 476      |
| time/              |          |
|    episodes        | 2824     |
|    fps             | 120      |
|    time_elapsed    | 16701    |
|    total_timesteps | 2008627  |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 1.55     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2742620  |
---------------------------------
Eval num_timesteps=2010000, episode_reward=407.62 +/- 0.00
Episode length: 489.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 489      |
|    mean_reward     | 408      |
| time/              |          |
|    total_timesteps | 2010000  |
| train/             |          |
|    actor_loss      | -38.5    |
|    critic_loss     | 7.5      |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 3.45     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2742623  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 579      |
|    ep_rew_mean     | 476      |
| time/              |          |
|    episodes        | 2828     |
|    fps             | 120      |
|    time_elapsed    | 16742    |
|    total_timesteps | 2010985  |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2742624  |
