Using cuda device
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_101
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1.11e+03  |
|    ep_rew_mean     | -4.13e+03 |
| time/              |           |
|    episodes        | 4         |
|    fps             | 49        |
|    time_elapsed    | 89        |
|    total_timesteps | 4437      |
| train/             |           |
|    actor_loss      | 148       |
|    critic_loss     | 2.84      |
|    ent_coef        | 0.0761    |
|    ent_coef_loss   | -18.4     |
|    learning_rate   | 0.001     |
|    n_updates       | 4336      |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 619       |
|    ep_rew_mean     | -2.18e+03 |
| time/              |           |
|    episodes        | 8         |
|    fps             | 44        |
|    time_elapsed    | 110       |
|    total_timesteps | 4953      |
| train/             |           |
|    actor_loss      | 162       |
|    critic_loss     | 70.6      |
|    ent_coef        | 0.0479    |
|    ent_coef_loss   | -22.9     |
|    learning_rate   | 0.001     |
|    n_updates       | 4852      |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 437       |
|    ep_rew_mean     | -1.44e+03 |
| time/              |           |
|    episodes        | 12        |
|    fps             | 40        |
|    time_elapsed    | 128       |
|    total_timesteps | 5248      |
| train/             |           |
|    actor_loss      | 143       |
|    critic_loss     | 5.12      |
|    ent_coef        | 0.0368    |
|    ent_coef_loss   | -21.8     |
|    learning_rate   | 0.000999  |
|    n_updates       | 5147      |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 344       |
|    ep_rew_mean     | -1.07e+03 |
| time/              |           |
|    episodes        | 16        |
|    fps             | 37        |
|    time_elapsed    | 145       |
|    total_timesteps | 5504      |
| train/             |           |
|    actor_loss      | 146       |
|    critic_loss     | 4.21      |
|    ent_coef        | 0.0305    |
|    ent_coef_loss   | -17.5     |
|    learning_rate   | 0.000999  |
|    n_updates       | 5403      |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 287      |
|    ep_rew_mean     | -851     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 35       |
|    time_elapsed    | 163      |
|    total_timesteps | 5739     |
| train/             |          |
|    actor_loss      | 146      |
|    critic_loss     | 464      |
|    ent_coef        | 0.0259   |
|    ent_coef_loss   | -17.6    |
|    learning_rate   | 0.000999 |
|    n_updates       | 5638     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -704     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 33       |
|    time_elapsed    | 179      |
|    total_timesteps | 5989     |
| train/             |          |
|    actor_loss      | 140      |
|    critic_loss     | 7.46     |
|    ent_coef        | 0.0222   |
|    ent_coef_loss   | -14.8    |
|    learning_rate   | 0.000999 |
|    n_updates       | 5888     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 226      |
|    ep_rew_mean     | -618     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 31       |
|    time_elapsed    | 198      |
|    total_timesteps | 6333     |
| train/             |          |
|    actor_loss      | 149      |
|    critic_loss     | 37.5     |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | 4.28     |
|    learning_rate   | 0.000999 |
|    n_updates       | 6232     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | -560     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 30       |
|    time_elapsed    | 217      |
|    total_timesteps | 6729     |
| train/             |          |
|    actor_loss      | 143      |
|    critic_loss     | 69.5     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -4.32    |
|    learning_rate   | 0.000999 |
|    n_updates       | 6628     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 193      |
|    ep_rew_mean     | -495     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 29       |
|    time_elapsed    | 234      |
|    total_timesteps | 6955     |
| train/             |          |
|    actor_loss      | 146      |
|    critic_loss     | 19.1     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -1.13    |
|    learning_rate   | 0.000999 |
|    n_updates       | 6854     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | -451     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 28       |
|    time_elapsed    | 252      |
|    total_timesteps | 7255     |
| train/             |          |
|    actor_loss      | 137      |
|    critic_loss     | 10.3     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 0.000999 |
|    n_updates       | 7154     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 172      |
|    ep_rew_mean     | -414     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 27       |
|    time_elapsed    | 270      |
|    total_timesteps | 7560     |
| train/             |          |
|    actor_loss      | 146      |
|    critic_loss     | 481      |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 4.27     |
|    learning_rate   | 0.000999 |
|    n_updates       | 7459     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | -424     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 27       |
|    time_elapsed    | 292      |
|    total_timesteps | 8079     |
| train/             |          |
|    actor_loss      | 122      |
|    critic_loss     | 94.4     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 0.964    |
|    learning_rate   | 0.000999 |
|    n_updates       | 7978     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | -454     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 27       |
|    time_elapsed    | 313      |
|    total_timesteps | 8517     |
| train/             |          |
|    actor_loss      | 140      |
|    critic_loss     | 41.7     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 0.000999 |
|    n_updates       | 8416     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | -419     |
| time/              |          |
|    episodes        | 56       |
|    fps             | 26       |
|    time_elapsed    | 329      |
|    total_timesteps | 8709     |
| train/             |          |
|    actor_loss      | 117      |
|    critic_loss     | 330      |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -5.59    |
|    learning_rate   | 0.000999 |
|    n_updates       | 8608     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -389     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 25       |
|    time_elapsed    | 346      |
|    total_timesteps | 8918     |
| train/             |          |
|    actor_loss      | 138      |
|    critic_loss     | 52.4     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.000999 |
|    n_updates       | 8817     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -363     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 25       |
|    time_elapsed    | 362      |
|    total_timesteps | 9140     |
| train/             |          |
|    actor_loss      | 128      |
|    critic_loss     | 44.8     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 0.000999 |
|    n_updates       | 9039     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | -339     |
| time/              |          |
|    episodes        | 68       |
|    fps             | 24       |
|    time_elapsed    | 379      |
|    total_timesteps | 9349     |
| train/             |          |
|    actor_loss      | 131      |
|    critic_loss     | 1.76e+03 |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -5.9     |
|    learning_rate   | 0.000999 |
|    n_updates       | 9248     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -318     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 24       |
|    time_elapsed    | 395      |
|    total_timesteps | 9564     |
| train/             |          |
|    actor_loss      | 124      |
|    critic_loss     | 23.2     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 0.000999 |
|    n_updates       | 9463     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | -299     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 23       |
|    time_elapsed    | 412      |
|    total_timesteps | 9790     |
| train/             |          |
|    actor_loss      | 138      |
|    critic_loss     | 363      |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | -0.481   |
|    learning_rate   | 0.000999 |
|    n_updates       | 9689     |
---------------------------------
Eval num_timesteps=10000, episode_reward=41.56 +/- 4.51
Episode length: 55.00 +/- 3.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 55       |
|    mean_reward     | 41.6     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 118      |
|    critic_loss     | 53.1     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -0.416   |
|    learning_rate   | 0.000999 |
|    n_updates       | 9899     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 125      |
|    ep_rew_mean     | -282     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 22       |
|    time_elapsed    | 449      |
|    total_timesteps | 10057    |
| train/             |          |
|    actor_loss      | 123      |
|    critic_loss     | 125      |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 0.000999 |
|    n_updates       | 9956     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 122      |
|    ep_rew_mean     | -267     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 22       |
|    time_elapsed    | 466      |
|    total_timesteps | 10271    |
| train/             |          |
|    actor_loss      | 110      |
|    critic_loss     | 33.3     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 0.000999 |
|    n_updates       | 10170    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 119      |
|    ep_rew_mean     | -253     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 21       |
|    time_elapsed    | 482      |
|    total_timesteps | 10495    |
| train/             |          |
|    actor_loss      | 116      |
|    critic_loss     | 46.6     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -2.16    |
|    learning_rate   | 0.000999 |
|    n_updates       | 10394    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 116      |
|    ep_rew_mean     | -240     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 21       |
|    time_elapsed    | 499      |
|    total_timesteps | 10729    |
| train/             |          |
|    actor_loss      | 108      |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0202   |
|    ent_coef_loss   | -0.573   |
|    learning_rate   | 0.000999 |
|    n_updates       | 10628    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 114      |
|    ep_rew_mean     | -228     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 21       |
|    time_elapsed    | 515      |
|    total_timesteps | 10958    |
| train/             |          |
|    actor_loss      | 134      |
|    critic_loss     | 183      |
|    ent_coef        | 0.0209   |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 0.000999 |
|    n_updates       | 10857    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 112      |
|    ep_rew_mean     | -218     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 21       |
|    time_elapsed    | 532      |
|    total_timesteps | 11204    |
| train/             |          |
|    actor_loss      | 102      |
|    critic_loss     | 211      |
|    ent_coef        | 0.0232   |
|    ent_coef_loss   | 0.599    |
|    learning_rate   | 0.000999 |
|    n_updates       | 11103    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 69.4     |
|    ep_rew_mean     | -51.2    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 20       |
|    time_elapsed    | 548      |
|    total_timesteps | 11421    |
| train/             |          |
|    actor_loss      | 95.5     |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0236   |
|    ent_coef_loss   | 0.547    |
|    learning_rate   | 0.000999 |
|    n_updates       | 11320    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66.4     |
|    ep_rew_mean     | -40.1    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 20       |
|    time_elapsed    | 564      |
|    total_timesteps | 11639    |
| train/             |          |
|    actor_loss      | 109      |
|    critic_loss     | 11.4     |
|    ent_coef        | 0.0227   |
|    ent_coef_loss   | 2.84     |
|    learning_rate   | 0.000999 |
|    n_updates       | 11538    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66       |
|    ep_rew_mean     | -40.3    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 20       |
|    time_elapsed    | 582      |
|    total_timesteps | 11890    |
| train/             |          |
|    actor_loss      | 111      |
|    critic_loss     | 355      |
|    ent_coef        | 0.0228   |
|    ent_coef_loss   | 0.411    |
|    learning_rate   | 0.000999 |
|    n_updates       | 11789    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.8     |
|    ep_rew_mean     | -40.5    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 20       |
|    time_elapsed    | 599      |
|    total_timesteps | 12131    |
| train/             |          |
|    actor_loss      | 98.4     |
|    critic_loss     | 106      |
|    ent_coef        | 0.0229   |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.000999 |
|    n_updates       | 12030    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.8     |
|    ep_rew_mean     | -40.9    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 20       |
|    time_elapsed    | 616      |
|    total_timesteps | 12363    |
| train/             |          |
|    actor_loss      | 101      |
|    critic_loss     | 154      |
|    ent_coef        | 0.023    |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 0.000999 |
|    n_updates       | 12262    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.9     |
|    ep_rew_mean     | -40.9    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 19       |
|    time_elapsed    | 633      |
|    total_timesteps | 12618    |
| train/             |          |
|    actor_loss      | 108      |
|    critic_loss     | 107      |
|    ent_coef        | 0.0224   |
|    ent_coef_loss   | 3.12     |
|    learning_rate   | 0.000999 |
|    n_updates       | 12517    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.8     |
|    ep_rew_mean     | -35.8    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 19       |
|    time_elapsed    | 650      |
|    total_timesteps | 12855    |
| train/             |          |
|    actor_loss      | 81.8     |
|    critic_loss     | 31.9     |
|    ent_coef        | 0.0217   |
|    ent_coef_loss   | -1.44    |
|    learning_rate   | 0.000999 |
|    n_updates       | 12754    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 63.7     |
|    ep_rew_mean     | -29.2    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 19       |
|    time_elapsed    | 668      |
|    total_timesteps | 13139    |
| train/             |          |
|    actor_loss      | 89.7     |
|    critic_loss     | 1.35e+03 |
|    ent_coef        | 0.0217   |
|    ent_coef_loss   | 4.69     |
|    learning_rate   | 0.000999 |
|    n_updates       | 13038    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.5     |
|    ep_rew_mean     | -31      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 19       |
|    time_elapsed    | 686      |
|    total_timesteps | 13447    |
| train/             |          |
|    actor_loss      | 90.9     |
|    critic_loss     | 21.3     |
|    ent_coef        | 0.021    |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.000999 |
|    n_updates       | 13346    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.5     |
|    ep_rew_mean     | -28.1    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 19       |
|    time_elapsed    | 703      |
|    total_timesteps | 13746    |
| train/             |          |
|    actor_loss      | 94.4     |
|    critic_loss     | 13.6     |
|    ent_coef        | 0.0205   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 0.000999 |
|    n_updates       | 13645    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.5     |
|    ep_rew_mean     | -26      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 19       |
|    time_elapsed    | 721      |
|    total_timesteps | 14049    |
| train/             |          |
|    actor_loss      | 95.3     |
|    critic_loss     | 51.5     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 0.000999 |
|    n_updates       | 13948    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 61.9     |
|    ep_rew_mean     | -3.99    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 19       |
|    time_elapsed    | 737      |
|    total_timesteps | 14314    |
| train/             |          |
|    actor_loss      | 72.1     |
|    critic_loss     | 22.5     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 0.255    |
|    learning_rate   | 0.000999 |
|    n_updates       | 14213    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60       |
|    ep_rew_mean     | 30.2     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 19       |
|    time_elapsed    | 754      |
|    total_timesteps | 14557    |
| train/             |          |
|    actor_loss      | 97.2     |
|    critic_loss     | 307      |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 0.000999 |
|    n_updates       | 14456    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.7     |
|    ep_rew_mean     | 29.7     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 19       |
|    time_elapsed    | 770      |
|    total_timesteps | 14824    |
| train/             |          |
|    actor_loss      | 89.5     |
|    critic_loss     | 11.6     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 0.000999 |
|    n_updates       | 14723    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 61.3     |
|    ep_rew_mean     | 28.4     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 19       |
|    time_elapsed    | 787      |
|    total_timesteps | 15093    |
| train/             |          |
|    actor_loss      | 83.7     |
|    critic_loss     | 24.5     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -1.54    |
|    learning_rate   | 0.000998 |
|    n_updates       | 14992    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 62.3     |
|    ep_rew_mean     | 24.1     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 19       |
|    time_elapsed    | 805      |
|    total_timesteps | 15411    |
| train/             |          |
|    actor_loss      | 69.6     |
|    critic_loss     | 9.19     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 0.000998 |
|    n_updates       | 15310    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.7     |
|    ep_rew_mean     | 8.02     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 19       |
|    time_elapsed    | 824      |
|    total_timesteps | 15859    |
| train/             |          |
|    actor_loss      | 62       |
|    critic_loss     | 16.1     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | 0.377    |
|    learning_rate   | 0.000998 |
|    n_updates       | 15758    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66.9     |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 19       |
|    time_elapsed    | 843      |
|    total_timesteps | 16293    |
| train/             |          |
|    actor_loss      | 75.2     |
|    critic_loss     | 64.8     |
|    ent_coef        | 0.0203   |
|    ent_coef_loss   | -1.44    |
|    learning_rate   | 0.000998 |
|    n_updates       | 16192    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 69.1     |
|    ep_rew_mean     | -24.7    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 19       |
|    time_elapsed    | 862      |
|    total_timesteps | 16742    |
| train/             |          |
|    actor_loss      | 78.5     |
|    critic_loss     | 30.3     |
|    ent_coef        | 0.0204   |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 0.000998 |
|    n_updates       | 16641    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 71.8     |
|    ep_rew_mean     | -39.1    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 19       |
|    time_elapsed    | 883      |
|    total_timesteps | 17242    |
| train/             |          |
|    actor_loss      | 70.8     |
|    critic_loss     | 31.7     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 0.000998 |
|    n_updates       | 17141    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | -60.3    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 19       |
|    time_elapsed    | 905      |
|    total_timesteps | 17840    |
| train/             |          |
|    actor_loss      | 93.7     |
|    critic_loss     | 30.6     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 0.000998 |
|    n_updates       | 17739    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.8     |
|    ep_rew_mean     | -83.2    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 19       |
|    time_elapsed    | 929      |
|    total_timesteps | 18480    |
| train/             |          |
|    actor_loss      | 81.6     |
|    critic_loss     | 7.64     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 2.95     |
|    learning_rate   | 0.000998 |
|    n_updates       | 18379    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.8     |
|    ep_rew_mean     | -85.6    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 19       |
|    time_elapsed    | 946      |
|    total_timesteps | 18813    |
| train/             |          |
|    actor_loss      | 74.9     |
|    critic_loss     | 56.9     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 4.29     |
|    learning_rate   | 0.000998 |
|    n_updates       | 18712    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.3     |
|    ep_rew_mean     | -85.9    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 19       |
|    time_elapsed    | 962      |
|    total_timesteps | 19085    |
| train/             |          |
|    actor_loss      | 68       |
|    critic_loss     | 12.8     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.0466   |
|    learning_rate   | 0.000998 |
|    n_updates       | 18984    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.5     |
|    ep_rew_mean     | -86      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 19       |
|    time_elapsed    | 979      |
|    total_timesteps | 19354    |
| train/             |          |
|    actor_loss      | 65.6     |
|    critic_loss     | 154      |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 2.07     |
|    learning_rate   | 0.000998 |
|    n_updates       | 19253    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82       |
|    ep_rew_mean     | -86.1    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 19       |
|    time_elapsed    | 996      |
|    total_timesteps | 19619    |
| train/             |          |
|    actor_loss      | 69.8     |
|    critic_loss     | 481      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.543    |
|    learning_rate   | 0.000998 |
|    n_updates       | 19518    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.1     |
|    ep_rew_mean     | -86.8    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 19       |
|    time_elapsed    | 1011     |
|    total_timesteps | 19852    |
| train/             |          |
|    actor_loss      | 69.1     |
|    critic_loss     | 43.1     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 0.000998 |
|    n_updates       | 19751    |
---------------------------------
Eval num_timesteps=20000, episode_reward=27.71 +/- 10.89
Episode length: 58.20 +/- 4.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 58.2     |
|    mean_reward     | 27.7     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 84.7     |
|    critic_loss     | 154      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.63     |
|    learning_rate   | 0.000998 |
|    n_updates       | 19899    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.1     |
|    ep_rew_mean     | -86.5    |
| time/              |          |
|    episodes        | 212      |
|    fps             | 19       |
|    time_elapsed    | 1046     |
|    total_timesteps | 20129    |
| train/             |          |
|    actor_loss      | 81.4     |
|    critic_loss     | 50       |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 0.729    |
|    learning_rate   | 0.000998 |
|    n_updates       | 20028    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.1     |
|    ep_rew_mean     | -86.5    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 19       |
|    time_elapsed    | 1062     |
|    total_timesteps | 20372    |
| train/             |          |
|    actor_loss      | 62.6     |
|    critic_loss     | 26.1     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.931    |
|    learning_rate   | 0.000998 |
|    n_updates       | 20271    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.1     |
|    ep_rew_mean     | -86.3    |
| time/              |          |
|    episodes        | 220      |
|    fps             | 19       |
|    time_elapsed    | 1078     |
|    total_timesteps | 20604    |
| train/             |          |
|    actor_loss      | 55.4     |
|    critic_loss     | 93.8     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.0806  |
|    learning_rate   | 0.000998 |
|    n_updates       | 20503    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.9     |
|    ep_rew_mean     | -86.2    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 19       |
|    time_elapsed    | 1094     |
|    total_timesteps | 20837    |
| train/             |          |
|    actor_loss      | 70.8     |
|    critic_loss     | 27       |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 0.000998 |
|    n_updates       | 20736    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82       |
|    ep_rew_mean     | -85.8    |
| time/              |          |
|    episodes        | 228      |
|    fps             | 18       |
|    time_elapsed    | 1110     |
|    total_timesteps | 21089    |
| train/             |          |
|    actor_loss      | 78.2     |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.59    |
|    learning_rate   | 0.000998 |
|    n_updates       | 20988    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.9     |
|    ep_rew_mean     | -84.9    |
| time/              |          |
|    episodes        | 232      |
|    fps             | 18       |
|    time_elapsed    | 1126     |
|    total_timesteps | 21354    |
| train/             |          |
|    actor_loss      | 73.8     |
|    critic_loss     | 15       |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 0.187    |
|    learning_rate   | 0.000998 |
|    n_updates       | 21253    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.3     |
|    ep_rew_mean     | -83.1    |
| time/              |          |
|    episodes        | 236      |
|    fps             | 18       |
|    time_elapsed    | 1142     |
|    total_timesteps | 21602    |
| train/             |          |
|    actor_loss      | 55.7     |
|    critic_loss     | 30.2     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 0.000998 |
|    n_updates       | 21501    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.8     |
|    ep_rew_mean     | -82.2    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 18       |
|    time_elapsed    | 1158     |
|    total_timesteps | 21857    |
| train/             |          |
|    actor_loss      | 63.4     |
|    critic_loss     | 8.54     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 0.000998 |
|    n_updates       | 21756    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.1     |
|    ep_rew_mean     | -81.2    |
| time/              |          |
|    episodes        | 244      |
|    fps             | 18       |
|    time_elapsed    | 1173     |
|    total_timesteps | 22092    |
| train/             |          |
|    actor_loss      | 70.3     |
|    critic_loss     | 492      |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 0.151    |
|    learning_rate   | 0.000998 |
|    n_updates       | 21991    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -80.7    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 18       |
|    time_elapsed    | 1189     |
|    total_timesteps | 22346    |
| train/             |          |
|    actor_loss      | 62.2     |
|    critic_loss     | 98       |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 0.554    |
|    learning_rate   | 0.000998 |
|    n_updates       | 22245    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.2     |
|    ep_rew_mean     | -80.7    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 18       |
|    time_elapsed    | 1205     |
|    total_timesteps | 22605    |
| train/             |          |
|    actor_loss      | 71.9     |
|    critic_loss     | 34.4     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -0.627   |
|    learning_rate   | 0.000998 |
|    n_updates       | 22504    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.1     |
|    ep_rew_mean     | -80.3    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 18       |
|    time_elapsed    | 1222     |
|    total_timesteps | 22861    |
| train/             |          |
|    actor_loss      | 57.5     |
|    critic_loss     | 28.8     |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | 2.18     |
|    learning_rate   | 0.000998 |
|    n_updates       | 22760    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.2     |
|    ep_rew_mean     | -79      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 18       |
|    time_elapsed    | 1239     |
|    total_timesteps | 23146    |
| train/             |          |
|    actor_loss      | 67       |
|    critic_loss     | 77.3     |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | 4.28     |
|    learning_rate   | 0.000998 |
|    n_updates       | 23045    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.7     |
|    ep_rew_mean     | -75      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 18       |
|    time_elapsed    | 1255     |
|    total_timesteps | 23405    |
| train/             |          |
|    actor_loss      | 65.1     |
|    critic_loss     | 50.9     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | 2.54     |
|    learning_rate   | 0.000998 |
|    n_updates       | 23304    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 77.8     |
|    ep_rew_mean     | -59.5    |
| time/              |          |
|    episodes        | 268      |
|    fps             | 18       |
|    time_elapsed    | 1271     |
|    total_timesteps | 23671    |
| train/             |          |
|    actor_loss      | 66.4     |
|    critic_loss     | 71.8     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | -0.302   |
|    learning_rate   | 0.000998 |
|    n_updates       | 23570    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.3     |
|    ep_rew_mean     | -39.7    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 18       |
|    time_elapsed    | 1288     |
|    total_timesteps | 23950    |
| train/             |          |
|    actor_loss      | 70.7     |
|    critic_loss     | 144      |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -1.58    |
|    learning_rate   | 0.000998 |
|    n_updates       | 23849    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.6     |
|    ep_rew_mean     | -27.3    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 18       |
|    time_elapsed    | 1304     |
|    total_timesteps | 24232    |
| train/             |          |
|    actor_loss      | 54.1     |
|    critic_loss     | 724      |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | 2.75     |
|    learning_rate   | 0.000998 |
|    n_updates       | 24131    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 72.4     |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 18       |
|    time_elapsed    | 1320     |
|    total_timesteps | 24511    |
| train/             |          |
|    actor_loss      | 46.8     |
|    critic_loss     | 358      |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 0.000998 |
|    n_updates       | 24410    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 69.3     |
|    ep_rew_mean     | 7.83     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 18       |
|    time_elapsed    | 1337     |
|    total_timesteps | 24802    |
| train/             |          |
|    actor_loss      | 49.3     |
|    critic_loss     | 552      |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -3.41    |
|    learning_rate   | 0.000998 |
|    n_updates       | 24701    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.8     |
|    ep_rew_mean     | 30.1     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 18       |
|    time_elapsed    | 1353     |
|    total_timesteps | 25091    |
| train/             |          |
|    actor_loss      | 70.7     |
|    critic_loss     | 103      |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -0.479   |
|    learning_rate   | 0.000997 |
|    n_updates       | 24990    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.5     |
|    ep_rew_mean     | 31.8     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 18       |
|    time_elapsed    | 1370     |
|    total_timesteps | 25388    |
| train/             |          |
|    actor_loss      | 38       |
|    critic_loss     | 13.2     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | -3.57    |
|    learning_rate   | 0.000997 |
|    n_updates       | 25287    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.7     |
|    ep_rew_mean     | 31.3     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 18       |
|    time_elapsed    | 1386     |
|    total_timesteps | 25682    |
| train/             |          |
|    actor_loss      | 50.2     |
|    critic_loss     | 467      |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 0.806    |
|    learning_rate   | 0.000997 |
|    n_updates       | 25581    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66.1     |
|    ep_rew_mean     | 31.2     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 18       |
|    time_elapsed    | 1403     |
|    total_timesteps | 25996    |
| train/             |          |
|    actor_loss      | 58.3     |
|    critic_loss     | 414      |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 0.000997 |
|    n_updates       | 25895    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66.7     |
|    ep_rew_mean     | 31.7     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 18       |
|    time_elapsed    | 1420     |
|    total_timesteps | 26315    |
| train/             |          |
|    actor_loss      | 54.7     |
|    critic_loss     | 50.1     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 0.000997 |
|    n_updates       | 26214    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 67.5     |
|    ep_rew_mean     | 31.8     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 18       |
|    time_elapsed    | 1438     |
|    total_timesteps | 26629    |
| train/             |          |
|    actor_loss      | 53       |
|    critic_loss     | 21.2     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -1.8     |
|    learning_rate   | 0.000997 |
|    n_updates       | 26528    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.5     |
|    ep_rew_mean     | 32.8     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 18       |
|    time_elapsed    | 1458     |
|    total_timesteps | 27175    |
| train/             |          |
|    actor_loss      | 81.2     |
|    critic_loss     | 57.6     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 0.000997 |
|    n_updates       | 27074    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 74.6     |
|    ep_rew_mean     | 34.3     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 18       |
|    time_elapsed    | 1480     |
|    total_timesteps | 27828    |
| train/             |          |
|    actor_loss      | 52.2     |
|    critic_loss     | 85.1     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -0.346   |
|    learning_rate   | 0.000997 |
|    n_updates       | 27727    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.7     |
|    ep_rew_mean     | 33       |
| time/              |          |
|    episodes        | 320      |
|    fps             | 19       |
|    time_elapsed    | 1509     |
|    total_timesteps | 28876    |
| train/             |          |
|    actor_loss      | 56.9     |
|    critic_loss     | 14.8     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.15     |
|    learning_rate   | 0.000997 |
|    n_updates       | 28775    |
---------------------------------
Eval num_timesteps=30000, episode_reward=107.28 +/- 51.24
Episode length: 269.20 +/- 282.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 269      |
|    mean_reward     | 107      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 46       |
|    critic_loss     | 28.2     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 0.000997 |
|    n_updates       | 29899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92.1     |
|    ep_rew_mean     | 28.7     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 19       |
|    time_elapsed    | 1564     |
|    total_timesteps | 30211    |
| train/             |          |
|    actor_loss      | 55.2     |
|    critic_loss     | 34.2     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 2.26     |
|    learning_rate   | 0.000997 |
|    n_updates       | 30110    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 114      |
|    ep_rew_mean     | 31.9     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 20       |
|    time_elapsed    | 1617     |
|    total_timesteps | 32704    |
| train/             |          |
|    actor_loss      | 37.8     |
|    critic_loss     | 141      |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -0.619   |
|    learning_rate   | 0.000997 |
|    n_updates       | 32603    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 152      |
|    ep_rew_mean     | 44.9     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 21       |
|    time_elapsed    | 1694     |
|    total_timesteps | 36718    |
| train/             |          |
|    actor_loss      | 38.7     |
|    critic_loss     | 12.4     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 0.000996 |
|    n_updates       | 36617    |
---------------------------------
Eval num_timesteps=40000, episode_reward=1505.57 +/- 914.69
Episode length: 2937.00 +/- 1446.42
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.94e+03 |
|    mean_reward     | 1.51e+03 |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 36       |
|    critic_loss     | 6.58     |
|    ent_coef        | 0.0238   |
|    ent_coef_loss   | -2.53    |
|    learning_rate   | 0.000996 |
|    n_updates       | 39899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 73.7     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 23       |
|    time_elapsed    | 1879     |
|    total_timesteps | 44709    |
| train/             |          |
|    actor_loss      | 30.6     |
|    critic_loss     | 14.6     |
|    ent_coef        | 0.0258   |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 0.000996 |
|    n_updates       | 44608    |
---------------------------------
Eval num_timesteps=50000, episode_reward=1570.05 +/- 562.77
Episode length: 3396.00 +/- 88.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.4e+03  |
|    mean_reward     | 1.57e+03 |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 21.3     |
|    critic_loss     | 21.1     |
|    ent_coef        | 0.0305   |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 0.000995 |
|    n_updates       | 49899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 268      |
|    ep_rew_mean     | 94.6     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 25       |
|    time_elapsed    | 2077     |
|    total_timesteps | 53363    |
| train/             |          |
|    actor_loss      | -9.33    |
|    critic_loss     | 11.4     |
|    ent_coef        | 0.03     |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 0.000995 |
|    n_updates       | 53262    |
---------------------------------
Eval num_timesteps=60000, episode_reward=1935.35 +/- 279.68
Episode length: 3570.60 +/- 190.04
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.57e+03 |
|    mean_reward     | 1.94e+03 |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 1.28     |
|    critic_loss     | 37.8     |
|    ent_coef        | 0.0235   |
|    ent_coef_loss   | 3.86     |
|    learning_rate   | 0.000994 |
|    n_updates       | 59899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 167      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 28       |
|    time_elapsed    | 2366     |
|    total_timesteps | 67368    |
| train/             |          |
|    actor_loss      | -3.75    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.0267   |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 0.000993 |
|    n_updates       | 67267    |
---------------------------------
Eval num_timesteps=70000, episode_reward=1288.04 +/- 1023.11
Episode length: 3932.40 +/- 1108.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.93e+03 |
|    mean_reward     | 1.29e+03 |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -3.48    |
|    critic_loss     | 10.2     |
|    ent_coef        | 0.0275   |
|    ent_coef_loss   | -4.27    |
|    learning_rate   | 0.000993 |
|    n_updates       | 69899    |
---------------------------------
Eval num_timesteps=80000, episode_reward=2236.11 +/- 1657.10
Episode length: 2862.00 +/- 1734.46
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.86e+03 |
|    mean_reward     | 2.24e+03 |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -21.9    |
|    critic_loss     | 16.4     |
|    ent_coef        | 0.0291   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 0.000992 |
|    n_updates       | 79899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 511      |
|    ep_rew_mean     | 237      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 30       |
|    time_elapsed    | 2765     |
|    total_timesteps | 85187    |
| train/             |          |
|    actor_loss      | -11.2    |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0253   |
|    ent_coef_loss   | 0.474    |
|    learning_rate   | 0.000991 |
|    n_updates       | 85086    |
---------------------------------
Eval num_timesteps=90000, episode_reward=2523.21 +/- 1339.63
Episode length: 3801.00 +/- 853.23
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.8e+03  |
|    mean_reward     | 2.52e+03 |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -15      |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.0239   |
|    ent_coef_loss   | -0.573   |
|    learning_rate   | 0.000991 |
|    n_updates       | 89899    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 644      |
|    ep_rew_mean     | 334      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 32       |
|    time_elapsed    | 3056     |
|    total_timesteps | 98968    |
| train/             |          |
|    actor_loss      | -18      |
|    critic_loss     | 9.09     |
|    ent_coef        | 0.0225   |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 0.00099  |
|    n_updates       | 98867    |
---------------------------------
Eval num_timesteps=100000, episode_reward=1518.53 +/- 901.96
Episode length: 2516.20 +/- 1152.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.52e+03 |
|    mean_reward     | 1.52e+03 |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -30.9    |
|    critic_loss     | 6.56     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | -0.651   |
|    learning_rate   | 0.00099  |
|    n_updates       | 99899    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 651      |
|    ep_rew_mean     | 334      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 32       |
|    time_elapsed    | 3131     |
|    total_timesteps | 100539   |
| train/             |          |
|    actor_loss      | -18.6    |
|    critic_loss     | 87.4     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | 0.317    |
|    learning_rate   | 0.00099  |
|    n_updates       | 100438   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 664      |
|    ep_rew_mean     | 337      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 32       |
|    time_elapsed    | 3169     |
|    total_timesteps | 102149   |
| train/             |          |
|    actor_loss      | -23.2    |
|    critic_loss     | 5.01     |
|    ent_coef        | 0.0216   |
|    ent_coef_loss   | 0.685    |
|    learning_rate   | 0.00099  |
|    n_updates       | 102048   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 706      |
|    ep_rew_mean     | 363      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 32       |
|    time_elapsed    | 3256     |
|    total_timesteps | 106589   |
| train/             |          |
|    actor_loss      | -28.1    |
|    critic_loss     | 9.63     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -3.91    |
|    learning_rate   | 0.000989 |
|    n_updates       | 106488   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 370      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 32       |
|    time_elapsed    | 3294     |
|    total_timesteps | 108225   |
| train/             |          |
|    actor_loss      | -19.2    |
|    critic_loss     | 16.2     |
|    ent_coef        | 0.0212   |
|    ent_coef_loss   | -3.09    |
|    learning_rate   | 0.000989 |
|    n_updates       | 108124   |
---------------------------------
Eval num_timesteps=110000, episode_reward=96.14 +/- 464.85
Episode length: 1772.40 +/- 1359.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.77e+03 |
|    mean_reward     | 96.1     |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -22      |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0205   |
|    ent_coef_loss   | 0.893    |
|    learning_rate   | 0.000989 |
|    n_updates       | 109899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 751      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 32       |
|    time_elapsed    | 3396     |
|    total_timesteps | 111750   |
| train/             |          |
|    actor_loss      | -23.9    |
|    critic_loss     | 5.29     |
|    ent_coef        | 0.0221   |
|    ent_coef_loss   | -3.68    |
|    learning_rate   | 0.000989 |
|    n_updates       | 111649   |
---------------------------------
Eval num_timesteps=120000, episode_reward=1593.49 +/- 523.13
Episode length: 2991.00 +/- 769.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.99e+03 |
|    mean_reward     | 1.59e+03 |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -28.7    |
|    critic_loss     | 8.04     |
|    ent_coef        | 0.0261   |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 0.000988 |
|    n_updates       | 119899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 867      |
|    ep_rew_mean     | 429      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 33       |
|    time_elapsed    | 3672     |
|    total_timesteps | 124067   |
| train/             |          |
|    actor_loss      | -15.8    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0236   |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 0.000988 |
|    n_updates       | 123966   |
---------------------------------
Eval num_timesteps=130000, episode_reward=376.13 +/- 802.69
Episode length: 2362.60 +/- 384.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.36e+03 |
|    mean_reward     | 376      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -19.6    |
|    critic_loss     | 13.3     |
|    ent_coef        | 0.0253   |
|    ent_coef_loss   | 2.68     |
|    learning_rate   | 0.000987 |
|    n_updates       | 129899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 436      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 34       |
|    time_elapsed    | 3850     |
|    total_timesteps | 131319   |
| train/             |          |
|    actor_loss      | -23.5    |
|    critic_loss     | 6.15     |
|    ent_coef        | 0.0245   |
|    ent_coef_loss   | 2.18     |
|    learning_rate   | 0.000987 |
|    n_updates       | 131218   |
---------------------------------
Eval num_timesteps=140000, episode_reward=3113.77 +/- 982.90
Episode length: 4271.40 +/- 504.56
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.27e+03 |
|    mean_reward     | 3.11e+03 |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -23.6    |
|    critic_loss     | 32.8     |
|    ent_coef        | 0.0285   |
|    ent_coef_loss   | 0.755    |
|    learning_rate   | 0.000986 |
|    n_updates       | 139899   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 489      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 34       |
|    time_elapsed    | 4127     |
|    total_timesteps | 143535   |
| train/             |          |
|    actor_loss      | -14.7    |
|    critic_loss     | 40.2     |
|    ent_coef        | 0.0287   |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 0.000986 |
|    n_updates       | 143434   |
---------------------------------
Eval num_timesteps=150000, episode_reward=1334.65 +/- 1098.17
Episode length: 3918.80 +/- 545.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.92e+03 |
|    mean_reward     | 1.33e+03 |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -31.3    |
|    critic_loss     | 4.58     |
|    ent_coef        | 0.0317   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 0.000985 |
|    n_updates       | 149899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 519      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 35       |
|    time_elapsed    | 4433     |
|    total_timesteps | 157883   |
| train/             |          |
|    actor_loss      | -35.1    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0317   |
|    ent_coef_loss   | 2.58     |
|    learning_rate   | 0.000984 |
|    n_updates       | 157782   |
---------------------------------
Eval num_timesteps=160000, episode_reward=587.41 +/- 603.24
Episode length: 2909.20 +/- 527.19
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.91e+03 |
|    mean_reward     | 587      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -31.6    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0294   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 0.000984 |
|    n_updates       | 159899   |
---------------------------------
Eval num_timesteps=170000, episode_reward=1965.15 +/- 966.96
Episode length: 3045.00 +/- 1430.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.04e+03 |
|    mean_reward     | 1.97e+03 |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -25.1    |
|    critic_loss     | 9.14     |
|    ent_coef        | 0.0297   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 0.000983 |
|    n_updates       | 169899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 36       |
|    time_elapsed    | 4829     |
|    total_timesteps | 176555   |
| train/             |          |
|    actor_loss      | -12.7    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0284   |
|    ent_coef_loss   | 3.49     |
|    learning_rate   | 0.000982 |
|    n_updates       | 176454   |
---------------------------------
Eval num_timesteps=180000, episode_reward=1135.66 +/- 567.52
Episode length: 2978.20 +/- 926.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.98e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 7.42     |
|    ent_coef        | 0.0252   |
|    ent_coef_loss   | 3.77     |
|    learning_rate   | 0.000982 |
|    n_updates       | 179899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 37       |
|    time_elapsed    | 5064     |
|    total_timesteps | 187794   |
| train/             |          |
|    actor_loss      | -30.3    |
|    critic_loss     | 30.5     |
|    ent_coef        | 0.0296   |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 0.000981 |
|    n_updates       | 187693   |
---------------------------------
Eval num_timesteps=190000, episode_reward=1152.86 +/- 1553.15
Episode length: 1904.00 +/- 1910.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.9e+03  |
|    mean_reward     | 1.15e+03 |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 12.7     |
|    ent_coef        | 0.0293   |
|    ent_coef_loss   | -0.529   |
|    learning_rate   | 0.000981 |
|    n_updates       | 189899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 631      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 37       |
|    time_elapsed    | 5270     |
|    total_timesteps | 197690   |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0324   |
|    ent_coef_loss   | 2.05     |
|    learning_rate   | 0.00098  |
|    n_updates       | 197589   |
---------------------------------
Eval num_timesteps=200000, episode_reward=2265.93 +/- 1344.45
Episode length: 4121.20 +/- 551.61
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.12e+03 |
|    mean_reward     | 2.27e+03 |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -29.9    |
|    critic_loss     | 45.7     |
|    ent_coef        | 0.0275   |
|    ent_coef_loss   | 1.32     |
|    learning_rate   | 0.00098  |
|    n_updates       | 199899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 37       |
|    time_elapsed    | 5441     |
|    total_timesteps | 204481   |
| train/             |          |
|    actor_loss      | -27.9    |
|    critic_loss     | 3.51     |
|    ent_coef        | 0.0287   |
|    ent_coef_loss   | 2.01     |
|    learning_rate   | 0.00098  |
|    n_updates       | 204380   |
---------------------------------
Eval num_timesteps=210000, episode_reward=1650.40 +/- 1514.87
Episode length: 2161.40 +/- 1726.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.16e+03 |
|    mean_reward     | 1.65e+03 |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 15.4     |
|    ent_coef        | 0.0351   |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 0.000979 |
|    n_updates       | 209899   |
---------------------------------
Eval num_timesteps=220000, episode_reward=1478.42 +/- 1248.84
Episode length: 2999.20 +/- 1257.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3e+03    |
|    mean_reward     | 1.48e+03 |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.036    |
|    ent_coef_loss   | -1.03    |
|    learning_rate   | 0.000978 |
|    n_updates       | 219899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.61e+03 |
|    ep_rew_mean     | 701      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 38       |
|    time_elapsed    | 5842     |
|    total_timesteps | 223407   |
| train/             |          |
|    actor_loss      | -24.4    |
|    critic_loss     | 14.8     |
|    ent_coef        | 0.0342   |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 0.000978 |
|    n_updates       | 223306   |
---------------------------------
Eval num_timesteps=230000, episode_reward=1393.69 +/- 1071.18
Episode length: 2684.40 +/- 1307.69
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.68e+03 |
|    mean_reward     | 1.39e+03 |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0293   |
|    ent_coef_loss   | 4.17     |
|    learning_rate   | 0.000977 |
|    n_updates       | 229899   |
---------------------------------
Eval num_timesteps=240000, episode_reward=572.61 +/- 1162.18
Episode length: 2902.20 +/- 1181.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.9e+03  |
|    mean_reward     | 573      |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -38.1    |
|    critic_loss     | 4.83     |
|    ent_coef        | 0.0321   |
|    ent_coef_loss   | 0.692    |
|    learning_rate   | 0.000976 |
|    n_updates       | 239899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.76e+03 |
|    ep_rew_mean     | 789      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 38       |
|    time_elapsed    | 6208     |
|    total_timesteps | 240000   |
---------------------------------
Eval num_timesteps=250000, episode_reward=1566.50 +/- 961.33
Episode length: 3079.40 +/- 1517.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.08e+03 |
|    mean_reward     | 1.57e+03 |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -34.9    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0318   |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 0.000975 |
|    n_updates       | 249899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.87e+03 |
|    ep_rew_mean     | 839      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 38       |
|    time_elapsed    | 6467     |
|    total_timesteps | 252100   |
| train/             |          |
|    actor_loss      | -35.1    |
|    critic_loss     | 6.16     |
|    ent_coef        | 0.0307   |
|    ent_coef_loss   | -0.568   |
|    learning_rate   | 0.000975 |
|    n_updates       | 251999   |
---------------------------------
Eval num_timesteps=260000, episode_reward=2072.27 +/- 715.93
Episode length: 3483.60 +/- 168.10
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.48e+03 |
|    mean_reward     | 2.07e+03 |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -31.9    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0306   |
|    ent_coef_loss   | -0.211   |
|    learning_rate   | 0.000974 |
|    n_updates       | 259899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 902      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 39       |
|    time_elapsed    | 6771     |
|    total_timesteps | 266738   |
| train/             |          |
|    actor_loss      | -29.2    |
|    critic_loss     | 6.65     |
|    ent_coef        | 0.0293   |
|    ent_coef_loss   | 0.382    |
|    learning_rate   | 0.000973 |
|    n_updates       | 266637   |
---------------------------------
Eval num_timesteps=270000, episode_reward=2690.88 +/- 434.39
Episode length: 3886.00 +/- 597.44
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.89e+03 |
|    mean_reward     | 2.69e+03 |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -30      |
|    critic_loss     | 16.8     |
|    ent_coef        | 0.0258   |
|    ent_coef_loss   | -1.07    |
|    learning_rate   | 0.000973 |
|    n_updates       | 269899   |
---------------------------------
Eval num_timesteps=280000, episode_reward=1672.91 +/- 590.12
Episode length: 2897.00 +/- 1032.11
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.9e+03  |
|    mean_reward     | 1.67e+03 |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -38.5    |
|    critic_loss     | 1.62     |
|    ent_coef        | 0.0271   |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 0.000972 |
|    n_updates       | 279899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.09e+03 |
|    ep_rew_mean     | 926      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 39       |
|    time_elapsed    | 7138     |
|    total_timesteps | 282873   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 2.65     |
|    ent_coef        | 0.0269   |
|    ent_coef_loss   | -2.25    |
|    learning_rate   | 0.000972 |
|    n_updates       | 282772   |
---------------------------------
Eval num_timesteps=290000, episode_reward=2226.11 +/- 343.58
Episode length: 3286.80 +/- 222.82
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.29e+03 |
|    mean_reward     | 2.23e+03 |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -32.6    |
|    critic_loss     | 15.8     |
|    ent_coef        | 0.028    |
|    ent_coef_loss   | -0.0593  |
|    learning_rate   | 0.000971 |
|    n_updates       | 289899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.21e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 428      |
|    fps             | 39       |
|    time_elapsed    | 7427     |
|    total_timesteps | 297009   |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0228   |
|    ent_coef_loss   | 2.48     |
|    learning_rate   | 0.00097  |
|    n_updates       | 296908   |
---------------------------------
Eval num_timesteps=300000, episode_reward=1200.19 +/- 1141.83
Episode length: 2278.00 +/- 1850.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.28e+03 |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -27.5    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0233   |
|    ent_coef_loss   | 0.109    |
|    learning_rate   | 0.00097  |
|    n_updates       | 299899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.23e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 432      |
|    fps             | 40       |
|    time_elapsed    | 7609     |
|    total_timesteps | 305123   |
| train/             |          |
|    actor_loss      | -36.5    |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.0251   |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 0.000969 |
|    n_updates       | 305022   |
---------------------------------
Eval num_timesteps=310000, episode_reward=575.69 +/- 716.97
Episode length: 961.60 +/- 1331.48
---------------------------------
| eval/              |          |
|    mean_ep_length  | 962      |
|    mean_reward     | 576      |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -27      |
|    critic_loss     | 32.6     |
|    ent_coef        | 0.0281   |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 0.000969 |
|    n_updates       | 309899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.24e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 436      |
|    fps             | 40       |
|    time_elapsed    | 7763     |
|    total_timesteps | 312301   |
| train/             |          |
|    actor_loss      | -40.4    |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0257   |
|    ent_coef_loss   | -4.68    |
|    learning_rate   | 0.000969 |
|    n_updates       | 312200   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.23e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 440      |
|    fps             | 40       |
|    time_elapsed    | 7875     |
|    total_timesteps | 318470   |
| train/             |          |
|    actor_loss      | -29.2    |
|    critic_loss     | 6.59     |
|    ent_coef        | 0.0268   |
|    ent_coef_loss   | 0.0408   |
|    learning_rate   | 0.000968 |
|    n_updates       | 318369   |
---------------------------------
Eval num_timesteps=320000, episode_reward=1855.76 +/- 1964.96
Episode length: 2241.60 +/- 2252.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.24e+03 |
|    mean_reward     | 1.86e+03 |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 12.1     |
|    ent_coef        | 0.0268   |
|    ent_coef_loss   | 0.698    |
|    learning_rate   | 0.000968 |
|    n_updates       | 319899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 444      |
|    fps             | 40       |
|    time_elapsed    | 8039     |
|    total_timesteps | 325719   |
| train/             |          |
|    actor_loss      | -34      |
|    critic_loss     | 6.74     |
|    ent_coef        | 0.0268   |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 0.000967 |
|    n_updates       | 325618   |
---------------------------------
Eval num_timesteps=330000, episode_reward=2585.91 +/- 795.71
Episode length: 3508.60 +/- 540.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.51e+03 |
|    mean_reward     | 2.59e+03 |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -27.1    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0265   |
|    ent_coef_loss   | -0.342   |
|    learning_rate   | 0.000967 |
|    n_updates       | 329899   |
---------------------------------
Eval num_timesteps=340000, episode_reward=1485.39 +/- 296.57
Episode length: 3437.00 +/- 73.88
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.44e+03 |
|    mean_reward     | 1.49e+03 |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0252   |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.000966 |
|    n_updates       | 339899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.2e+03  |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 448      |
|    fps             | 40       |
|    time_elapsed    | 8443     |
|    total_timesteps | 344264   |
| train/             |          |
|    actor_loss      | -40.1    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.0263   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 0.000966 |
|    n_updates       | 344163   |
---------------------------------
Eval num_timesteps=350000, episode_reward=2410.38 +/- 643.27
Episode length: 3722.20 +/- 575.01
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.72e+03 |
|    mean_reward     | 2.41e+03 |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 3        |
|    ent_coef        | 0.0299   |
|    ent_coef_loss   | 0.178    |
|    learning_rate   | 0.000965 |
|    n_updates       | 349899   |
---------------------------------
Eval num_timesteps=360000, episode_reward=774.90 +/- 867.48
Episode length: 3470.20 +/- 839.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.47e+03 |
|    mean_reward     | 775      |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -47      |
|    critic_loss     | 5.17     |
|    ent_coef        | 0.0281   |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 0.000964 |
|    n_updates       | 359899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.22e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 452      |
|    fps             | 41       |
|    time_elapsed    | 8876     |
|    total_timesteps | 364456   |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.0256   |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 0.000964 |
|    n_updates       | 364355   |
---------------------------------
Eval num_timesteps=370000, episode_reward=2759.20 +/- 896.34
Episode length: 4269.60 +/- 473.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.27e+03 |
|    mean_reward     | 2.76e+03 |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -46.6    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0232   |
|    ent_coef_loss   | 0.604    |
|    learning_rate   | 0.000963 |
|    n_updates       | 369899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.34e+03 |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    episodes        | 456      |
|    fps             | 41       |
|    time_elapsed    | 9188     |
|    total_timesteps | 379919   |
| train/             |          |
|    actor_loss      | -34.8    |
|    critic_loss     | 2.12     |
|    ent_coef        | 0.0231   |
|    ent_coef_loss   | -2.58    |
|    learning_rate   | 0.000962 |
|    n_updates       | 379818   |
---------------------------------
Eval num_timesteps=380000, episode_reward=1950.80 +/- 408.41
Episode length: 3629.20 +/- 345.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.63e+03 |
|    mean_reward     | 1.95e+03 |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -48.8    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0223   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 0.000962 |
|    n_updates       | 379899   |
---------------------------------
Eval num_timesteps=390000, episode_reward=921.72 +/- 1290.25
Episode length: 3201.00 +/- 717.43
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.2e+03  |
|    mean_reward     | 922      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -33.7    |
|    critic_loss     | 7.67     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 0.000961 |
|    n_updates       | 389899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.46e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 460      |
|    fps             | 41       |
|    time_elapsed    | 9553     |
|    total_timesteps | 396351   |
| train/             |          |
|    actor_loss      | -34.9    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0202   |
|    ent_coef_loss   | 2.16     |
|    learning_rate   | 0.00096  |
|    n_updates       | 396250   |
---------------------------------
Eval num_timesteps=400000, episode_reward=2829.06 +/- 1217.91
Episode length: 3847.80 +/- 1619.22
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.85e+03 |
|    mean_reward     | 2.83e+03 |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -0.553   |
|    learning_rate   | 0.00096  |
|    n_updates       | 399899   |
---------------------------------
Eval num_timesteps=410000, episode_reward=881.30 +/- 1134.22
Episode length: 1985.40 +/- 1258.62
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.99e+03 |
|    mean_reward     | 881      |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 0.000959 |
|    n_updates       | 409899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.53e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 464      |
|    fps             | 41       |
|    time_elapsed    | 9917     |
|    total_timesteps | 413295   |
| train/             |          |
|    actor_loss      | -30.4    |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 0.000959 |
|    n_updates       | 413194   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.55e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 468      |
|    fps             | 41       |
|    time_elapsed    | 9995     |
|    total_timesteps | 417373   |
| train/             |          |
|    actor_loss      | -46.9    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.034    |
|    learning_rate   | 0.000958 |
|    n_updates       | 417272   |
---------------------------------
Eval num_timesteps=420000, episode_reward=233.00 +/- 1147.52
Episode length: 2721.80 +/- 1519.97
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.72e+03 |
|    mean_reward     | 233      |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -45.1    |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 9.81     |
|    learning_rate   | 0.000958 |
|    n_updates       | 419899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.54e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    episodes        | 472      |
|    fps             | 41       |
|    time_elapsed    | 10114    |
|    total_timesteps | 421758   |
| train/             |          |
|    actor_loss      | -34.2    |
|    critic_loss     | 8.42     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -1.87    |
|    learning_rate   | 0.000958 |
|    n_updates       | 421657   |
---------------------------------
Eval num_timesteps=430000, episode_reward=2224.90 +/- 437.79
Episode length: 3175.80 +/- 540.66
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.18e+03 |
|    mean_reward     | 2.22e+03 |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -31.7    |
|    critic_loss     | 42.7     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.000957 |
|    n_updates       | 429899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.54e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    episodes        | 476      |
|    fps             | 41       |
|    time_elapsed    | 10395    |
|    total_timesteps | 436264   |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 2.51     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 2.76     |
|    learning_rate   | 0.000956 |
|    n_updates       | 436163   |
---------------------------------
Eval num_timesteps=440000, episode_reward=1697.91 +/- 392.25
Episode length: 3383.80 +/- 35.17
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.38e+03 |
|    mean_reward     | 1.7e+03  |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.89    |
|    learning_rate   | 0.000956 |
|    n_updates       | 439899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.58e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    episodes        | 480      |
|    fps             | 42       |
|    time_elapsed    | 10613    |
|    total_timesteps | 446499   |
| train/             |          |
|    actor_loss      | -42.3    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.000955 |
|    n_updates       | 446398   |
---------------------------------
Eval num_timesteps=450000, episode_reward=1364.14 +/- 632.58
Episode length: 2687.80 +/- 239.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.69e+03 |
|    mean_reward     | 1.36e+03 |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -39.2    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 0.000955 |
|    n_updates       | 449899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.59e+03 |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 484      |
|    fps             | 42       |
|    time_elapsed    | 10855    |
|    total_timesteps | 458715   |
| train/             |          |
|    actor_loss      | -40.4    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 0.000954 |
|    n_updates       | 458614   |
---------------------------------
Eval num_timesteps=460000, episode_reward=1228.65 +/- 1774.52
Episode length: 3921.20 +/- 565.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.92e+03 |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -0.587   |
|    learning_rate   | 0.000954 |
|    n_updates       | 459899   |
---------------------------------
Eval num_timesteps=470000, episode_reward=1517.50 +/- 1452.86
Episode length: 3843.80 +/- 779.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.84e+03 |
|    mean_reward     | 1.52e+03 |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -31.6    |
|    critic_loss     | 5.77     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 3.38     |
|    learning_rate   | 0.000953 |
|    n_updates       | 469899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.61e+03 |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    episodes        | 488      |
|    fps             | 42       |
|    time_elapsed    | 11280    |
|    total_timesteps | 478899   |
| train/             |          |
|    actor_loss      | -35.5    |
|    critic_loss     | 14.6     |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -4.7     |
|    learning_rate   | 0.000952 |
|    n_updates       | 478798   |
---------------------------------
Eval num_timesteps=480000, episode_reward=1291.99 +/- 208.73
Episode length: 3399.40 +/- 69.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.4e+03  |
|    mean_reward     | 1.29e+03 |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -32.7    |
|    critic_loss     | 8.44     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 0.583    |
|    learning_rate   | 0.000952 |
|    n_updates       | 479899   |
---------------------------------
Eval num_timesteps=490000, episode_reward=2674.09 +/- 1167.75
Episode length: 3870.00 +/- 608.65
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.87e+03 |
|    mean_reward     | 2.67e+03 |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -28.5    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0208   |
|    ent_coef_loss   | 0.0191   |
|    learning_rate   | 0.000951 |
|    n_updates       | 489899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.62e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 492      |
|    fps             | 42       |
|    time_elapsed    | 11606    |
|    total_timesteps | 493371   |
| train/             |          |
|    actor_loss      | -29.5    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0205   |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 0.000951 |
|    n_updates       | 493270   |
---------------------------------
Eval num_timesteps=500000, episode_reward=1668.10 +/- 1073.67
Episode length: 3367.60 +/- 105.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.37e+03 |
|    mean_reward     | 1.67e+03 |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -27.8    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.02     |
|    ent_coef_loss   | 0.898    |
|    learning_rate   | 0.00095  |
|    n_updates       | 499899   |
---------------------------------
Eval num_timesteps=510000, episode_reward=1794.89 +/- 250.40
Episode length: 3371.80 +/- 8.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.37e+03 |
|    mean_reward     | 1.79e+03 |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -35.4    |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.0212   |
|    ent_coef_loss   | 0.779    |
|    learning_rate   | 0.000949 |
|    n_updates       | 509899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.7e+03  |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 496      |
|    fps             | 42       |
|    time_elapsed    | 12016    |
|    total_timesteps | 513530   |
| train/             |          |
|    actor_loss      | -31.5    |
|    critic_loss     | 14.5     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 0.000949 |
|    n_updates       | 513429   |
---------------------------------
Eval num_timesteps=520000, episode_reward=2272.41 +/- 1240.51
Episode length: 3698.60 +/- 686.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.7e+03  |
|    mean_reward     | 2.27e+03 |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -27.6    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 0.000948 |
|    n_updates       | 519899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.72e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    episodes        | 500      |
|    fps             | 42       |
|    time_elapsed    | 12266    |
|    total_timesteps | 525893   |
| train/             |          |
|    actor_loss      | -30.4    |
|    critic_loss     | 6.15     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 3        |
|    learning_rate   | 0.000947 |
|    n_updates       | 525792   |
---------------------------------
Eval num_timesteps=530000, episode_reward=1139.06 +/- 887.05
Episode length: 1988.40 +/- 1606.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.99e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -35.9    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -5.12    |
|    learning_rate   | 0.000947 |
|    n_updates       | 529899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.75e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    episodes        | 504      |
|    fps             | 42       |
|    time_elapsed    | 12455    |
|    total_timesteps | 535073   |
| train/             |          |
|    actor_loss      | -38.1    |
|    critic_loss     | 2.58     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 0.000946 |
|    n_updates       | 534972   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.61e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 508      |
|    fps             | 42       |
|    time_elapsed    | 12471    |
|    total_timesteps | 535303   |
| train/             |          |
|    actor_loss      | -37.3    |
|    critic_loss     | 19.9     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 0.116    |
|    learning_rate   | 0.000946 |
|    n_updates       | 535202   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.46e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    episodes        | 512      |
|    fps             | 42       |
|    time_elapsed    | 12487    |
|    total_timesteps | 535529   |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 0.000946 |
|    n_updates       | 535428   |
---------------------------------
Eval num_timesteps=540000, episode_reward=1342.75 +/- 916.26
Episode length: 2180.60 +/- 1315.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.18e+03 |
|    mean_reward     | 1.34e+03 |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 1.51     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 0.000946 |
|    n_updates       | 539899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.43e+03 |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 516      |
|    fps             | 43       |
|    time_elapsed    | 12744    |
|    total_timesteps | 548796   |
| train/             |          |
|    actor_loss      | -35      |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -3.84    |
|    learning_rate   | 0.000945 |
|    n_updates       | 548695   |
---------------------------------
Eval num_timesteps=550000, episode_reward=1698.91 +/- 964.83
Episode length: 3464.40 +/- 280.02
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.46e+03 |
|    mean_reward     | 1.7e+03  |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -28.6    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.166   |
|    learning_rate   | 0.000945 |
|    n_updates       | 549899   |
---------------------------------
Eval num_timesteps=560000, episode_reward=1721.91 +/- 698.23
Episode length: 3299.20 +/- 79.81
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.3e+03  |
|    mean_reward     | 1.72e+03 |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -35.2    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | -0.207   |
|    learning_rate   | 0.000944 |
|    n_updates       | 559899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.43e+03 |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 520      |
|    fps             | 43       |
|    time_elapsed    | 13124    |
|    total_timesteps | 566859   |
| train/             |          |
|    actor_loss      | -29      |
|    critic_loss     | 1.36     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 0.375    |
|    learning_rate   | 0.000943 |
|    n_updates       | 566758   |
---------------------------------
Eval num_timesteps=570000, episode_reward=2049.65 +/- 1407.45
Episode length: 3900.00 +/- 933.41
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.9e+03  |
|    mean_reward     | 2.05e+03 |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -36.6    |
|    critic_loss     | 2.33     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 0.000943 |
|    n_updates       | 569899   |
---------------------------------
Eval num_timesteps=580000, episode_reward=1626.35 +/- 777.28
Episode length: 3117.20 +/- 686.71
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.12e+03 |
|    mean_reward     | 1.63e+03 |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -44.4    |
|    critic_loss     | 1.44     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -3.8     |
|    learning_rate   | 0.000942 |
|    n_updates       | 579899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.44e+03 |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    episodes        | 524      |
|    fps             | 43       |
|    time_elapsed    | 13504    |
|    total_timesteps | 584617   |
| train/             |          |
|    actor_loss      | -38.4    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.72     |
|    learning_rate   | 0.000942 |
|    n_updates       | 584516   |
---------------------------------
Eval num_timesteps=590000, episode_reward=2044.25 +/- 785.53
Episode length: 3356.80 +/- 511.86
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.36e+03 |
|    mean_reward     | 2.04e+03 |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -37.8    |
|    critic_loss     | 5.33     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 0.000941 |
|    n_updates       | 589899   |
---------------------------------
Eval num_timesteps=600000, episode_reward=1777.48 +/- 1119.07
Episode length: 3651.40 +/- 1279.39
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.65e+03 |
|    mean_reward     | 1.78e+03 |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -35.1    |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -0.329   |
|    learning_rate   | 0.00094  |
|    n_updates       | 599899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.49e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 528      |
|    fps             | 43       |
|    time_elapsed    | 13925    |
|    total_timesteps | 605000   |
| train/             |          |
|    actor_loss      | -36.1    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 0.233    |
|    learning_rate   | 0.00094  |
|    n_updates       | 604899   |
---------------------------------
Eval num_timesteps=610000, episode_reward=1783.39 +/- 105.80
Episode length: 3481.40 +/- 72.18
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.48e+03 |
|    mean_reward     | 1.78e+03 |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -35.1    |
|    critic_loss     | 5.81     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 1.73     |
|    learning_rate   | 0.000939 |
|    n_updates       | 609899   |
---------------------------------
Eval num_timesteps=620000, episode_reward=2220.95 +/- 1137.83
Episode length: 3690.60 +/- 663.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.69e+03 |
|    mean_reward     | 2.22e+03 |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -37.4    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -3.1     |
|    learning_rate   | 0.000938 |
|    n_updates       | 619899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.55e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 532      |
|    fps             | 43       |
|    time_elapsed    | 14338    |
|    total_timesteps | 623002   |
| train/             |          |
|    actor_loss      | -39.4    |
|    critic_loss     | 0.74     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 0.000938 |
|    n_updates       | 622901   |
---------------------------------
Eval num_timesteps=630000, episode_reward=1531.54 +/- 157.77
Episode length: 3140.20 +/- 232.49
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.14e+03 |
|    mean_reward     | 1.53e+03 |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -33      |
|    critic_loss     | 2.58     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.286    |
|    learning_rate   | 0.000937 |
|    n_updates       | 629899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.61e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 536      |
|    fps             | 43       |
|    time_elapsed    | 14640    |
|    total_timesteps | 636729   |
| train/             |          |
|    actor_loss      | -36.6    |
|    critic_loss     | 6.99     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 0.000936 |
|    n_updates       | 636628   |
---------------------------------
Eval num_timesteps=640000, episode_reward=2877.55 +/- 976.83
Episode length: 4008.20 +/- 566.98
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.01e+03 |
|    mean_reward     | 2.88e+03 |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -35.8    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.21     |
|    learning_rate   | 0.000936 |
|    n_updates       | 639899   |
---------------------------------
Eval num_timesteps=650000, episode_reward=1394.98 +/- 1824.03
Episode length: 4212.60 +/- 291.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.21e+03 |
|    mean_reward     | 1.39e+03 |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -35.4    |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 0.000935 |
|    n_updates       | 649899   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.68e+03 |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 540      |
|    fps             | 43       |
|    time_elapsed    | 15132    |
|    total_timesteps | 656891   |
| train/             |          |
|    actor_loss      | -40.7    |
|    critic_loss     | 3.29     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 0.000934 |
|    n_updates       | 656790   |
---------------------------------
Eval num_timesteps=660000, episode_reward=2232.26 +/- 1006.04
Episode length: 3817.60 +/- 414.26
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.82e+03 |
|    mean_reward     | 2.23e+03 |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -40.8    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -2.19    |
|    learning_rate   | 0.000934 |
|    n_updates       | 659899   |
---------------------------------
Eval num_timesteps=670000, episode_reward=1891.17 +/- 744.89
Episode length: 3462.40 +/- 101.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.46e+03 |
|    mean_reward     | 1.89e+03 |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 0.000933 |
|    n_updates       | 669899   |
---------------------------------