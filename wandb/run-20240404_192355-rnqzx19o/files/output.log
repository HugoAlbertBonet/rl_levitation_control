Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_73
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 129      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 29       |
|    time_elapsed    | 24       |
|    total_timesteps | 716      |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 26.3     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 9.9      |
|    learning_rate   | 0.0001   |
|    n_updates       | 810514   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 145      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 32       |
|    time_elapsed    | 50       |
|    total_timesteps | 1629     |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.75     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 0.816    |
|    learning_rate   | 0.0001   |
|    n_updates       | 811427   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 188      |
|    ep_rew_mean     | 134      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 31       |
|    time_elapsed    | 72       |
|    total_timesteps | 2252     |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -6.4     |
|    learning_rate   | 0.0001   |
|    n_updates       | 812050   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 30       |
|    time_elapsed    | 93       |
|    total_timesteps | 2823     |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.3      |
|    learning_rate   | 0.0001   |
|    n_updates       | 812621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 165      |
|    ep_rew_mean     | 113      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 29       |
|    time_elapsed    | 112      |
|    total_timesteps | 3298     |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 6.52     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -0.859   |
|    learning_rate   | 0.0001   |
|    n_updates       | 813096   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 103      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 28       |
|    time_elapsed    | 128      |
|    total_timesteps | 3628     |
| train/             |          |
|    actor_loss      | -49.7    |
|    critic_loss     | 13.1     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -1.81    |
|    learning_rate   | 0.0001   |
|    n_updates       | 813426   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 98.1     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 27       |
|    time_elapsed    | 146      |
|    total_timesteps | 4055     |
| train/             |          |
|    actor_loss      | -48.3    |
|    critic_loss     | 9.79     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 3.26     |
|    learning_rate   | 0.0001   |
|    n_updates       | 813853   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 94.9     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 27       |
|    time_elapsed    | 165      |
|    total_timesteps | 4527     |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 4.92     |
|    learning_rate   | 0.0001   |
|    n_updates       | 814325   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 92.8     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 27       |
|    time_elapsed    | 183      |
|    total_timesteps | 5011     |
| train/             |          |
|    actor_loss      | -45.7    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 4.88     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 814809   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 93.4     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 27       |
|    time_elapsed    | 205      |
|    total_timesteps | 5617     |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 5.7      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 3.64     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 815415   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 93.5     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 27       |
|    time_elapsed    | 225      |
|    total_timesteps | 6189     |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 815987   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 92.6     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 27       |
|    time_elapsed    | 245      |
|    total_timesteps | 6718     |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.311    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 816516   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 91.8     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 27       |
|    time_elapsed    | 265      |
|    total_timesteps | 7242     |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 5.8      |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.959    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 817040   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 91       |
| time/              |          |
|    episodes        | 56       |
|    fps             | 27       |
|    time_elapsed    | 284      |
|    total_timesteps | 7764     |
| train/             |          |
|    actor_loss      | -41.4    |
|    critic_loss     | 8.52     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 0.183    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 817562   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 90.3     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 27       |
|    time_elapsed    | 305      |
|    total_timesteps | 8309     |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 4.37     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 0.0621   |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 818107   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | 89.2     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 27       |
|    time_elapsed    | 324      |
|    total_timesteps | 8823     |
| train/             |          |
|    actor_loss      | -43.4    |
|    critic_loss     | 6.97     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.23     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 818621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 88       |
| time/              |          |
|    episodes        | 68       |
|    fps             | 27       |
|    time_elapsed    | 343      |
|    total_timesteps | 9319     |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 5.35     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 0.743    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 819117   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | 87.1     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 27       |
|    time_elapsed    | 362      |
|    total_timesteps | 9813     |
| train/             |          |
|    actor_loss      | -39.5    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 819611   |
---------------------------------
Eval num_timesteps=10000, episode_reward=75.57 +/- 0.00
Episode length: 128.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 128      |
|    mean_reward     | 75.6     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -42.6    |
|    critic_loss     | 16.4     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -0.702   |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 819798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | 86.5     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 25       |
|    time_elapsed    | 399      |
|    total_timesteps | 10349    |
| train/             |          |
|    actor_loss      | -39.4    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 820147   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 85.6     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 25       |
|    time_elapsed    | 417      |
|    total_timesteps | 10747    |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 15.3     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 820545   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 85.6     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 25       |
|    time_elapsed    | 436      |
|    total_timesteps | 11238    |
| train/             |          |
|    actor_loss      | -40      |
|    critic_loss     | 8.79     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 0.289    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 821036   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | 85.8     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 25       |
|    time_elapsed    | 455      |
|    total_timesteps | 11764    |
| train/             |          |
|    actor_loss      | -35.5    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -1.48    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 821562   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | 86.3     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 25       |
|    time_elapsed    | 476      |
|    total_timesteps | 12346    |
| train/             |          |
|    actor_loss      | -37.9    |
|    critic_loss     | 6.51     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.29    |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 822144   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 89.3     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 26       |
|    time_elapsed    | 502      |
|    total_timesteps | 13209    |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 10       |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 6.8      |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 823007   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | 98       |
| time/              |          |
|    episodes        | 100      |
|    fps             | 27       |
|    time_elapsed    | 541      |
|    total_timesteps | 14842    |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 8.11     |
|    ent_coef        | 0.02     |
|    ent_coef_loss   | 7.82     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 824640   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 153      |
|    ep_rew_mean     | 102      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 27       |
|    time_elapsed    | 575      |
|    total_timesteps | 16104    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 8.23     |
|    ent_coef        | 0.0208   |
|    ent_coef_loss   | 4.3      |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 825902   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 159      |
|    ep_rew_mean     | 106      |
| time/              |          |
|    episodes        | 108      |
|    fps             | 28       |
|    time_elapsed    | 608      |
|    total_timesteps | 17591    |
| train/             |          |
|    actor_loss      | -35.5    |
|    critic_loss     | 13.6     |
|    ent_coef        | 0.0205   |
|    ent_coef_loss   | 0.998    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 827389   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 109      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 29       |
|    time_elapsed    | 637      |
|    total_timesteps | 18680    |
| train/             |          |
|    actor_loss      | -39      |
|    critic_loss     | 12.3     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 828478   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | 111      |
| time/              |          |
|    episodes        | 116      |
|    fps             | 29       |
|    time_elapsed    | 663      |
|    total_timesteps | 19667    |
| train/             |          |
|    actor_loss      | -37      |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -4.35    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 829465   |
---------------------------------
Eval num_timesteps=20000, episode_reward=130.88 +/- 0.00
Episode length: 201.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 201      |
|    mean_reward     | 131      |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -37.9    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 829798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 172      |
|    ep_rew_mean     | 114      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 29       |
|    time_elapsed    | 706      |
|    total_timesteps | 20634    |
| train/             |          |
|    actor_loss      | -36.9    |
|    critic_loss     | 7.54     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -1.44    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 830432   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 117      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 29       |
|    time_elapsed    | 728      |
|    total_timesteps | 21349    |
| train/             |          |
|    actor_loss      | -35.3    |
|    critic_loss     | 8.1      |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -2.06    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 831147   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 179      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 29       |
|    time_elapsed    | 750      |
|    total_timesteps | 22119    |
| train/             |          |
|    actor_loss      | -36.1    |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -2.99    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 831917   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 126      |
| time/              |          |
|    episodes        | 132      |
|    fps             | 29       |
|    time_elapsed    | 777      |
|    total_timesteps | 23144    |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 4.17     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 832942   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 191      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 30       |
|    time_elapsed    | 805      |
|    total_timesteps | 24317    |
| train/             |          |
|    actor_loss      | -36.5    |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.612    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 834115   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 195      |
|    ep_rew_mean     | 134      |
| time/              |          |
|    episodes        | 140      |
|    fps             | 30       |
|    time_elapsed    | 831      |
|    total_timesteps | 25282    |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 5.61     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.287   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 835080   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 201      |
|    ep_rew_mean     | 138      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 30       |
|    time_elapsed    | 859      |
|    total_timesteps | 26420    |
| train/             |          |
|    actor_loss      | -36.7    |
|    critic_loss     | 8.77     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 4.4      |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 836218   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 144      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 31       |
|    time_elapsed    | 894      |
|    total_timesteps | 27937    |
| train/             |          |
|    actor_loss      | -37.3    |
|    critic_loss     | 3        |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 0.441    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 837735   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 215      |
|    ep_rew_mean     | 147      |
| time/              |          |
|    episodes        | 152      |
|    fps             | 31       |
|    time_elapsed    | 920      |
|    total_timesteps | 28947    |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 0.0868   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 838745   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 31       |
|    time_elapsed    | 944      |
|    total_timesteps | 29810    |
| train/             |          |
|    actor_loss      | -37.6    |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 839608   |
---------------------------------
Eval num_timesteps=30000, episode_reward=116.55 +/- 0.00
Episode length: 190.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 190      |
|    mean_reward     | 117      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -39.2    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 3.73     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 839798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 31       |
|    time_elapsed    | 985      |
|    total_timesteps | 30723    |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -5.63    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 840521   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 152      |
| time/              |          |
|    episodes        | 164      |
|    fps             | 31       |
|    time_elapsed    | 1006     |
|    total_timesteps | 31417    |
| train/             |          |
|    actor_loss      | -39.1    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 2.67     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 841215   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 168      |
|    fps             | 31       |
|    time_elapsed    | 1027     |
|    total_timesteps | 32137    |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 841935   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    episodes        | 172      |
|    fps             | 31       |
|    time_elapsed    | 1055     |
|    total_timesteps | 33267    |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 1.44     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 843065   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    episodes        | 176      |
|    fps             | 31       |
|    time_elapsed    | 1073     |
|    total_timesteps | 33735    |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0199   |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 843533   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 232      |
|    ep_rew_mean     | 158      |
| time/              |          |
|    episodes        | 180      |
|    fps             | 31       |
|    time_elapsed    | 1092     |
|    total_timesteps | 34267    |
| train/             |          |
|    actor_loss      | -42.6    |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.0202   |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 844065   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 160      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 31       |
|    time_elapsed    | 1114     |
|    total_timesteps | 35039    |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 11.4     |
|    ent_coef        | 0.0203   |
|    ent_coef_loss   | 0.278    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 844837   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 165      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 31       |
|    time_elapsed    | 1142     |
|    total_timesteps | 36135    |
| train/             |          |
|    actor_loss      | -39.7    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0197   |
|    ent_coef_loss   | 1.22     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 845933   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 171      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 31       |
|    time_elapsed    | 1175     |
|    total_timesteps | 37584    |
| train/             |          |
|    actor_loss      | -41.1    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 847382   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 252      |
|    ep_rew_mean     | 173      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 32       |
|    time_elapsed    | 1203     |
|    total_timesteps | 38696    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | 0.113    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 848494   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 168      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 32       |
|    time_elapsed    | 1229     |
|    total_timesteps | 39741    |
| train/             |          |
|    actor_loss      | -37.9    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -1.56    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 849539   |
---------------------------------
Eval num_timesteps=40000, episode_reward=127.74 +/- 0.00
Episode length: 173.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 173      |
|    mean_reward     | 128      |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -38.9    |
|    critic_loss     | 5.09     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 849798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 164      |
| time/              |          |
|    episodes        | 204      |
|    fps             | 31       |
|    time_elapsed    | 1268     |
|    total_timesteps | 40564    |
| train/             |          |
|    actor_loss      | -40.1    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 0.504    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 850362   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 233      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 31       |
|    time_elapsed    | 1289     |
|    total_timesteps | 41240    |
| train/             |          |
|    actor_loss      | -35.1    |
|    critic_loss     | 2.86     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -0.0983  |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 851038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 31       |
|    time_elapsed    | 1309     |
|    total_timesteps | 41857    |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 4.3      |
|    ent_coef        | 0.0182   |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 851655   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 155      |
| time/              |          |
|    episodes        | 216      |
|    fps             | 31       |
|    time_elapsed    | 1328     |
|    total_timesteps | 42460    |
| train/             |          |
|    actor_loss      | -39.8    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -0.182   |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 852258   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 222      |
|    ep_rew_mean     | 154      |
| time/              |          |
|    episodes        | 220      |
|    fps             | 31       |
|    time_elapsed    | 1348     |
|    total_timesteps | 43075    |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 2.04     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 0.529    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 852873   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 224      |
|    fps             | 31       |
|    time_elapsed    | 1369     |
|    total_timesteps | 43743    |
| train/             |          |
|    actor_loss      | -35.9    |
|    critic_loss     | 2.35     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 853541   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 228      |
|    fps             | 31       |
|    time_elapsed    | 1390     |
|    total_timesteps | 44439    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 1.85     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 3.16     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 854237   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 218      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    episodes        | 232      |
|    fps             | 31       |
|    time_elapsed    | 1412     |
|    total_timesteps | 45188    |
| train/             |          |
|    actor_loss      | -37.9    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 854986   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 32       |
|    time_elapsed    | 1441     |
|    total_timesteps | 46466    |
| train/             |          |
|    actor_loss      | -36.2    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 856264   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 240      |
|    fps             | 32       |
|    time_elapsed    | 1467     |
|    total_timesteps | 47477    |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -0.466   |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 857275   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 219      |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 244      |
|    fps             | 32       |
|    time_elapsed    | 1495     |
|    total_timesteps | 48599    |
| train/             |          |
|    actor_loss      | -35.3    |
|    critic_loss     | 2.42     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 858397   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | 150      |
| time/              |          |
|    episodes        | 248      |
|    fps             | 32       |
|    time_elapsed    | 1526     |
|    total_timesteps | 49954    |
| train/             |          |
|    actor_loss      | -39.2    |
|    critic_loss     | 5.63     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 859752   |
---------------------------------
Eval num_timesteps=50000, episode_reward=183.44 +/- 0.00
Episode length: 252.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 252      |
|    mean_reward     | 183      |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 2.33     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 859798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 221      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 32       |
|    time_elapsed    | 1575     |
|    total_timesteps | 51353    |
| train/             |          |
|    actor_loss      | -36.7    |
|    critic_loss     | 3.43     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -0.944   |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 861151   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 32       |
|    time_elapsed    | 1605     |
|    total_timesteps | 52597    |
| train/             |          |
|    actor_loss      | -36.9    |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 862395   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 162      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 32       |
|    time_elapsed    | 1635     |
|    total_timesteps | 53933    |
| train/             |          |
|    actor_loss      | -37.9    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 863731   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 237      |
|    ep_rew_mean     | 167      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 33       |
|    time_elapsed    | 1666     |
|    total_timesteps | 55275    |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 865073   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | 172      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 33       |
|    time_elapsed    | 1698     |
|    total_timesteps | 56686    |
| train/             |          |
|    actor_loss      | -36.7    |
|    critic_loss     | 1.91     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 866484   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | 177      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 33       |
|    time_elapsed    | 1734     |
|    total_timesteps | 58354    |
| train/             |          |
|    actor_loss      | -36.6    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -0.772   |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 868152   |
---------------------------------
Eval num_timesteps=60000, episode_reward=244.20 +/- 0.00
Episode length: 369.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 369      |
|    mean_reward     | 244      |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 2.16     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -5.59    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 869798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 264      |
|    ep_rew_mean     | 186      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 33       |
|    time_elapsed    | 1795     |
|    total_timesteps | 60482    |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 2.02     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 0.163    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 870280   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 195      |
| time/              |          |
|    episodes        | 280      |
|    fps             | 34       |
|    time_elapsed    | 1835     |
|    total_timesteps | 62480    |
| train/             |          |
|    actor_loss      | -35.9    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.56     |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 872278   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 202      |
| time/              |          |
|    episodes        | 284      |
|    fps             | 34       |
|    time_elapsed    | 1873     |
|    total_timesteps | 64353    |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -3.72    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 874151   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 205      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 34       |
|    time_elapsed    | 1908     |
|    total_timesteps | 65864    |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 875662   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 296      |
|    ep_rew_mean     | 207      |
| time/              |          |
|    episodes        | 292      |
|    fps             | 34       |
|    time_elapsed    | 1945     |
|    total_timesteps | 67617    |
| train/             |          |
|    actor_loss      | -40      |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 877415   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 302      |
|    ep_rew_mean     | 210      |
| time/              |          |
|    episodes        | 296      |
|    fps             | 34       |
|    time_elapsed    | 1981     |
|    total_timesteps | 69261    |
| train/             |          |
|    actor_loss      | -37.5    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -3.23    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 879059   |
---------------------------------
Eval num_timesteps=70000, episode_reward=345.51 +/- 0.00
Episode length: 513.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 513      |
|    mean_reward     | 346      |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 2.58     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 1.53     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 879798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 214      |
| time/              |          |
|    episodes        | 300      |
|    fps             | 34       |
|    time_elapsed    | 2037     |
|    total_timesteps | 71043    |
| train/             |          |
|    actor_loss      | -37.6    |
|    critic_loss     | 3.48     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.646    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 880841   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 316      |
|    ep_rew_mean     | 220      |
| time/              |          |
|    episodes        | 304      |
|    fps             | 35       |
|    time_elapsed    | 2071     |
|    total_timesteps | 72643    |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 1.85     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 882441   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 225      |
| time/              |          |
|    episodes        | 308      |
|    fps             | 35       |
|    time_elapsed    | 2104     |
|    total_timesteps | 74090    |
| train/             |          |
|    actor_loss      | -35.3    |
|    critic_loss     | 2.05     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 883888   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 331      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    episodes        | 312      |
|    fps             | 35       |
|    time_elapsed    | 2135     |
|    total_timesteps | 75450    |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 885248   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 337      |
|    ep_rew_mean     | 234      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 35       |
|    time_elapsed    | 2163     |
|    total_timesteps | 76613    |
| train/             |          |
|    actor_loss      | -36.6    |
|    critic_loss     | 3.65     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 886411   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 345      |
|    ep_rew_mean     | 240      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 35       |
|    time_elapsed    | 2195     |
|    total_timesteps | 78084    |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -3.98    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 887882   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 356      |
|    ep_rew_mean     | 247      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 35       |
|    time_elapsed    | 2233     |
|    total_timesteps | 79821    |
| train/             |          |
|    actor_loss      | -35.8    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 0.226    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 889619   |
---------------------------------
Eval num_timesteps=80000, episode_reward=329.03 +/- 0.00
Episode length: 482.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 482      |
|    mean_reward     | 329      |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -34.1    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 889798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 35       |
|    time_elapsed    | 2297     |
|    total_timesteps | 82159    |
| train/             |          |
|    actor_loss      | -36.5    |
|    critic_loss     | 2.63     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 891957   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 35       |
|    time_elapsed    | 2331     |
|    total_timesteps | 83656    |
| train/             |          |
|    actor_loss      | -33.8    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -3.85    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 893454   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 35       |
|    time_elapsed    | 2364     |
|    total_timesteps | 85130    |
| train/             |          |
|    actor_loss      | -38.1    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 894928   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 272      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 36       |
|    time_elapsed    | 2400     |
|    total_timesteps | 86766    |
| train/             |          |
|    actor_loss      | -33.1    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.797    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 896564   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | 277      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 36       |
|    time_elapsed    | 2437     |
|    total_timesteps | 88459    |
| train/             |          |
|    actor_loss      | -36      |
|    critic_loss     | 2.09     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 898257   |
---------------------------------
Eval num_timesteps=90000, episode_reward=205.22 +/- 0.00
Episode length: 271.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 271      |
|    mean_reward     | 205      |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 5.14     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 899798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 36       |
|    time_elapsed    | 2490     |
|    total_timesteps | 90283    |
| train/             |          |
|    actor_loss      | -34.5    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.5      |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 900081   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 395      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 36       |
|    time_elapsed    | 2523     |
|    total_timesteps | 91751    |
| train/             |          |
|    actor_loss      | -37.6    |
|    critic_loss     | 2.95     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 901549   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 395      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 36       |
|    time_elapsed    | 2554     |
|    total_timesteps | 93065    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -0.797   |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 902863   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 36       |
|    time_elapsed    | 2586     |
|    total_timesteps | 94486    |
| train/             |          |
|    actor_loss      | -36      |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 904284   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 284      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 36       |
|    time_elapsed    | 2616     |
|    total_timesteps | 95816    |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -0.534   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 905614   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 36       |
|    time_elapsed    | 2650     |
|    total_timesteps | 97358    |
| train/             |          |
|    actor_loss      | -38.7    |
|    critic_loss     | 2.45     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.0651  |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 907156   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 399      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 36       |
|    time_elapsed    | 2688     |
|    total_timesteps | 99215    |
| train/             |          |
|    actor_loss      | -36      |
|    critic_loss     | 2.42     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.997    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 909013   |
---------------------------------
Eval num_timesteps=100000, episode_reward=375.67 +/- 0.00
Episode length: 521.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 521      |
|    mean_reward     | 376      |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -35.7    |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 909798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 399      |
|    ep_rew_mean     | 289      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 36       |
|    time_elapsed    | 2751     |
|    total_timesteps | 101452   |
| train/             |          |
|    actor_loss      | -36.4    |
|    critic_loss     | 2.47     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -4.02    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 911250   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 286      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 36       |
|    time_elapsed    | 2783     |
|    total_timesteps | 102870   |
| train/             |          |
|    actor_loss      | -37.5    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -1.61    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 912668   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 37       |
|    time_elapsed    | 2815     |
|    total_timesteps | 104271   |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 0.0178   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 914069   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 37       |
|    time_elapsed    | 2847     |
|    total_timesteps | 105642   |
| train/             |          |
|    actor_loss      | -34.8    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 0.597    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 915440   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 37       |
|    time_elapsed    | 2878     |
|    total_timesteps | 107075   |
| train/             |          |
|    actor_loss      | -36.4    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 2.86     |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 916873   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 279      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 37       |
|    time_elapsed    | 2912     |
|    total_timesteps | 108562   |
| train/             |          |
|    actor_loss      | -36.2    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 918360   |
---------------------------------
Eval num_timesteps=110000, episode_reward=360.49 +/- 0.00
Episode length: 547.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 547      |
|    mean_reward     | 360      |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -34.7    |
|    critic_loss     | 3.02     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 0.0833   |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 919798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 37       |
|    time_elapsed    | 2976     |
|    total_timesteps | 110926   |
| train/             |          |
|    actor_loss      | -34.6    |
|    critic_loss     | 2.52     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -1.58    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 920724   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 37       |
|    time_elapsed    | 3013     |
|    total_timesteps | 112571   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 2.87     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -5.06    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 922369   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 387      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 37       |
|    time_elapsed    | 3046     |
|    total_timesteps | 114099   |
| train/             |          |
|    actor_loss      | -34.9    |
|    critic_loss     | 2.16     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 2        |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 923897   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 282      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 37       |
|    time_elapsed    | 3076     |
|    total_timesteps | 115366   |
| train/             |          |
|    actor_loss      | -36.9    |
|    critic_loss     | 1.87     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.014    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 925164   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 283      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 37       |
|    time_elapsed    | 3107     |
|    total_timesteps | 116739   |
| train/             |          |
|    actor_loss      | -36.9    |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 0.774    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 926537   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 37       |
|    time_elapsed    | 3137     |
|    total_timesteps | 117959   |
| train/             |          |
|    actor_loss      | -36.7    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -0.171   |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 927757   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 280      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 37       |
|    time_elapsed    | 3173     |
|    total_timesteps | 119583   |
| train/             |          |
|    actor_loss      | -34.4    |
|    critic_loss     | 2.34     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -3.71    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 929381   |
---------------------------------
Eval num_timesteps=120000, episode_reward=207.59 +/- 0.00
Episode length: 282.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 282      |
|    mean_reward     | 208      |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -36.2    |
|    critic_loss     | 3.7      |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 929798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 376      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 37       |
|    time_elapsed    | 3223     |
|    total_timesteps | 121037   |
| train/             |          |
|    actor_loss      | -35      |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -4.38    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 930835   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 37       |
|    time_elapsed    | 3254     |
|    total_timesteps | 122417   |
| train/             |          |
|    actor_loss      | -34.9    |
|    critic_loss     | 3.55     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -5.61    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 932215   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 273      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 37       |
|    time_elapsed    | 3288     |
|    total_timesteps | 124014   |
| train/             |          |
|    actor_loss      | -36      |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.0939   |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 933812   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    episodes        | 440      |
|    fps             | 37       |
|    time_elapsed    | 3321     |
|    total_timesteps | 125469   |
| train/             |          |
|    actor_loss      | -37      |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 935267   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 444      |
|    fps             | 37       |
|    time_elapsed    | 3356     |
|    total_timesteps | 127030   |
| train/             |          |
|    actor_loss      | -37.8    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.4     |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 936828   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 269      |
| time/              |          |
|    episodes        | 448      |
|    fps             | 37       |
|    time_elapsed    | 3390     |
|    total_timesteps | 128527   |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 2.04     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 2.91     |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 938325   |
---------------------------------
Eval num_timesteps=130000, episode_reward=199.37 +/- 0.00
Episode length: 283.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 283      |
|    mean_reward     | 199      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -35      |
|    critic_loss     | 1.94     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 939798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 452      |
|    fps             | 37       |
|    time_elapsed    | 3446     |
|    total_timesteps | 130383   |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 5.36     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 3.55     |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 940181   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 456      |
|    fps             | 37       |
|    time_elapsed    | 3478     |
|    total_timesteps | 131861   |
| train/             |          |
|    actor_loss      | -38.8    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.602   |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 941659   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 460      |
|    fps             | 37       |
|    time_elapsed    | 3511     |
|    total_timesteps | 133315   |
| train/             |          |
|    actor_loss      | -35.2    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.161    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 943113   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 379      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    episodes        | 464      |
|    fps             | 38       |
|    time_elapsed    | 3544     |
|    total_timesteps | 134767   |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 2.01     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.204    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 944565   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 270      |
| time/              |          |
|    episodes        | 468      |
|    fps             | 38       |
|    time_elapsed    | 3577     |
|    total_timesteps | 136229   |
| train/             |          |
|    actor_loss      | -35      |
|    critic_loss     | 2.63     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 946027   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    episodes        | 472      |
|    fps             | 38       |
|    time_elapsed    | 3609     |
|    total_timesteps | 137574   |
| train/             |          |
|    actor_loss      | -35.6    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.272   |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 947372   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 369      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    episodes        | 476      |
|    fps             | 38       |
|    time_elapsed    | 3642     |
|    total_timesteps | 139041   |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 2.54     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.529    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 948839   |
---------------------------------
Eval num_timesteps=140000, episode_reward=259.50 +/- 0.00
Episode length: 360.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 360      |
|    mean_reward     | 260      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -35      |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 1.43     |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 949798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 370      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 480      |
|    fps             | 38       |
|    time_elapsed    | 3694     |
|    total_timesteps | 140713   |
| train/             |          |
|    actor_loss      | -34.2    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 950511   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 373      |
|    ep_rew_mean     | 267      |
| time/              |          |
|    episodes        | 484      |
|    fps             | 38       |
|    time_elapsed    | 3730     |
|    total_timesteps | 142406   |
| train/             |          |
|    actor_loss      | -36.3    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.661   |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 952204   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 271      |
| time/              |          |
|    episodes        | 488      |
|    fps             | 38       |
|    time_elapsed    | 3769     |
|    total_timesteps | 144238   |
| train/             |          |
|    actor_loss      | -35.3    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -0.919   |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 954036   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    episodes        | 492      |
|    fps             | 38       |
|    time_elapsed    | 3808     |
|    total_timesteps | 146103   |
| train/             |          |
|    actor_loss      | -34.2    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 0.727    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 955901   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 276      |
| time/              |          |
|    episodes        | 496      |
|    fps             | 38       |
|    time_elapsed    | 3843     |
|    total_timesteps | 147713   |
| train/             |          |
|    actor_loss      | -34.4    |
|    critic_loss     | 3.05     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 0.794    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 957511   |
---------------------------------
Eval num_timesteps=150000, episode_reward=387.25 +/- 0.00
Episode length: 520.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 520      |
|    mean_reward     | 387      |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -35.4    |
|    critic_loss     | 2.34     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 1.32     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 959798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 281      |
| time/              |          |
|    episodes        | 500      |
|    fps             | 38       |
|    time_elapsed    | 3916     |
|    total_timesteps | 150656   |
| train/             |          |
|    actor_loss      | -39.8    |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 960454   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 288      |
| time/              |          |
|    episodes        | 504      |
|    fps             | 38       |
|    time_elapsed    | 3964     |
|    total_timesteps | 153097   |
| train/             |          |
|    actor_loss      | -36.9    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -0.687   |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 962895   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 293      |
| time/              |          |
|    episodes        | 508      |
|    fps             | 38       |
|    time_elapsed    | 4008     |
|    total_timesteps | 155223   |
| train/             |          |
|    actor_loss      | -37.2    |
|    critic_loss     | 4.21     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.0761   |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 965021   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | 298      |
| time/              |          |
|    episodes        | 512      |
|    fps             | 38       |
|    time_elapsed    | 4048     |
|    total_timesteps | 157123   |
| train/             |          |
|    actor_loss      | -36.5    |
|    critic_loss     | 5.46     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 966921   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | 301      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 38       |
|    time_elapsed    | 4083     |
|    total_timesteps | 158711   |
| train/             |          |
|    actor_loss      | -34.7    |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 968509   |
---------------------------------
Eval num_timesteps=160000, episode_reward=391.37 +/- 0.00
Episode length: 542.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 542      |
|    mean_reward     | 391      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -39.9    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.1     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 969798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 304      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 38       |
|    time_elapsed    | 4137     |
|    total_timesteps | 160387   |
| train/             |          |
|    actor_loss      | -34.8    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 970185   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 414      |
|    ep_rew_mean     | 305      |
| time/              |          |
|    episodes        | 524      |
|    fps             | 38       |
|    time_elapsed    | 4172     |
|    total_timesteps | 162045   |
| train/             |          |
|    actor_loss      | -39.8    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 971843   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 310      |
| time/              |          |
|    episodes        | 528      |
|    fps             | 38       |
|    time_elapsed    | 4212     |
|    total_timesteps | 163909   |
| train/             |          |
|    actor_loss      | -38.3    |
|    critic_loss     | 3.65     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.853    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 973707   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 426      |
|    ep_rew_mean     | 315      |
| time/              |          |
|    episodes        | 532      |
|    fps             | 39       |
|    time_elapsed    | 4254     |
|    total_timesteps | 165948   |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 2.41     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -2.35    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 975746   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 429      |
|    ep_rew_mean     | 318      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 39       |
|    time_elapsed    | 4293     |
|    total_timesteps | 167849   |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -0.0822  |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 977647   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 433      |
|    ep_rew_mean     | 322      |
| time/              |          |
|    episodes        | 540      |
|    fps             | 39       |
|    time_elapsed    | 4332     |
|    total_timesteps | 169744   |
| train/             |          |
|    actor_loss      | -36.8    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 4.24     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 979542   |
---------------------------------
Eval num_timesteps=170000, episode_reward=373.72 +/- 0.00
Episode length: 495.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 495      |
|    mean_reward     | 374      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.35     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 979798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 436      |
|    ep_rew_mean     | 324      |
| time/              |          |
|    episodes        | 544      |
|    fps             | 39       |
|    time_elapsed    | 4393     |
|    total_timesteps | 171898   |
| train/             |          |
|    actor_loss      | -37.7    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -4.13    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 981696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 442      |
|    ep_rew_mean     | 329      |
| time/              |          |
|    episodes        | 548      |
|    fps             | 39       |
|    time_elapsed    | 4436     |
|    total_timesteps | 173973   |
| train/             |          |
|    actor_loss      | -38.2    |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -2.44    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 983771   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 445      |
|    ep_rew_mean     | 332      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 39       |
|    time_elapsed    | 4476     |
|    total_timesteps | 175894   |
| train/             |          |
|    actor_loss      | -40.3    |
|    critic_loss     | 3.08     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 985692   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 335      |
| time/              |          |
|    episodes        | 556      |
|    fps             | 39       |
|    time_elapsed    | 4515     |
|    total_timesteps | 177763   |
| train/             |          |
|    actor_loss      | -42.8    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 987561   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 449      |
|    ep_rew_mean     | 335      |
| time/              |          |
|    episodes        | 560      |
|    fps             | 39       |
|    time_elapsed    | 4548     |
|    total_timesteps | 179300   |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -0.625   |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 989098   |
---------------------------------
Eval num_timesteps=180000, episode_reward=262.13 +/- 0.00
Episode length: 376.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 376      |
|    mean_reward     | 262      |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -39.4    |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 989798   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 337      |
| time/              |          |
|    episodes        | 564      |
|    fps             | 39       |
|    time_elapsed    | 4606     |
|    total_timesteps | 181210   |
| train/             |          |
|    actor_loss      | -39.4    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 5.47     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 991008   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 454      |
|    ep_rew_mean     | 338      |
| time/              |          |
|    episodes        | 568      |
|    fps             | 39       |
|    time_elapsed    | 4642     |
|    total_timesteps | 182913   |
| train/             |          |
|    actor_loss      | -41.8    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 3.23     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 992711   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 456      |
|    ep_rew_mean     | 340      |
| time/              |          |
|    episodes        | 572      |
|    fps             | 39       |
|    time_elapsed    | 4677     |
|    total_timesteps | 184463   |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 994261   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 460      |
|    ep_rew_mean     | 342      |
| time/              |          |
|    episodes        | 576      |
|    fps             | 39       |
|    time_elapsed    | 4715     |
|    total_timesteps | 186299   |
| train/             |          |
|    actor_loss      | -41.9    |
|    critic_loss     | 2.48     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 996097   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 464      |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 580      |
|    fps             | 39       |
|    time_elapsed    | 4753     |
|    total_timesteps | 188172   |
| train/             |          |
|    actor_loss      | -40.2    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 997970   |
---------------------------------
Eval num_timesteps=190000, episode_reward=395.40 +/- 0.00
Episode length: 537.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 537      |
|    mean_reward     | 395      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 2.07     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 0.612    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 999798   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 467      |
|    ep_rew_mean     | 347      |
| time/              |          |
|    episodes        | 584      |
|    fps             | 39       |
|    time_elapsed    | 4818     |
|    total_timesteps | 190489   |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 1.66     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1000287  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 469      |
|    ep_rew_mean     | 350      |
| time/              |          |
|    episodes        | 588      |
|    fps             | 39       |
|    time_elapsed    | 4860     |
|    total_timesteps | 192528   |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 3.16     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1002326  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 471      |
|    ep_rew_mean     | 352      |
| time/              |          |
|    episodes        | 592      |
|    fps             | 39       |
|    time_elapsed    | 4902     |
|    total_timesteps | 194632   |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 2.47     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -0.214   |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1004430  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 482      |
|    ep_rew_mean     | 361      |
| time/              |          |
|    episodes        | 596      |
|    fps             | 39       |
|    time_elapsed    | 4953     |
|    total_timesteps | 197323   |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 2.5      |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 2.34     |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1007121  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 484      |
|    ep_rew_mean     | 362      |
| time/              |          |
|    episodes        | 600      |
|    fps             | 39       |
|    time_elapsed    | 5004     |
|    total_timesteps | 199967   |
| train/             |          |
|    actor_loss      | -42.9    |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.2      |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1009765  |
---------------------------------
Eval num_timesteps=200000, episode_reward=571.05 +/- 0.00
Episode length: 723.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 723      |
|    mean_reward     | 571      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.498   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1009798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 486      |
|    ep_rew_mean     | 364      |
| time/              |          |
|    episodes        | 604      |
|    fps             | 39       |
|    time_elapsed    | 5075     |
|    total_timesteps | 202629   |
| train/             |          |
|    actor_loss      | -42.5    |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -3.66    |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1012427  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 488      |
|    ep_rew_mean     | 366      |
| time/              |          |
|    episodes        | 608      |
|    fps             | 40       |
|    time_elapsed    | 5121     |
|    total_timesteps | 204935   |
| train/             |          |
|    actor_loss      | -41.6    |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1014733  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 490      |
|    ep_rew_mean     | 369      |
| time/              |          |
|    episodes        | 612      |
|    fps             | 40       |
|    time_elapsed    | 5163     |
|    total_timesteps | 207096   |
| train/             |          |
|    actor_loss      | -43.2    |
|    critic_loss     | 2.31     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 0.00754  |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1016894  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 497      |
|    ep_rew_mean     | 374      |
| time/              |          |
|    episodes        | 616      |
|    fps             | 40       |
|    time_elapsed    | 5208     |
|    total_timesteps | 209333   |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 1.78     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -0.157   |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1019131  |
---------------------------------
Eval num_timesteps=210000, episode_reward=553.20 +/- 0.00
Episode length: 724.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 724      |
|    mean_reward     | 553      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -42.2    |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 3.34     |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1019798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 503      |
|    ep_rew_mean     | 380      |
| time/              |          |
|    episodes        | 620      |
|    fps             | 40       |
|    time_elapsed    | 5275     |
|    total_timesteps | 211726   |
| train/             |          |
|    actor_loss      | -41      |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -0.824   |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1021524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 509      |
|    ep_rew_mean     | 385      |
| time/              |          |
|    episodes        | 624      |
|    fps             | 40       |
|    time_elapsed    | 5319     |
|    total_timesteps | 213963   |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 2.28     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 1023761  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 516      |
|    ep_rew_mean     | 390      |
| time/              |          |
|    episodes        | 628      |
|    fps             | 40       |
|    time_elapsed    | 5367     |
|    total_timesteps | 216509   |
| train/             |          |
|    actor_loss      | -41.5    |
|    critic_loss     | 1.94     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -0.618   |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1026307  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 520      |
|    ep_rew_mean     | 393      |
| time/              |          |
|    episodes        | 632      |
|    fps             | 40       |
|    time_elapsed    | 5415     |
|    total_timesteps | 218909   |
| train/             |          |
|    actor_loss      | -43      |
|    critic_loss     | 2.55     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1028707  |
---------------------------------
Eval num_timesteps=220000, episode_reward=541.01 +/- 0.00
Episode length: 699.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 699      |
|    mean_reward     | 541      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -41.2    |
|    critic_loss     | 1.77     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1029798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 530      |
|    ep_rew_mean     | 402      |
| time/              |          |
|    episodes        | 636      |
|    fps             | 40       |
|    time_elapsed    | 5495     |
|    total_timesteps | 222148   |
| train/             |          |
|    actor_loss      | -39.6    |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 1031946  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 540      |
|    ep_rew_mean     | 410      |
| time/              |          |
|    episodes        | 640      |
|    fps             | 40       |
|    time_elapsed    | 5550     |
|    total_timesteps | 225055   |
| train/             |          |
|    actor_loss      | -40.5    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1034853  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 558      |
|    ep_rew_mean     | 425      |
| time/              |          |
|    episodes        | 644      |
|    fps             | 40       |
|    time_elapsed    | 5618     |
|    total_timesteps | 228724   |
| train/             |          |
|    actor_loss      | -41.8    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1038522  |
---------------------------------
Eval num_timesteps=230000, episode_reward=772.69 +/- 0.00
Episode length: 950.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 950      |
|    mean_reward     | 773      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -41.3    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.644    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1039798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 574      |
|    ep_rew_mean     | 439      |
| time/              |          |
|    episodes        | 648      |
|    fps             | 40       |
|    time_elapsed    | 5714     |
|    total_timesteps | 232857   |
| train/             |          |
|    actor_loss      | -43.3    |
|    critic_loss     | 2        |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 1042655  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 595      |
|    ep_rew_mean     | 457      |
| time/              |          |
|    episodes        | 652      |
|    fps             | 40       |
|    time_elapsed    | 5786     |
|    total_timesteps | 236895   |
| train/             |          |
|    actor_loss      | -42.1    |
|    critic_loss     | 1.73     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1046693  |
---------------------------------
Eval num_timesteps=240000, episode_reward=1026.58 +/- 0.00
Episode length: 1298.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.3e+03  |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 1.94     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.0125  |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1049798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 618      |
|    ep_rew_mean     | 476      |
| time/              |          |
|    episodes        | 656      |
|    fps             | 41       |
|    time_elapsed    | 5900     |
|    total_timesteps | 242069   |
| train/             |          |
|    actor_loss      | -44.2    |
|    critic_loss     | 2.3      |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.72    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 1051867  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 640      |
|    ep_rew_mean     | 495      |
| time/              |          |
|    episodes        | 660      |
|    fps             | 41       |
|    time_elapsed    | 5966     |
|    total_timesteps | 245822   |
| train/             |          |
|    actor_loss      | -44.6    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.277    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1055620  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 662      |
|    ep_rew_mean     | 514      |
| time/              |          |
|    episodes        | 664      |
|    fps             | 41       |
|    time_elapsed    | 6037     |
|    total_timesteps | 249649   |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 0.966    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1059447  |
---------------------------------
Eval num_timesteps=250000, episode_reward=831.65 +/- 0.00
Episode length: 1026.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 832      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -47.2    |
|    critic_loss     | 1.65     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1059798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 682      |
|    ep_rew_mean     | 531      |
| time/              |          |
|    episodes        | 668      |
|    fps             | 41       |
|    time_elapsed    | 6132     |
|    total_timesteps | 253729   |
| train/             |          |
|    actor_loss      | -46      |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 1063527  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 701      |
|    ep_rew_mean     | 548      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 41       |
|    time_elapsed    | 6194     |
|    total_timesteps | 257221   |
| train/             |          |
|    actor_loss      | -50.2    |
|    critic_loss     | 1.63     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -0.271   |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1067019  |
---------------------------------
Eval num_timesteps=260000, episode_reward=580.27 +/- 0.00
Episode length: 727.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 727      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -47.8    |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -0.225   |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1069798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 564      |
| time/              |          |
|    episodes        | 676      |
|    fps             | 41       |
|    time_elapsed    | 6284     |
|    total_timesteps | 261008   |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 2.34     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -0.175   |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1070806  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 575      |
| time/              |          |
|    episodes        | 680      |
|    fps             | 41       |
|    time_elapsed    | 6344     |
|    total_timesteps | 264213   |
| train/             |          |
|    actor_loss      | -50.8    |
|    critic_loss     | 2.62     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 1074011  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 584      |
| time/              |          |
|    episodes        | 684      |
|    fps             | 41       |
|    time_elapsed    | 6401     |
|    total_timesteps | 267281   |
| train/             |          |
|    actor_loss      | -46.8    |
|    critic_loss     | 2.5      |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.26     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1077079  |
---------------------------------
Eval num_timesteps=270000, episode_reward=664.39 +/- 0.00
Episode length: 873.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 873      |
|    mean_reward     | 664      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 3.09     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1079798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 688      |
|    fps             | 41       |
|    time_elapsed    | 6487     |
|    total_timesteps | 270893   |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1080691  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 773      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 692      |
|    fps             | 41       |
|    time_elapsed    | 6554     |
|    total_timesteps | 274475   |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.79    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 1084273  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 780      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 696      |
|    fps             | 42       |
|    time_elapsed    | 6617     |
|    total_timesteps | 277943   |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 2.37     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.02    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1087741  |
---------------------------------
Eval num_timesteps=280000, episode_reward=864.46 +/- 0.00
Episode length: 1108.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 864      |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -44.9    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.8      |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1089798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 624      |
| time/              |          |
|    episodes        | 700      |
|    fps             | 42       |
|    time_elapsed    | 6715     |
|    total_timesteps | 282149   |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 2.52     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.698    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 1091947  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 704      |
|    fps             | 42       |
|    time_elapsed    | 6791     |
|    total_timesteps | 286491   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1096289  |
---------------------------------
Eval num_timesteps=290000, episode_reward=799.92 +/- 0.00
Episode length: 1009.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 800      |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 2.57     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.487   |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1099798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 826      |
|    ep_rew_mean     | 653      |
| time/              |          |
|    episodes        | 708      |
|    fps             | 42       |
|    time_elapsed    | 6895     |
|    total_timesteps | 291102   |
| train/             |          |
|    actor_loss      | -50.5    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 0.43     |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 1100900  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 857      |
|    ep_rew_mean     | 680      |
| time/              |          |
|    episodes        | 712      |
|    fps             | 42       |
|    time_elapsed    | 6984     |
|    total_timesteps | 296341   |
| train/             |          |
|    actor_loss      | -50.2    |
|    critic_loss     | 5.02     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -0.887   |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 1106139  |
---------------------------------
Eval num_timesteps=300000, episode_reward=1025.64 +/- 0.00
Episode length: 1261.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 1109798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 897      |
|    ep_rew_mean     | 715      |
| time/              |          |
|    episodes        | 716      |
|    fps             | 42       |
|    time_elapsed    | 7122     |
|    total_timesteps | 303098   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 1.96     |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 1112896  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 739      |
| time/              |          |
|    episodes        | 720      |
|    fps             | 42       |
|    time_elapsed    | 7209     |
|    total_timesteps | 308125   |
| train/             |          |
|    actor_loss      | -51.1    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 3.03     |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1117923  |
---------------------------------
Eval num_timesteps=310000, episode_reward=1134.21 +/- 0.00
Episode length: 1376.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 8.06     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 0.569    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1119798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 952      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 724      |
|    fps             | 42       |
|    time_elapsed    | 7331     |
|    total_timesteps | 313855   |
| train/             |          |
|    actor_loss      | -51.1    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -4.14    |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 1123653  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 976      |
|    ep_rew_mean     | 781      |
| time/              |          |
|    episodes        | 728      |
|    fps             | 42       |
|    time_elapsed    | 7417     |
|    total_timesteps | 318786   |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1128584  |
---------------------------------
Eval num_timesteps=320000, episode_reward=929.12 +/- 0.00
Episode length: 1175.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 929      |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 2.57     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 1129798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 810      |
| time/              |          |
|    episodes        | 732      |
|    fps             | 43       |
|    time_elapsed    | 7560     |
|    total_timesteps | 325904   |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1135702  |
---------------------------------
Eval num_timesteps=330000, episode_reward=1227.05 +/- 0.00
Episode length: 1525.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.52e+03 |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 1.65     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 0.614    |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1139798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 835      |
| time/              |          |
|    episodes        | 736      |
|    fps             | 43       |
|    time_elapsed    | 7694     |
|    total_timesteps | 332387   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 3.37     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 0.32     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 1142185  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 854      |
| time/              |          |
|    episodes        | 740      |
|    fps             | 43       |
|    time_elapsed    | 7782     |
|    total_timesteps | 337535   |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 1.81     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1147333  |
---------------------------------
Eval num_timesteps=340000, episode_reward=1021.30 +/- 0.00
Episode length: 1240.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 1.76     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.328   |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1149798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 871      |
| time/              |          |
|    episodes        | 744      |
|    fps             | 43       |
|    time_elapsed    | 7919     |
|    total_timesteps | 344196   |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 2.42     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 1153994  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 882      |
| time/              |          |
|    episodes        | 748      |
|    fps             | 43       |
|    time_elapsed    | 8003     |
|    total_timesteps | 349087   |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 2.5      |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.249   |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1158885  |
---------------------------------
Eval num_timesteps=350000, episode_reward=936.08 +/- 0.00
Episode length: 1173.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 936      |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.923   |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 1159798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 752      |
|    fps             | 43       |
|    time_elapsed    | 8143     |
|    total_timesteps | 355985   |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.365    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1165783  |
---------------------------------
Eval num_timesteps=360000, episode_reward=1026.56 +/- 0.00
Episode length: 1236.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1169798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 910      |
| time/              |          |
|    episodes        | 756      |
|    fps             | 43       |
|    time_elapsed    | 8276     |
|    total_timesteps | 362553   |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 2.3      |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -3.68    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 1172351  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 925      |
| time/              |          |
|    episodes        | 760      |
|    fps             | 43       |
|    time_elapsed    | 8373     |
|    total_timesteps | 368117   |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 2.02     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1177915  |
---------------------------------
Eval num_timesteps=370000, episode_reward=892.04 +/- 0.00
Episode length: 1114.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 892      |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 2.86     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 0.739    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1179798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    episodes        | 764      |
|    fps             | 44       |
|    time_elapsed    | 8491     |
|    total_timesteps | 373829   |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 2.52     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -0.901   |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 1183627  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 950      |
| time/              |          |
|    episodes        | 768      |
|    fps             | 44       |
|    time_elapsed    | 8581     |
|    total_timesteps | 378961   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1188759  |
---------------------------------
Eval num_timesteps=380000, episode_reward=1099.95 +/- 0.00
Episode length: 1366.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.37e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 2.59     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 1189798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 968      |
| time/              |          |
|    episodes        | 772      |
|    fps             | 44       |
|    time_elapsed    | 8715     |
|    total_timesteps | 385524   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 2.28     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1195322  |
---------------------------------
Eval num_timesteps=390000, episode_reward=968.25 +/- 0.00
Episode length: 1202.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 968      |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 2.75     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1199798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 985      |
| time/              |          |
|    episodes        | 776      |
|    fps             | 44       |
|    time_elapsed    | 8857     |
|    total_timesteps | 392762   |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 2.95     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 1.94     |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 1202560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 780      |
|    fps             | 44       |
|    time_elapsed    | 8943     |
|    total_timesteps | 398175   |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 3.27     |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1207973  |
---------------------------------
Eval num_timesteps=400000, episode_reward=1139.16 +/- 0.00
Episode length: 1383.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -53.2    |
|    critic_loss     | 1.48     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 2.66     |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1209798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 784      |
|    fps             | 44       |
|    time_elapsed    | 9054     |
|    total_timesteps | 403762   |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 1.85     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 2.5      |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 1213560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 788      |
|    fps             | 44       |
|    time_elapsed    | 9132     |
|    total_timesteps | 408587   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 0.471    |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1218385  |
---------------------------------
Eval num_timesteps=410000, episode_reward=1007.73 +/- 0.00
Episode length: 1247.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 3        |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 1219798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 792      |
|    fps             | 44       |
|    time_elapsed    | 9257     |
|    total_timesteps | 415301   |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 1.61     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 3.66     |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1225099  |
---------------------------------
Eval num_timesteps=420000, episode_reward=872.78 +/- 0.00
Episode length: 1110.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 873      |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 2.14     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -1.56    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1229798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.3e+03  |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 796      |
|    fps             | 44       |
|    time_elapsed    | 9373     |
|    total_timesteps | 421353   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 2.61     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -0.78    |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 1231151  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.32e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    episodes        | 800      |
|    fps             | 45       |
|    time_elapsed    | 9458     |
|    total_timesteps | 426653   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1236451  |
---------------------------------
Eval num_timesteps=430000, episode_reward=893.53 +/- 0.00
Episode length: 1119.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 894      |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 2.18     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -2.34    |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1239798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    episodes        | 804      |
|    fps             | 45       |
|    time_elapsed    | 9573     |
|    total_timesteps | 432660   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 1242458  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.34e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 808      |
|    fps             | 45       |
|    time_elapsed    | 9661     |
|    total_timesteps | 438168   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 1.8      |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | -0.737   |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1247966  |
---------------------------------
Eval num_timesteps=440000, episode_reward=1122.98 +/- 0.00
Episode length: 1376.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -3.36    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1249798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.35e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 812      |
|    fps             | 45       |
|    time_elapsed    | 9772     |
|    total_timesteps | 443890   |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 1.76     |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 1253688  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.34e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 816      |
|    fps             | 45       |
|    time_elapsed    | 9866     |
|    total_timesteps | 449810   |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 2.67     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 1259608  |
---------------------------------
Eval num_timesteps=450000, episode_reward=930.91 +/- 0.00
Episode length: 1139.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.14e+03 |
|    mean_reward     | 931      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 2.12     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -0.00201 |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 1259798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.34e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 820      |
|    fps             | 45       |
|    time_elapsed    | 9971     |
|    total_timesteps | 455152   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 5.81     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 4.52     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1264950  |
---------------------------------
Eval num_timesteps=460000, episode_reward=1229.37 +/- 0.00
Episode length: 1513.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.51e+03 |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 1.18     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 0.355    |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1269798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.35e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 824      |
|    fps             | 45       |
|    time_elapsed    | 10092    |
|    total_timesteps | 461517   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 2.32     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 1.81     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 1271315  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 828      |
|    fps             | 45       |
|    time_elapsed    | 10182    |
|    total_timesteps | 467178   |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 2.05     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -0.405   |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1276976  |
---------------------------------
Eval num_timesteps=470000, episode_reward=1246.77 +/- 0.00
Episode length: 1527.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 2.78     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1279798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.35e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 832      |
|    fps             | 45       |
|    time_elapsed    | 10308    |
|    total_timesteps | 473839   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.3     |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 1283637  |
---------------------------------
Eval num_timesteps=480000, episode_reward=854.69 +/- 0.00
Episode length: 1079.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 855      |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 1.25     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -4.58    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 1289798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 836      |
|    fps             | 46       |
|    time_elapsed    | 10441    |
|    total_timesteps | 481193   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 1.75     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 1290991  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.37e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 840      |
|    fps             | 46       |
|    time_elapsed    | 10539    |
|    total_timesteps | 487424   |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 1.93     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1297222  |
---------------------------------
Eval num_timesteps=490000, episode_reward=847.84 +/- 0.00
Episode length: 1089.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 848      |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 1.52     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.79    |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1299798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.37e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 844      |
|    fps             | 46       |
|    time_elapsed    | 10671    |
|    total_timesteps | 494658   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 1.55     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 1304456  |
---------------------------------
Eval num_timesteps=500000, episode_reward=904.89 +/- 0.00
Episode length: 1162.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 905      |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 1309798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.39e+03 |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 848      |
|    fps             | 46       |
|    time_elapsed    | 10798    |
|    total_timesteps | 501489   |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 5.61     |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 1311287  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 852      |
|    fps             | 46       |
|    time_elapsed    | 10876    |
|    total_timesteps | 506318   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 2.25     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -0.697   |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1316116  |
---------------------------------
Eval num_timesteps=510000, episode_reward=865.84 +/- 0.00
Episode length: 1100.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.1e+03  |
|    mean_reward     | 866      |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 2.59     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1319798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.37e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 856      |
|    fps             | 46       |
|    time_elapsed    | 10976    |
|    total_timesteps | 511326   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -2.75    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 1321124  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.37e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 860      |
|    fps             | 46       |
|    time_elapsed    | 11070    |
|    total_timesteps | 517282   |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 2.07     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -0.856   |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1327080  |
---------------------------------
Eval num_timesteps=520000, episode_reward=748.85 +/- 0.00
Episode length: 961.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 961      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 2.02     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | 2.22     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1329798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 864      |
|    fps             | 46       |
|    time_elapsed    | 11176    |
|    total_timesteps | 522727   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 1.59     |
|    ent_coef        | 0.00991  |
|    ent_coef_loss   | -0.731   |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 1332525  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 868      |
|    fps             | 46       |
|    time_elapsed    | 11265    |
|    total_timesteps | 528271   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 1.35     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1338069  |
---------------------------------
Eval num_timesteps=530000, episode_reward=1069.67 +/- 0.00
Episode length: 1314.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 1.3      |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -3.38    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1339798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 872      |
|    fps             | 46       |
|    time_elapsed    | 11376    |
|    total_timesteps | 534000   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 1.54     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 1343798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 876      |
|    fps             | 47       |
|    time_elapsed    | 11466    |
|    total_timesteps | 539658   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 2.16     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -4.23    |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1349456  |
---------------------------------
Eval num_timesteps=540000, episode_reward=1095.06 +/- 0.00
Episode length: 1377.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 1.78     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 1349798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 880      |
|    fps             | 47       |
|    time_elapsed    | 11586    |
|    total_timesteps | 545952   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 1.82     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1355750  |
---------------------------------
Eval num_timesteps=550000, episode_reward=949.85 +/- 0.00
Episode length: 1182.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 950      |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 1.77     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -0.0143  |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1359798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.4e+03  |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 884      |
|    fps             | 47       |
|    time_elapsed    | 11715    |
|    total_timesteps | 552866   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -2.84    |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 1362664  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.41e+03 |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    episodes        | 888      |
|    fps             | 47       |
|    time_elapsed    | 11810    |
|    total_timesteps | 558862   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 2.11     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1368660  |
---------------------------------
Eval num_timesteps=560000, episode_reward=1422.02 +/- 0.00
Episode length: 1716.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.72e+03 |
|    mean_reward     | 1.42e+03 |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 2        |
|    ent_coef        | 0.00997  |
|    ent_coef_loss   | -0.0538  |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 1369798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    episodes        | 892      |
|    fps             | 47       |
|    time_elapsed    | 11950    |
|    total_timesteps | 566440   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.00995  |
|    ent_coef_loss   | -3.12    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1376238  |
---------------------------------
Eval num_timesteps=570000, episode_reward=1081.57 +/- 0.00
Episode length: 1311.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 1.96     |
|    ent_coef        | 0.00976  |
|    ent_coef_loss   | 2.19     |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1379798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 896      |
|    fps             | 47       |
|    time_elapsed    | 12081    |
|    total_timesteps | 573543   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 1.64     |
|    ent_coef        | 0.00932  |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 1383341  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 900      |
|    fps             | 47       |
|    time_elapsed    | 12168    |
|    total_timesteps | 579015   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.00981  |
|    ent_coef_loss   | -1.57    |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 1388813  |
---------------------------------
Eval num_timesteps=580000, episode_reward=1242.48 +/- 0.00
Episode length: 1535.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.54e+03 |
|    mean_reward     | 1.24e+03 |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 1389798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 904      |
|    fps             | 47       |
|    time_elapsed    | 12315    |
|    total_timesteps | 587097   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 2.23     |
|    ent_coef        | 0.00964  |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1396895  |
---------------------------------
Eval num_timesteps=590000, episode_reward=1360.31 +/- 0.00
Episode length: 1636.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.64e+03 |
|    mean_reward     | 1.36e+03 |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 1.64     |
|    ent_coef        | 0.00941  |
|    ent_coef_loss   | 2.81     |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1399798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 908      |
|    fps             | 47       |
|    time_elapsed    | 12429    |
|    total_timesteps | 592838   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 1.33     |
|    ent_coef        | 0.00948  |
|    ent_coef_loss   | -0.997   |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 1402636  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 912      |
|    fps             | 47       |
|    time_elapsed    | 12529    |
|    total_timesteps | 599150   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 1.36     |
|    ent_coef        | 0.00994  |
|    ent_coef_loss   | -1.65    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1408948  |
---------------------------------
Eval num_timesteps=600000, episode_reward=989.50 +/- 0.00
Episode length: 1210.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 990      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 2.71     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 1409798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 916      |
|    fps             | 47       |
|    time_elapsed    | 12659    |
|    total_timesteps | 606144   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.00993  |
|    ent_coef_loss   | 0.156    |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1415942  |
---------------------------------
Eval num_timesteps=610000, episode_reward=1224.85 +/- 0.00
Episode length: 1460.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.46e+03 |
|    mean_reward     | 1.22e+03 |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 1.52     |
|    ent_coef        | 0.00944  |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1419798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 920      |
|    fps             | 47       |
|    time_elapsed    | 12765    |
|    total_timesteps | 611454   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.00947  |
|    ent_coef_loss   | 4.59     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 1421252  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.48e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 924      |
|    fps             | 48       |
|    time_elapsed    | 12861    |
|    total_timesteps | 617591   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.00979  |
|    ent_coef_loss   | 1.97     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 1427389  |
---------------------------------
Eval num_timesteps=620000, episode_reward=1551.03 +/- 0.00
Episode length: 1822.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.82e+03 |
|    mean_reward     | 1.55e+03 |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 1.44     |
|    ent_coef        | 0.00973  |
|    ent_coef_loss   | 0.786    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 1429798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.5e+03  |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 928      |
|    fps             | 48       |
|    time_elapsed    | 13003    |
|    total_timesteps | 625251   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.00953  |
|    ent_coef_loss   | -0.33    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1435049  |
---------------------------------
Eval num_timesteps=630000, episode_reward=1171.56 +/- 0.00
Episode length: 1424.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.17e+03 |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.26     |
|    ent_coef        | 0.00946  |
|    ent_coef_loss   | 0.149    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1439798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.51e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    episodes        | 932      |
|    fps             | 48       |
|    time_elapsed    | 13150    |
|    total_timesteps | 633428   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 1.54     |
|    ent_coef        | 0.00903  |
|    ent_coef_loss   | 0.931    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 1443226  |
---------------------------------
Eval num_timesteps=640000, episode_reward=1121.33 +/- 0.00
Episode length: 1389.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 2.03     |
|    ent_coef        | 0.00933  |
|    ent_coef_loss   | -3.51    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1449798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.52e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    episodes        | 936      |
|    fps             | 48       |
|    time_elapsed    | 13293    |
|    total_timesteps | 641260   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 1.52     |
|    ent_coef        | 0.00914  |
|    ent_coef_loss   | 0.213    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 1451058  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.53e+03 |
|    ep_rew_mean     | 1.26e+03 |
| time/              |          |
|    episodes        | 940      |
|    fps             | 48       |
|    time_elapsed    | 13407    |
|    total_timesteps | 648666   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.00896  |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1458464  |
---------------------------------
Eval num_timesteps=650000, episode_reward=1769.02 +/- 0.00
Episode length: 2143.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.14e+03 |
|    mean_reward     | 1.77e+03 |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 1.77     |
|    ent_coef        | 0.00892  |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 1459798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.54e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 944      |
|    fps             | 48       |
|    time_elapsed    | 13558    |
|    total_timesteps | 656866   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 1.67     |
|    ent_coef        | 0.0087   |
|    ent_coef_loss   | -3.52    |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 1466664  |
---------------------------------
Eval num_timesteps=660000, episode_reward=1581.29 +/- 0.00
Episode length: 1833.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.83e+03 |
|    mean_reward     | 1.58e+03 |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 1.76     |
|    ent_coef        | 0.00841  |
|    ent_coef_loss   | -3.3     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 1469798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.57e+03 |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    episodes        | 948      |
|    fps             | 48       |
|    time_elapsed    | 13726    |
|    total_timesteps | 666348   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 1.2      |
|    ent_coef        | 0.00925  |
|    ent_coef_loss   | -5.2     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1476146  |
---------------------------------
Eval num_timesteps=670000, episode_reward=1670.70 +/- 0.00
Episode length: 2019.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.02e+03 |
|    mean_reward     | 1.67e+03 |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 1.6      |
|    ent_coef        | 0.00882  |
|    ent_coef_loss   | 0.345    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 1479798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.61e+03 |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 952      |
|    fps             | 48       |
|    time_elapsed    | 13908    |
|    total_timesteps | 676741   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 1.59     |
|    ent_coef        | 0.00851  |
|    ent_coef_loss   | -0.765   |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1486539  |
---------------------------------
Eval num_timesteps=680000, episode_reward=1335.98 +/- 0.00
Episode length: 1582.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.58e+03 |
|    mean_reward     | 1.34e+03 |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.00875  |
|    ent_coef_loss   | 3.82     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 1489798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 956      |
|    fps             | 48       |
|    time_elapsed    | 14064    |
|    total_timesteps | 685567   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 1.1      |
|    ent_coef        | 0.0084   |
|    ent_coef_loss   | 0.634    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1495365  |
---------------------------------
Eval num_timesteps=690000, episode_reward=1889.00 +/- 0.00
Episode length: 2272.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.27e+03 |
|    mean_reward     | 1.89e+03 |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.00887  |
|    ent_coef_loss   | -2.79    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1499798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 960      |
|    fps             | 48       |
|    time_elapsed    | 14215    |
|    total_timesteps | 693775   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 1.62     |
|    ent_coef        | 0.0087   |
|    ent_coef_loss   | -1.38    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 1503573  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 964      |
|    fps             | 48       |
|    time_elapsed    | 14310    |
|    total_timesteps | 699812   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 1.58     |
|    ent_coef        | 0.00833  |
|    ent_coef_loss   | -3.08    |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1509610  |
---------------------------------
Eval num_timesteps=700000, episode_reward=1443.49 +/- 0.00
Episode length: 1742.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.74e+03 |
|    mean_reward     | 1.44e+03 |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.00826  |
|    ent_coef_loss   | 0.92     |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 1509798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 968      |
|    fps             | 48       |
|    time_elapsed    | 14428    |
|    total_timesteps | 705811   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 1.34     |
|    ent_coef        | 0.00815  |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1515609  |
---------------------------------
Eval num_timesteps=710000, episode_reward=452.37 +/- 0.00
Episode length: 604.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 604      |
|    mean_reward     | 452      |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 1.98     |
|    ent_coef        | 0.00824  |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1519798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    episodes        | 972      |
|    fps             | 48       |
|    time_elapsed    | 14526    |
|    total_timesteps | 710858   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 1.23     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | -4.67    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 1520656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 976      |
|    fps             | 49       |
|    time_elapsed    | 14604    |
|    total_timesteps | 715701   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 1.95     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | -3.37    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1525499  |
---------------------------------
Eval num_timesteps=720000, episode_reward=1187.93 +/- 0.00
Episode length: 1416.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.19e+03 |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.00857  |
|    ent_coef_loss   | 0.49     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1529798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 980      |
|    fps             | 49       |
|    time_elapsed    | 14720    |
|    total_timesteps | 721628   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 2.4      |
|    ent_coef        | 0.00822  |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 1531426  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 984      |
|    fps             | 49       |
|    time_elapsed    | 14815    |
|    total_timesteps | 727669   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 1.95     |
|    ent_coef        | 0.00833  |
|    ent_coef_loss   | 0.248    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1537467  |
---------------------------------
Eval num_timesteps=730000, episode_reward=1256.46 +/- 0.00
Episode length: 1541.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.54e+03 |
|    mean_reward     | 1.26e+03 |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 1.29     |
|    ent_coef        | 0.00826  |
|    ent_coef_loss   | -4.68    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1539798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 988      |
|    fps             | 49       |
|    time_elapsed    | 14948    |
|    total_timesteps | 734812   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 2.22     |
|    ent_coef        | 0.00835  |
|    ent_coef_loss   | 0.12     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 1544610  |
---------------------------------
Eval num_timesteps=740000, episode_reward=1265.75 +/- 0.00
Episode length: 1539.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.54e+03 |
|    mean_reward     | 1.27e+03 |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.00827  |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1549798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 992      |
|    fps             | 49       |
|    time_elapsed    | 15086    |
|    total_timesteps | 742301   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.00809  |
|    ent_coef_loss   | 2.53     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 1552099  |
---------------------------------
Eval num_timesteps=750000, episode_reward=1431.54 +/- 0.00
Episode length: 1758.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.76e+03 |
|    mean_reward     | 1.43e+03 |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 2.21     |
|    ent_coef        | 0.00837  |
|    ent_coef_loss   | 7.64     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1559798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    episodes        | 996      |
|    fps             | 49       |
|    time_elapsed    | 15244    |
|    total_timesteps | 751169   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 1.55     |
|    ent_coef        | 0.00836  |
|    ent_coef_loss   | 6.94     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 1560967  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 49       |
|    time_elapsed    | 15320    |
|    total_timesteps | 755818   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.00796  |
|    ent_coef_loss   | -0.324   |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1565616  |
---------------------------------
Eval num_timesteps=760000, episode_reward=1213.67 +/- 0.00
Episode length: 1511.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.51e+03 |
|    mean_reward     | 1.21e+03 |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.00829  |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1569798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.63e+03 |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 49       |
|    time_elapsed    | 15461    |
|    total_timesteps | 763387   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.00801  |
|    ent_coef_loss   | -4.04    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 1573185  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 49       |
|    time_elapsed    | 15560    |
|    total_timesteps | 769589   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.00839  |
|    ent_coef_loss   | 5.35     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1579387  |
---------------------------------
Eval num_timesteps=770000, episode_reward=1959.35 +/- 0.00
Episode length: 2302.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.3e+03  |
|    mean_reward     | 1.96e+03 |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.00843  |
|    ent_coef_loss   | -3.29    |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 1579798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 49       |
|    time_elapsed    | 15700    |
|    total_timesteps | 777030   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 1.64     |
|    ent_coef        | 0.00842  |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1586828  |
---------------------------------
Eval num_timesteps=780000, episode_reward=1455.96 +/- 0.00
Episode length: 1754.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.75e+03 |
|    mean_reward     | 1.46e+03 |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 2.1      |
|    ent_coef        | 0.00825  |
|    ent_coef_loss   | -0.315   |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1589798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 49       |
|    time_elapsed    | 15830    |
|    total_timesteps | 783844   |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 2.33     |
|    ent_coef        | 0.00852  |
|    ent_coef_loss   | -1.77    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 1593642  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.63e+03 |
|    ep_rew_mean     | 1.35e+03 |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 49       |
|    time_elapsed    | 15902    |
|    total_timesteps | 788212   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.00886  |
|    ent_coef_loss   | 2.18     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1598010  |
---------------------------------
Eval num_timesteps=790000, episode_reward=995.10 +/- 0.00
Episode length: 1195.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 995      |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.00852  |
|    ent_coef_loss   | -4.9     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1599798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 49       |
|    time_elapsed    | 16013    |
|    total_timesteps | 793936   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.00811  |
|    ent_coef_loss   | 0.126    |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 1603734  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.6e+03  |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 49       |
|    time_elapsed    | 16100    |
|    total_timesteps | 799428   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 1.84     |
|    ent_coef        | 0.00807  |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1609226  |
---------------------------------
Eval num_timesteps=800000, episode_reward=1185.07 +/- 0.00
Episode length: 1430.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.43e+03 |
|    mean_reward     | 1.19e+03 |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 1.44     |
|    ent_coef        | 0.0081   |
|    ent_coef_loss   | 0.67     |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 1609798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.59e+03 |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 49       |
|    time_elapsed    | 16220    |
|    total_timesteps | 805670   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 2.13     |
|    ent_coef        | 0.00848  |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1615468  |
---------------------------------
Eval num_timesteps=810000, episode_reward=1403.13 +/- 0.00
Episode length: 1717.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.72e+03 |
|    mean_reward     | 1.4e+03  |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 1.37     |
|    ent_coef        | 0.00868  |
|    ent_coef_loss   | -1.57    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1619798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.58e+03 |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 49       |
|    time_elapsed    | 16354    |
|    total_timesteps | 812879   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 2.04     |
|    ent_coef        | 0.00854  |
|    ent_coef_loss   | -0.146   |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 1622677  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.57e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 49       |
|    time_elapsed    | 16455    |
|    total_timesteps | 819384   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 2.53     |
|    ent_coef        | 0.0086   |
|    ent_coef_loss   | 0.358    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1629182  |
---------------------------------
Eval num_timesteps=820000, episode_reward=1517.95 +/- 0.00
Episode length: 1868.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.87e+03 |
|    mean_reward     | 1.52e+03 |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 1.58     |
|    ent_coef        | 0.00866  |
|    ent_coef_loss   | 2.94     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 1629798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.57e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 49       |
|    time_elapsed    | 16599    |
|    total_timesteps | 827062   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 1.63     |
|    ent_coef        | 0.0084   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1636860  |
---------------------------------
Eval num_timesteps=830000, episode_reward=1626.91 +/- 0.00
Episode length: 1979.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.98e+03 |
|    mean_reward     | 1.63e+03 |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.00853  |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1639798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.55e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 49       |
|    time_elapsed    | 16744    |
|    total_timesteps | 834809   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 1.36     |
|    ent_coef        | 0.0084   |
|    ent_coef_loss   | 0.0491   |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 1644607  |
---------------------------------
Eval num_timesteps=840000, episode_reward=1526.12 +/- 0.00
Episode length: 1895.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.9e+03  |
|    mean_reward     | 1.53e+03 |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.00859  |
|    ent_coef_loss   | 2.18     |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1649798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.52e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 49       |
|    time_elapsed    | 16870    |
|    total_timesteps | 841329   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 2.17     |
|    ent_coef        | 0.00848  |
|    ent_coef_loss   | 3.57     |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 1651127  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.5e+03  |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 49       |
|    time_elapsed    | 16977    |
|    total_timesteps | 848116   |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 2.69     |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1657914  |
---------------------------------
Eval num_timesteps=850000, episode_reward=2053.71 +/- 0.00
Episode length: 2530.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.53e+03 |
|    mean_reward     | 2.05e+03 |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 1.64     |
|    ent_coef        | 0.00837  |
|    ent_coef_loss   | 0.696    |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1659798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 49       |
|    time_elapsed    | 17110    |
|    total_timesteps | 854813   |
| train/             |          |
|    actor_loss      | -66.3    |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.00792  |
|    ent_coef_loss   | -4.52    |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 1664611  |
---------------------------------
Eval num_timesteps=860000, episode_reward=2017.99 +/- 0.00
Episode length: 2493.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.49e+03 |
|    mean_reward     | 2.02e+03 |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 2.35     |
|    ent_coef        | 0.00816  |
|    ent_coef_loss   | -0.283   |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 1669798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.5e+03  |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 49       |
|    time_elapsed    | 17266    |
|    total_timesteps | 863257   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 1.64     |
|    ent_coef        | 0.00794  |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 1673055  |
---------------------------------
Eval num_timesteps=870000, episode_reward=1642.91 +/- 0.00
Episode length: 1968.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.97e+03 |
|    mean_reward     | 1.64e+03 |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.00819  |
|    ent_coef_loss   | 0.704    |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1679798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.51e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 50       |
|    time_elapsed    | 17422    |
|    total_timesteps | 871946   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.00822  |
|    ent_coef_loss   | -0.139   |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 1681744  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.54e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 50       |
|    time_elapsed    | 17537    |
|    total_timesteps | 879367   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 1.38     |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | -2.38    |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1689165  |
---------------------------------
Eval num_timesteps=880000, episode_reward=1440.05 +/- 0.00
Episode length: 1717.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.72e+03 |
|    mean_reward     | 1.44e+03 |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 2.63     |
|    ent_coef        | 0.00797  |
|    ent_coef_loss   | 2        |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 1689798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.58e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 50       |
|    time_elapsed    | 17698    |
|    total_timesteps | 888396   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 2.35     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 7.46     |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 1698194  |
---------------------------------
Eval num_timesteps=890000, episode_reward=1291.09 +/- 0.00
Episode length: 1620.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.62e+03 |
|    mean_reward     | 1.29e+03 |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | -67.4    |
|    critic_loss     | 0.897    |
|    ent_coef        | 0.00843  |
|    ent_coef_loss   | -3.54    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 1699798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.59e+03 |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 50       |
|    time_elapsed    | 17855    |
|    total_timesteps | 897256   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 1.53     |
|    ent_coef        | 0.00818  |
|    ent_coef_loss   | 0.811    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 1707054  |
---------------------------------
Eval num_timesteps=900000, episode_reward=1712.40 +/- 0.00
Episode length: 2107.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.11e+03 |
|    mean_reward     | 1.71e+03 |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.00833  |
|    ent_coef_loss   | 2.92     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 1709798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 50       |
|    time_elapsed    | 18028    |
|    total_timesteps | 907014   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 2.21     |
|    ent_coef        | 0.00777  |
|    ent_coef_loss   | 0.0419   |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 1716812  |
---------------------------------
Eval num_timesteps=910000, episode_reward=1565.23 +/- 0.00
Episode length: 1885.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.88e+03 |
|    mean_reward     | 1.57e+03 |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.00761  |
|    ent_coef_loss   | 3.12     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 1719798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 50       |
|    time_elapsed    | 18202    |
|    total_timesteps | 916887   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 4.73     |
|    ent_coef        | 0.00796  |
|    ent_coef_loss   | 3.53     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 1726685  |
---------------------------------
Eval num_timesteps=920000, episode_reward=1309.26 +/- 0.00
Episode length: 1596.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 1.31e+03 |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.00795  |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 1729798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.68e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 50       |
|    time_elapsed    | 18376    |
|    total_timesteps | 926766   |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 1.59     |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1736564  |
---------------------------------
Eval num_timesteps=930000, episode_reward=1877.16 +/- 0.00
Episode length: 2292.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.29e+03 |
|    mean_reward     | 1.88e+03 |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.00768  |
|    ent_coef_loss   | 2        |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 1739798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.71e+03 |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 50       |
|    time_elapsed    | 18562    |
|    total_timesteps | 937478   |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 1.51     |
|    ent_coef        | 0.00766  |
|    ent_coef_loss   | 0.899    |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 1747276  |
---------------------------------
Eval num_timesteps=940000, episode_reward=1576.54 +/- 0.00
Episode length: 1967.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.97e+03 |
|    mean_reward     | 1.58e+03 |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 3.51     |
|    ent_coef        | 0.00757  |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 1749798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.75e+03 |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 50       |
|    time_elapsed    | 18737    |
|    total_timesteps | 947507   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 1.56     |
|    ent_coef        | 0.00733  |
|    ent_coef_loss   | 0.639    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 1757305  |
---------------------------------
Eval num_timesteps=950000, episode_reward=3804.41 +/- 0.00
Episode length: 4472.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 4.47e+03 |
|    mean_reward     | 3.8e+03  |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.00771  |
|    ent_coef_loss   | 8.03     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 1759798  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.77e+03 |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 50       |
|    time_elapsed    | 18913    |
|    total_timesteps | 956603   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.00772  |
|    ent_coef_loss   | 4.64     |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 1766401  |
---------------------------------
Eval num_timesteps=960000, episode_reward=1456.91 +/- 0.00
Episode length: 1799.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.8e+03  |
|    mean_reward     | 1.46e+03 |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 1.81     |
|    ent_coef        | 0.00805  |
|    ent_coef_loss   | -3.42    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 1769798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.81e+03 |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 50       |
|    time_elapsed    | 19101    |
|    total_timesteps | 967490   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 1.69     |
|    ent_coef        | 0.00774  |
|    ent_coef_loss   | -0.576   |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 1777288  |
---------------------------------
Eval num_timesteps=970000, episode_reward=2046.56 +/- 0.00
Episode length: 2491.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.49e+03 |
|    mean_reward     | 2.05e+03 |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | -67      |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.00789  |
|    ent_coef_loss   | -0.00478 |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 1779798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.83e+03 |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 50       |
|    time_elapsed    | 19272    |
|    total_timesteps | 976935   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.00778  |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 1786733  |
---------------------------------
Eval num_timesteps=980000, episode_reward=1806.75 +/- 0.00
Episode length: 2117.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.12e+03 |
|    mean_reward     | 1.81e+03 |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 1.77     |
|    ent_coef        | 0.00783  |
|    ent_coef_loss   | -3.09    |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 1789798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.87e+03 |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 50       |
|    time_elapsed    | 19454    |
|    total_timesteps | 987351   |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 1.88     |
|    ent_coef        | 0.00792  |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 1797149  |
---------------------------------
Eval num_timesteps=990000, episode_reward=2181.94 +/- 0.00
Episode length: 2539.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.54e+03 |
|    mean_reward     | 2.18e+03 |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.00815  |
|    ent_coef_loss   | -0.963   |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 1799798  |
---------------------------------
Eval num_timesteps=1000000, episode_reward=1939.98 +/- 0.00
Episode length: 2390.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.39e+03 |
|    mean_reward     | 1.94e+03 |
| time/              |          |
|    total_timesteps | 1000000  |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 2.43     |
|    ent_coef        | 0.00798  |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 9e-05    |
|    n_updates       | 1809798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.93e+03 |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 50       |
|    time_elapsed    | 19721    |
|    total_timesteps | 1001682  |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 1.35     |
|    ent_coef        | 0.00767  |
|    ent_coef_loss   | -0.55    |
|    learning_rate   | 9e-05    |
|    n_updates       | 1811480  |
---------------------------------
Eval num_timesteps=1010000, episode_reward=1801.76 +/- 0.00
Episode length: 2165.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.16e+03 |
|    mean_reward     | 1.8e+03  |
| time/              |          |
|    total_timesteps | 1010000  |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 1.82     |
|    ent_coef        | 0.00799  |
|    ent_coef_loss   | 0.649    |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 1819798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.96e+03 |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 50       |
|    time_elapsed    | 19902    |
|    total_timesteps | 1012029  |
| train/             |          |
|    actor_loss      | -67.1    |
|    critic_loss     | 1.01     |
|    ent_coef        | 0.00783  |
|    ent_coef_loss   | 1.19     |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 1821827  |
---------------------------------
Eval num_timesteps=1020000, episode_reward=1800.52 +/- 0.00
Episode length: 2162.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.16e+03 |
|    mean_reward     | 1.8e+03  |
| time/              |          |
|    total_timesteps | 1020000  |
| train/             |          |
|    actor_loss      | -67.6    |
|    critic_loss     | 1.55     |
|    ent_coef        | 0.00727  |
|    ent_coef_loss   | -2.4     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 1829798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 50       |
|    time_elapsed    | 20087    |
|    total_timesteps | 1022613  |
| train/             |          |
|    actor_loss      | -66.8    |
|    critic_loss     | 1.23     |
|    ent_coef        | 0.00712  |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 1832411  |
---------------------------------
Eval num_timesteps=1030000, episode_reward=2611.13 +/- 0.00
Episode length: 3091.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 3.09e+03 |
|    mean_reward     | 2.61e+03 |
| time/              |          |
|    total_timesteps | 1030000  |
| train/             |          |
|    actor_loss      | -68      |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.0075   |
|    ent_coef_loss   | 1.95     |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 1839798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.04e+03 |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 50       |
|    time_elapsed    | 20265    |
|    total_timesteps | 1032477  |
| train/             |          |
|    actor_loss      | -68      |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.00749  |
|    ent_coef_loss   | 4.8      |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 1842275  |
---------------------------------
Eval num_timesteps=1040000, episode_reward=2356.19 +/- 0.00
Episode length: 2788.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.79e+03 |
|    mean_reward     | 2.36e+03 |
| time/              |          |
|    total_timesteps | 1040000  |
| train/             |          |
|    actor_loss      | -67.5    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.00722  |
|    ent_coef_loss   | -0.116   |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 1849798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.08e+03 |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 51       |
|    time_elapsed    | 20483    |
|    total_timesteps | 1045128  |
| train/             |          |
|    actor_loss      | -70.6    |
|    critic_loss     | 1.31     |
|    ent_coef        | 0.00731  |
|    ent_coef_loss   | 2.4      |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 1854926  |
---------------------------------
Eval num_timesteps=1050000, episode_reward=2008.36 +/- 0.00
Episode length: 2377.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.38e+03 |
|    mean_reward     | 2.01e+03 |
| time/              |          |
|    total_timesteps | 1050000  |
| train/             |          |
|    actor_loss      | -70.6    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.00775  |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 1859798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.11e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 51       |
|    time_elapsed    | 20686    |
|    total_timesteps | 1056918  |
| train/             |          |
|    actor_loss      | -70      |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.00775  |
|    ent_coef_loss   | 4.16     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 1866716  |
---------------------------------
Eval num_timesteps=1060000, episode_reward=2202.42 +/- 0.00
Episode length: 2607.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.61e+03 |
|    mean_reward     | 2.2e+03  |
| time/              |          |
|    total_timesteps | 1060000  |
| train/             |          |
|    actor_loss      | -73.8    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.00815  |
|    ent_coef_loss   | -6.02    |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 1869798  |
---------------------------------
Eval num_timesteps=1070000, episode_reward=1747.89 +/- 0.00
Episode length: 2060.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.06e+03 |
|    mean_reward     | 1.75e+03 |
| time/              |          |
|    total_timesteps | 1070000  |
| train/             |          |
|    actor_loss      | -74.1    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.00826  |
|    ent_coef_loss   | -0.398   |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 1879798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.14e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 51       |
|    time_elapsed    | 20964    |
|    total_timesteps | 1072184  |
| train/             |          |
|    actor_loss      | -76      |
|    critic_loss     | 1.24     |
|    ent_coef        | 0.00808  |
|    ent_coef_loss   | -4.89    |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 1881982  |
---------------------------------
Eval num_timesteps=1080000, episode_reward=2295.37 +/- 0.00
Episode length: 2700.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.7e+03  |
|    mean_reward     | 2.3e+03  |
| time/              |          |
|    total_timesteps | 1080000  |
| train/             |          |
|    actor_loss      | -73.5    |
|    critic_loss     | 1.38     |
|    ent_coef        | 0.00794  |
|    ent_coef_loss   | 0.567    |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 1889798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 51       |
|    time_elapsed    | 21158    |
|    total_timesteps | 1083042  |
| train/             |          |
|    actor_loss      | -72.1    |
|    critic_loss     | 1.23     |
|    ent_coef        | 0.00792  |
|    ent_coef_loss   | 4.89     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 1892840  |
---------------------------------
Eval num_timesteps=1090000, episode_reward=2004.73 +/- 0.00
Episode length: 2348.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.35e+03 |
|    mean_reward     | 2e+03    |
| time/              |          |
|    total_timesteps | 1090000  |
| train/             |          |
|    actor_loss      | -75.7    |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.00819  |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 1899798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.17e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 51       |
|    time_elapsed    | 21331    |
|    total_timesteps | 1092654  |
| train/             |          |
|    actor_loss      | -74.5    |
|    critic_loss     | 2.56     |
|    ent_coef        | 0.00801  |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 1902452  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.18e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 51       |
|    time_elapsed    | 21447    |
|    total_timesteps | 1099834  |
| train/             |          |
|    actor_loss      | -73.5    |
|    critic_loss     | 2.1      |
|    ent_coef        | 0.00796  |
|    ent_coef_loss   | 4.94     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 1909632  |
---------------------------------
Eval num_timesteps=1100000, episode_reward=1731.15 +/- 0.00
Episode length: 2106.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.11e+03 |
|    mean_reward     | 1.73e+03 |
| time/              |          |
|    total_timesteps | 1100000  |
| train/             |          |
|    actor_loss      | -76.5    |
|    critic_loss     | 1.86     |
|    ent_coef        | 0.00799  |
|    ent_coef_loss   | 1.42     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 1909798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.17e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 51       |
|    time_elapsed    | 21576    |
|    total_timesteps | 1106366  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.00838  |
|    ent_coef_loss   | -0.466   |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 1916164  |
---------------------------------
Eval num_timesteps=1110000, episode_reward=1528.68 +/- 0.00
Episode length: 1873.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.87e+03 |
|    mean_reward     | 1.53e+03 |
| time/              |          |
|    total_timesteps | 1110000  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 1.36     |
|    ent_coef        | 0.00828  |
|    ent_coef_loss   | 6        |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 1919798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 51       |
|    time_elapsed    | 21705    |
|    total_timesteps | 1113165  |
| train/             |          |
|    actor_loss      | -74.8    |
|    critic_loss     | 1.75     |
|    ent_coef        | 0.00797  |
|    ent_coef_loss   | 0.545    |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 1922963  |
---------------------------------
Eval num_timesteps=1120000, episode_reward=1589.11 +/- 0.00
Episode length: 1932.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.93e+03 |
|    mean_reward     | 1.59e+03 |
| time/              |          |
|    total_timesteps | 1120000  |
| train/             |          |
|    actor_loss      | -78.9    |
|    critic_loss     | 1.44     |
|    ent_coef        | 0.00775  |
|    ent_coef_loss   | 2.63     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 1929798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 51       |
|    time_elapsed    | 21858    |
|    total_timesteps | 1121590  |
| train/             |          |
|    actor_loss      | -80.2    |
|    critic_loss     | 1.04     |
|    ent_coef        | 0.00781  |
|    ent_coef_loss   | -2.76    |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 1931388  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.16e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 51       |
|    time_elapsed    | 21966    |
|    total_timesteps | 1128569  |
| train/             |          |
|    actor_loss      | -78.5    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.00823  |
|    ent_coef_loss   | -0.186   |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 1938367  |
---------------------------------
Eval num_timesteps=1130000, episode_reward=1472.66 +/- 0.00
Episode length: 1758.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.76e+03 |
|    mean_reward     | 1.47e+03 |
| time/              |          |
|    total_timesteps | 1130000  |
| train/             |          |
|    actor_loss      | -77.6    |
|    critic_loss     | 1.34     |
|    ent_coef        | 0.00814  |
|    ent_coef_loss   | 3.37     |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 1939798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.13e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 51       |
|    time_elapsed    | 22101    |
|    total_timesteps | 1135697  |
| train/             |          |
|    actor_loss      | -79.9    |
|    critic_loss     | 1.11     |
|    ent_coef        | 0.00755  |
|    ent_coef_loss   | -2.45    |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 1945495  |
---------------------------------
Eval num_timesteps=1140000, episode_reward=1495.00 +/- 0.00
Episode length: 1818.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.82e+03 |
|    mean_reward     | 1.5e+03  |
| time/              |          |
|    total_timesteps | 1140000  |
| train/             |          |
|    actor_loss      | -81.5    |
|    critic_loss     | 1.12     |
|    ent_coef        | 0.00773  |
|    ent_coef_loss   | -0.517   |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 1949798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.11e+03 |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 51       |
|    time_elapsed    | 22215    |
|    total_timesteps | 1141392  |
| train/             |          |
|    actor_loss      | -79.3    |
|    critic_loss     | 1.15     |
|    ent_coef        | 0.00759  |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 1951190  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.08e+03 |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 51       |
|    time_elapsed    | 22304    |
|    total_timesteps | 1147013  |
| train/             |          |
|    actor_loss      | -81.5    |
|    critic_loss     | 1.21     |
|    ent_coef        | 0.00766  |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 1956811  |
---------------------------------
Eval num_timesteps=1150000, episode_reward=1300.62 +/- 0.00
Episode length: 1606.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.61e+03 |
|    mean_reward     | 1.3e+03  |
| time/              |          |
|    total_timesteps | 1150000  |
| train/             |          |
|    actor_loss      | -78.6    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.00754  |
|    ent_coef_loss   | 2.29     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 1959798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.05e+03 |
|    ep_rew_mean     | 1.72e+03 |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 51       |
|    time_elapsed    | 22443    |
|    total_timesteps | 1154620  |
| train/             |          |
|    actor_loss      | -79.7    |
|    critic_loss     | 1.66     |
|    ent_coef        | 0.00737  |
|    ent_coef_loss   | 0.0846   |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 1964418  |
---------------------------------
Eval num_timesteps=1160000, episode_reward=1279.48 +/- 0.00
Episode length: 1588.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.59e+03 |
|    mean_reward     | 1.28e+03 |
| time/              |          |
|    total_timesteps | 1160000  |
| train/             |          |
|    actor_loss      | -82.5    |
|    critic_loss     | 1.2      |
|    ent_coef        | 0.0076   |
|    ent_coef_loss   | -3.09    |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 1969798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.01e+03 |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 51       |
|    time_elapsed    | 22572    |
|    total_timesteps | 1161409  |
| train/             |          |
|    actor_loss      | -76.5    |
|    critic_loss     | 1.67     |
|    ent_coef        | 0.0077   |
|    ent_coef_loss   | 3.75     |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 1971207  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.97e+03 |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 51       |
|    time_elapsed    | 22656    |
|    total_timesteps | 1166605  |
| train/             |          |
|    actor_loss      | -80.7    |
|    critic_loss     | 1.56     |
|    ent_coef        | 0.00722  |
|    ent_coef_loss   | 0.713    |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 1976403  |
---------------------------------
Eval num_timesteps=1170000, episode_reward=1102.68 +/- 0.00
Episode length: 1425.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 1170000  |
| train/             |          |
|    actor_loss      | -81.3    |
|    critic_loss     | 0.891    |
|    ent_coef        | 0.0069   |
|    ent_coef_loss   | -0.991   |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 1979798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.93e+03 |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 51       |
|    time_elapsed    | 22772    |
|    total_timesteps | 1172615  |
| train/             |          |
|    actor_loss      | -80.1    |
|    critic_loss     | 1.33     |
|    ent_coef        | 0.007    |
|    ent_coef_loss   | 0.149    |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 1982413  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.88e+03 |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 51       |
|    time_elapsed    | 22831    |
|    total_timesteps | 1176103  |
| train/             |          |
|    actor_loss      | -82.6    |
|    critic_loss     | 1.35     |
|    ent_coef        | 0.00698  |
|    ent_coef_loss   | -3.25    |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 1985901  |
---------------------------------
Eval num_timesteps=1180000, episode_reward=152.25 +/- 0.00
Episode length: 219.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 219      |
|    mean_reward     | 152      |
| time/              |          |
|    total_timesteps | 1180000  |
| train/             |          |
|    actor_loss      | -76.8    |
|    critic_loss     | 1.38     |
|    ent_coef        | 0.00673  |
|    ent_coef_loss   | -0.209   |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 1989798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.84e+03 |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 51       |
|    time_elapsed    | 22952    |
|    total_timesteps | 1182879  |
| train/             |          |
|    actor_loss      | -81.1    |
|    critic_loss     | 1.12     |
|    ent_coef        | 0.00668  |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 1992677  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.81e+03 |
|    ep_rew_mean     | 1.5e+03  |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 51       |
|    time_elapsed    | 23051    |
|    total_timesteps | 1189159  |
| train/             |          |
|    actor_loss      | -81.4    |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.007    |
|    ent_coef_loss   | -6.14    |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 1998957  |
---------------------------------
Eval num_timesteps=1190000, episode_reward=1372.19 +/- 0.00
Episode length: 1613.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.61e+03 |
|    mean_reward     | 1.37e+03 |
| time/              |          |
|    total_timesteps | 1190000  |
| train/             |          |
|    actor_loss      | -78.6    |
|    critic_loss     | 1.53     |
|    ent_coef        | 0.00704  |
|    ent_coef_loss   | -4.84    |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 1999798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.76e+03 |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 51       |
|    time_elapsed    | 23174    |
|    total_timesteps | 1195651  |
| train/             |          |
|    actor_loss      | -81      |
|    critic_loss     | 1.05     |
|    ent_coef        | 0.00708  |
|    ent_coef_loss   | -0.455   |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2005449  |
---------------------------------
Eval num_timesteps=1200000, episode_reward=1403.91 +/- 0.00
Episode length: 1726.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.73e+03 |
|    mean_reward     | 1.4e+03  |
| time/              |          |
|    total_timesteps | 1200000  |
| train/             |          |
|    actor_loss      | -79.6    |
|    critic_loss     | 2.28     |
|    ent_coef        | 0.00682  |
|    ent_coef_loss   | -2.53    |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2009798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.73e+03 |
|    ep_rew_mean     | 1.43e+03 |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 51       |
|    time_elapsed    | 23293    |
|    total_timesteps | 1201747  |
| train/             |          |
|    actor_loss      | -77.6    |
|    critic_loss     | 1.62     |
|    ent_coef        | 0.00682  |
|    ent_coef_loss   | 1.63     |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2011545  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.72e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 51       |
|    time_elapsed    | 23405    |
|    total_timesteps | 1208992  |
| train/             |          |
|    actor_loss      | -81.1    |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.00682  |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2018790  |
---------------------------------
Eval num_timesteps=1210000, episode_reward=1321.51 +/- 0.00
Episode length: 1558.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.56e+03 |
|    mean_reward     | 1.32e+03 |
| time/              |          |
|    total_timesteps | 1210000  |
| train/             |          |
|    actor_loss      | -79.7    |
|    critic_loss     | 1.24     |
|    ent_coef        | 0.00687  |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 2019798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.68e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 51       |
|    time_elapsed    | 23534    |
|    total_timesteps | 1215801  |
| train/             |          |
|    actor_loss      | -77.5    |
|    critic_loss     | 1.51     |
|    ent_coef        | 0.00686  |
|    ent_coef_loss   | 1.67     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2025599  |
---------------------------------
Eval num_timesteps=1220000, episode_reward=1039.55 +/- 0.00
Episode length: 1322.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 1220000  |
| train/             |          |
|    actor_loss      | -78.4    |
|    critic_loss     | 1.57     |
|    ent_coef        | 0.00667  |
|    ent_coef_loss   | 0.613    |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2029798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.65e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 51       |
|    time_elapsed    | 23668    |
|    total_timesteps | 1223154  |
| train/             |          |
|    actor_loss      | -80.3    |
|    critic_loss     | 1.01     |
|    ent_coef        | 0.0068   |
|    ent_coef_loss   | -3.57    |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 2032952  |
---------------------------------
Eval num_timesteps=1230000, episode_reward=1118.83 +/- 0.00
Episode length: 1379.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 1230000  |
| train/             |          |
|    actor_loss      | -79.4    |
|    critic_loss     | 1.58     |
|    ent_coef        | 0.00657  |
|    ent_coef_loss   | -0.775   |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 2039798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 51       |
|    time_elapsed    | 23817    |
|    total_timesteps | 1231536  |
| train/             |          |
|    actor_loss      | -77.8    |
|    critic_loss     | 1.8      |
|    ent_coef        | 0.00641  |
|    ent_coef_loss   | 8.65     |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 2041334  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.59e+03 |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 51       |
|    time_elapsed    | 23917    |
|    total_timesteps | 1237842  |
| train/             |          |
|    actor_loss      | -80      |
|    critic_loss     | 1.54     |
|    ent_coef        | 0.00714  |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 2047640  |
---------------------------------
Eval num_timesteps=1240000, episode_reward=1266.54 +/- 0.00
Episode length: 1526.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.27e+03 |
| time/              |          |
|    total_timesteps | 1240000  |
| train/             |          |
|    actor_loss      | -80.3    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.00718  |
|    ent_coef_loss   | -0.754   |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 2049798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.55e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 51       |
|    time_elapsed    | 24058    |
|    total_timesteps | 1245542  |
| train/             |          |
|    actor_loss      | -80.1    |
|    critic_loss     | 0.987    |
|    ent_coef        | 0.00733  |
|    ent_coef_loss   | 2.07     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2055340  |
---------------------------------
Eval num_timesteps=1250000, episode_reward=1482.46 +/- 0.00
Episode length: 1857.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.86e+03 |
|    mean_reward     | 1.48e+03 |
| time/              |          |
|    total_timesteps | 1250000  |
| train/             |          |
|    actor_loss      | -80.6    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.00718  |
|    ent_coef_loss   | 7.17     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2059798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.53e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 51       |
|    time_elapsed    | 24202    |
|    total_timesteps | 1253390  |
| train/             |          |
|    actor_loss      | -75.4    |
|    critic_loss     | 2.21     |
|    ent_coef        | 0.00736  |
|    ent_coef_loss   | 10.7     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 2063188  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.52e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 51       |
|    time_elapsed    | 24295    |
|    total_timesteps | 1259282  |
| train/             |          |
|    actor_loss      | -81      |
|    critic_loss     | 1        |
|    ent_coef        | 0.0073   |
|    ent_coef_loss   | 4.13     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 2069080  |
---------------------------------
Eval num_timesteps=1260000, episode_reward=1085.35 +/- 0.00
Episode length: 1396.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 1260000  |
| train/             |          |
|    actor_loss      | -80.4    |
|    critic_loss     | 1.9      |
|    ent_coef        | 0.00731  |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 2069798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.51e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 51       |
|    time_elapsed    | 24422    |
|    total_timesteps | 1266065  |
| train/             |          |
|    actor_loss      | -82.4    |
|    critic_loss     | 1.08     |
|    ent_coef        | 0.00759  |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2075863  |
---------------------------------
Eval num_timesteps=1270000, episode_reward=1479.28 +/- 0.00
Episode length: 1840.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.84e+03 |
|    mean_reward     | 1.48e+03 |
| time/              |          |
|    total_timesteps | 1270000  |
| train/             |          |
|    actor_loss      | -81      |
|    critic_loss     | 1.52     |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | -4.3     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2079798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.5e+03  |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 51       |
|    time_elapsed    | 24550    |
|    total_timesteps | 1272749  |
| train/             |          |
|    actor_loss      | -78.9    |
|    critic_loss     | 1.42     |
|    ent_coef        | 0.00786  |
|    ent_coef_loss   | 0.838    |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 2082547  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 51       |
|    time_elapsed    | 24635    |
|    total_timesteps | 1278055  |
| train/             |          |
|    actor_loss      | -79.7    |
|    critic_loss     | 0.96     |
|    ent_coef        | 0.00821  |
|    ent_coef_loss   | -2.81    |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2087853  |
---------------------------------
Eval num_timesteps=1280000, episode_reward=1031.28 +/- 0.00
Episode length: 1253.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 1280000  |
| train/             |          |
|    actor_loss      | -81.5    |
|    critic_loss     | 0.916    |
|    ent_coef        | 0.00818  |
|    ent_coef_loss   | -2.92    |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2089798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 51       |
|    time_elapsed    | 24745    |
|    total_timesteps | 1283675  |
| train/             |          |
|    actor_loss      | -77.7    |
|    critic_loss     | 1.72     |
|    ent_coef        | 0.0082   |
|    ent_coef_loss   | -0.525   |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 2093473  |
---------------------------------
Eval num_timesteps=1290000, episode_reward=1265.79 +/- 0.00
Episode length: 1567.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.57e+03 |
|    mean_reward     | 1.27e+03 |
| time/              |          |
|    total_timesteps | 1290000  |
| train/             |          |
|    actor_loss      | -78.5    |
|    critic_loss     | 1.55     |
|    ent_coef        | 0.0085   |
|    ent_coef_loss   | 3.11     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2099798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 51       |
|    time_elapsed    | 24892    |
|    total_timesteps | 1291756  |
| train/             |          |
|    actor_loss      | -80.2    |
|    critic_loss     | 1.22     |
|    ent_coef        | 0.00844  |
|    ent_coef_loss   | -1.33    |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 2101554  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 51       |
|    time_elapsed    | 24984    |
|    total_timesteps | 1297645  |
| train/             |          |
|    actor_loss      | -78.2    |
|    critic_loss     | 0.947    |
|    ent_coef        | 0.00832  |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2107443  |
---------------------------------
Eval num_timesteps=1300000, episode_reward=952.37 +/- 0.00
Episode length: 1152.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.15e+03 |
|    mean_reward     | 952      |
| time/              |          |
|    total_timesteps | 1300000  |
| train/             |          |
|    actor_loss      | -80.1    |
|    critic_loss     | 2.2      |
|    ent_coef        | 0.00838  |
|    ent_coef_loss   | -0.294   |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2109798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 51       |
|    time_elapsed    | 25109    |
|    total_timesteps | 1304314  |
| train/             |          |
|    actor_loss      | -81.6    |
|    critic_loss     | 1.06     |
|    ent_coef        | 0.00848  |
|    ent_coef_loss   | 0.308    |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 2114112  |
---------------------------------
Eval num_timesteps=1310000, episode_reward=1248.73 +/- 0.00
Episode length: 1472.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 1310000  |
| train/             |          |
|    actor_loss      | -78.7    |
|    critic_loss     | 1.26     |
|    ent_coef        | 0.00836  |
|    ent_coef_loss   | -1.23    |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2119798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 51       |
|    time_elapsed    | 25242    |
|    total_timesteps | 1311426  |
| train/             |          |
|    actor_loss      | -79.4    |
|    critic_loss     | 2.09     |
|    ent_coef        | 0.00849  |
|    ent_coef_loss   | -0.0902  |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 2121224  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 51       |
|    time_elapsed    | 25325    |
|    total_timesteps | 1316559  |
| train/             |          |
|    actor_loss      | -80.7    |
|    critic_loss     | 0.911    |
|    ent_coef        | 0.00858  |
|    ent_coef_loss   | -7       |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2126357  |
---------------------------------
Eval num_timesteps=1320000, episode_reward=1199.90 +/- 0.00
Episode length: 1431.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.43e+03 |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 1320000  |
| train/             |          |
|    actor_loss      | -77      |
|    critic_loss     | 3.74     |
|    ent_coef        | 0.00828  |
|    ent_coef_loss   | -0.511   |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2129798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 51       |
|    time_elapsed    | 25441    |
|    total_timesteps | 1322489  |
| train/             |          |
|    actor_loss      | -80      |
|    critic_loss     | 0.994    |
|    ent_coef        | 0.00836  |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 2132287  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 52       |
|    time_elapsed    | 25531    |
|    total_timesteps | 1328145  |
| train/             |          |
|    actor_loss      | -80.4    |
|    critic_loss     | 2.09     |
|    ent_coef        | 0.00865  |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2137943  |
---------------------------------
Eval num_timesteps=1330000, episode_reward=1162.48 +/- 0.00
Episode length: 1408.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.41e+03 |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 1330000  |
| train/             |          |
|    actor_loss      | -80.7    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.00871  |
|    ent_coef_loss   | -4.56    |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2139798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 52       |
|    time_elapsed    | 25651    |
|    total_timesteps | 1334331  |
| train/             |          |
|    actor_loss      | -79.2    |
|    critic_loss     | 1.68     |
|    ent_coef        | 0.00886  |
|    ent_coef_loss   | 0.53     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 2144129  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 52       |
|    time_elapsed    | 25734    |
|    total_timesteps | 1339418  |
| train/             |          |
|    actor_loss      | -80      |
|    critic_loss     | 1.58     |
|    ent_coef        | 0.00869  |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2149216  |
---------------------------------
Eval num_timesteps=1340000, episode_reward=1413.19 +/- 0.00
Episode length: 1733.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.73e+03 |
|    mean_reward     | 1.41e+03 |
| time/              |          |
|    total_timesteps | 1340000  |
| train/             |          |
|    actor_loss      | -81.8    |
|    critic_loss     | 1.45     |
|    ent_coef        | 0.00873  |
|    ent_coef_loss   | -4.42    |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 2149798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 52       |
|    time_elapsed    | 25858    |
|    total_timesteps | 1345790  |
| train/             |          |
|    actor_loss      | -81.3    |
|    critic_loss     | 1.92     |
|    ent_coef        | 0.00933  |
|    ent_coef_loss   | -4.6     |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2155588  |
---------------------------------
Eval num_timesteps=1350000, episode_reward=1502.90 +/- 0.00
Episode length: 1833.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.83e+03 |
|    mean_reward     | 1.5e+03  |
| time/              |          |
|    total_timesteps | 1350000  |
| train/             |          |
|    actor_loss      | -80.1    |
|    critic_loss     | 1.45     |
|    ent_coef        | 0.00927  |
|    ent_coef_loss   | -5.85    |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2159798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.48e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 52       |
|    time_elapsed    | 25974    |
|    total_timesteps | 1351577  |
| train/             |          |
|    actor_loss      | -77.3    |
|    critic_loss     | 1.7      |
|    ent_coef        | 0.00896  |
|    ent_coef_loss   | 6.37     |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 2161375  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.48e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 52       |
|    time_elapsed    | 26065    |
|    total_timesteps | 1357307  |
| train/             |          |
|    actor_loss      | -79.7    |
|    critic_loss     | 1.49     |
|    ent_coef        | 0.00894  |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2167105  |
---------------------------------
Eval num_timesteps=1360000, episode_reward=1423.75 +/- 0.00
Episode length: 1769.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.77e+03 |
|    mean_reward     | 1.42e+03 |
| time/              |          |
|    total_timesteps | 1360000  |
| train/             |          |
|    actor_loss      | -79      |
|    critic_loss     | 2.17     |
|    ent_coef        | 0.00933  |
|    ent_coef_loss   | -0.311   |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2169798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 52       |
|    time_elapsed    | 26207    |
|    total_timesteps | 1364902  |
| train/             |          |
|    actor_loss      | -76.2    |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.00883  |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 2174700  |
---------------------------------
Eval num_timesteps=1370000, episode_reward=1323.84 +/- 0.00
Episode length: 1636.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.64e+03 |
|    mean_reward     | 1.32e+03 |
| time/              |          |
|    total_timesteps | 1370000  |
| train/             |          |
|    actor_loss      | -77.9    |
|    critic_loss     | 1.68     |
|    ent_coef        | 0.00891  |
|    ent_coef_loss   | 0.291    |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2179798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.48e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 52       |
|    time_elapsed    | 26334    |
|    total_timesteps | 1371550  |
| train/             |          |
|    actor_loss      | -79      |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.00855  |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 2181348  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 52       |
|    time_elapsed    | 26418    |
|    total_timesteps | 1376718  |
| train/             |          |
|    actor_loss      | -76.4    |
|    critic_loss     | 3.02     |
|    ent_coef        | 0.00863  |
|    ent_coef_loss   | 2.07     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2186516  |
---------------------------------
Eval num_timesteps=1380000, episode_reward=1558.50 +/- 0.00
Episode length: 1903.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.9e+03  |
|    mean_reward     | 1.56e+03 |
| time/              |          |
|    total_timesteps | 1380000  |
| train/             |          |
|    actor_loss      | -78.3    |
|    critic_loss     | 1.71     |
|    ent_coef        | 0.00898  |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2189798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 52       |
|    time_elapsed    | 26538    |
|    total_timesteps | 1382763  |
| train/             |          |
|    actor_loss      | -78      |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.00867  |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 2192561  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 52       |
|    time_elapsed    | 26635    |
|    total_timesteps | 1388920  |
| train/             |          |
|    actor_loss      | -75.6    |
|    critic_loss     | 2.14     |
|    ent_coef        | 0.00887  |
|    ent_coef_loss   | 4.68     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2198718  |
---------------------------------
Eval num_timesteps=1390000, episode_reward=1316.78 +/- 0.00
Episode length: 1585.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.58e+03 |
|    mean_reward     | 1.32e+03 |
| time/              |          |
|    total_timesteps | 1390000  |
| train/             |          |
|    actor_loss      | -77      |
|    critic_loss     | 2.71     |
|    ent_coef        | 0.00873  |
|    ent_coef_loss   | 3.91     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 2199798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 52       |
|    time_elapsed    | 26765    |
|    total_timesteps | 1395773  |
| train/             |          |
|    actor_loss      | -78.3    |
|    critic_loss     | 3        |
|    ent_coef        | 0.00866  |
|    ent_coef_loss   | -2.77    |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2205571  |
---------------------------------
Eval num_timesteps=1400000, episode_reward=1209.32 +/- 0.00
Episode length: 1501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.5e+03  |
|    mean_reward     | 1.21e+03 |
| time/              |          |
|    total_timesteps | 1400000  |
| train/             |          |
|    actor_loss      | -73.9    |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.00827  |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2209798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 52       |
|    time_elapsed    | 26877    |
|    total_timesteps | 1401393  |
| train/             |          |
|    actor_loss      | -77.9    |
|    critic_loss     | 1.46     |
|    ent_coef        | 0.00841  |
|    ent_coef_loss   | -0.0678  |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 2211191  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 52       |
|    time_elapsed    | 26969    |
|    total_timesteps | 1407179  |
| train/             |          |
|    actor_loss      | -75.6    |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.00846  |
|    ent_coef_loss   | 3.46     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2216977  |
---------------------------------
Eval num_timesteps=1410000, episode_reward=1115.01 +/- 0.00
Episode length: 1395.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 1410000  |
| train/             |          |
|    actor_loss      | -78.6    |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.00871  |
|    ent_coef_loss   | -2.94    |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2219798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 52       |
|    time_elapsed    | 27099    |
|    total_timesteps | 1414174  |
| train/             |          |
|    actor_loss      | -75.1    |
|    critic_loss     | 1.75     |
|    ent_coef        | 0.00831  |
|    ent_coef_loss   | 5.3      |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 2223972  |
---------------------------------
Eval num_timesteps=1420000, episode_reward=1601.31 +/- 0.00
Episode length: 1934.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.93e+03 |
|    mean_reward     | 1.6e+03  |
| time/              |          |
|    total_timesteps | 1420000  |
| train/             |          |
|    actor_loss      | -76.3    |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.00866  |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2229798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 52       |
|    time_elapsed    | 27235    |
|    total_timesteps | 1421399  |
| train/             |          |
|    actor_loss      | -75.6    |
|    critic_loss     | 5.61     |
|    ent_coef        | 0.00862  |
|    ent_coef_loss   | 1.87     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 2231197  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 52       |
|    time_elapsed    | 27325    |
|    total_timesteps | 1427082  |
| train/             |          |
|    actor_loss      | -74.5    |
|    critic_loss     | 2.56     |
|    ent_coef        | 0.00834  |
|    ent_coef_loss   | 3.48     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2236880  |
---------------------------------
Eval num_timesteps=1430000, episode_reward=1769.58 +/- 0.00
Episode length: 2181.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 2.18e+03 |
|    mean_reward     | 1.77e+03 |
| time/              |          |
|    total_timesteps | 1430000  |
| train/             |          |
|    actor_loss      | -77.9    |
|    critic_loss     | 0.975    |
|    ent_coef        | 0.00812  |
|    ent_coef_loss   | -4.95    |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2239798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 52       |
|    time_elapsed    | 27466    |
|    total_timesteps | 1434639  |
| train/             |          |
|    actor_loss      | -75.1    |
|    critic_loss     | 1.2      |
|    ent_coef        | 0.00814  |
|    ent_coef_loss   | 4.07     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 2244437  |
---------------------------------
Eval num_timesteps=1440000, episode_reward=1175.41 +/- 0.00
Episode length: 1467.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 1440000  |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 1.95     |
|    ent_coef        | 0.00818  |
|    ent_coef_loss   | -2.92    |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2249798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 52       |
|    time_elapsed    | 27591    |
|    total_timesteps | 1441221  |
| train/             |          |
|    actor_loss      | -77.1    |
|    critic_loss     | 5.41     |
|    ent_coef        | 0.00821  |
|    ent_coef_loss   | 1.14     |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 2251019  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 52       |
|    time_elapsed    | 27689    |
|    total_timesteps | 1447466  |
| train/             |          |
|    actor_loss      | -77.5    |
|    critic_loss     | 1.9      |
|    ent_coef        | 0.00837  |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2257264  |
---------------------------------
Eval num_timesteps=1450000, episode_reward=1182.42 +/- 0.00
Episode length: 1482.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.48e+03 |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 1450000  |
| train/             |          |
|    actor_loss      | -75.2    |
|    critic_loss     | 1.75     |
|    ent_coef        | 0.00846  |
|    ent_coef_loss   | -4.02    |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2259798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 52       |
|    time_elapsed    | 27823    |
|    total_timesteps | 1454710  |
| train/             |          |
|    actor_loss      | -72.5    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.00821  |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 2264508  |
---------------------------------
Eval num_timesteps=1460000, episode_reward=1176.06 +/- 0.00
Episode length: 1476.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.48e+03 |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 1460000  |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.00802  |
|    ent_coef_loss   | -0.561   |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2269798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 52       |
|    time_elapsed    | 27949    |
|    total_timesteps | 1461415  |
| train/             |          |
|    actor_loss      | -75.9    |
|    critic_loss     | 3.82     |
|    ent_coef        | 0.00789  |
|    ent_coef_loss   | 0.495    |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 2271213  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 52       |
|    time_elapsed    | 28040    |
|    total_timesteps | 1467136  |
| train/             |          |
|    actor_loss      | -75.4    |
|    critic_loss     | 5.48     |
|    ent_coef        | 0.00842  |
|    ent_coef_loss   | 0.911    |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2276934  |
---------------------------------
Eval num_timesteps=1470000, episode_reward=1312.00 +/- 0.00
Episode length: 1613.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.61e+03 |
|    mean_reward     | 1.31e+03 |
| time/              |          |
|    total_timesteps | 1470000  |
| train/             |          |
|    actor_loss      | -76.4    |
|    critic_loss     | 2.42     |
|    ent_coef        | 0.00821  |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2279798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 52       |
|    time_elapsed    | 28149    |
|    total_timesteps | 1472586  |
| train/             |          |
|    actor_loss      | -77.9    |
|    critic_loss     | 1.43     |
|    ent_coef        | 0.00805  |
|    ent_coef_loss   | -5.22    |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 2282384  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 52       |
|    time_elapsed    | 28231    |
|    total_timesteps | 1477731  |
| train/             |          |
|    actor_loss      | -71.4    |
|    critic_loss     | 1.91     |
|    ent_coef        | 0.00805  |
|    ent_coef_loss   | 5.72     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2287529  |
---------------------------------
Eval num_timesteps=1480000, episode_reward=1193.95 +/- 0.00
Episode length: 1513.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.51e+03 |
|    mean_reward     | 1.19e+03 |
| time/              |          |
|    total_timesteps | 1480000  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 2.12     |
|    ent_coef        | 0.00803  |
|    ent_coef_loss   | 4.99     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2289798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 52       |
|    time_elapsed    | 28374    |
|    total_timesteps | 1484809  |
| train/             |          |
|    actor_loss      | -75.1    |
|    critic_loss     | 2.07     |
|    ent_coef        | 0.00767  |
|    ent_coef_loss   | -0.881   |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 2294607  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 52       |
|    time_elapsed    | 28454    |
|    total_timesteps | 1489755  |
| train/             |          |
|    actor_loss      | -76.8    |
|    critic_loss     | 3.93     |
|    ent_coef        | 0.00791  |
|    ent_coef_loss   | -0.818   |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2299553  |
---------------------------------
Eval num_timesteps=1490000, episode_reward=1246.38 +/- 0.00
Episode length: 1564.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.56e+03 |
|    mean_reward     | 1.25e+03 |
| time/              |          |
|    total_timesteps | 1490000  |
| train/             |          |
|    actor_loss      | -75.2    |
|    critic_loss     | 2.79     |
|    ent_coef        | 0.00793  |
|    ent_coef_loss   | -3.22    |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 2299798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 52       |
|    time_elapsed    | 28566    |
|    total_timesteps | 1495415  |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 2.54     |
|    ent_coef        | 0.00769  |
|    ent_coef_loss   | 0.622    |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2305213  |
---------------------------------
Eval num_timesteps=1500000, episode_reward=1379.33 +/- 0.00
Episode length: 1694.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.69e+03 |
|    mean_reward     | 1.38e+03 |
| time/              |          |
|    total_timesteps | 1500000  |
| train/             |          |
|    actor_loss      | -74      |
|    critic_loss     | 1.99     |
|    ent_coef        | 0.00768  |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2309798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 52       |
|    time_elapsed    | 28685    |
|    total_timesteps | 1501509  |
| train/             |          |
|    actor_loss      | -76.2    |
|    critic_loss     | 2.52     |
|    ent_coef        | 0.00791  |
|    ent_coef_loss   | -5.63    |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 2311307  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 52       |
|    time_elapsed    | 28768    |
|    total_timesteps | 1506714  |
| train/             |          |
|    actor_loss      | -72      |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.00755  |
|    ent_coef_loss   | 3.96     |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2316512  |
---------------------------------
Eval num_timesteps=1510000, episode_reward=1329.70 +/- 0.00
Episode length: 1682.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.68e+03 |
|    mean_reward     | 1.33e+03 |
| time/              |          |
|    total_timesteps | 1510000  |
| train/             |          |
|    actor_loss      | -75.4    |
|    critic_loss     | 1.71     |
|    ent_coef        | 0.00792  |
|    ent_coef_loss   | -0.287   |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2319798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 52       |
|    time_elapsed    | 28894    |
|    total_timesteps | 1513300  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 1.97     |
|    ent_coef        | 0.0075   |
|    ent_coef_loss   | 0.285    |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 2323098  |
---------------------------------
Eval num_timesteps=1520000, episode_reward=1329.92 +/- 0.00
Episode length: 1642.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.64e+03 |
|    mean_reward     | 1.33e+03 |
| time/              |          |
|    total_timesteps | 1520000  |
| train/             |          |
|    actor_loss      | -74.5    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.00759  |
|    ent_coef_loss   | 3.1      |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2329798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 52       |
|    time_elapsed    | 29037    |
|    total_timesteps | 1521113  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.00736  |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 2330911  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 52       |
|    time_elapsed    | 29134    |
|    total_timesteps | 1527260  |
| train/             |          |
|    actor_loss      | -72.8    |
|    critic_loss     | 2.26     |
|    ent_coef        | 0.00705  |
|    ent_coef_loss   | 8.23     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2337058  |
---------------------------------
Eval num_timesteps=1530000, episode_reward=926.69 +/- 0.00
Episode length: 1198.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 927      |
| time/              |          |
|    total_timesteps | 1530000  |
| train/             |          |
|    actor_loss      | -74.6    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.00716  |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2339798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.45e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 52       |
|    time_elapsed    | 29257    |
|    total_timesteps | 1533817  |
| train/             |          |
|    actor_loss      | -75.7    |
|    critic_loss     | 2.87     |
|    ent_coef        | 0.00764  |
|    ent_coef_loss   | 2.24     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 2343615  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.46e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 52       |
|    time_elapsed    | 29349    |
|    total_timesteps | 1539644  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 2.01     |
|    ent_coef        | 0.00771  |
|    ent_coef_loss   | 0.519    |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2349442  |
---------------------------------
Eval num_timesteps=1540000, episode_reward=1099.52 +/- 0.00
Episode length: 1385.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 1540000  |
| train/             |          |
|    actor_loss      | -75.1    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.00779  |
|    ent_coef_loss   | 2.2      |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2349798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 52       |
|    time_elapsed    | 29454    |
|    total_timesteps | 1544896  |
| train/             |          |
|    actor_loss      | -76      |
|    critic_loss     | 1.79     |
|    ent_coef        | 0.00752  |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 2354694  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 52       |
|    time_elapsed    | 29534    |
|    total_timesteps | 1549831  |
| train/             |          |
|    actor_loss      | -74.7    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.00745  |
|    ent_coef_loss   | -2.88    |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2359629  |
---------------------------------
Eval num_timesteps=1550000, episode_reward=1204.86 +/- 0.00
Episode length: 1511.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.51e+03 |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 1550000  |
| train/             |          |
|    actor_loss      | -73.9    |
|    critic_loss     | 2.37     |
|    ent_coef        | 0.00744  |
|    ent_coef_loss   | -1.85    |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 2359798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 52       |
|    time_elapsed    | 29645    |
|    total_timesteps | 1555442  |
| train/             |          |
|    actor_loss      | -72.5    |
|    critic_loss     | 1.89     |
|    ent_coef        | 0.00795  |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2365240  |
---------------------------------
Eval num_timesteps=1560000, episode_reward=1075.14 +/- 0.00
Episode length: 1313.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 1560000  |
| train/             |          |
|    actor_loss      | -75      |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.00806  |
|    ent_coef_loss   | -0.366   |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2369798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 52       |
|    time_elapsed    | 29757    |
|    total_timesteps | 1561182  |
| train/             |          |
|    actor_loss      | -73.4    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.00785  |
|    ent_coef_loss   | -3.88    |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 2370980  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 52       |
|    time_elapsed    | 29851    |
|    total_timesteps | 1567140  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 1.44     |
|    ent_coef        | 0.00798  |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2376938  |
---------------------------------
Eval num_timesteps=1570000, episode_reward=1127.03 +/- 0.00
Episode length: 1398.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 1570000  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 2.62     |
|    ent_coef        | 0.0083   |
|    ent_coef_loss   | 5.03     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2379798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.43e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 52       |
|    time_elapsed    | 29976    |
|    total_timesteps | 1573788  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0084   |
|    ent_coef_loss   | 4.38     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 2383586  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 52       |
|    time_elapsed    | 30057    |
|    total_timesteps | 1578840  |
| train/             |          |
|    actor_loss      | -72.8    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.00799  |
|    ent_coef_loss   | 2.62     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2388638  |
---------------------------------
Eval num_timesteps=1580000, episode_reward=1043.87 +/- 0.00
Episode length: 1278.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.28e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 1580000  |
| train/             |          |
|    actor_loss      | -75      |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.00795  |
|    ent_coef_loss   | -0.883   |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2389798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.4e+03  |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 52       |
|    time_elapsed    | 30167    |
|    total_timesteps | 1584476  |
| train/             |          |
|    actor_loss      | -71.8    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0078   |
|    ent_coef_loss   | 5.14     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 2394274  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.39e+03 |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 52       |
|    time_elapsed    | 30254    |
|    total_timesteps | 1589874  |
| train/             |          |
|    actor_loss      | -71.7    |
|    critic_loss     | 6.9      |
|    ent_coef        | 0.0086   |
|    ent_coef_loss   | 6.82     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2399672  |
---------------------------------
Eval num_timesteps=1590000, episode_reward=827.01 +/- 0.00
Episode length: 1037.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.04e+03 |
|    mean_reward     | 827      |
| time/              |          |
|    total_timesteps | 1590000  |
| train/             |          |
|    actor_loss      | -74.6    |
|    critic_loss     | 4.93     |
|    ent_coef        | 0.00861  |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 2399798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.39e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 52       |
|    time_elapsed    | 30364    |
|    total_timesteps | 1595640  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 5.43     |
|    ent_coef        | 0.00873  |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2405438  |
---------------------------------
Eval num_timesteps=1600000, episode_reward=958.27 +/- 0.00
Episode length: 1174.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 958      |
| time/              |          |
|    total_timesteps | 1600000  |
| train/             |          |
|    actor_loss      | -75.8    |
|    critic_loss     | 2.45     |
|    ent_coef        | 0.00876  |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2409798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 52       |
|    time_elapsed    | 30478    |
|    total_timesteps | 1601452  |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.00863  |
|    ent_coef_loss   | -3.1     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 2411250  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 52       |
|    time_elapsed    | 30561    |
|    total_timesteps | 1606615  |
| train/             |          |
|    actor_loss      | -72.4    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0083   |
|    ent_coef_loss   | 5.38     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2416413  |
---------------------------------
Eval num_timesteps=1610000, episode_reward=945.56 +/- 0.00
Episode length: 1155.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 946      |
| time/              |          |
|    total_timesteps | 1610000  |
| train/             |          |
|    actor_loss      | -72.2    |
|    critic_loss     | 3.52     |
|    ent_coef        | 0.00849  |
|    ent_coef_loss   | 5.35     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2419798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.36e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 52       |
|    time_elapsed    | 30682    |
|    total_timesteps | 1612962  |
| train/             |          |
|    actor_loss      | -78      |
|    critic_loss     | 1.5      |
|    ent_coef        | 0.00863  |
|    ent_coef_loss   | -8.91    |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 2422760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.35e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 52       |
|    time_elapsed    | 30757    |
|    total_timesteps | 1617507  |
| train/             |          |
|    actor_loss      | -74.6    |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.00828  |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2427305  |
---------------------------------
Eval num_timesteps=1620000, episode_reward=1055.92 +/- 0.00
Episode length: 1284.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.28e+03 |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 1620000  |
| train/             |          |
|    actor_loss      | -75.6    |
|    critic_loss     | 4.02     |
|    ent_coef        | 0.00825  |
|    ent_coef_loss   | -3.16    |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2429798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.35e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 52       |
|    time_elapsed    | 30873    |
|    total_timesteps | 1623540  |
| train/             |          |
|    actor_loss      | -75.9    |
|    critic_loss     | 2.97     |
|    ent_coef        | 0.00868  |
|    ent_coef_loss   | -0.972   |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 2433338  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 52       |
|    time_elapsed    | 30946    |
|    total_timesteps | 1627987  |
| train/             |          |
|    actor_loss      | -76      |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0085   |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2437785  |
---------------------------------
Eval num_timesteps=1630000, episode_reward=1048.95 +/- 0.00
Episode length: 1273.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.27e+03 |
|    mean_reward     | 1.05e+03 |
| time/              |          |
|    total_timesteps | 1630000  |
| train/             |          |
|    actor_loss      | -75.5    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.00878  |
|    ent_coef_loss   | -0.891   |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2439798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 52       |
|    time_elapsed    | 31058    |
|    total_timesteps | 1633632  |
| train/             |          |
|    actor_loss      | -74.3    |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.00922  |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 2443430  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 52       |
|    time_elapsed    | 31147    |
|    total_timesteps | 1639126  |
| train/             |          |
|    actor_loss      | -75.9    |
|    critic_loss     | 2.36     |
|    ent_coef        | 0.00914  |
|    ent_coef_loss   | -4.52    |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2448924  |
---------------------------------
Eval num_timesteps=1640000, episode_reward=1063.10 +/- 0.00
Episode length: 1309.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 1640000  |
| train/             |          |
|    actor_loss      | -73.1    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.00906  |
|    ent_coef_loss   | 0.0704   |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2449798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.32e+03 |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 52       |
|    time_elapsed    | 31259    |
|    total_timesteps | 1644791  |
| train/             |          |
|    actor_loss      | -71.3    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.00898  |
|    ent_coef_loss   | -1.61    |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 2454589  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.32e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 52       |
|    time_elapsed    | 31336    |
|    total_timesteps | 1649588  |
| train/             |          |
|    actor_loss      | -74.4    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.00922  |
|    ent_coef_loss   | -5.24    |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2459386  |
---------------------------------
Eval num_timesteps=1650000, episode_reward=1282.04 +/- 0.00
Episode length: 1586.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.59e+03 |
|    mean_reward     | 1.28e+03 |
| time/              |          |
|    total_timesteps | 1650000  |
| train/             |          |
|    actor_loss      | -73.5    |
|    critic_loss     | 2.36     |
|    ent_coef        | 0.00923  |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 2459798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.3e+03  |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 52       |
|    time_elapsed    | 31445    |
|    total_timesteps | 1655044  |
| train/             |          |
|    actor_loss      | -76      |
|    critic_loss     | 2.56     |
|    ent_coef        | 0.00924  |
|    ent_coef_loss   | -4.23    |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2464842  |
---------------------------------
Eval num_timesteps=1660000, episode_reward=1104.81 +/- 0.00
Episode length: 1345.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.34e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 1660000  |
| train/             |          |
|    actor_loss      | -75.3    |
|    critic_loss     | 2.45     |
|    ent_coef        | 0.00912  |
|    ent_coef_loss   | -4.75    |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2469798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 52       |
|    time_elapsed    | 31562    |
|    total_timesteps | 1661154  |
| train/             |          |
|    actor_loss      | -72.5    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.00898  |
|    ent_coef_loss   | -0.877   |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 2470952  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 52       |
|    time_elapsed    | 31652    |
|    total_timesteps | 1666846  |
| train/             |          |
|    actor_loss      | -72.7    |
|    critic_loss     | 2.58     |
|    ent_coef        | 0.00902  |
|    ent_coef_loss   | -5.49    |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2476644  |
---------------------------------
Eval num_timesteps=1670000, episode_reward=830.51 +/- 0.00
Episode length: 1021.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 831      |
| time/              |          |
|    total_timesteps | 1670000  |
| train/             |          |
|    actor_loss      | -72.7    |
|    critic_loss     | 3.07     |
|    ent_coef        | 0.00913  |
|    ent_coef_loss   | 3.47     |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2479798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 52       |
|    time_elapsed    | 31761    |
|    total_timesteps | 1672472  |
| train/             |          |
|    actor_loss      | -72.3    |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.00967  |
|    ent_coef_loss   | -0.141   |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 2482270  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 52       |
|    time_elapsed    | 31842    |
|    total_timesteps | 1677488  |
| train/             |          |
|    actor_loss      | -72.4    |
|    critic_loss     | 4.1      |
|    ent_coef        | 0.00943  |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2487286  |
---------------------------------
Eval num_timesteps=1680000, episode_reward=1076.18 +/- 0.00
Episode length: 1325.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 1680000  |
| train/             |          |
|    actor_loss      | -75      |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.00925  |
|    ent_coef_loss   | -6.22    |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2489798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 52       |
|    time_elapsed    | 31957    |
|    total_timesteps | 1683402  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.00916  |
|    ent_coef_loss   | -1.1     |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 2493200  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 52       |
|    time_elapsed    | 32036    |
|    total_timesteps | 1688278  |
| train/             |          |
|    actor_loss      | -72.4    |
|    critic_loss     | 4.82     |
|    ent_coef        | 0.00973  |
|    ent_coef_loss   | 2.95     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2498076  |
---------------------------------
Eval num_timesteps=1690000, episode_reward=684.16 +/- 0.00
Episode length: 911.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 911      |
|    mean_reward     | 684      |
| time/              |          |
|    total_timesteps | 1690000  |
| train/             |          |
|    actor_loss      | -72.1    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.00937  |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2499798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 52       |
|    time_elapsed    | 32131    |
|    total_timesteps | 1692923  |
| train/             |          |
|    actor_loss      | -68.7    |
|    critic_loss     | 4        |
|    ent_coef        | 0.00923  |
|    ent_coef_loss   | 0.263    |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 2502721  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 992      |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 52       |
|    time_elapsed    | 32187    |
|    total_timesteps | 1696184  |
| train/             |          |
|    actor_loss      | -74      |
|    critic_loss     | 1.39     |
|    ent_coef        | 0.00895  |
|    ent_coef_loss   | -7.11    |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2505982  |
---------------------------------
Eval num_timesteps=1700000, episode_reward=612.18 +/- 0.00
Episode length: 802.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 612      |
| time/              |          |
|    total_timesteps | 1700000  |
| train/             |          |
|    actor_loss      | -70.8    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.00965  |
|    ent_coef_loss   | 0.981    |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2509798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 52       |
|    time_elapsed    | 32283    |
|    total_timesteps | 1700938  |
| train/             |          |
|    actor_loss      | -70.8    |
|    critic_loss     | 4.3      |
|    ent_coef        | 0.00961  |
|    ent_coef_loss   | 2.9      |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 2510736  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 975      |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 52       |
|    time_elapsed    | 32361    |
|    total_timesteps | 1705720  |
| train/             |          |
|    actor_loss      | -73.3    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.00971  |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2515518  |
---------------------------------
Eval num_timesteps=1710000, episode_reward=1194.53 +/- 0.00
Episode length: 1532.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.19e+03 |
| time/              |          |
|    total_timesteps | 1710000  |
| train/             |          |
|    actor_loss      | -71.1    |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.00935  |
|    ent_coef_loss   | -2.97    |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2519798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 970      |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 52       |
|    time_elapsed    | 32476    |
|    total_timesteps | 1711554  |
| train/             |          |
|    actor_loss      | -71.1    |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.00953  |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 2521352  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 962      |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 52       |
|    time_elapsed    | 32536    |
|    total_timesteps | 1715139  |
| train/             |          |
|    actor_loss      | -72.9    |
|    critic_loss     | 8.83     |
|    ent_coef        | 0.00958  |
|    ent_coef_loss   | -2.33    |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2524937  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 52       |
|    time_elapsed    | 32600    |
|    total_timesteps | 1718918  |
| train/             |          |
|    actor_loss      | -71      |
|    critic_loss     | 5.5      |
|    ent_coef        | 0.00948  |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2528716  |
---------------------------------
Eval num_timesteps=1720000, episode_reward=814.47 +/- 0.00
Episode length: 1090.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 814      |
| time/              |          |
|    total_timesteps | 1720000  |
| train/             |          |
|    actor_loss      | -71.3    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.00939  |
|    ent_coef_loss   | -6       |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2529798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 935      |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 52       |
|    time_elapsed    | 32690    |
|    total_timesteps | 1723189  |
| train/             |          |
|    actor_loss      | -69.3    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.00957  |
|    ent_coef_loss   | 0.82     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 2532987  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 920      |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 52       |
|    time_elapsed    | 32751    |
|    total_timesteps | 1726815  |
| train/             |          |
|    actor_loss      | -68      |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.00948  |
|    ent_coef_loss   | 4.53     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2536613  |
---------------------------------
Eval num_timesteps=1730000, episode_reward=676.42 +/- 0.00
Episode length: 883.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 883      |
|    mean_reward     | 676      |
| time/              |          |
|    total_timesteps | 1730000  |
| train/             |          |
|    actor_loss      | -69.8    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.00967  |
|    ent_coef_loss   | 7.26     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2539798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 914      |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 52       |
|    time_elapsed    | 32856    |
|    total_timesteps | 1732157  |
| train/             |          |
|    actor_loss      | -70.2    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.00959  |
|    ent_coef_loss   | 4.57     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 2541955  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 911      |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 52       |
|    time_elapsed    | 32935    |
|    total_timesteps | 1737108  |
| train/             |          |
|    actor_loss      | -70.7    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.00921  |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2546906  |
---------------------------------
Eval num_timesteps=1740000, episode_reward=504.85 +/- 0.00
Episode length: 649.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 649      |
|    mean_reward     | 505      |
| time/              |          |
|    total_timesteps | 1740000  |
| train/             |          |
|    actor_loss      | -69.1    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.00893  |
|    ent_coef_loss   | -2.16    |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2549798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 902      |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 52       |
|    time_elapsed    | 33022    |
|    total_timesteps | 1741323  |
| train/             |          |
|    actor_loss      | -68.8    |
|    critic_loss     | 2.69     |
|    ent_coef        | 0.00884  |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 2551121  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 895      |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 52       |
|    time_elapsed    | 33089    |
|    total_timesteps | 1745348  |
| train/             |          |
|    actor_loss      | -68.1    |
|    critic_loss     | 5.14     |
|    ent_coef        | 0.00851  |
|    ent_coef_loss   | 4.69     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2555146  |
---------------------------------
Eval num_timesteps=1750000, episode_reward=1388.50 +/- 0.00
Episode length: 1670.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.67e+03 |
|    mean_reward     | 1.39e+03 |
| time/              |          |
|    total_timesteps | 1750000  |
| train/             |          |
|    actor_loss      | -70.2    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.00818  |
|    ent_coef_loss   | 3.12     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2559798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 896      |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 52       |
|    time_elapsed    | 33204    |
|    total_timesteps | 1751273  |
| train/             |          |
|    actor_loss      | -70.1    |
|    critic_loss     | 5.95     |
|    ent_coef        | 0.00804  |
|    ent_coef_loss   | -0.398   |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 2561071  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 896      |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 52       |
|    time_elapsed    | 33281    |
|    total_timesteps | 1755989  |
| train/             |          |
|    actor_loss      | -70.3    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.00812  |
|    ent_coef_loss   | -0.431   |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2565787  |
---------------------------------
Eval num_timesteps=1760000, episode_reward=720.16 +/- 0.00
Episode length: 906.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 906      |
|    mean_reward     | 720      |
| time/              |          |
|    total_timesteps | 1760000  |
| train/             |          |
|    actor_loss      | -69.5    |
|    critic_loss     | 4.96     |
|    ent_coef        | 0.00772  |
|    ent_coef_loss   | 2.46     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2569798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 888      |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 52       |
|    time_elapsed    | 33378    |
|    total_timesteps | 1760872  |
| train/             |          |
|    actor_loss      | -70      |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.00778  |
|    ent_coef_loss   | 6.29     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 2570670  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 887      |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 52       |
|    time_elapsed    | 33456    |
|    total_timesteps | 1765646  |
| train/             |          |
|    actor_loss      | -69.8    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.00855  |
|    ent_coef_loss   | 0.129    |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2575444  |
---------------------------------
Eval num_timesteps=1770000, episode_reward=818.58 +/- 0.00
Episode length: 1027.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 819      |
| time/              |          |
|    total_timesteps | 1770000  |
| train/             |          |
|    actor_loss      | -69.3    |
|    critic_loss     | 3.48     |
|    ent_coef        | 0.00825  |
|    ent_coef_loss   | -0.668   |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2579798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 885      |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 52       |
|    time_elapsed    | 33561    |
|    total_timesteps | 1771037  |
| train/             |          |
|    actor_loss      | -69.6    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.00844  |
|    ent_coef_loss   | 5.36     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 2580835  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 885      |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 52       |
|    time_elapsed    | 33642    |
|    total_timesteps | 1776043  |
| train/             |          |
|    actor_loss      | -70.6    |
|    critic_loss     | 6.18     |
|    ent_coef        | 0.00923  |
|    ent_coef_loss   | 4.58     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2585841  |
---------------------------------
Eval num_timesteps=1780000, episode_reward=1140.78 +/- 0.00
Episode length: 1368.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.37e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 1780000  |
| train/             |          |
|    actor_loss      | -70.8    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.00917  |
|    ent_coef_loss   | 5.41     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2589798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 887      |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 52       |
|    time_elapsed    | 33750    |
|    total_timesteps | 1781498  |
| train/             |          |
|    actor_loss      | -68.7    |
|    critic_loss     | 9.81     |
|    ent_coef        | 0.00907  |
|    ent_coef_loss   | 1.03     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 2591296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 880      |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 52       |
|    time_elapsed    | 33827    |
|    total_timesteps | 1786276  |
| train/             |          |
|    actor_loss      | -70.9    |
|    critic_loss     | 6.51     |
|    ent_coef        | 0.00891  |
|    ent_coef_loss   | 0.41     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2596074  |
---------------------------------
Eval num_timesteps=1790000, episode_reward=1129.61 +/- 0.00
Episode length: 1374.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.37e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 1790000  |
| train/             |          |
|    actor_loss      | -69.4    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.00941  |
|    ent_coef_loss   | 0.617    |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2599798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 883      |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 52       |
|    time_elapsed    | 33944    |
|    total_timesteps | 1792400  |
| train/             |          |
|    actor_loss      | -72.1    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.00904  |
|    ent_coef_loss   | -4.96    |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 2602198  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 888      |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 52       |
|    time_elapsed    | 34033    |
|    total_timesteps | 1798016  |
| train/             |          |
|    actor_loss      | -68.6    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.00951  |
|    ent_coef_loss   | 2.24     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2607814  |
---------------------------------
Eval num_timesteps=1800000, episode_reward=817.34 +/- 0.00
Episode length: 1028.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 817      |
| time/              |          |
|    total_timesteps | 1800000  |
| train/             |          |
|    actor_loss      | -69.7    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.00945  |
|    ent_coef_loss   | -5.35    |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2609798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 888      |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 52       |
|    time_elapsed    | 34139    |
|    total_timesteps | 1803389  |
| train/             |          |
|    actor_loss      | -68      |
|    critic_loss     | 7.24     |
|    ent_coef        | 0.00936  |
|    ent_coef_loss   | 4.03     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 2613187  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 891      |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 52       |
|    time_elapsed    | 34221    |
|    total_timesteps | 1808509  |
| train/             |          |
|    actor_loss      | -67.7    |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.00951  |
|    ent_coef_loss   | 0.141    |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2618307  |
---------------------------------
Eval num_timesteps=1810000, episode_reward=1335.28 +/- 0.00
Episode length: 1596.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.6e+03  |
|    mean_reward     | 1.34e+03 |
| time/              |          |
|    total_timesteps | 1810000  |
| train/             |          |
|    actor_loss      | -71.2    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.00959  |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2619798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 903      |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 52       |
|    time_elapsed    | 34332    |
|    total_timesteps | 1814112  |
| train/             |          |
|    actor_loss      | -69.9    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | -2.87    |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 2623910  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 924      |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 52       |
|    time_elapsed    | 34422    |
|    total_timesteps | 1819780  |
| train/             |          |
|    actor_loss      | -68.6    |
|    critic_loss     | 3        |
|    ent_coef        | 0.00989  |
|    ent_coef_loss   | -3.98    |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2629578  |
---------------------------------
Eval num_timesteps=1820000, episode_reward=996.74 +/- 0.00
Episode length: 1218.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 997      |
| time/              |          |
|    total_timesteps | 1820000  |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | 2.56     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2629798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 930      |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 52       |
|    time_elapsed    | 34525    |
|    total_timesteps | 1824942  |
| train/             |          |
|    actor_loss      | -66.6    |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 3.24     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 2634740  |
---------------------------------
Eval num_timesteps=1830000, episode_reward=927.55 +/- 0.00
Episode length: 1170.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 928      |
| time/              |          |
|    total_timesteps | 1830000  |
| train/             |          |
|    actor_loss      | -68.8    |
|    critic_loss     | 8.89     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 0.932    |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2639798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 932      |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 52       |
|    time_elapsed    | 34642    |
|    total_timesteps | 1831033  |
| train/             |          |
|    actor_loss      | -69.2    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -2.34    |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 2640831  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 52       |
|    time_elapsed    | 34726    |
|    total_timesteps | 1836290  |
| train/             |          |
|    actor_loss      | -68.1    |
|    critic_loss     | 6.04     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 7.45     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2646088  |
---------------------------------
Eval num_timesteps=1840000, episode_reward=718.11 +/- 0.00
Episode length: 926.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 926      |
|    mean_reward     | 718      |
| time/              |          |
|    total_timesteps | 1840000  |
| train/             |          |
|    actor_loss      | -69.7    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 3.91     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2649798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 955      |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 52       |
|    time_elapsed    | 34846    |
|    total_timesteps | 1842758  |
| train/             |          |
|    actor_loss      | -68.8    |
|    critic_loss     | 4.97     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -3.26    |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 2652556  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 966      |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 52       |
|    time_elapsed    | 34927    |
|    total_timesteps | 1847775  |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 14.6     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 0.917    |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2657573  |
---------------------------------
Eval num_timesteps=1850000, episode_reward=843.91 +/- 0.00
Episode length: 1086.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 1850000  |
| train/             |          |
|    actor_loss      | -66.5    |
|    critic_loss     | 10.3     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 8.16     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2659798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 968      |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 52       |
|    time_elapsed    | 35033    |
|    total_timesteps | 1853215  |
| train/             |          |
|    actor_loss      | -68.7    |
|    critic_loss     | 5.14     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 4.15     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2663013  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 945      |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 52       |
|    time_elapsed    | 35053    |
|    total_timesteps | 1853931  |
| train/             |          |
|    actor_loss      | -71      |
|    critic_loss     | 5.69     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -4.02    |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 2663729  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 52       |
|    time_elapsed    | 35084    |
|    total_timesteps | 1855401  |
| train/             |          |
|    actor_loss      | -68.1    |
|    critic_loss     | 7.65     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 5.79     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2665199  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 917      |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 52       |
|    time_elapsed    | 35156    |
|    total_timesteps | 1859834  |
| train/             |          |
|    actor_loss      | -71.8    |
|    critic_loss     | 7.13     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -0.864   |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2669632  |
---------------------------------
Eval num_timesteps=1860000, episode_reward=579.12 +/- 0.00
Episode length: 755.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 755      |
|    mean_reward     | 579      |
| time/              |          |
|    total_timesteps | 1860000  |
| train/             |          |
|    actor_loss      | -71.3    |
|    critic_loss     | 8.1      |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 2669798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 52       |
|    time_elapsed    | 35273    |
|    total_timesteps | 1866076  |
| train/             |          |
|    actor_loss      | -70.3    |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -2.59    |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2675874  |
---------------------------------
Eval num_timesteps=1870000, episode_reward=1523.91 +/- 0.00
Episode length: 1797.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.8e+03  |
|    mean_reward     | 1.52e+03 |
| time/              |          |
|    total_timesteps | 1870000  |
| train/             |          |
|    actor_loss      | -70.5    |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -0.0758  |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2679798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 965      |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 52       |
|    time_elapsed    | 35417    |
|    total_timesteps | 1873795  |
| train/             |          |
|    actor_loss      | -67.7    |
|    critic_loss     | 10       |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.964    |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 2683593  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 972      |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 52       |
|    time_elapsed    | 35509    |
|    total_timesteps | 1879147  |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 5.82     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.541    |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2688945  |
---------------------------------
Eval num_timesteps=1880000, episode_reward=1092.16 +/- 0.00
Episode length: 1309.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 1880000  |
| train/             |          |
|    actor_loss      | -69.1    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -4.79    |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2689798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 973      |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 52       |
|    time_elapsed    | 35622    |
|    total_timesteps | 1884932  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 3.46     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 2694730  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 972      |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 52       |
|    time_elapsed    | 35691    |
|    total_timesteps | 1889086  |
| train/             |          |
|    actor_loss      | -68.4    |
|    critic_loss     | 4.98     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -2.78    |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2698884  |
---------------------------------
Eval num_timesteps=1890000, episode_reward=1084.26 +/- 0.00
Episode length: 1314.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 1890000  |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 0.113    |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2699798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 973      |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 52       |
|    time_elapsed    | 35804    |
|    total_timesteps | 1894847  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 5.44     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 4.05     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 2704645  |
---------------------------------
Eval num_timesteps=1900000, episode_reward=1176.62 +/- 0.00
Episode length: 1429.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.43e+03 |
|    mean_reward     | 1.18e+03 |
| time/              |          |
|    total_timesteps | 1900000  |
| train/             |          |
|    actor_loss      | -67.2    |
|    critic_loss     | 7.55     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2709798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 984      |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 52       |
|    time_elapsed    | 35933    |
|    total_timesteps | 1901735  |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 2711533  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 996      |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 52       |
|    time_elapsed    | 36034    |
|    total_timesteps | 1908128  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.91     |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2717926  |
---------------------------------
Eval num_timesteps=1910000, episode_reward=1186.19 +/- 0.00
Episode length: 1440.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.44e+03 |
|    mean_reward     | 1.19e+03 |
| time/              |          |
|    total_timesteps | 1910000  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.635   |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2719798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 999      |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 52       |
|    time_elapsed    | 36153    |
|    total_timesteps | 1914248  |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 7.95     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 3.39     |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 2724046  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 996      |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 52       |
|    time_elapsed    | 36224    |
|    total_timesteps | 1918555  |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -9.01    |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2728353  |
---------------------------------
Eval num_timesteps=1920000, episode_reward=1117.80 +/- 0.00
Episode length: 1401.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 1920000  |
| train/             |          |
|    actor_loss      | -67      |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 4.15     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2729798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 52       |
|    time_elapsed    | 36337    |
|    total_timesteps | 1924304  |
| train/             |          |
|    actor_loss      | -69.9    |
|    critic_loss     | 6.66     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -3.44    |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 2734102  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 997      |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 52       |
|    time_elapsed    | 36421    |
|    total_timesteps | 1929497  |
| train/             |          |
|    actor_loss      | -68.2    |
|    critic_loss     | 7.79     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -0.873   |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2739295  |
---------------------------------
Eval num_timesteps=1930000, episode_reward=906.22 +/- 0.00
Episode length: 1145.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.14e+03 |
|    mean_reward     | 906      |
| time/              |          |
|    total_timesteps | 1930000  |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 3.7      |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 2739798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 52       |
|    time_elapsed    | 36541    |
|    total_timesteps | 1935499  |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 23.4     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 4.94     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2745297  |
---------------------------------
Eval num_timesteps=1940000, episode_reward=794.02 +/- 0.00
Episode length: 989.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 989      |
|    mean_reward     | 794      |
| time/              |          |
|    total_timesteps | 1940000  |
| train/             |          |
|    actor_loss      | -73      |
|    critic_loss     | 4.94     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -2.34    |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2749798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 52       |
|    time_elapsed    | 36651    |
|    total_timesteps | 1941215  |
| train/             |          |
|    actor_loss      | -69.4    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 3.22     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 2751013  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 993      |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 52       |
|    time_elapsed    | 36725    |
|    total_timesteps | 1945777  |
| train/             |          |
|    actor_loss      | -69.2    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 0.213    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2755575  |
---------------------------------
Eval num_timesteps=1950000, episode_reward=941.44 +/- 0.00
Episode length: 1167.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 941      |
| time/              |          |
|    total_timesteps | 1950000  |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 7.05     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2759798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 988      |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 52       |
|    time_elapsed    | 36831    |
|    total_timesteps | 1951152  |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -3.55    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 2760950  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 988      |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 52       |
|    time_elapsed    | 36910    |
|    total_timesteps | 1956074  |
| train/             |          |
|    actor_loss      | -69.2    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2765872  |
---------------------------------
Eval num_timesteps=1960000, episode_reward=856.55 +/- 0.00
Episode length: 1072.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.07e+03 |
|    mean_reward     | 857      |
| time/              |          |
|    total_timesteps | 1960000  |
| train/             |          |
|    actor_loss      | -68.3    |
|    critic_loss     | 6.26     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.789   |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2769798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 987      |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 52       |
|    time_elapsed    | 37013    |
|    total_timesteps | 1961266  |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 6.26     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.331   |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 2771064  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 982      |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 53       |
|    time_elapsed    | 37090    |
|    total_timesteps | 1965939  |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 9.16     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2775737  |
---------------------------------
Eval num_timesteps=1970000, episode_reward=956.02 +/- 0.00
Episode length: 1178.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 956      |
| time/              |          |
|    total_timesteps | 1970000  |
| train/             |          |
|    actor_loss      | -67.7    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.99    |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2779798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 52       |
|    time_elapsed    | 37194    |
|    total_timesteps | 1971180  |
| train/             |          |
|    actor_loss      | -68.6    |
|    critic_loss     | 8.91     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -2.51    |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 2780978  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 975      |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 53       |
|    time_elapsed    | 37270    |
|    total_timesteps | 1975848  |
| train/             |          |
|    actor_loss      | -67.4    |
|    critic_loss     | 43.9     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.2     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2785646  |
---------------------------------
Eval num_timesteps=1980000, episode_reward=1029.29 +/- 0.00
Episode length: 1307.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 1980000  |
| train/             |          |
|    actor_loss      | -67.6    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2789798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 53       |
|    time_elapsed    | 37376    |
|    total_timesteps | 1981169  |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 6.22     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 3.63     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 2790967  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 53       |
|    time_elapsed    | 37449    |
|    total_timesteps | 1985613  |
| train/             |          |
|    actor_loss      | -68.9    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2795411  |
---------------------------------
Eval num_timesteps=1990000, episode_reward=645.32 +/- 0.00
Episode length: 799.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 799      |
|    mean_reward     | 645      |
| time/              |          |
|    total_timesteps | 1990000  |
| train/             |          |
|    actor_loss      | -65.3    |
|    critic_loss     | 7.52     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.189    |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2799798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 53       |
|    time_elapsed    | 37557    |
|    total_timesteps | 1991222  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 6.12     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 7        |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 2801020  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 53       |
|    time_elapsed    | 37627    |
|    total_timesteps | 1995448  |
| train/             |          |
|    actor_loss      | -68.9    |
|    critic_loss     | 8.08     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2805246  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 53       |
|    time_elapsed    | 37697    |
|    total_timesteps | 1999739  |
| train/             |          |
|    actor_loss      | -68.5    |
|    critic_loss     | 6.59     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 8e-05    |
|    n_updates       | 2809537  |
---------------------------------
Eval num_timesteps=2000000, episode_reward=677.16 +/- 0.00
Episode length: 855.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 855      |
|    mean_reward     | 677      |
| time/              |          |
|    total_timesteps | 2000000  |
| train/             |          |
|    actor_loss      | -67.9    |
|    critic_loss     | 6.24     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 6.47     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2809798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 991      |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 53       |
|    time_elapsed    | 37792    |
|    total_timesteps | 2004406  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 12       |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 5.39     |
|    learning_rate   | 8e-05    |
|    n_updates       | 2814204  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 981      |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 53       |
|    time_elapsed    | 37862    |
|    total_timesteps | 2008622  |
| train/             |          |
|    actor_loss      | -67.4    |
|    critic_loss     | 7.99     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.476   |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2818420  |
---------------------------------
Eval num_timesteps=2010000, episode_reward=743.97 +/- 0.00
Episode length: 926.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 926      |
|    mean_reward     | 744      |
| time/              |          |
|    total_timesteps | 2010000  |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 9.47     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2819798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 976      |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 53       |
|    time_elapsed    | 37957    |
|    total_timesteps | 2013358  |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 8.89     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 5.72     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 2823156  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 980      |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 53       |
|    time_elapsed    | 38034    |
|    total_timesteps | 2018038  |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 7.69     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.06     |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 2827836  |
---------------------------------
Eval num_timesteps=2020000, episode_reward=947.56 +/- 0.00
Episode length: 1215.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 948      |
| time/              |          |
|    total_timesteps | 2020000  |
| train/             |          |
|    actor_loss      | -69.6    |
|    critic_loss     | 5        |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.47    |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 2829798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 972      |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 53       |
|    time_elapsed    | 38132    |
|    total_timesteps | 2022849  |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 8.96     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.98     |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 2832647  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 961      |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 53       |
|    time_elapsed    | 38206    |
|    total_timesteps | 2027403  |
| train/             |          |
|    actor_loss      | -68.4    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 2837201  |
---------------------------------
Eval num_timesteps=2030000, episode_reward=994.89 +/- 0.00
Episode length: 1228.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.23e+03 |
|    mean_reward     | 995      |
| time/              |          |
|    total_timesteps | 2030000  |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 8.12     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.524    |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 2839798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 944      |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 53       |
|    time_elapsed    | 38308    |
|    total_timesteps | 2032378  |
| train/             |          |
|    actor_loss      | -67.1    |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -3.31    |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 2842176  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 53       |
|    time_elapsed    | 38385    |
|    total_timesteps | 2037070  |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -0.842   |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 2846868  |
---------------------------------
Eval num_timesteps=2040000, episode_reward=799.89 +/- 0.00
Episode length: 994.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 994      |
|    mean_reward     | 800      |
| time/              |          |
|    total_timesteps | 2040000  |
| train/             |          |
|    actor_loss      | -66.3    |
|    critic_loss     | 5.8      |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -3.3     |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 2849798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 941      |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 53       |
|    time_elapsed    | 38489    |
|    total_timesteps | 2042329  |
| train/             |          |
|    actor_loss      | -68.3    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.106   |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 2852127  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 931      |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 53       |
|    time_elapsed    | 38562    |
|    total_timesteps | 2046831  |
| train/             |          |
|    actor_loss      | -67.7    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.991   |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 2856629  |
---------------------------------
Eval num_timesteps=2050000, episode_reward=728.08 +/- 0.00
Episode length: 920.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 920      |
|    mean_reward     | 728      |
| time/              |          |
|    total_timesteps | 2050000  |
| train/             |          |
|    actor_loss      | -70.4    |
|    critic_loss     | 3.55     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -4.67    |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 2859798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 53       |
|    time_elapsed    | 38652    |
|    total_timesteps | 2051170  |
| train/             |          |
|    actor_loss      | -68.5    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 2860968  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 910      |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 53       |
|    time_elapsed    | 38722    |
|    total_timesteps | 2055383  |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 6.35     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1       |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 2865181  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 904      |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 53       |
|    time_elapsed    | 38790    |
|    total_timesteps | 2059501  |
| train/             |          |
|    actor_loss      | -67.2    |
|    critic_loss     | 3.48     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.06    |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 2869299  |
---------------------------------
Eval num_timesteps=2060000, episode_reward=738.82 +/- 0.00
Episode length: 947.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 947      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 2060000  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.57     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 2869798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 53       |
|    time_elapsed    | 38883    |
|    total_timesteps | 2064081  |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.281   |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 2873879  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 889      |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 53       |
|    time_elapsed    | 38948    |
|    total_timesteps | 2067940  |
| train/             |          |
|    actor_loss      | -64.1    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 2877738  |
---------------------------------
Eval num_timesteps=2070000, episode_reward=823.11 +/- 0.00
Episode length: 1047.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.05e+03 |
|    mean_reward     | 823      |
| time/              |          |
|    total_timesteps | 2070000  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 6.67     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 2879798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 882      |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 53       |
|    time_elapsed    | 39047    |
|    total_timesteps | 2072832  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 7.09     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 0.239    |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 2882630  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 872      |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 53       |
|    time_elapsed    | 39109    |
|    total_timesteps | 2076514  |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.522    |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 2886312  |
---------------------------------
Eval num_timesteps=2080000, episode_reward=614.08 +/- 0.00
Episode length: 768.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 768      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 2080000  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 0.13     |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 2889798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 866      |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 53       |
|    time_elapsed    | 39199    |
|    total_timesteps | 2080876  |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 6.9      |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 4.1      |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 2890674  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 855      |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 53       |
|    time_elapsed    | 39260    |
|    total_timesteps | 2084498  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 5.04     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 2894296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 848      |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 53       |
|    time_elapsed    | 39324    |
|    total_timesteps | 2088334  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 8.14     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 6.95     |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 2898132  |
---------------------------------
Eval num_timesteps=2090000, episode_reward=700.49 +/- 0.00
Episode length: 896.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 896      |
|    mean_reward     | 700      |
| time/              |          |
|    total_timesteps | 2090000  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 8.68     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 2899798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 834      |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 53       |
|    time_elapsed    | 39409    |
|    total_timesteps | 2092288  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 5.7      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 3.76     |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 2902086  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 826      |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 53       |
|    time_elapsed    | 39468    |
|    total_timesteps | 2095780  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 7.07     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.82     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 2905578  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 819      |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 53       |
|    time_elapsed    | 39530    |
|    total_timesteps | 2099419  |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 8.68     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.9     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 2909217  |
---------------------------------
Eval num_timesteps=2100000, episode_reward=667.24 +/- 0.00
Episode length: 855.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 855      |
|    mean_reward     | 667      |
| time/              |          |
|    total_timesteps | 2100000  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 9.63     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 6.08     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 2909798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 816      |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 53       |
|    time_elapsed    | 39620    |
|    total_timesteps | 2103765  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 2913563  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 811      |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 53       |
|    time_elapsed    | 39682    |
|    total_timesteps | 2107421  |
| train/             |          |
|    actor_loss      | -66.7    |
|    critic_loss     | 5.23     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.27     |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 2917219  |
---------------------------------
Eval num_timesteps=2110000, episode_reward=726.67 +/- 0.00
Episode length: 916.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 916      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 2110000  |
| train/             |          |
|    actor_loss      | -67.1    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.324   |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 2919798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 805      |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 53       |
|    time_elapsed    | 39775    |
|    total_timesteps | 2111958  |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 5.6      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 2.16     |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 2921756  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 799      |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 53       |
|    time_elapsed    | 39834    |
|    total_timesteps | 2115407  |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 5.86     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.991   |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 2925205  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 796      |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 53       |
|    time_elapsed    | 39899    |
|    total_timesteps | 2119309  |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -3.88    |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 2929107  |
---------------------------------
Eval num_timesteps=2120000, episode_reward=728.26 +/- 0.00
Episode length: 907.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 907      |
|    mean_reward     | 728      |
| time/              |          |
|    total_timesteps | 2120000  |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.708    |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 2929798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 991      |
|    ep_rew_mean     | 787      |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 53       |
|    time_elapsed    | 39987    |
|    total_timesteps | 2123514  |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 4.92     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 2933312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 995      |
|    ep_rew_mean     | 790      |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 53       |
|    time_elapsed    | 40059    |
|    total_timesteps | 2127892  |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 6.32     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -0.0549  |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 2937690  |
---------------------------------
Eval num_timesteps=2130000, episode_reward=949.01 +/- 0.00
Episode length: 1203.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 949      |
| time/              |          |
|    total_timesteps | 2130000  |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -5.34    |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 2939798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 991      |
|    ep_rew_mean     | 787      |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 53       |
|    time_elapsed    | 40163    |
|    total_timesteps | 2133100  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 2.22     |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 2942898  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 787      |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 53       |
|    time_elapsed    | 40236    |
|    total_timesteps | 2137578  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 4.64     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -0.512   |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 2947376  |
---------------------------------
Eval num_timesteps=2140000, episode_reward=958.40 +/- 0.00
Episode length: 1204.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 958      |
| time/              |          |
|    total_timesteps | 2140000  |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 5.21     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -1.19    |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 2949798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 989      |
|    ep_rew_mean     | 786      |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 53       |
|    time_elapsed    | 40335    |
|    total_timesteps | 2142358  |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -0.962   |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 2952156  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 983      |
|    ep_rew_mean     | 782      |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 53       |
|    time_elapsed    | 40406    |
|    total_timesteps | 2146678  |
| train/             |          |
|    actor_loss      | -66.3    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -1.55    |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 2956476  |
---------------------------------
Eval num_timesteps=2150000, episode_reward=828.34 +/- 0.00
Episode length: 1032.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 828      |
| time/              |          |
|    total_timesteps | 2150000  |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.243   |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 2959798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 979      |
|    ep_rew_mean     | 778      |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 53       |
|    time_elapsed    | 40496    |
|    total_timesteps | 2150974  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.72    |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 2960772  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 981      |
|    ep_rew_mean     | 781      |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 53       |
|    time_elapsed    | 40568    |
|    total_timesteps | 2155352  |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.875   |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 2965150  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 780      |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 53       |
|    time_elapsed    | 40637    |
|    total_timesteps | 2159459  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 2969257  |
---------------------------------
Eval num_timesteps=2160000, episode_reward=878.63 +/- 0.00
Episode length: 1114.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 879      |
| time/              |          |
|    total_timesteps | 2160000  |
| train/             |          |
|    actor_loss      | -68.5    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 2969798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 980      |
|    ep_rew_mean     | 780      |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 53       |
|    time_elapsed    | 40733    |
|    total_timesteps | 2164156  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 7.23     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 2973954  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 982      |
|    ep_rew_mean     | 782      |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 53       |
|    time_elapsed    | 40803    |
|    total_timesteps | 2168450  |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.216   |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 2978248  |
---------------------------------
Eval num_timesteps=2170000, episode_reward=783.69 +/- 0.00
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 784      |
| time/              |          |
|    total_timesteps | 2170000  |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -3.14    |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 2979798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 787      |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 53       |
|    time_elapsed    | 40902    |
|    total_timesteps | 2173336  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 2.48     |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 2983134  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 995      |
|    ep_rew_mean     | 790      |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 53       |
|    time_elapsed    | 40977    |
|    total_timesteps | 2177895  |
| train/             |          |
|    actor_loss      | -66.6    |
|    critic_loss     | 35.2     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 2987693  |
---------------------------------
Eval num_timesteps=2180000, episode_reward=938.44 +/- 0.00
Episode length: 1199.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 938      |
| time/              |          |
|    total_timesteps | 2180000  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 2989798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 796      |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 53       |
|    time_elapsed    | 41084    |
|    total_timesteps | 2183322  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.57     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.99    |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 2993120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 800      |
| time/              |          |
|    episodes        | 1960     |
|    fps             | 53       |
|    time_elapsed    | 41159    |
|    total_timesteps | 2187938  |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 16.7     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.13     |
|    learning_rate   | 7.81e-05 |
|    n_updates       | 2997736  |
---------------------------------
Eval num_timesteps=2190000, episode_reward=986.57 +/- 0.00
Episode length: 1269.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.27e+03 |
|    mean_reward     | 987      |
| time/              |          |
|    total_timesteps | 2190000  |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.513   |
|    learning_rate   | 7.81e-05 |
|    n_updates       | 2999798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 804      |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 53       |
|    time_elapsed    | 41249    |
|    total_timesteps | 2192142  |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 7.81e-05 |
|    n_updates       | 3001940  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 808      |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 53       |
|    time_elapsed    | 41322    |
|    total_timesteps | 2196494  |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 5.37     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 7.8e-05  |
|    n_updates       | 3006292  |
---------------------------------
Eval num_timesteps=2200000, episode_reward=895.27 +/- 0.00
Episode length: 1146.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.15e+03 |
|    mean_reward     | 895      |
| time/              |          |
|    total_timesteps | 2200000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 6.32     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 3.68     |
|    learning_rate   | 7.8e-05  |
|    n_updates       | 3009798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 816      |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 53       |
|    time_elapsed    | 41415    |
|    total_timesteps | 2200915  |
| train/             |          |
|    actor_loss      | -66.5    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -4.94    |
|    learning_rate   | 7.8e-05  |
|    n_updates       | 3010713  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 821      |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 53       |
|    time_elapsed    | 41483    |
|    total_timesteps | 2205057  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 8.32     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 0.577    |
|    learning_rate   | 7.79e-05 |
|    n_updates       | 3014855  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 826      |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 53       |
|    time_elapsed    | 41554    |
|    total_timesteps | 2209388  |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 8.43     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.598   |
|    learning_rate   | 7.79e-05 |
|    n_updates       | 3019186  |
---------------------------------
Eval num_timesteps=2210000, episode_reward=908.12 +/- 0.00
Episode length: 1173.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 908      |
| time/              |          |
|    total_timesteps | 2210000  |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 7.79e-05 |
|    n_updates       | 3019798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 831      |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 53       |
|    time_elapsed    | 41658    |
|    total_timesteps | 2214549  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 7.91     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 4.1      |
|    learning_rate   | 7.79e-05 |
|    n_updates       | 3024347  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 835      |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 53       |
|    time_elapsed    | 41727    |
|    total_timesteps | 2218753  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 3.86     |
|    learning_rate   | 7.78e-05 |
|    n_updates       | 3028551  |
---------------------------------
Eval num_timesteps=2220000, episode_reward=829.52 +/- 0.00
Episode length: 1062.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.06e+03 |
|    mean_reward     | 830      |
| time/              |          |
|    total_timesteps | 2220000  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -1.41    |
|    learning_rate   | 7.78e-05 |
|    n_updates       | 3029798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 837      |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 53       |
|    time_elapsed    | 41818    |
|    total_timesteps | 2223076  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 7.66     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 1.98     |
|    learning_rate   | 7.78e-05 |
|    n_updates       | 3032874  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 842      |
| time/              |          |
|    episodes        | 1996     |
|    fps             | 53       |
|    time_elapsed    | 41887    |
|    total_timesteps | 2227241  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 7.77e-05 |
|    n_updates       | 3037039  |
---------------------------------
Eval num_timesteps=2230000, episode_reward=876.47 +/- 0.00
Episode length: 1121.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 876      |
| time/              |          |
|    total_timesteps | 2230000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -0.851   |
|    learning_rate   | 7.77e-05 |
|    n_updates       | 3039798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.07e+03 |
|    ep_rew_mean     | 846      |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 53       |
|    time_elapsed    | 41988    |
|    total_timesteps | 2232274  |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -2.87    |
|    learning_rate   | 7.77e-05 |
|    n_updates       | 3042072  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 852      |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 53       |
|    time_elapsed    | 42061    |
|    total_timesteps | 2236726  |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 13.1     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.454    |
|    learning_rate   | 7.76e-05 |
|    n_updates       | 3046524  |
---------------------------------
Eval num_timesteps=2240000, episode_reward=868.86 +/- 0.00
Episode length: 1116.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 869      |
| time/              |          |
|    total_timesteps | 2240000  |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 7.26     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 2.78     |
|    learning_rate   | 7.76e-05 |
|    n_updates       | 3049798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 851      |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 53       |
|    time_elapsed    | 42154    |
|    total_timesteps | 2241111  |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -0.155   |
|    learning_rate   | 7.76e-05 |
|    n_updates       | 3050909  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 851      |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 53       |
|    time_elapsed    | 42222    |
|    total_timesteps | 2245258  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 7.65     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 0.661    |
|    learning_rate   | 7.75e-05 |
|    n_updates       | 3055056  |
---------------------------------
Eval num_timesteps=2250000, episode_reward=1402.29 +/- 0.00
Episode length: 1820.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.82e+03 |
|    mean_reward     | 1.4e+03  |
| time/              |          |
|    total_timesteps | 2250000  |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 5        |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -0.626   |
|    learning_rate   | 7.75e-05 |
|    n_updates       | 3059798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 853      |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 53       |
|    time_elapsed    | 42340    |
|    total_timesteps | 2251220  |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 6.91     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 7.75e-05 |
|    n_updates       | 3061018  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.08e+03 |
|    ep_rew_mean     | 851      |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 53       |
|    time_elapsed    | 42409    |
|    total_timesteps | 2255436  |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 7.25     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -0.939   |
|    learning_rate   | 7.74e-05 |
|    n_updates       | 3065234  |
---------------------------------
Eval num_timesteps=2260000, episode_reward=1028.99 +/- 0.00
Episode length: 1294.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2260000  |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -0.0422  |
|    learning_rate   | 7.74e-05 |
|    n_updates       | 3069798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.09e+03 |
|    ep_rew_mean     | 857      |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 53       |
|    time_elapsed    | 42527    |
|    total_timesteps | 2261588  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 9.35     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 1.97     |
|    learning_rate   | 7.74e-05 |
|    n_updates       | 3071386  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 862      |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 53       |
|    time_elapsed    | 42603    |
|    total_timesteps | 2266283  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 8.66     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 4.6      |
|    learning_rate   | 7.73e-05 |
|    n_updates       | 3076081  |
---------------------------------
Eval num_timesteps=2270000, episode_reward=1005.30 +/- 0.00
Episode length: 1287.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 1.01e+03 |
| time/              |          |
|    total_timesteps | 2270000  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 8.67     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -0.933   |
|    learning_rate   | 7.73e-05 |
|    n_updates       | 3079798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.1e+03  |
|    ep_rew_mean     | 862      |
| time/              |          |
|    episodes        | 2032     |
|    fps             | 53       |
|    time_elapsed    | 42702    |
|    total_timesteps | 2271114  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 7.78     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 7.73e-05 |
|    n_updates       | 3080912  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.11e+03 |
|    ep_rew_mean     | 868      |
| time/              |          |
|    episodes        | 2036     |
|    fps             | 53       |
|    time_elapsed    | 42780    |
|    total_timesteps | 2275963  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 6.01     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 0.892    |
|    learning_rate   | 7.72e-05 |
|    n_updates       | 3085761  |
---------------------------------
Eval num_timesteps=2280000, episode_reward=961.39 +/- 0.00
Episode length: 1239.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 961      |
| time/              |          |
|    total_timesteps | 2280000  |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 5.8      |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -5.03    |
|    learning_rate   | 7.72e-05 |
|    n_updates       | 3089798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 873      |
| time/              |          |
|    episodes        | 2040     |
|    fps             | 53       |
|    time_elapsed    | 42888    |
|    total_timesteps | 2281440  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -3.73    |
|    learning_rate   | 7.72e-05 |
|    n_updates       | 3091238  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 877      |
| time/              |          |
|    episodes        | 2044     |
|    fps             | 53       |
|    time_elapsed    | 42967    |
|    total_timesteps | 2286310  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 7.21     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.985    |
|    learning_rate   | 7.71e-05 |
|    n_updates       | 3096108  |
---------------------------------
Eval num_timesteps=2290000, episode_reward=997.20 +/- 0.00
Episode length: 1260.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 997      |
| time/              |          |
|    total_timesteps | 2290000  |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.7      |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 0.823    |
|    learning_rate   | 7.71e-05 |
|    n_updates       | 3099798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 884      |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 53       |
|    time_elapsed    | 43087    |
|    total_timesteps | 2292649  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 6.15     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 0.00955  |
|    learning_rate   | 7.71e-05 |
|    n_updates       | 3102447  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 889      |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 53       |
|    time_elapsed    | 43169    |
|    total_timesteps | 2297836  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 6.27     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 7.7e-05  |
|    n_updates       | 3107634  |
---------------------------------
Eval num_timesteps=2300000, episode_reward=930.90 +/- 0.00
Episode length: 1193.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.19e+03 |
|    mean_reward     | 931      |
| time/              |          |
|    total_timesteps | 2300000  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 4.7      |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -3.45    |
|    learning_rate   | 7.7e-05  |
|    n_updates       | 3109798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 894      |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 53       |
|    time_elapsed    | 43284    |
|    total_timesteps | 2303761  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 7.18     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -0.98    |
|    learning_rate   | 7.7e-05  |
|    n_updates       | 3113559  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 53       |
|    time_elapsed    | 43367    |
|    total_timesteps | 2308993  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 6.53     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 7.69e-05 |
|    n_updates       | 3118791  |
---------------------------------
Eval num_timesteps=2310000, episode_reward=1292.15 +/- 0.00
Episode length: 1659.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.66e+03 |
|    mean_reward     | 1.29e+03 |
| time/              |          |
|    total_timesteps | 2310000  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 8.64     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 3.38     |
|    learning_rate   | 7.69e-05 |
|    n_updates       | 3119798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 905      |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 53       |
|    time_elapsed    | 43483    |
|    total_timesteps | 2314873  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 9.48     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 2.79     |
|    learning_rate   | 7.69e-05 |
|    n_updates       | 3124671  |
---------------------------------
Eval num_timesteps=2320000, episode_reward=1230.67 +/- 0.00
Episode length: 1557.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.56e+03 |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 2320000  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 7.1      |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | 1.31     |
|    learning_rate   | 7.68e-05 |
|    n_updates       | 3129798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 53       |
|    time_elapsed    | 43604    |
|    total_timesteps | 2321224  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 6.31     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 0.424    |
|    learning_rate   | 7.68e-05 |
|    n_updates       | 3131022  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 917      |
| time/              |          |
|    episodes        | 2072     |
|    fps             | 53       |
|    time_elapsed    | 43684    |
|    total_timesteps | 2326186  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -4.8     |
|    learning_rate   | 7.67e-05 |
|    n_updates       | 3135984  |
---------------------------------
Eval num_timesteps=2330000, episode_reward=1044.13 +/- 0.00
Episode length: 1333.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.33e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 2330000  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.228   |
|    learning_rate   | 7.67e-05 |
|    n_updates       | 3139798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 921      |
| time/              |          |
|    episodes        | 2076     |
|    fps             | 53       |
|    time_elapsed    | 43786    |
|    total_timesteps | 2331268  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 9        |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 7.67e-05 |
|    n_updates       | 3141066  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 927      |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 53       |
|    time_elapsed    | 43865    |
|    total_timesteps | 2336154  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 7.66e-05 |
|    n_updates       | 3145952  |
---------------------------------
Eval num_timesteps=2340000, episode_reward=1030.83 +/- 0.00
Episode length: 1286.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.29e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2340000  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 7.64     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 7.66e-05 |
|    n_updates       | 3149798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 934      |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 53       |
|    time_elapsed    | 43984    |
|    total_timesteps | 2342528  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 5.91     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -0.872   |
|    learning_rate   | 7.66e-05 |
|    n_updates       | 3152326  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 942      |
| time/              |          |
|    episodes        | 2088     |
|    fps             | 53       |
|    time_elapsed    | 44068    |
|    total_timesteps | 2347785  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 8.71     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 0.0381   |
|    learning_rate   | 7.65e-05 |
|    n_updates       | 3157583  |
---------------------------------
Eval num_timesteps=2350000, episode_reward=1050.88 +/- 0.00
Episode length: 1350.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.35e+03 |
|    mean_reward     | 1.05e+03 |
| time/              |          |
|    total_timesteps | 2350000  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -2.97    |
|    learning_rate   | 7.65e-05 |
|    n_updates       | 3159798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 952      |
| time/              |          |
|    episodes        | 2092     |
|    fps             | 53       |
|    time_elapsed    | 44185    |
|    total_timesteps | 2353795  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 9.12     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 2.36     |
|    learning_rate   | 7.65e-05 |
|    n_updates       | 3163593  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 960      |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 53       |
|    time_elapsed    | 44266    |
|    total_timesteps | 2358882  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 7.64e-05 |
|    n_updates       | 3168680  |
---------------------------------
Eval num_timesteps=2360000, episode_reward=1026.15 +/- 0.00
Episode length: 1258.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2360000  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 8.06     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 7.64e-05 |
|    n_updates       | 3169798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 965      |
| time/              |          |
|    episodes        | 2100     |
|    fps             | 53       |
|    time_elapsed    | 44384    |
|    total_timesteps | 2365009  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 6.23     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 0.27     |
|    learning_rate   | 7.63e-05 |
|    n_updates       | 3174807  |
---------------------------------
Eval num_timesteps=2370000, episode_reward=933.63 +/- 0.00
Episode length: 1165.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 934      |
| time/              |          |
|    total_timesteps | 2370000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 6.64     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 7.63e-05 |
|    n_updates       | 3179798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 960      |
| time/              |          |
|    episodes        | 2104     |
|    fps             | 53       |
|    time_elapsed    | 44485    |
|    total_timesteps | 2370032  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 7.63e-05 |
|    n_updates       | 3179830  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 965      |
| time/              |          |
|    episodes        | 2108     |
|    fps             | 53       |
|    time_elapsed    | 44564    |
|    total_timesteps | 2374898  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 9.28     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -2.64    |
|    learning_rate   | 7.63e-05 |
|    n_updates       | 3184696  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 970      |
| time/              |          |
|    episodes        | 2112     |
|    fps             | 53       |
|    time_elapsed    | 44640    |
|    total_timesteps | 2379558  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 6.31     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -2.64    |
|    learning_rate   | 7.62e-05 |
|    n_updates       | 3189356  |
---------------------------------
Eval num_timesteps=2380000, episode_reward=968.61 +/- 0.00
Episode length: 1200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 969      |
| time/              |          |
|    total_timesteps | 2380000  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 6.28     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 0.53     |
|    learning_rate   | 7.62e-05 |
|    n_updates       | 3189798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 969      |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 53       |
|    time_elapsed    | 44742    |
|    total_timesteps | 2384648  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 6.25     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.461    |
|    learning_rate   | 7.62e-05 |
|    n_updates       | 3194446  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 977      |
| time/              |          |
|    episodes        | 2120     |
|    fps             | 53       |
|    time_elapsed    | 44825    |
|    total_timesteps | 2389766  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 5.62     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | 0.623    |
|    learning_rate   | 7.61e-05 |
|    n_updates       | 3199564  |
---------------------------------
Eval num_timesteps=2390000, episode_reward=935.46 +/- 0.00
Episode length: 1165.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 935      |
| time/              |          |
|    total_timesteps | 2390000  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 6.33     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 0.749    |
|    learning_rate   | 7.61e-05 |
|    n_updates       | 3199798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 53       |
|    time_elapsed    | 44930    |
|    total_timesteps | 2395094  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 5.26     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 7.6e-05  |
|    n_updates       | 3204892  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2128     |
|    fps             | 53       |
|    time_elapsed    | 45006    |
|    total_timesteps | 2399670  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 7.61     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 0.365    |
|    learning_rate   | 7.6e-05  |
|    n_updates       | 3209468  |
---------------------------------
Eval num_timesteps=2400000, episode_reward=887.97 +/- 0.00
Episode length: 1086.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 888      |
| time/              |          |
|    total_timesteps | 2400000  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 5.41     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 1.24     |
|    learning_rate   | 7.6e-05  |
|    n_updates       | 3209798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2132     |
|    fps             | 53       |
|    time_elapsed    | 45102    |
|    total_timesteps | 2404428  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 5.97     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 0.0596   |
|    learning_rate   | 7.6e-05  |
|    n_updates       | 3214226  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 976      |
| time/              |          |
|    episodes        | 2136     |
|    fps             | 53       |
|    time_elapsed    | 45175    |
|    total_timesteps | 2408846  |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 43.9     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 2.96     |
|    learning_rate   | 7.59e-05 |
|    n_updates       | 3218644  |
---------------------------------
Eval num_timesteps=2410000, episode_reward=1134.42 +/- 0.00
Episode length: 1406.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.41e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 2410000  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.75    |
|    learning_rate   | 7.59e-05 |
|    n_updates       | 3219798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2140     |
|    fps             | 53       |
|    time_elapsed    | 45294    |
|    total_timesteps | 2415076  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 6.65     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.9     |
|    learning_rate   | 7.58e-05 |
|    n_updates       | 3224874  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 980      |
| time/              |          |
|    episodes        | 2144     |
|    fps             | 53       |
|    time_elapsed    | 45373    |
|    total_timesteps | 2419971  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 15.5     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 7.58e-05 |
|    n_updates       | 3229769  |
---------------------------------
Eval num_timesteps=2420000, episode_reward=956.64 +/- 0.00
Episode length: 1205.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 957      |
| time/              |          |
|    total_timesteps | 2420000  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 8.31     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 0.601    |
|    learning_rate   | 7.58e-05 |
|    n_updates       | 3229798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 976      |
| time/              |          |
|    episodes        | 2148     |
|    fps             | 53       |
|    time_elapsed    | 45472    |
|    total_timesteps | 2424742  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 6.73     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 7.58e-05 |
|    n_updates       | 3234540  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 977      |
| time/              |          |
|    episodes        | 2152     |
|    fps             | 53       |
|    time_elapsed    | 45554    |
|    total_timesteps | 2429736  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 0.314    |
|    learning_rate   | 7.57e-05 |
|    n_updates       | 3239534  |
---------------------------------
Eval num_timesteps=2430000, episode_reward=863.43 +/- 0.00
Episode length: 1085.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 863      |
| time/              |          |
|    total_timesteps | 2430000  |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 7.21     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -3.68    |
|    learning_rate   | 7.57e-05 |
|    n_updates       | 3239798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2156     |
|    fps             | 53       |
|    time_elapsed    | 45664    |
|    total_timesteps | 2435054  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -5.32    |
|    learning_rate   | 7.56e-05 |
|    n_updates       | 3244852  |
---------------------------------
Eval num_timesteps=2440000, episode_reward=872.81 +/- 0.00
Episode length: 1094.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 873      |
| time/              |          |
|    total_timesteps | 2440000  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -3.54    |
|    learning_rate   | 7.56e-05 |
|    n_updates       | 3249798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 983      |
| time/              |          |
|    episodes        | 2160     |
|    fps             | 53       |
|    time_elapsed    | 45798    |
|    total_timesteps | 2441474  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6.15     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -0.133   |
|    learning_rate   | 7.56e-05 |
|    n_updates       | 3251272  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 983      |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 53       |
|    time_elapsed    | 45878    |
|    total_timesteps | 2446287  |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 6.02     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | -0.516   |
|    learning_rate   | 7.55e-05 |
|    n_updates       | 3256085  |
---------------------------------
Eval num_timesteps=2450000, episode_reward=834.21 +/- 0.00
Episode length: 1028.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 834      |
| time/              |          |
|    total_timesteps | 2450000  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.16     |
|    learning_rate   | 7.55e-05 |
|    n_updates       | 3259798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 984      |
| time/              |          |
|    episodes        | 2168     |
|    fps             | 53       |
|    time_elapsed    | 46000    |
|    total_timesteps | 2452660  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 6.52     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 7.55e-05 |
|    n_updates       | 3262458  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 965      |
| time/              |          |
|    episodes        | 2172     |
|    fps             | 53       |
|    time_elapsed    | 46045    |
|    total_timesteps | 2455081  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -3.37    |
|    learning_rate   | 7.54e-05 |
|    n_updates       | 3264879  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 967      |
| time/              |          |
|    episodes        | 2176     |
|    fps             | 53       |
|    time_elapsed    | 46128    |
|    total_timesteps | 2459849  |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 1.48     |
|    learning_rate   | 7.54e-05 |
|    n_updates       | 3269647  |
---------------------------------
Eval num_timesteps=2460000, episode_reward=894.49 +/- 0.00
Episode length: 1106.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 894      |
| time/              |          |
|    total_timesteps | 2460000  |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 2.96     |
|    learning_rate   | 7.54e-05 |
|    n_updates       | 3269798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 966      |
| time/              |          |
|    episodes        | 2180     |
|    fps             | 53       |
|    time_elapsed    | 46231    |
|    total_timesteps | 2464650  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.71     |
|    learning_rate   | 7.54e-05 |
|    n_updates       | 3274448  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 966      |
| time/              |          |
|    episodes        | 2184     |
|    fps             | 53       |
|    time_elapsed    | 46318    |
|    total_timesteps | 2469854  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.632    |
|    learning_rate   | 7.53e-05 |
|    n_updates       | 3279652  |
---------------------------------
Eval num_timesteps=2470000, episode_reward=929.98 +/- 0.00
Episode length: 1146.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.15e+03 |
|    mean_reward     | 930      |
| time/              |          |
|    total_timesteps | 2470000  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -0.0975  |
|    learning_rate   | 7.53e-05 |
|    n_updates       | 3279798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 965      |
| time/              |          |
|    episodes        | 2188     |
|    fps             | 53       |
|    time_elapsed    | 46423    |
|    total_timesteps | 2474968  |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 6.28     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 7.53e-05 |
|    n_updates       | 3284766  |
---------------------------------
Eval num_timesteps=2480000, episode_reward=933.22 +/- 0.00
Episode length: 1145.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.14e+03 |
|    mean_reward     | 933      |
| time/              |          |
|    total_timesteps | 2480000  |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -0.722   |
|    learning_rate   | 7.52e-05 |
|    n_updates       | 3289798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 956      |
| time/              |          |
|    episodes        | 2192     |
|    fps             | 53       |
|    time_elapsed    | 46526    |
|    total_timesteps | 2480034  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 7.52e-05 |
|    n_updates       | 3289832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 956      |
| time/              |          |
|    episodes        | 2196     |
|    fps             | 53       |
|    time_elapsed    | 46610    |
|    total_timesteps | 2485090  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 7.62     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.413    |
|    learning_rate   | 7.51e-05 |
|    n_updates       | 3294888  |
---------------------------------
Eval num_timesteps=2490000, episode_reward=1136.01 +/- 0.00
Episode length: 1435.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.44e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 2490000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 5.26     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 5.19     |
|    learning_rate   | 7.51e-05 |
|    n_updates       | 3299798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 955      |
| time/              |          |
|    episodes        | 2200     |
|    fps             | 53       |
|    time_elapsed    | 46732    |
|    total_timesteps | 2491267  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 7.42     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -0.825   |
|    learning_rate   | 7.51e-05 |
|    n_updates       | 3301065  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 962      |
| time/              |          |
|    episodes        | 2204     |
|    fps             | 53       |
|    time_elapsed    | 46809    |
|    total_timesteps | 2495889  |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 5.62     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -2.86    |
|    learning_rate   | 7.5e-05  |
|    n_updates       | 3305687  |
---------------------------------
Eval num_timesteps=2500000, episode_reward=936.73 +/- 0.00
Episode length: 1147.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.15e+03 |
|    mean_reward     | 937      |
| time/              |          |
|    total_timesteps | 2500000  |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -0.357   |
|    learning_rate   | 7.5e-05  |
|    n_updates       | 3309798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 963      |
| time/              |          |
|    episodes        | 2208     |
|    fps             | 53       |
|    time_elapsed    | 46916    |
|    total_timesteps | 2501152  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 0.776    |
|    learning_rate   | 7.5e-05  |
|    n_updates       | 3310950  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 966      |
| time/              |          |
|    episodes        | 2212     |
|    fps             | 53       |
|    time_elapsed    | 46999    |
|    total_timesteps | 2506188  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 7.49e-05 |
|    n_updates       | 3315986  |
---------------------------------
Eval num_timesteps=2510000, episode_reward=1023.52 +/- 0.00
Episode length: 1268.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.27e+03 |
|    mean_reward     | 1.02e+03 |
| time/              |          |
|    total_timesteps | 2510000  |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -3.49    |
|    learning_rate   | 7.49e-05 |
|    n_updates       | 3319798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 972      |
| time/              |          |
|    episodes        | 2216     |
|    fps             | 53       |
|    time_elapsed    | 47119    |
|    total_timesteps | 2512386  |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -4.76    |
|    learning_rate   | 7.49e-05 |
|    n_updates       | 3322184  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 972      |
| time/              |          |
|    episodes        | 2220     |
|    fps             | 53       |
|    time_elapsed    | 47204    |
|    total_timesteps | 2517548  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | -2.89    |
|    learning_rate   | 7.48e-05 |
|    n_updates       | 3327346  |
---------------------------------
Eval num_timesteps=2520000, episode_reward=1067.05 +/- 0.00
Episode length: 1322.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 2520000  |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 7.03     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 7.48e-05 |
|    n_updates       | 3329798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 974      |
| time/              |          |
|    episodes        | 2224     |
|    fps             | 53       |
|    time_elapsed    | 47328    |
|    total_timesteps | 2523984  |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -3.3     |
|    learning_rate   | 7.48e-05 |
|    n_updates       | 3333782  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 981      |
| time/              |          |
|    episodes        | 2228     |
|    fps             | 53       |
|    time_elapsed    | 47416    |
|    total_timesteps | 2529396  |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 7.47e-05 |
|    n_updates       | 3339194  |
---------------------------------
Eval num_timesteps=2530000, episode_reward=1138.54 +/- 0.00
Episode length: 1433.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.43e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 2530000  |
| train/             |          |
|    actor_loss      | -65.5    |
|    critic_loss     | 6.28     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 7.47e-05 |
|    n_updates       | 3339798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 990      |
| time/              |          |
|    episodes        | 2232     |
|    fps             | 53       |
|    time_elapsed    | 47536    |
|    total_timesteps | 2535545  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.93     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 3.08     |
|    learning_rate   | 7.46e-05 |
|    n_updates       | 3345343  |
---------------------------------
Eval num_timesteps=2540000, episode_reward=1031.17 +/- 0.00
Episode length: 1319.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2540000  |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -4.85    |
|    learning_rate   | 7.46e-05 |
|    n_updates       | 3349798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 997      |
| time/              |          |
|    episodes        | 2236     |
|    fps             | 53       |
|    time_elapsed    | 47648    |
|    total_timesteps | 2541161  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 6.17     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 3.69     |
|    learning_rate   | 7.46e-05 |
|    n_updates       | 3350959  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 997      |
| time/              |          |
|    episodes        | 2240     |
|    fps             | 53       |
|    time_elapsed    | 47731    |
|    total_timesteps | 2546309  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 7.17     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 7.45e-05 |
|    n_updates       | 3356107  |
---------------------------------
Eval num_timesteps=2550000, episode_reward=1089.53 +/- 0.00
Episode length: 1359.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.36e+03 |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 2550000  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 7.45e-05 |
|    n_updates       | 3359798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 2244     |
|    fps             | 53       |
|    time_elapsed    | 47851    |
|    total_timesteps | 2552430  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.733   |
|    learning_rate   | 7.45e-05 |
|    n_updates       | 3362228  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2248     |
|    fps             | 53       |
|    time_elapsed    | 47940    |
|    total_timesteps | 2557960  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 2.66     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 7.44e-05 |
|    n_updates       | 3367758  |
---------------------------------
Eval num_timesteps=2560000, episode_reward=878.41 +/- 0.00
Episode length: 1086.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 878      |
| time/              |          |
|    total_timesteps | 2560000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.287    |
|    learning_rate   | 7.44e-05 |
|    n_updates       | 3369798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2252     |
|    fps             | 53       |
|    time_elapsed    | 48065    |
|    total_timesteps | 2564555  |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 4.57     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.0458  |
|    learning_rate   | 7.44e-05 |
|    n_updates       | 3374353  |
---------------------------------
Eval num_timesteps=2570000, episode_reward=1136.10 +/- 0.00
Episode length: 1429.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.43e+03 |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 2570000  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 4.49     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.613   |
|    learning_rate   | 7.43e-05 |
|    n_updates       | 3379798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2256     |
|    fps             | 53       |
|    time_elapsed    | 48191    |
|    total_timesteps | 2571112  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 3.53     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 7.43e-05 |
|    n_updates       | 3380910  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2260     |
|    fps             | 53       |
|    time_elapsed    | 48272    |
|    total_timesteps | 2576056  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 7.42     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 7.42e-05 |
|    n_updates       | 3385854  |
---------------------------------
Eval num_timesteps=2580000, episode_reward=987.99 +/- 0.00
Episode length: 1218.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 988      |
| time/              |          |
|    total_timesteps | 2580000  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.886    |
|    learning_rate   | 7.42e-05 |
|    n_updates       | 3389798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2264     |
|    fps             | 53       |
|    time_elapsed    | 48379    |
|    total_timesteps | 2581307  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 6.73     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 7.42e-05 |
|    n_updates       | 3391105  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2268     |
|    fps             | 53       |
|    time_elapsed    | 48458    |
|    total_timesteps | 2586110  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.467    |
|    learning_rate   | 7.41e-05 |
|    n_updates       | 3395908  |
---------------------------------
Eval num_timesteps=2590000, episode_reward=953.75 +/- 0.00
Episode length: 1216.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 954      |
| time/              |          |
|    total_timesteps | 2590000  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.672   |
|    learning_rate   | 7.41e-05 |
|    n_updates       | 3399798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2272     |
|    fps             | 53       |
|    time_elapsed    | 48579    |
|    total_timesteps | 2592398  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.978   |
|    learning_rate   | 7.41e-05 |
|    n_updates       | 3402196  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2276     |
|    fps             | 53       |
|    time_elapsed    | 48666    |
|    total_timesteps | 2597777  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 7.4e-05  |
|    n_updates       | 3407575  |
---------------------------------
Eval num_timesteps=2600000, episode_reward=984.29 +/- 0.00
Episode length: 1248.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 984      |
| time/              |          |
|    total_timesteps | 2600000  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6.12     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 0.543    |
|    learning_rate   | 7.4e-05  |
|    n_updates       | 3409798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2280     |
|    fps             | 53       |
|    time_elapsed    | 48784    |
|    total_timesteps | 2603865  |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 7.07     |
|    learning_rate   | 7.4e-05  |
|    n_updates       | 3413663  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2284     |
|    fps             | 53       |
|    time_elapsed    | 48864    |
|    total_timesteps | 2608810  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 7.39e-05 |
|    n_updates       | 3418608  |
---------------------------------
Eval num_timesteps=2610000, episode_reward=967.83 +/- 0.00
Episode length: 1209.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 968      |
| time/              |          |
|    total_timesteps | 2610000  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 7.02     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 0.129    |
|    learning_rate   | 7.39e-05 |
|    n_updates       | 3419798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2288     |
|    fps             | 53       |
|    time_elapsed    | 48984    |
|    total_timesteps | 2615021  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 4.68     |
|    learning_rate   | 7.38e-05 |
|    n_updates       | 3424819  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2292     |
|    fps             | 53       |
|    time_elapsed    | 49065    |
|    total_timesteps | 2619969  |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 4.37     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 5.35     |
|    learning_rate   | 7.38e-05 |
|    n_updates       | 3429767  |
---------------------------------
Eval num_timesteps=2620000, episode_reward=909.22 +/- 0.00
Episode length: 1115.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 909      |
| time/              |          |
|    total_timesteps | 2620000  |
| train/             |          |
|    actor_loss      | -65.4    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 7.38e-05 |
|    n_updates       | 3429798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2296     |
|    fps             | 53       |
|    time_elapsed    | 49167    |
|    total_timesteps | 2624936  |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -3.14    |
|    learning_rate   | 7.38e-05 |
|    n_updates       | 3434734  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2300     |
|    fps             | 53       |
|    time_elapsed    | 49247    |
|    total_timesteps | 2629813  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 7.37e-05 |
|    n_updates       | 3439611  |
---------------------------------
Eval num_timesteps=2630000, episode_reward=909.79 +/- 0.00
Episode length: 1128.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 910      |
| time/              |          |
|    total_timesteps | 2630000  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 2.38     |
|    learning_rate   | 7.37e-05 |
|    n_updates       | 3439798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2304     |
|    fps             | 53       |
|    time_elapsed    | 49350    |
|    total_timesteps | 2634899  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -0.134   |
|    learning_rate   | 7.37e-05 |
|    n_updates       | 3444697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2308     |
|    fps             | 53       |
|    time_elapsed    | 49429    |
|    total_timesteps | 2639691  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -2.73    |
|    learning_rate   | 7.36e-05 |
|    n_updates       | 3449489  |
---------------------------------
Eval num_timesteps=2640000, episode_reward=919.69 +/- 0.00
Episode length: 1127.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 920      |
| time/              |          |
|    total_timesteps | 2640000  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 6.16     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 7.36e-05 |
|    n_updates       | 3449798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2312     |
|    fps             | 53       |
|    time_elapsed    | 49536    |
|    total_timesteps | 2645086  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.662    |
|    learning_rate   | 7.35e-05 |
|    n_updates       | 3454884  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2316     |
|    fps             | 53       |
|    time_elapsed    | 49616    |
|    total_timesteps | 2649973  |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 3.84     |
|    learning_rate   | 7.35e-05 |
|    n_updates       | 3459771  |
---------------------------------
Eval num_timesteps=2650000, episode_reward=942.18 +/- 0.00
Episode length: 1187.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.19e+03 |
|    mean_reward     | 942      |
| time/              |          |
|    total_timesteps | 2650000  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -2.56    |
|    learning_rate   | 7.35e-05 |
|    n_updates       | 3459798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2320     |
|    fps             | 53       |
|    time_elapsed    | 49722    |
|    total_timesteps | 2655145  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 0.0468   |
|    learning_rate   | 7.34e-05 |
|    n_updates       | 3464943  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2324     |
|    fps             | 53       |
|    time_elapsed    | 49798    |
|    total_timesteps | 2659767  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -0.501   |
|    learning_rate   | 7.34e-05 |
|    n_updates       | 3469565  |
---------------------------------
Eval num_timesteps=2660000, episode_reward=943.67 +/- 0.00
Episode length: 1201.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 944      |
| time/              |          |
|    total_timesteps | 2660000  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 5.24     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 5.99     |
|    learning_rate   | 7.34e-05 |
|    n_updates       | 3469798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2328     |
|    fps             | 53       |
|    time_elapsed    | 49903    |
|    total_timesteps | 2664934  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.6      |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 7.34e-05 |
|    n_updates       | 3474732  |
---------------------------------
Eval num_timesteps=2670000, episode_reward=874.51 +/- 0.00
Episode length: 1121.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 875      |
| time/              |          |
|    total_timesteps | 2670000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.05     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 7.33e-05 |
|    n_updates       | 3479798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2332     |
|    fps             | 53       |
|    time_elapsed    | 50027    |
|    total_timesteps | 2671430  |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 2.52     |
|    learning_rate   | 7.33e-05 |
|    n_updates       | 3481228  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2336     |
|    fps             | 53       |
|    time_elapsed    | 50107    |
|    total_timesteps | 2676270  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.807   |
|    learning_rate   | 7.32e-05 |
|    n_updates       | 3486068  |
---------------------------------
Eval num_timesteps=2680000, episode_reward=1120.27 +/- 0.00
Episode length: 1423.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 2680000  |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 7.32e-05 |
|    n_updates       | 3489798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2340     |
|    fps             | 53       |
|    time_elapsed    | 50229    |
|    total_timesteps | 2682524  |
| train/             |          |
|    actor_loss      | -66.5    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -2.87    |
|    learning_rate   | 7.32e-05 |
|    n_updates       | 3492322  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2344     |
|    fps             | 53       |
|    time_elapsed    | 50310    |
|    total_timesteps | 2687411  |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 6.27     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 2.98     |
|    learning_rate   | 7.31e-05 |
|    n_updates       | 3497209  |
---------------------------------
Eval num_timesteps=2690000, episode_reward=959.28 +/- 0.00
Episode length: 1239.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 959      |
| time/              |          |
|    total_timesteps | 2690000  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 7.21     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 0.69     |
|    learning_rate   | 7.31e-05 |
|    n_updates       | 3499798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2348     |
|    fps             | 53       |
|    time_elapsed    | 50415    |
|    total_timesteps | 2692566  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 1.82     |
|    learning_rate   | 7.31e-05 |
|    n_updates       | 3502364  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 999      |
| time/              |          |
|    episodes        | 2352     |
|    fps             | 53       |
|    time_elapsed    | 50495    |
|    total_timesteps | 2697417  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -0.892   |
|    learning_rate   | 7.3e-05  |
|    n_updates       | 3507215  |
---------------------------------
Eval num_timesteps=2700000, episode_reward=912.76 +/- 0.00
Episode length: 1120.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 913      |
| time/              |          |
|    total_timesteps | 2700000  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 6.64     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 3.75     |
|    learning_rate   | 7.3e-05  |
|    n_updates       | 3509798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 996      |
| time/              |          |
|    episodes        | 2356     |
|    fps             | 53       |
|    time_elapsed    | 50619    |
|    total_timesteps | 2703895  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.69     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 7.3e-05  |
|    n_updates       | 3513693  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 993      |
| time/              |          |
|    episodes        | 2360     |
|    fps             | 53       |
|    time_elapsed    | 50695    |
|    total_timesteps | 2708549  |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 7.29e-05 |
|    n_updates       | 3518347  |
---------------------------------
Eval num_timesteps=2710000, episode_reward=845.17 +/- 0.00
Episode length: 1052.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.05e+03 |
|    mean_reward     | 845      |
| time/              |          |
|    total_timesteps | 2710000  |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 0.425    |
|    learning_rate   | 7.29e-05 |
|    n_updates       | 3519798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 993      |
| time/              |          |
|    episodes        | 2364     |
|    fps             | 53       |
|    time_elapsed    | 50802    |
|    total_timesteps | 2713942  |
| train/             |          |
|    actor_loss      | -67.1    |
|    critic_loss     | 6.24     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 7.29e-05 |
|    n_updates       | 3523740  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 995      |
| time/              |          |
|    episodes        | 2368     |
|    fps             | 53       |
|    time_elapsed    | 50886    |
|    total_timesteps | 2719053  |
| train/             |          |
|    actor_loss      | -68      |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.965   |
|    learning_rate   | 7.28e-05 |
|    n_updates       | 3528851  |
---------------------------------
Eval num_timesteps=2720000, episode_reward=910.59 +/- 0.00
Episode length: 1131.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.13e+03 |
|    mean_reward     | 911      |
| time/              |          |
|    total_timesteps | 2720000  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 7.28e-05 |
|    n_updates       | 3529798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 990      |
| time/              |          |
|    episodes        | 2372     |
|    fps             | 53       |
|    time_elapsed    | 50995    |
|    total_timesteps | 2724524  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 1.65     |
|    learning_rate   | 7.28e-05 |
|    n_updates       | 3534322  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 987      |
| time/              |          |
|    episodes        | 2376     |
|    fps             | 53       |
|    time_elapsed    | 51076    |
|    total_timesteps | 2729516  |
| train/             |          |
|    actor_loss      | -68.5    |
|    critic_loss     | 5.56     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.51    |
|    learning_rate   | 7.27e-05 |
|    n_updates       | 3539314  |
---------------------------------
Eval num_timesteps=2730000, episode_reward=790.34 +/- 0.00
Episode length: 977.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 977      |
|    mean_reward     | 790      |
| time/              |          |
|    total_timesteps | 2730000  |
| train/             |          |
|    actor_loss      | -67      |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -0.53    |
|    learning_rate   | 7.27e-05 |
|    n_updates       | 3539798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 984      |
| time/              |          |
|    episodes        | 2380     |
|    fps             | 53       |
|    time_elapsed    | 51180    |
|    total_timesteps | 2734684  |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 4.98     |
|    learning_rate   | 7.27e-05 |
|    n_updates       | 3544482  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 982      |
| time/              |          |
|    episodes        | 2384     |
|    fps             | 53       |
|    time_elapsed    | 51260    |
|    total_timesteps | 2739574  |
| train/             |          |
|    actor_loss      | -67.5    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 3.94     |
|    learning_rate   | 7.26e-05 |
|    n_updates       | 3549372  |
---------------------------------
Eval num_timesteps=2740000, episode_reward=802.85 +/- 0.00
Episode length: 1005.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 803      |
| time/              |          |
|    total_timesteps | 2740000  |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 6.69     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 3.2      |
|    learning_rate   | 7.26e-05 |
|    n_updates       | 3549798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 981      |
| time/              |          |
|    episodes        | 2388     |
|    fps             | 53       |
|    time_elapsed    | 51365    |
|    total_timesteps | 2744858  |
| train/             |          |
|    actor_loss      | -67.4    |
|    critic_loss     | 6.9      |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 4.22     |
|    learning_rate   | 7.26e-05 |
|    n_updates       | 3554656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 977      |
| time/              |          |
|    episodes        | 2392     |
|    fps             | 53       |
|    time_elapsed    | 51439    |
|    total_timesteps | 2749325  |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.888    |
|    learning_rate   | 7.25e-05 |
|    n_updates       | 3559123  |
---------------------------------
Eval num_timesteps=2750000, episode_reward=747.52 +/- 0.00
Episode length: 936.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 936      |
|    mean_reward     | 748      |
| time/              |          |
|    total_timesteps | 2750000  |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 0.427    |
|    learning_rate   | 7.25e-05 |
|    n_updates       | 3559798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 973      |
| time/              |          |
|    episodes        | 2396     |
|    fps             | 53       |
|    time_elapsed    | 51543    |
|    total_timesteps | 2754516  |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 5.45     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 1.8      |
|    learning_rate   | 7.25e-05 |
|    n_updates       | 3564314  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 971      |
| time/              |          |
|    episodes        | 2400     |
|    fps             | 53       |
|    time_elapsed    | 51621    |
|    total_timesteps | 2759212  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 3.25     |
|    learning_rate   | 7.24e-05 |
|    n_updates       | 3569010  |
---------------------------------
Eval num_timesteps=2760000, episode_reward=950.33 +/- 0.00
Episode length: 1223.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 950      |
| time/              |          |
|    total_timesteps | 2760000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 4.64     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 7.24e-05 |
|    n_updates       | 3569798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 970      |
| time/              |          |
|    episodes        | 2404     |
|    fps             | 53       |
|    time_elapsed    | 51731    |
|    total_timesteps | 2764774  |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 3.28     |
|    learning_rate   | 7.24e-05 |
|    n_updates       | 3574572  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 968      |
| time/              |          |
|    episodes        | 2408     |
|    fps             | 53       |
|    time_elapsed    | 51808    |
|    total_timesteps | 2769409  |
| train/             |          |
|    actor_loss      | -65.3    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -3.92    |
|    learning_rate   | 7.23e-05 |
|    n_updates       | 3579207  |
---------------------------------
Eval num_timesteps=2770000, episode_reward=1032.06 +/- 0.00
Episode length: 1298.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.3e+03  |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 2770000  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 4.7      |
|    learning_rate   | 7.23e-05 |
|    n_updates       | 3579798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 964      |
| time/              |          |
|    episodes        | 2412     |
|    fps             | 53       |
|    time_elapsed    | 51914    |
|    total_timesteps | 2774637  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 5.59     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -0.0753  |
|    learning_rate   | 7.23e-05 |
|    n_updates       | 3584435  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 958      |
| time/              |          |
|    episodes        | 2416     |
|    fps             | 53       |
|    time_elapsed    | 51985    |
|    total_timesteps | 2778858  |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 7.22e-05 |
|    n_updates       | 3588656  |
---------------------------------
Eval num_timesteps=2780000, episode_reward=839.72 +/- 0.00
Episode length: 1082.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 840      |
| time/              |          |
|    total_timesteps | 2780000  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 4.37     |
|    learning_rate   | 7.22e-05 |
|    n_updates       | 3589798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 954      |
| time/              |          |
|    episodes        | 2420     |
|    fps             | 53       |
|    time_elapsed    | 52083    |
|    total_timesteps | 2783588  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 4.67     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 7.22e-05 |
|    n_updates       | 3593386  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 952      |
| time/              |          |
|    episodes        | 2424     |
|    fps             | 53       |
|    time_elapsed    | 52156    |
|    total_timesteps | 2787937  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.365   |
|    learning_rate   | 7.21e-05 |
|    n_updates       | 3597735  |
---------------------------------
Eval num_timesteps=2790000, episode_reward=807.33 +/- 0.00
Episode length: 1035.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.04e+03 |
|    mean_reward     | 807      |
| time/              |          |
|    total_timesteps | 2790000  |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 7.21e-05 |
|    n_updates       | 3599798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 2428     |
|    fps             | 53       |
|    time_elapsed    | 52262    |
|    total_timesteps | 2793266  |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 7.56     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 0.719    |
|    learning_rate   | 7.21e-05 |
|    n_updates       | 3603064  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 943      |
| time/              |          |
|    episodes        | 2432     |
|    fps             | 53       |
|    time_elapsed    | 52339    |
|    total_timesteps | 2797881  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 7.2e-05  |
|    n_updates       | 3607679  |
---------------------------------
Eval num_timesteps=2800000, episode_reward=754.56 +/- 0.00
Episode length: 952.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 952      |
|    mean_reward     | 755      |
| time/              |          |
|    total_timesteps | 2800000  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.9      |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 3.85     |
|    learning_rate   | 7.2e-05  |
|    n_updates       | 3609798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 946      |
| time/              |          |
|    episodes        | 2436     |
|    fps             | 53       |
|    time_elapsed    | 52455    |
|    total_timesteps | 2803873  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 7.2e-05  |
|    n_updates       | 3613671  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 945      |
| time/              |          |
|    episodes        | 2440     |
|    fps             | 53       |
|    time_elapsed    | 52536    |
|    total_timesteps | 2808801  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 7.19e-05 |
|    n_updates       | 3618599  |
---------------------------------
Eval num_timesteps=2810000, episode_reward=964.79 +/- 0.00
Episode length: 1200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 965      |
| time/              |          |
|    total_timesteps | 2810000  |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 4.68     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.87     |
|    learning_rate   | 7.19e-05 |
|    n_updates       | 3619798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    episodes        | 2444     |
|    fps             | 53       |
|    time_elapsed    | 52645    |
|    total_timesteps | 2814305  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 5.21     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -0.271   |
|    learning_rate   | 7.19e-05 |
|    n_updates       | 3624103  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    episodes        | 2448     |
|    fps             | 53       |
|    time_elapsed    | 52727    |
|    total_timesteps | 2819168  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 7.18e-05 |
|    n_updates       | 3628966  |
---------------------------------
Eval num_timesteps=2820000, episode_reward=966.48 +/- 0.00
Episode length: 1229.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.23e+03 |
|    mean_reward     | 966      |
| time/              |          |
|    total_timesteps | 2820000  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 3.12     |
|    learning_rate   | 7.18e-05 |
|    n_updates       | 3629798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    episodes        | 2452     |
|    fps             | 53       |
|    time_elapsed    | 52843    |
|    total_timesteps | 2825044  |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.805   |
|    learning_rate   | 7.17e-05 |
|    n_updates       | 3634842  |
---------------------------------
Eval num_timesteps=2830000, episode_reward=1159.69 +/- 0.00
Episode length: 1468.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 2830000  |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 7.17e-05 |
|    n_updates       | 3639798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    episodes        | 2456     |
|    fps             | 53       |
|    time_elapsed    | 52946    |
|    total_timesteps | 2830000  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 2460     |
|    fps             | 53       |
|    time_elapsed    | 53039    |
|    total_timesteps | 2835681  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 2.75     |
|    learning_rate   | 7.16e-05 |
|    n_updates       | 3645479  |
---------------------------------
Eval num_timesteps=2840000, episode_reward=993.71 +/- 0.00
Episode length: 1236.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 994      |
| time/              |          |
|    total_timesteps | 2840000  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 3.58     |
|    learning_rate   | 7.16e-05 |
|    n_updates       | 3649798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 950      |
| time/              |          |
|    episodes        | 2464     |
|    fps             | 53       |
|    time_elapsed    | 53150    |
|    total_timesteps | 2841246  |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -2.83    |
|    learning_rate   | 7.16e-05 |
|    n_updates       | 3651044  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 950      |
| time/              |          |
|    episodes        | 2468     |
|    fps             | 53       |
|    time_elapsed    | 53233    |
|    total_timesteps | 2846350  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 7.57     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -0.311   |
|    learning_rate   | 7.15e-05 |
|    n_updates       | 3656148  |
---------------------------------
Eval num_timesteps=2850000, episode_reward=599.14 +/- 0.00
Episode length: 715.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 715      |
|    mean_reward     | 599      |
| time/              |          |
|    total_timesteps | 2850000  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 6.04     |
|    learning_rate   | 7.15e-05 |
|    n_updates       | 3659798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 957      |
| time/              |          |
|    episodes        | 2472     |
|    fps             | 53       |
|    time_elapsed    | 53355    |
|    total_timesteps | 2852848  |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 7.15e-05 |
|    n_updates       | 3662646  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 956      |
| time/              |          |
|    episodes        | 2476     |
|    fps             | 53       |
|    time_elapsed    | 53437    |
|    total_timesteps | 2857797  |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 4.52     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 7.14e-05 |
|    n_updates       | 3667595  |
---------------------------------
Eval num_timesteps=2860000, episode_reward=987.43 +/- 0.00
Episode length: 1244.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 987      |
| time/              |          |
|    total_timesteps | 2860000  |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -0.377   |
|    learning_rate   | 7.14e-05 |
|    n_updates       | 3669798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 962      |
| time/              |          |
|    episodes        | 2480     |
|    fps             | 53       |
|    time_elapsed    | 53558    |
|    total_timesteps | 2864087  |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 4.3      |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -4.18    |
|    learning_rate   | 7.14e-05 |
|    n_updates       | 3673885  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 969      |
| time/              |          |
|    episodes        | 2484     |
|    fps             | 53       |
|    time_elapsed    | 53654    |
|    total_timesteps | 2869777  |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -1.98    |
|    learning_rate   | 7.13e-05 |
|    n_updates       | 3679575  |
---------------------------------
Eval num_timesteps=2870000, episode_reward=1004.13 +/- 0.00
Episode length: 1238.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 1e+03    |
| time/              |          |
|    total_timesteps | 2870000  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 2.79     |
|    learning_rate   | 7.13e-05 |
|    n_updates       | 3679798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 973      |
| time/              |          |
|    episodes        | 2488     |
|    fps             | 53       |
|    time_elapsed    | 53766    |
|    total_timesteps | 2875311  |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 4.02     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 7.12e-05 |
|    n_updates       | 3685109  |
---------------------------------
Eval num_timesteps=2880000, episode_reward=1133.63 +/- 0.00
Episode length: 1425.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.42e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 2880000  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -4.54    |
|    learning_rate   | 7.12e-05 |
|    n_updates       | 3689798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    episodes        | 2492     |
|    fps             | 53       |
|    time_elapsed    | 53889    |
|    total_timesteps | 2881267  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -0.0286  |
|    learning_rate   | 7.12e-05 |
|    n_updates       | 3691065  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 985      |
| time/              |          |
|    episodes        | 2496     |
|    fps             | 53       |
|    time_elapsed    | 53982    |
|    total_timesteps | 2886579  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 6.78     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 5.18     |
|    learning_rate   | 7.11e-05 |
|    n_updates       | 3696377  |
---------------------------------
Eval num_timesteps=2890000, episode_reward=1121.91 +/- 0.00
Episode length: 1401.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.12e+03 |
| time/              |          |
|    total_timesteps | 2890000  |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 7.11e-05 |
|    n_updates       | 3699798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 991      |
| time/              |          |
|    episodes        | 2500     |
|    fps             | 53       |
|    time_elapsed    | 54109    |
|    total_timesteps | 2892553  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 7.11e-05 |
|    n_updates       | 3702351  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 996      |
| time/              |          |
|    episodes        | 2504     |
|    fps             | 53       |
|    time_elapsed    | 54204    |
|    total_timesteps | 2897946  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -2.17    |
|    learning_rate   | 7.1e-05  |
|    n_updates       | 3707744  |
---------------------------------
Eval num_timesteps=2900000, episode_reward=1114.78 +/- 0.00
Episode length: 1397.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 2900000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -0.881   |
|    learning_rate   | 7.1e-05  |
|    n_updates       | 3709798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 2508     |
|    fps             | 53       |
|    time_elapsed    | 54328    |
|    total_timesteps | 2904034  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 2.41     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -2.35    |
|    learning_rate   | 7.1e-05  |
|    n_updates       | 3713832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2512     |
|    fps             | 53       |
|    time_elapsed    | 54411    |
|    total_timesteps | 2909100  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 7.09e-05 |
|    n_updates       | 3718898  |
---------------------------------
Eval num_timesteps=2910000, episode_reward=1004.72 +/- 0.00
Episode length: 1259.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1e+03    |
| time/              |          |
|    total_timesteps | 2910000  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -3.08    |
|    learning_rate   | 7.09e-05 |
|    n_updates       | 3719798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2516     |
|    fps             | 53       |
|    time_elapsed    | 54535    |
|    total_timesteps | 2915593  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -4.58    |
|    learning_rate   | 7.08e-05 |
|    n_updates       | 3725391  |
---------------------------------
Eval num_timesteps=2920000, episode_reward=1107.75 +/- 0.00
Episode length: 1396.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 2920000  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -4.25    |
|    learning_rate   | 7.08e-05 |
|    n_updates       | 3729798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2520     |
|    fps             | 53       |
|    time_elapsed    | 54655    |
|    total_timesteps | 2921747  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -0.0569  |
|    learning_rate   | 7.08e-05 |
|    n_updates       | 3731545  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2524     |
|    fps             | 53       |
|    time_elapsed    | 54741    |
|    total_timesteps | 2927045  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 4.35     |
|    learning_rate   | 7.07e-05 |
|    n_updates       | 3736843  |
---------------------------------
Eval num_timesteps=2930000, episode_reward=1142.23 +/- 0.00
Episode length: 1402.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.4e+03  |
|    mean_reward     | 1.14e+03 |
| time/              |          |
|    total_timesteps | 2930000  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 6.04     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -0.812   |
|    learning_rate   | 7.07e-05 |
|    n_updates       | 3739798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.3e+03  |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2528     |
|    fps             | 53       |
|    time_elapsed    | 54852    |
|    total_timesteps | 2932511  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 2.84     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -4.71    |
|    learning_rate   | 7.07e-05 |
|    n_updates       | 3742309  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.31e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 2532     |
|    fps             | 53       |
|    time_elapsed    | 54944    |
|    total_timesteps | 2938144  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 7.69     |
|    learning_rate   | 7.06e-05 |
|    n_updates       | 3747942  |
---------------------------------
Eval num_timesteps=2940000, episode_reward=1207.70 +/- 0.00
Episode length: 1503.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.5e+03  |
|    mean_reward     | 1.21e+03 |
| time/              |          |
|    total_timesteps | 2940000  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 7.06e-05 |
|    n_updates       | 3749798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.31e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 2536     |
|    fps             | 53       |
|    time_elapsed    | 55060    |
|    total_timesteps | 2943928  |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 2.66     |
|    learning_rate   | 7.06e-05 |
|    n_updates       | 3753726  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.31e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 2540     |
|    fps             | 53       |
|    time_elapsed    | 55145    |
|    total_timesteps | 2949129  |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 4.1      |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 0.913    |
|    learning_rate   | 7.05e-05 |
|    n_updates       | 3758927  |
---------------------------------
Eval num_timesteps=2950000, episode_reward=1173.78 +/- 0.00
Episode length: 1472.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.47e+03 |
|    mean_reward     | 1.17e+03 |
| time/              |          |
|    total_timesteps | 2950000  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -0.971   |
|    learning_rate   | 7.05e-05 |
|    n_updates       | 3759798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.32e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 2544     |
|    fps             | 53       |
|    time_elapsed    | 55266    |
|    total_timesteps | 2955254  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -0.405   |
|    learning_rate   | 7.04e-05 |
|    n_updates       | 3765052  |
---------------------------------
Eval num_timesteps=2960000, episode_reward=1082.85 +/- 0.00
Episode length: 1366.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.37e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 2960000  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.18     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -3.6     |
|    learning_rate   | 7.04e-05 |
|    n_updates       | 3769798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    episodes        | 2548     |
|    fps             | 53       |
|    time_elapsed    | 55383    |
|    total_timesteps | 2961222  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 8.19     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 7.04e-05 |
|    n_updates       | 3771020  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 2552     |
|    fps             | 53       |
|    time_elapsed    | 55469    |
|    total_timesteps | 2966473  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 5.71     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -2.39    |
|    learning_rate   | 7.03e-05 |
|    n_updates       | 3776271  |
---------------------------------
Eval num_timesteps=2970000, episode_reward=1219.11 +/- 0.00
Episode length: 1549.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.55e+03 |
|    mean_reward     | 1.22e+03 |
| time/              |          |
|    total_timesteps | 2970000  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 0.307    |
|    learning_rate   | 7.03e-05 |
|    n_updates       | 3779798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 2556     |
|    fps             | 53       |
|    time_elapsed    | 55588    |
|    total_timesteps | 2972496  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 2.94     |
|    learning_rate   | 7.03e-05 |
|    n_updates       | 3782294  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.33e+03 |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    episodes        | 2560     |
|    fps             | 53       |
|    time_elapsed    | 55680    |
|    total_timesteps | 2978117  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 5.01     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.0546  |
|    learning_rate   | 7.02e-05 |
|    n_updates       | 3787915  |
---------------------------------
Eval num_timesteps=2980000, episode_reward=1044.36 +/- 0.00
Episode length: 1321.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 2980000  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 7.02e-05 |
|    n_updates       | 3789798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.31e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    episodes        | 2564     |
|    fps             | 53       |
|    time_elapsed    | 55781    |
|    total_timesteps | 2982928  |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 5.55     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 1.23     |
|    learning_rate   | 7.02e-05 |
|    n_updates       | 3792726  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    episodes        | 2568     |
|    fps             | 53       |
|    time_elapsed    | 55837    |
|    total_timesteps | 2986114  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -2.12    |
|    learning_rate   | 7.01e-05 |
|    n_updates       | 3795912  |
---------------------------------
Eval num_timesteps=2990000, episode_reward=826.07 +/- 0.00
Episode length: 1043.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.04e+03 |
|    mean_reward     | 826      |
| time/              |          |
|    total_timesteps | 2990000  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -4.96    |
|    learning_rate   | 7.01e-05 |
|    n_updates       | 3799798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.29e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2572     |
|    fps             | 53       |
|    time_elapsed    | 55939    |
|    total_timesteps | 2991105  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 3.83     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 7.01e-05 |
|    n_updates       | 3800903  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2576     |
|    fps             | 53       |
|    time_elapsed    | 56016    |
|    total_timesteps | 2995815  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.06     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 7e-05    |
|    n_updates       | 3805613  |
---------------------------------
Eval num_timesteps=3000000, episode_reward=879.38 +/- 0.00
Episode length: 1107.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 879      |
| time/              |          |
|    total_timesteps | 3000000  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -4.31    |
|    learning_rate   | 7e-05    |
|    n_updates       | 3809798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    episodes        | 2580     |
|    fps             | 53       |
|    time_elapsed    | 56123    |
|    total_timesteps | 3001118  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -0.687   |
|    learning_rate   | 7e-05    |
|    n_updates       | 3810916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2584     |
|    fps             | 53       |
|    time_elapsed    | 56187    |
|    total_timesteps | 3004906  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -1.78    |
|    learning_rate   | 7e-05    |
|    n_updates       | 3814704  |
---------------------------------
Eval num_timesteps=3010000, episode_reward=861.21 +/- 0.00
Episode length: 1083.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 861      |
| time/              |          |
|    total_timesteps | 3010000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 2.9      |
|    learning_rate   | 6.99e-05 |
|    n_updates       | 3819798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2588     |
|    fps             | 53       |
|    time_elapsed    | 56310    |
|    total_timesteps | 3011360  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.13     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 6.99e-05 |
|    n_updates       | 3821158  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2592     |
|    fps             | 53       |
|    time_elapsed    | 56382    |
|    total_timesteps | 3015698  |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.17     |
|    learning_rate   | 6.98e-05 |
|    n_updates       | 3825496  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 992      |
| time/              |          |
|    episodes        | 2596     |
|    fps             | 53       |
|    time_elapsed    | 56446    |
|    total_timesteps | 3019468  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.983   |
|    learning_rate   | 6.98e-05 |
|    n_updates       | 3829266  |
---------------------------------
Eval num_timesteps=3020000, episode_reward=878.02 +/- 0.00
Episode length: 1106.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.11e+03 |
|    mean_reward     | 878      |
| time/              |          |
|    total_timesteps | 3020000  |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 3.43     |
|    learning_rate   | 6.98e-05 |
|    n_updates       | 3829798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 985      |
| time/              |          |
|    episodes        | 2600     |
|    fps             | 53       |
|    time_elapsed    | 56549    |
|    total_timesteps | 3024514  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.54     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 6.98e-05 |
|    n_updates       | 3834312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 979      |
| time/              |          |
|    episodes        | 2604     |
|    fps             | 53       |
|    time_elapsed    | 56626    |
|    total_timesteps | 3029188  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -0.806   |
|    learning_rate   | 6.97e-05 |
|    n_updates       | 3838986  |
---------------------------------
Eval num_timesteps=3030000, episode_reward=858.69 +/- 0.00
Episode length: 1102.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.1e+03  |
|    mean_reward     | 859      |
| time/              |          |
|    total_timesteps | 3030000  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.75     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 2.37     |
|    learning_rate   | 6.97e-05 |
|    n_updates       | 3839798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 979      |
| time/              |          |
|    episodes        | 2608     |
|    fps             | 53       |
|    time_elapsed    | 56744    |
|    total_timesteps | 3035324  |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 6.96e-05 |
|    n_updates       | 3845122  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 974      |
| time/              |          |
|    episodes        | 2612     |
|    fps             | 53       |
|    time_elapsed    | 56819    |
|    total_timesteps | 3039862  |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 3.21     |
|    learning_rate   | 6.96e-05 |
|    n_updates       | 3849660  |
---------------------------------
Eval num_timesteps=3040000, episode_reward=853.32 +/- 0.00
Episode length: 1084.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 853      |
| time/              |          |
|    total_timesteps | 3040000  |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 6.96e-05 |
|    n_updates       | 3849798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 970      |
| time/              |          |
|    episodes        | 2616     |
|    fps             | 53       |
|    time_elapsed    | 56926    |
|    total_timesteps | 3045190  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.78     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -4.33    |
|    learning_rate   | 6.95e-05 |
|    n_updates       | 3854988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 961      |
| time/              |          |
|    episodes        | 2620     |
|    fps             | 53       |
|    time_elapsed    | 57002    |
|    total_timesteps | 3049797  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 4.17     |
|    learning_rate   | 6.95e-05 |
|    n_updates       | 3859595  |
---------------------------------
Eval num_timesteps=3050000, episode_reward=758.87 +/- 0.00
Episode length: 967.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 967      |
|    mean_reward     | 759      |
| time/              |          |
|    total_timesteps | 3050000  |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 6.95e-05 |
|    n_updates       | 3859798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 954      |
| time/              |          |
|    episodes        | 2624     |
|    fps             | 53       |
|    time_elapsed    | 57099    |
|    total_timesteps | 3054534  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 6.95e-05 |
|    n_updates       | 3864332  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 2628     |
|    fps             | 53       |
|    time_elapsed    | 57176    |
|    total_timesteps | 3059156  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 6.94e-05 |
|    n_updates       | 3868954  |
---------------------------------
Eval num_timesteps=3060000, episode_reward=867.85 +/- 0.00
Episode length: 1095.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.1e+03  |
|    mean_reward     | 868      |
| time/              |          |
|    total_timesteps | 3060000  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 4.41     |
|    learning_rate   | 6.94e-05 |
|    n_updates       | 3869798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    episodes        | 2632     |
|    fps             | 53       |
|    time_elapsed    | 57281    |
|    total_timesteps | 3064372  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 6.26     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -5.45    |
|    learning_rate   | 6.94e-05 |
|    n_updates       | 3874170  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 929      |
| time/              |          |
|    episodes        | 2636     |
|    fps             | 53       |
|    time_elapsed    | 57350    |
|    total_timesteps | 3068523  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -1.72    |
|    learning_rate   | 6.93e-05 |
|    n_updates       | 3878321  |
---------------------------------
Eval num_timesteps=3070000, episode_reward=838.49 +/- 0.00
Episode length: 1077.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 838      |
| time/              |          |
|    total_timesteps | 3070000  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 0.102    |
|    learning_rate   | 6.93e-05 |
|    n_updates       | 3879798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 2640     |
|    fps             | 53       |
|    time_elapsed    | 57448    |
|    total_timesteps | 3073279  |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 6.93e-05 |
|    n_updates       | 3883077  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 916      |
| time/              |          |
|    episodes        | 2644     |
|    fps             | 53       |
|    time_elapsed    | 57524    |
|    total_timesteps | 3077831  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -1.52    |
|    learning_rate   | 6.92e-05 |
|    n_updates       | 3887629  |
---------------------------------
Eval num_timesteps=3080000, episode_reward=856.25 +/- 0.00
Episode length: 1104.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.1e+03  |
|    mean_reward     | 856      |
| time/              |          |
|    total_timesteps | 3080000  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 5.41     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 1.08     |
|    learning_rate   | 6.92e-05 |
|    n_updates       | 3889798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 915      |
| time/              |          |
|    episodes        | 2648     |
|    fps             | 53       |
|    time_elapsed    | 57643    |
|    total_timesteps | 3083909  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 7.61     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 3.77     |
|    learning_rate   | 6.92e-05 |
|    n_updates       | 3893707  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    episodes        | 2652     |
|    fps             | 53       |
|    time_elapsed    | 57721    |
|    total_timesteps | 3088693  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 5.51     |
|    learning_rate   | 6.91e-05 |
|    n_updates       | 3898491  |
---------------------------------
Eval num_timesteps=3090000, episode_reward=787.60 +/- 0.00
Episode length: 1002.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 788      |
| time/              |          |
|    total_timesteps | 3090000  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -4.55    |
|    learning_rate   | 6.91e-05 |
|    n_updates       | 3899798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 909      |
| time/              |          |
|    episodes        | 2656     |
|    fps             | 53       |
|    time_elapsed    | 57821    |
|    total_timesteps | 3093582  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 0.301    |
|    learning_rate   | 6.91e-05 |
|    n_updates       | 3903380  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.12e+03 |
|    ep_rew_mean     | 898      |
| time/              |          |
|    episodes        | 2660     |
|    fps             | 53       |
|    time_elapsed    | 57893    |
|    total_timesteps | 3097891  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -3.69    |
|    learning_rate   | 6.9e-05  |
|    n_updates       | 3907689  |
---------------------------------
Eval num_timesteps=3100000, episode_reward=843.90 +/- 0.00
Episode length: 1087.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.09e+03 |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 3100000  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 6.64     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 4.6      |
|    learning_rate   | 6.9e-05  |
|    n_updates       | 3909798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.13e+03 |
|    ep_rew_mean     | 900      |
| time/              |          |
|    episodes        | 2664     |
|    fps             | 53       |
|    time_elapsed    | 57990    |
|    total_timesteps | 3102612  |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -0.554   |
|    learning_rate   | 6.9e-05  |
|    n_updates       | 3912410  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    episodes        | 2668     |
|    fps             | 53       |
|    time_elapsed    | 58066    |
|    total_timesteps | 3107193  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.1      |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 6.89e-05 |
|    n_updates       | 3916991  |
---------------------------------
Eval num_timesteps=3110000, episode_reward=778.72 +/- 0.00
Episode length: 985.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 985      |
|    mean_reward     | 779      |
| time/              |          |
|    total_timesteps | 3110000  |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 10.3     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 5.73     |
|    learning_rate   | 6.89e-05 |
|    n_updates       | 3919798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 914      |
| time/              |          |
|    episodes        | 2672     |
|    fps             | 53       |
|    time_elapsed    | 58167    |
|    total_timesteps | 3112215  |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -1.97    |
|    learning_rate   | 6.89e-05 |
|    n_updates       | 3922013  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 911      |
| time/              |          |
|    episodes        | 2676     |
|    fps             | 53       |
|    time_elapsed    | 58239    |
|    total_timesteps | 3116555  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 6.03     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -0.594   |
|    learning_rate   | 6.88e-05 |
|    n_updates       | 3926353  |
---------------------------------
Eval num_timesteps=3120000, episode_reward=1004.28 +/- 0.00
Episode length: 1270.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.27e+03 |
|    mean_reward     | 1e+03    |
| time/              |          |
|    total_timesteps | 3120000  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 3.93     |
|    learning_rate   | 6.88e-05 |
|    n_updates       | 3929798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 911      |
| time/              |          |
|    episodes        | 2680     |
|    fps             | 53       |
|    time_elapsed    | 58352    |
|    total_timesteps | 3122277  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 4.93     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 1.56     |
|    learning_rate   | 6.88e-05 |
|    n_updates       | 3932075  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 919      |
| time/              |          |
|    episodes        | 2684     |
|    fps             | 53       |
|    time_elapsed    | 58433    |
|    total_timesteps | 3127157  |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 4.58     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 3.37     |
|    learning_rate   | 6.87e-05 |
|    n_updates       | 3936955  |
---------------------------------
Eval num_timesteps=3130000, episode_reward=820.11 +/- 0.00
Episode length: 1027.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 820      |
| time/              |          |
|    total_timesteps | 3130000  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -2.03    |
|    learning_rate   | 6.87e-05 |
|    n_updates       | 3939798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    episodes        | 2688     |
|    fps             | 53       |
|    time_elapsed    | 58541    |
|    total_timesteps | 3132626  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -4.17    |
|    learning_rate   | 6.87e-05 |
|    n_updates       | 3942424  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.14e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    episodes        | 2692     |
|    fps             | 53       |
|    time_elapsed    | 58605    |
|    total_timesteps | 3136409  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -6.65    |
|    learning_rate   | 6.86e-05 |
|    n_updates       | 3946207  |
---------------------------------
Eval num_timesteps=3140000, episode_reward=938.79 +/- 0.00
Episode length: 1186.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.19e+03 |
|    mean_reward     | 939      |
| time/              |          |
|    total_timesteps | 3140000  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 5.37     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -2.89    |
|    learning_rate   | 6.86e-05 |
|    n_updates       | 3949798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 917      |
| time/              |          |
|    episodes        | 2696     |
|    fps             | 53       |
|    time_elapsed    | 58701    |
|    total_timesteps | 3141020  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 2.56     |
|    learning_rate   | 6.86e-05 |
|    n_updates       | 3950818  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 2700     |
|    fps             | 53       |
|    time_elapsed    | 58785    |
|    total_timesteps | 3146214  |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -2.9     |
|    learning_rate   | 6.85e-05 |
|    n_updates       | 3956012  |
---------------------------------
Eval num_timesteps=3150000, episode_reward=805.69 +/- 0.00
Episode length: 1025.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 806      |
| time/              |          |
|    total_timesteps | 3150000  |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -9.46    |
|    learning_rate   | 6.85e-05 |
|    n_updates       | 3959798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 2704     |
|    fps             | 53       |
|    time_elapsed    | 58885    |
|    total_timesteps | 3151103  |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -3.84    |
|    learning_rate   | 6.85e-05 |
|    n_updates       | 3960901  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 919      |
| time/              |          |
|    episodes        | 2708     |
|    fps             | 53       |
|    time_elapsed    | 58966    |
|    total_timesteps | 3156086  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 6.84e-05 |
|    n_updates       | 3965884  |
---------------------------------
Eval num_timesteps=3160000, episode_reward=310.00 +/- 0.00
Episode length: 441.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 441      |
|    mean_reward     | 310      |
| time/              |          |
|    total_timesteps | 3160000  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 4.94     |
|    learning_rate   | 6.84e-05 |
|    n_updates       | 3969798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 925      |
| time/              |          |
|    episodes        | 2712     |
|    fps             | 53       |
|    time_elapsed    | 59070    |
|    total_timesteps | 3161455  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.57     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 6.84e-05 |
|    n_updates       | 3971253  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 921      |
| time/              |          |
|    episodes        | 2716     |
|    fps             | 53       |
|    time_elapsed    | 59147    |
|    total_timesteps | 3166160  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -2.78    |
|    learning_rate   | 6.83e-05 |
|    n_updates       | 3975958  |
---------------------------------
Eval num_timesteps=3170000, episode_reward=783.53 +/- 0.00
Episode length: 991.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 991      |
|    mean_reward     | 784      |
| time/              |          |
|    total_timesteps | 3170000  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 6.83e-05 |
|    n_updates       | 3979798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.15e+03 |
|    ep_rew_mean     | 922      |
| time/              |          |
|    episodes        | 2720     |
|    fps             | 53       |
|    time_elapsed    | 59251    |
|    total_timesteps | 3171333  |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 2.67     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -1.79    |
|    learning_rate   | 6.83e-05 |
|    n_updates       | 3981131  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 925      |
| time/              |          |
|    episodes        | 2724     |
|    fps             | 53       |
|    time_elapsed    | 59332    |
|    total_timesteps | 3176286  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 6.82e-05 |
|    n_updates       | 3986084  |
---------------------------------
Eval num_timesteps=3180000, episode_reward=1066.47 +/- 0.00
Episode length: 1354.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.35e+03 |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 3180000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 2.4      |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -5.38    |
|    learning_rate   | 6.82e-05 |
|    n_updates       | 3989798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 930      |
| time/              |          |
|    episodes        | 2728     |
|    fps             | 53       |
|    time_elapsed    | 59457    |
|    total_timesteps | 3182714  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -3.85    |
|    learning_rate   | 6.82e-05 |
|    n_updates       | 3992512  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.17e+03 |
|    ep_rew_mean     | 936      |
| time/              |          |
|    episodes        | 2732     |
|    fps             | 53       |
|    time_elapsed    | 59540    |
|    total_timesteps | 3187828  |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 4.38     |
|    learning_rate   | 6.81e-05 |
|    n_updates       | 3997626  |
---------------------------------
Eval num_timesteps=3190000, episode_reward=1088.77 +/- 0.00
Episode length: 1382.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.38e+03 |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 3190000  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -5.94    |
|    learning_rate   | 6.81e-05 |
|    n_updates       | 3999798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 942      |
| time/              |          |
|    episodes        | 2736     |
|    fps             | 53       |
|    time_elapsed    | 59657    |
|    total_timesteps | 3193731  |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 0.135    |
|    learning_rate   | 6.81e-05 |
|    n_updates       | 4003529  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 947      |
| time/              |          |
|    episodes        | 2740     |
|    fps             | 53       |
|    time_elapsed    | 59738    |
|    total_timesteps | 3198681  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 6.8e-05  |
|    n_updates       | 4008479  |
---------------------------------
Eval num_timesteps=3200000, episode_reward=1353.96 +/- 0.00
Episode length: 1731.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.73e+03 |
|    mean_reward     | 1.35e+03 |
| time/              |          |
|    total_timesteps | 3200000  |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -0.16    |
|    learning_rate   | 6.8e-05  |
|    n_updates       | 4009798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 954      |
| time/              |          |
|    episodes        | 2744     |
|    fps             | 53       |
|    time_elapsed    | 59870    |
|    total_timesteps | 3205534  |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 5.24     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 0.409    |
|    learning_rate   | 6.79e-05 |
|    n_updates       | 4015332  |
---------------------------------
Eval num_timesteps=3210000, episode_reward=1299.52 +/- 0.00
Episode length: 1639.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.64e+03 |
|    mean_reward     | 1.3e+03  |
| time/              |          |
|    total_timesteps | 3210000  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 4.98     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 2.92     |
|    learning_rate   | 6.79e-05 |
|    n_updates       | 4019798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 955      |
| time/              |          |
|    episodes        | 2748     |
|    fps             | 53       |
|    time_elapsed    | 59987    |
|    total_timesteps | 3211404  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 2.64     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 6.79e-05 |
|    n_updates       | 4021202  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.2e+03  |
|    ep_rew_mean     | 961      |
| time/              |          |
|    episodes        | 2752     |
|    fps             | 53       |
|    time_elapsed    | 60077    |
|    total_timesteps | 3216981  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 5.18     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 6.78e-05 |
|    n_updates       | 4026779  |
---------------------------------
Eval num_timesteps=3220000, episode_reward=1107.02 +/- 0.00
Episode length: 1414.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.41e+03 |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 3220000  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 2.72     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.86    |
|    learning_rate   | 6.78e-05 |
|    n_updates       | 4029798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.21e+03 |
|    ep_rew_mean     | 963      |
| time/              |          |
|    episodes        | 2756     |
|    fps             | 53       |
|    time_elapsed    | 60187    |
|    total_timesteps | 3222473  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -2.41    |
|    learning_rate   | 6.78e-05 |
|    n_updates       | 4032271  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 970      |
| time/              |          |
|    episodes        | 2760     |
|    fps             | 53       |
|    time_elapsed    | 60271    |
|    total_timesteps | 3227685  |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 5.65     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 6.77e-05 |
|    n_updates       | 4037483  |
---------------------------------
Eval num_timesteps=3230000, episode_reward=952.41 +/- 0.00
Episode length: 1200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 952      |
| time/              |          |
|    total_timesteps | 3230000  |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 6.77e-05 |
|    n_updates       | 4039798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.23e+03 |
|    ep_rew_mean     | 983      |
| time/              |          |
|    episodes        | 2764     |
|    fps             | 53       |
|    time_elapsed    | 60391    |
|    total_timesteps | 3233971  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 6.77e-05 |
|    n_updates       | 4043769  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 989      |
| time/              |          |
|    episodes        | 2768     |
|    fps             | 53       |
|    time_elapsed    | 60479    |
|    total_timesteps | 3239430  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 3.31     |
|    learning_rate   | 6.76e-05 |
|    n_updates       | 4049228  |
---------------------------------
Eval num_timesteps=3240000, episode_reward=1029.29 +/- 0.00
Episode length: 1318.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.32e+03 |
|    mean_reward     | 1.03e+03 |
| time/              |          |
|    total_timesteps | 3240000  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 3.77     |
|    learning_rate   | 6.76e-05 |
|    n_updates       | 4049798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 994      |
| time/              |          |
|    episodes        | 2772     |
|    fps             | 53       |
|    time_elapsed    | 60597    |
|    total_timesteps | 3245457  |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 3.32     |
|    ent_coef        | 0.0098   |
|    ent_coef_loss   | 4.84     |
|    learning_rate   | 6.75e-05 |
|    n_updates       | 4055255  |
---------------------------------
Eval num_timesteps=3250000, episode_reward=972.23 +/- 0.00
Episode length: 1231.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.23e+03 |
|    mean_reward     | 972      |
| time/              |          |
|    total_timesteps | 3250000  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 5.49     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -2.4     |
|    learning_rate   | 6.75e-05 |
|    n_updates       | 4059798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 997      |
| time/              |          |
|    episodes        | 2776     |
|    fps             | 53       |
|    time_elapsed    | 60709    |
|    total_timesteps | 3251124  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.00998  |
|    ent_coef_loss   | -0.625   |
|    learning_rate   | 6.75e-05 |
|    n_updates       | 4060922  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 2780     |
|    fps             | 53       |
|    time_elapsed    | 60793    |
|    total_timesteps | 3256321  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 5.75     |
|    ent_coef        | 0.00993  |
|    ent_coef_loss   | -0.967   |
|    learning_rate   | 6.74e-05 |
|    n_updates       | 4066119  |
---------------------------------
Eval num_timesteps=3260000, episode_reward=908.29 +/- 0.00
Episode length: 1141.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.14e+03 |
|    mean_reward     | 908      |
| time/              |          |
|    total_timesteps | 3260000  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 6.27     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 6.74e-05 |
|    n_updates       | 4069798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 992      |
| time/              |          |
|    episodes        | 2784     |
|    fps             | 53       |
|    time_elapsed    | 60898    |
|    total_timesteps | 3261513  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.00957  |
|    ent_coef_loss   | -0.16    |
|    learning_rate   | 6.74e-05 |
|    n_updates       | 4071311  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.24e+03 |
|    ep_rew_mean     | 991      |
| time/              |          |
|    episodes        | 2788     |
|    fps             | 53       |
|    time_elapsed    | 60983    |
|    total_timesteps | 3266458  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 2.93     |
|    ent_coef        | 0.00959  |
|    ent_coef_loss   | -0.275   |
|    learning_rate   | 6.73e-05 |
|    n_updates       | 4076256  |
---------------------------------
Eval num_timesteps=3270000, episode_reward=1171.51 +/- 0.00
Episode length: 1446.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.45e+03 |
|    mean_reward     | 1.17e+03 |
| time/              |          |
|    total_timesteps | 3270000  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 0.122    |
|    learning_rate   | 6.73e-05 |
|    n_updates       | 4079798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    episodes        | 2792     |
|    fps             | 53       |
|    time_elapsed    | 61101    |
|    total_timesteps | 3272235  |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 5.84     |
|    learning_rate   | 6.73e-05 |
|    n_updates       | 4082033  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2796     |
|    fps             | 53       |
|    time_elapsed    | 61183    |
|    total_timesteps | 3277123  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 0.324    |
|    learning_rate   | 6.72e-05 |
|    n_updates       | 4086921  |
---------------------------------
Eval num_timesteps=3280000, episode_reward=994.05 +/- 0.00
Episode length: 1243.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.24e+03 |
|    mean_reward     | 994      |
| time/              |          |
|    total_timesteps | 3280000  |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 6.72e-05 |
|    n_updates       | 4089798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2800     |
|    fps             | 53       |
|    time_elapsed    | 61297    |
|    total_timesteps | 3282622  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | 2.34     |
|    learning_rate   | 6.72e-05 |
|    n_updates       | 4092420  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2804     |
|    fps             | 53       |
|    time_elapsed    | 61380    |
|    total_timesteps | 3287547  |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 7.52     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 15       |
|    learning_rate   | 6.71e-05 |
|    n_updates       | 4097345  |
---------------------------------
Eval num_timesteps=3290000, episode_reward=983.94 +/- 0.00
Episode length: 1251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 984      |
| time/              |          |
|    total_timesteps | 3290000  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 4.32     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 0.132    |
|    learning_rate   | 6.71e-05 |
|    n_updates       | 4099798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2808     |
|    fps             | 53       |
|    time_elapsed    | 61482    |
|    total_timesteps | 3292322  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.89     |
|    ent_coef        | 0.00997  |
|    ent_coef_loss   | 2.39     |
|    learning_rate   | 6.71e-05 |
|    n_updates       | 4102120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2812     |
|    fps             | 53       |
|    time_elapsed    | 61562    |
|    total_timesteps | 3297026  |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 5.5      |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 6.7e-05  |
|    n_updates       | 4106824  |
---------------------------------
Eval num_timesteps=3300000, episode_reward=1066.84 +/- 0.00
Episode length: 1301.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.3e+03  |
|    mean_reward     | 1.07e+03 |
| time/              |          |
|    total_timesteps | 3300000  |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 1.83     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -8.03    |
|    learning_rate   | 6.7e-05  |
|    n_updates       | 4109798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    episodes        | 2816     |
|    fps             | 53       |
|    time_elapsed    | 61672    |
|    total_timesteps | 3302443  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -0.144   |
|    learning_rate   | 6.7e-05  |
|    n_updates       | 4112241  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2820     |
|    fps             | 53       |
|    time_elapsed    | 61759    |
|    total_timesteps | 3307798  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 4.27     |
|    ent_coef        | 0.0098   |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 6.69e-05 |
|    n_updates       | 4117596  |
---------------------------------
Eval num_timesteps=3310000, episode_reward=1002.00 +/- 0.00
Episode length: 1223.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.22e+03 |
|    mean_reward     | 1e+03    |
| time/              |          |
|    total_timesteps | 3310000  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 2.93     |
|    ent_coef        | 0.00978  |
|    ent_coef_loss   | -0.412   |
|    learning_rate   | 6.69e-05 |
|    n_updates       | 4119798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2824     |
|    fps             | 53       |
|    time_elapsed    | 61873    |
|    total_timesteps | 3313553  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 5.07     |
|    ent_coef        | 0.00946  |
|    ent_coef_loss   | 0.964    |
|    learning_rate   | 6.69e-05 |
|    n_updates       | 4123351  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2828     |
|    fps             | 53       |
|    time_elapsed    | 61957    |
|    total_timesteps | 3318731  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 3.07     |
|    ent_coef        | 0.00982  |
|    ent_coef_loss   | 0.771    |
|    learning_rate   | 6.68e-05 |
|    n_updates       | 4128529  |
---------------------------------
Eval num_timesteps=3320000, episode_reward=749.22 +/- 0.00
Episode length: 903.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 903      |
|    mean_reward     | 749      |
| time/              |          |
|    total_timesteps | 3320000  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 4.22     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 3.06     |
|    learning_rate   | 6.68e-05 |
|    n_updates       | 4129798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.27e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2832     |
|    fps             | 53       |
|    time_elapsed    | 62077    |
|    total_timesteps | 3325044  |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 2.81     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 6.67e-05 |
|    n_updates       | 4134842  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2836     |
|    fps             | 53       |
|    time_elapsed    | 62153    |
|    total_timesteps | 3329606  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 7.33     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 3.82     |
|    learning_rate   | 6.67e-05 |
|    n_updates       | 4139404  |
---------------------------------
Eval num_timesteps=3330000, episode_reward=941.82 +/- 0.00
Episode length: 1137.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.14e+03 |
|    mean_reward     | 942      |
| time/              |          |
|    total_timesteps | 3330000  |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -3.81    |
|    learning_rate   | 6.67e-05 |
|    n_updates       | 4139798  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.26e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    episodes        | 2840     |
|    fps             | 53       |
|    time_elapsed    | 62257    |
|    total_timesteps | 3334728  |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 4.08     |
|    learning_rate   | 6.67e-05 |
|    n_updates       | 4144526  |
---------------------------------
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_74
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | 159      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 35       |
|    time_elapsed    | 25       |
|    total_timesteps | 911      |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 5.17     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 0.0001   |
|    n_updates       | 810709   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 210      |
|    ep_rew_mean     | 144      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 34       |
|    time_elapsed    | 48       |
|    total_timesteps | 1679     |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 4.64     |
|    learning_rate   | 0.0001   |
|    n_updates       | 811477   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 189      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 33       |
|    time_elapsed    | 67       |
|    total_timesteps | 2270     |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 12.7     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 0.79     |
|    learning_rate   | 0.0001   |
|    n_updates       | 812068   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 187      |
|    ep_rew_mean     | 131      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 33       |
|    time_elapsed    | 89       |
|    total_timesteps | 2989     |
| train/             |          |
|    actor_loss      | -49.5    |
|    critic_loss     | 1.81     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -3.18    |
|    learning_rate   | 0.0001   |
|    n_updates       | 812787   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 203      |
|    ep_rew_mean     | 143      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 34       |
|    time_elapsed    | 116      |
|    total_timesteps | 4063     |
| train/             |          |
|    actor_loss      | -49.7    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 2.91     |
|    learning_rate   | 0.0001   |
|    n_updates       | 813861   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 206      |
|    ep_rew_mean     | 145      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 35       |
|    time_elapsed    | 139      |
|    total_timesteps | 4955     |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 3.51     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 2.25     |
|    learning_rate   | 0.0001   |
|    n_updates       | 814753   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 209      |
|    ep_rew_mean     | 144      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 35       |
|    time_elapsed    | 164      |
|    total_timesteps | 5844     |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 4.79     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 8        |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 815642   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 140      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 35       |
|    time_elapsed    | 185      |
|    total_timesteps | 6541     |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 8.01     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 816339   |
---------------------------------