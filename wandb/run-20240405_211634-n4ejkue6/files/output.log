Using cuda device
Wrapping the env in a DummyVecEnv.
Wrapping the env in a DummyVecEnv.
Logging to 5gdl/SAC_80
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 197      |
|    ep_rew_mean     | 165      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 25       |
|    time_elapsed    | 30       |
|    total_timesteps | 787      |
| train/             |          |
|    actor_loss      | -35.2    |
|    critic_loss     | 18.1     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 40.3     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1800484  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 153      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 26       |
|    time_elapsed    | 54       |
|    total_timesteps | 1460     |
| train/             |          |
|    actor_loss      | -36.1    |
|    critic_loss     | 16.6     |
|    ent_coef        | 0.0193   |
|    ent_coef_loss   | 36.9     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1801157  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 135      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 25       |
|    time_elapsed    | 75       |
|    total_timesteps | 1926     |
| train/             |          |
|    actor_loss      | -44.1    |
|    critic_loss     | 20.9     |
|    ent_coef        | 0.0204   |
|    ent_coef_loss   | 33.9     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1801623  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 123      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 24       |
|    time_elapsed    | 96       |
|    total_timesteps | 2319     |
| train/             |          |
|    actor_loss      | -42.4    |
|    critic_loss     | 25.7     |
|    ent_coef        | 0.0212   |
|    ent_coef_loss   | 26       |
|    learning_rate   | 0.0001   |
|    n_updates       | 1802016  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 121      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 23       |
|    time_elapsed    | 118      |
|    total_timesteps | 2839     |
| train/             |          |
|    actor_loss      | -46.2    |
|    critic_loss     | 20.1     |
|    ent_coef        | 0.0221   |
|    ent_coef_loss   | 25.1     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1802536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 128      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 24       |
|    time_elapsed    | 145      |
|    total_timesteps | 3620     |
| train/             |          |
|    actor_loss      | -47      |
|    critic_loss     | 22.3     |
|    ent_coef        | 0.0236   |
|    ent_coef_loss   | 24.9     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1803317  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 157      |
|    ep_rew_mean     | 133      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 25       |
|    time_elapsed    | 171      |
|    total_timesteps | 4389     |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 17.5     |
|    ent_coef        | 0.0252   |
|    ent_coef_loss   | 18.8     |
|    learning_rate   | 0.0001   |
|    n_updates       | 1804086  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 185      |
|    ep_rew_mean     | 157      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 27       |
|    time_elapsed    | 213      |
|    total_timesteps | 5915     |
| train/             |          |
|    actor_loss      | -50.5    |
|    critic_loss     | 15.1     |
|    ent_coef        | 0.0284   |
|    ent_coef_loss   | 18.3     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1805612  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 192      |
| time/              |          |
|    episodes        | 36       |
|    fps             | 30       |
|    time_elapsed    | 268      |
|    total_timesteps | 8087     |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.0337   |
|    ent_coef_loss   | 10.9     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1807784  |
---------------------------------
Eval num_timesteps=10000, episode_reward=759.16 +/- 0.00
Episode length: 882.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 882      |
|    mean_reward     | 759      |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 8.47     |
|    ent_coef        | 0.0379   |
|    ent_coef_loss   | 4.49     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1809697  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 267      |
|    ep_rew_mean     | 230      |
| time/              |          |
|    episodes        | 40       |
|    fps             | 30       |
|    time_elapsed    | 358      |
|    total_timesteps | 10797    |
| train/             |          |
|    actor_loss      | -49.1    |
|    critic_loss     | 6.86     |
|    ent_coef        | 0.0389   |
|    ent_coef_loss   | -1.7     |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1810494  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 307      |
|    ep_rew_mean     | 264      |
| time/              |          |
|    episodes        | 44       |
|    fps             | 31       |
|    time_elapsed    | 425      |
|    total_timesteps | 13616    |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 18.1     |
|    ent_coef        | 0.0362   |
|    ent_coef_loss   | -0.359   |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1813313  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    episodes        | 48       |
|    fps             | 31       |
|    time_elapsed    | 458      |
|    total_timesteps | 14648    |
| train/             |          |
|    actor_loss      | -45.2    |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0343   |
|    ent_coef_loss   | -0.712   |
|    learning_rate   | 9.99e-05 |
|    n_updates       | 1814345  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 300      |
|    ep_rew_mean     | 258      |
| time/              |          |
|    episodes        | 52       |
|    fps             | 31       |
|    time_elapsed    | 492      |
|    total_timesteps | 15703    |
| train/             |          |
|    actor_loss      | -43.7    |
|    critic_loss     | 5.63     |
|    ent_coef        | 0.0325   |
|    ent_coef_loss   | -1.24    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1815400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | 255      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 31       |
|    time_elapsed    | 525      |
|    total_timesteps | 16765    |
| train/             |          |
|    actor_loss      | -46.9    |
|    critic_loss     | 7.15     |
|    ent_coef        | 0.0317   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1816462  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 293      |
|    ep_rew_mean     | 251      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 31       |
|    time_elapsed    | 554      |
|    total_timesteps | 17676    |
| train/             |          |
|    actor_loss      | -43.9    |
|    critic_loss     | 6.65     |
|    ent_coef        | 0.031    |
|    ent_coef_loss   | 0.0986   |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1817373  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 247      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 31       |
|    time_elapsed    | 585      |
|    total_timesteps | 18619    |
| train/             |          |
|    actor_loss      | -42      |
|    critic_loss     | 8.21     |
|    ent_coef        | 0.0311   |
|    ent_coef_loss   | 0.631    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1818316  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 289      |
|    ep_rew_mean     | 247      |
| time/              |          |
|    episodes        | 68       |
|    fps             | 31       |
|    time_elapsed    | 618      |
|    total_timesteps | 19729    |
| train/             |          |
|    actor_loss      | -45.6    |
|    critic_loss     | 5.53     |
|    ent_coef        | 0.0305   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1819426  |
---------------------------------
Eval num_timesteps=20000, episode_reward=248.38 +/- 0.00
Episode length: 292.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 292      |
|    mean_reward     | 248      |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -46.3    |
|    critic_loss     | 3.69     |
|    ent_coef        | 0.0303   |
|    ent_coef_loss   | 0.881    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1819697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 302      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    episodes        | 72       |
|    fps             | 31       |
|    time_elapsed    | 695      |
|    total_timesteps | 22085    |
| train/             |          |
|    actor_loss      | -44.8    |
|    critic_loss     | 7.09     |
|    ent_coef        | 0.0269   |
|    ent_coef_loss   | -4.85    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1821782  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 309      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 76       |
|    fps             | 32       |
|    time_elapsed    | 740      |
|    total_timesteps | 23831    |
| train/             |          |
|    actor_loss      | -46      |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.0232   |
|    ent_coef_loss   | -5.75    |
|    learning_rate   | 9.98e-05 |
|    n_updates       | 1823528  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 310      |
|    ep_rew_mean     | 266      |
| time/              |          |
|    episodes        | 80       |
|    fps             | 32       |
|    time_elapsed    | 775      |
|    total_timesteps | 25151    |
| train/             |          |
|    actor_loss      | -46.6    |
|    critic_loss     | 5.36     |
|    ent_coef        | 0.0211   |
|    ent_coef_loss   | -6.96    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1824848  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 308      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 84       |
|    fps             | 32       |
|    time_elapsed    | 806      |
|    total_timesteps | 26214    |
| train/             |          |
|    actor_loss      | -46.3    |
|    critic_loss     | 3.58     |
|    ent_coef        | 0.0207   |
|    ent_coef_loss   | 1.7      |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1825911  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 306      |
|    ep_rew_mean     | 263      |
| time/              |          |
|    episodes        | 88       |
|    fps             | 32       |
|    time_elapsed    | 837      |
|    total_timesteps | 27265    |
| train/             |          |
|    actor_loss      | -47.3    |
|    critic_loss     | 6.45     |
|    ent_coef        | 0.0221   |
|    ent_coef_loss   | 1.45     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1826962  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 304      |
|    ep_rew_mean     | 261      |
| time/              |          |
|    episodes        | 92       |
|    fps             | 32       |
|    time_elapsed    | 870      |
|    total_timesteps | 28364    |
| train/             |          |
|    actor_loss      | -46      |
|    critic_loss     | 4.86     |
|    ent_coef        | 0.023    |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1828061  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 302      |
|    ep_rew_mean     | 259      |
| time/              |          |
|    episodes        | 96       |
|    fps             | 32       |
|    time_elapsed    | 900      |
|    total_timesteps | 29353    |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 4.9      |
|    ent_coef        | 0.0226   |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1829050  |
---------------------------------
Eval num_timesteps=30000, episode_reward=355.78 +/- 0.00
Episode length: 427.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 427      |
|    mean_reward     | 356      |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -47.1    |
|    critic_loss     | 5.58     |
|    ent_coef        | 0.0221   |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1829697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 309      |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 100      |
|    fps             | 32       |
|    time_elapsed    | 968      |
|    total_timesteps | 31396    |
| train/             |          |
|    actor_loss      | -48.8    |
|    critic_loss     | 5.76     |
|    ent_coef        | 0.0217   |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1831093  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 320      |
|    ep_rew_mean     | 274      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 32       |
|    time_elapsed    | 1014     |
|    total_timesteps | 33283    |
| train/             |          |
|    actor_loss      | -49.6    |
|    critic_loss     | 4.97     |
|    ent_coef        | 0.0209   |
|    ent_coef_loss   | -0.753   |
|    learning_rate   | 9.97e-05 |
|    n_updates       | 1832980  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 332      |
|    ep_rew_mean     | 285      |
| time/              |          |
|    episodes        | 108      |
|    fps             | 33       |
|    time_elapsed    | 1060     |
|    total_timesteps | 35160    |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0213   |
|    ent_coef_loss   | -2.04    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 1834857  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 359      |
|    ep_rew_mean     | 309      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 33       |
|    time_elapsed    | 1130     |
|    total_timesteps | 38318    |
| train/             |          |
|    actor_loss      | -47.9    |
|    critic_loss     | 6.41     |
|    ent_coef        | 0.023    |
|    ent_coef_loss   | 0.638    |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 1838015  |
---------------------------------
Eval num_timesteps=40000, episode_reward=488.51 +/- 0.00
Episode length: 566.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 566      |
|    mean_reward     | 489      |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -47.9    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.023    |
|    ent_coef_loss   | 4.98     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 1839697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 348      |
| time/              |          |
|    episodes        | 116      |
|    fps             | 34       |
|    time_elapsed    | 1261     |
|    total_timesteps | 43703    |
| train/             |          |
|    actor_loss      | -50.5    |
|    critic_loss     | 8.69     |
|    ent_coef        | 0.0233   |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 9.96e-05 |
|    n_updates       | 1843400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 430      |
|    ep_rew_mean     | 373      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 35       |
|    time_elapsed    | 1332     |
|    total_timesteps | 47003    |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0226   |
|    ent_coef_loss   | 0.694    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 1846700  |
---------------------------------
Eval num_timesteps=50000, episode_reward=565.09 +/- 0.00
Episode length: 631.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 631      |
|    mean_reward     | 565      |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 3.96     |
|    ent_coef        | 0.0226   |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 1849697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 453      |
|    ep_rew_mean     | 394      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 35       |
|    time_elapsed    | 1433     |
|    total_timesteps | 50772    |
| train/             |          |
|    actor_loss      | -49.8    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0224   |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 1850469  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 476      |
|    ep_rew_mean     | 415      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 35       |
|    time_elapsed    | 1502     |
|    total_timesteps | 53884    |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 3.92     |
|    ent_coef        | 0.0216   |
|    ent_coef_loss   | 0.642    |
|    learning_rate   | 9.95e-05 |
|    n_updates       | 1853581  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 430      |
| time/              |          |
|    episodes        | 132      |
|    fps             | 36       |
|    time_elapsed    | 1574     |
|    total_timesteps | 57143    |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0201   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 1856840  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 497      |
|    ep_rew_mean     | 434      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 36       |
|    time_elapsed    | 1632     |
|    total_timesteps | 59672    |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.0192   |
|    ent_coef_loss   | -2.22    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 1859369  |
---------------------------------
Eval num_timesteps=60000, episode_reward=500.57 +/- 0.00
Episode length: 571.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 501      |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | -0.0625  |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 1859697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 492      |
|    ep_rew_mean     | 429      |
| time/              |          |
|    episodes        | 140      |
|    fps             | 36       |
|    time_elapsed    | 1702     |
|    total_timesteps | 61851    |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -0.228   |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 1861548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 485      |
|    ep_rew_mean     | 424      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 36       |
|    time_elapsed    | 1754     |
|    total_timesteps | 63965    |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -3.53    |
|    learning_rate   | 9.94e-05 |
|    n_updates       | 1863662  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 499      |
|    ep_rew_mean     | 436      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 36       |
|    time_elapsed    | 1810     |
|    total_timesteps | 66353    |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 2.79     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.9     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 1866050  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 511      |
|    ep_rew_mean     | 447      |
| time/              |          |
|    episodes        | 152      |
|    fps             | 36       |
|    time_elapsed    | 1864     |
|    total_timesteps | 68640    |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 1868337  |
---------------------------------
Eval num_timesteps=70000, episode_reward=624.36 +/- 0.00
Episode length: 706.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 706      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 2.62     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 1869697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 528      |
|    ep_rew_mean     | 463      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 36       |
|    time_elapsed    | 1951     |
|    total_timesteps | 71503    |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.59    |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 1871200  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 552      |
|    ep_rew_mean     | 485      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 36       |
|    time_elapsed    | 2024     |
|    total_timesteps | 74827    |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 6.42     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.9     |
|    learning_rate   | 9.93e-05 |
|    n_updates       | 1874524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 567      |
|    ep_rew_mean     | 499      |
| time/              |          |
|    episodes        | 164      |
|    fps             | 37       |
|    time_elapsed    | 2083     |
|    total_timesteps | 77289    |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 3.13     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 1876986  |
---------------------------------
Eval num_timesteps=80000, episode_reward=897.84 +/- 0.00
Episode length: 1001.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 898      |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -54.1    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.41     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 1879697  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 593      |
|    ep_rew_mean     | 523      |
| time/              |          |
|    episodes        | 168      |
|    fps             | 37       |
|    time_elapsed    | 2189     |
|    total_timesteps | 81049    |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 3.16     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.164    |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 1880746  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 601      |
|    ep_rew_mean     | 530      |
| time/              |          |
|    episodes        | 172      |
|    fps             | 37       |
|    time_elapsed    | 2254     |
|    total_timesteps | 83919    |
| train/             |          |
|    actor_loss      | -54.1    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 1.71     |
|    learning_rate   | 9.92e-05 |
|    n_updates       | 1883616  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 616      |
|    ep_rew_mean     | 544      |
| time/              |          |
|    episodes        | 176      |
|    fps             | 37       |
|    time_elapsed    | 2328     |
|    total_timesteps | 87224    |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 1886921  |
---------------------------------
Eval num_timesteps=90000, episode_reward=580.12 +/- 0.00
Episode length: 639.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 639      |
|    mean_reward     | 580      |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 2.28     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 1889697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 636      |
|    ep_rew_mean     | 562      |
| time/              |          |
|    episodes        | 180      |
|    fps             | 37       |
|    time_elapsed    | 2423     |
|    total_timesteps | 90540    |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 2.62     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -3.13    |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 1890237  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 654      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 37       |
|    time_elapsed    | 2488     |
|    total_timesteps | 93353    |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.21     |
|    learning_rate   | 9.91e-05 |
|    n_updates       | 1893050  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 672      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 37       |
|    time_elapsed    | 2554     |
|    total_timesteps | 96291    |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 1.77     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -3.48    |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 1895988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 694      |
|    ep_rew_mean     | 615      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 37       |
|    time_elapsed    | 2627     |
|    total_timesteps | 99518    |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 2.3      |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -0.258   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 1899215  |
---------------------------------
Eval num_timesteps=100000, episode_reward=789.41 +/- 0.00
Episode length: 894.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 894      |
|    mean_reward     | 789      |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 3.12     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -0.821   |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 1899697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 37       |
|    time_elapsed    | 2742     |
|    total_timesteps | 103784   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 1.87     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.67     |
|    learning_rate   | 9.9e-05  |
|    n_updates       | 1903481  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 655      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 38       |
|    time_elapsed    | 2821     |
|    total_timesteps | 107295   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 2.94     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 4.97     |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 1906992  |
---------------------------------
Eval num_timesteps=110000, episode_reward=1150.00 +/- 0.00
Episode length: 1256.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1.15e+03 |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 6.28     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 0.397    |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 1909697  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 762      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 204      |
|    fps             | 38       |
|    time_elapsed    | 2946     |
|    total_timesteps | 112173   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 1.74     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 1.13     |
|    learning_rate   | 9.89e-05 |
|    n_updates       | 1911870  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 783      |
|    ep_rew_mean     | 696      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 38       |
|    time_elapsed    | 3031     |
|    total_timesteps | 116103   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 2.65     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 1915800  |
---------------------------------
Eval num_timesteps=120000, episode_reward=1047.19 +/- 0.00
Episode length: 1160.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 1.05e+03 |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 2.16     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -0.893   |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 1919697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 709      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 38       |
|    time_elapsed    | 3158     |
|    total_timesteps | 120948   |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 3.48     |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 1920645  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 783      |
|    ep_rew_mean     | 697      |
| time/              |          |
|    episodes        | 216      |
|    fps             | 38       |
|    time_elapsed    | 3234     |
|    total_timesteps | 124369   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 2.29     |
|    ent_coef        | 0.00979  |
|    ent_coef_loss   | -5.09    |
|    learning_rate   | 9.88e-05 |
|    n_updates       | 1924066  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 796      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 220      |
|    fps             | 38       |
|    time_elapsed    | 3331     |
|    total_timesteps | 128934   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0089   |
|    ent_coef_loss   | 1.84     |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 1928631  |
---------------------------------
Eval num_timesteps=130000, episode_reward=801.77 +/- 0.00
Episode length: 902.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 902      |
|    mean_reward     | 802      |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0089   |
|    ent_coef_loss   | 0.809    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 1929697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 711      |
| time/              |          |
|    episodes        | 224      |
|    fps             | 38       |
|    time_elapsed    | 3429     |
|    total_timesteps | 132368   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 1.67     |
|    ent_coef        | 0.00862  |
|    ent_coef_loss   | -1.21    |
|    learning_rate   | 9.87e-05 |
|    n_updates       | 1932065  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 720      |
| time/              |          |
|    episodes        | 228      |
|    fps             | 38       |
|    time_elapsed    | 3515     |
|    total_timesteps | 136406   |
| train/             |          |
|    actor_loss      | -65.2    |
|    critic_loss     | 1.35     |
|    ent_coef        | 0.00913  |
|    ent_coef_loss   | -1.14    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 1936103  |
---------------------------------
Eval num_timesteps=140000, episode_reward=772.05 +/- 0.00
Episode length: 861.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 861      |
|    mean_reward     | 772      |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 2.82     |
|    ent_coef        | 0.00918  |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 1939697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 724      |
| time/              |          |
|    episodes        | 232      |
|    fps             | 38       |
|    time_elapsed    | 3637     |
|    total_timesteps | 140948   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 2.08     |
|    ent_coef        | 0.00923  |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 9.86e-05 |
|    n_updates       | 1940645  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 740      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 38       |
|    time_elapsed    | 3728     |
|    total_timesteps | 145257   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 2.18     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -5.92    |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 1944954  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 759      |
| time/              |          |
|    episodes        | 240      |
|    fps             | 39       |
|    time_elapsed    | 3816     |
|    total_timesteps | 149332   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.77     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 1949029  |
---------------------------------
Eval num_timesteps=150000, episode_reward=1062.91 +/- 0.00
Episode length: 1173.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 2.64     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 1949697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 870      |
|    ep_rew_mean     | 779      |
| time/              |          |
|    episodes        | 244      |
|    fps             | 39       |
|    time_elapsed    | 3945     |
|    total_timesteps | 154282   |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 2.7      |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 4.39     |
|    learning_rate   | 9.85e-05 |
|    n_updates       | 1953979  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 800      |
| time/              |          |
|    episodes        | 248      |
|    fps             | 39       |
|    time_elapsed    | 4042     |
|    total_timesteps | 158831   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 1958528  |
---------------------------------
Eval num_timesteps=160000, episode_reward=424.89 +/- 0.00
Episode length: 516.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 516      |
|    mean_reward     | 425      |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 2.36     |
|    ent_coef        | 0.00994  |
|    ent_coef_loss   | 2.46     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 1959697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 895      |
|    ep_rew_mean     | 802      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 39       |
|    time_elapsed    | 4122     |
|    total_timesteps | 161423   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.18     |
|    ent_coef        | 0.00989  |
|    ent_coef_loss   | 5.13     |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 1961120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 902      |
|    ep_rew_mean     | 807      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 39       |
|    time_elapsed    | 4201     |
|    total_timesteps | 164839   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 6.75     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 9.84e-05 |
|    n_updates       | 1964536  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 915      |
|    ep_rew_mean     | 821      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 39       |
|    time_elapsed    | 4299     |
|    total_timesteps | 169537   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 5.17     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 1969234  |
---------------------------------
Eval num_timesteps=170000, episode_reward=872.22 +/- 0.00
Episode length: 959.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 959      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 2.93     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 3.87     |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 1969697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 939      |
|    ep_rew_mean     | 843      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 39       |
|    time_elapsed    | 4434     |
|    total_timesteps | 174846   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 2.35     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -2.02    |
|    learning_rate   | 9.83e-05 |
|    n_updates       | 1974543  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 945      |
|    ep_rew_mean     | 848      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 39       |
|    time_elapsed    | 4525     |
|    total_timesteps | 179109   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 2.59     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -3       |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 1978806  |
---------------------------------
Eval num_timesteps=180000, episode_reward=1042.24 +/- 0.00
Episode length: 1156.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.16e+03 |
|    mean_reward     | 1.04e+03 |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -68.1    |
|    critic_loss     | 2.71     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -3.89    |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 1979697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 955      |
|    ep_rew_mean     | 857      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 39       |
|    time_elapsed    | 4651     |
|    total_timesteps | 183908   |
| train/             |          |
|    actor_loss      | -64.7    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.335   |
|    learning_rate   | 9.82e-05 |
|    n_updates       | 1983605  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 960      |
|    ep_rew_mean     | 862      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 39       |
|    time_elapsed    | 4734     |
|    total_timesteps | 187686   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 7.51     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1987383  |
---------------------------------
Eval num_timesteps=190000, episode_reward=766.70 +/- 0.00
Episode length: 846.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 846      |
|    mean_reward     | 767      |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | -64.1    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 1.55     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1989697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 967      |
|    ep_rew_mean     | 868      |
| time/              |          |
|    episodes        | 280      |
|    fps             | 39       |
|    time_elapsed    | 4846     |
|    total_timesteps | 191944   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 2.75     |
|    learning_rate   | 9.81e-05 |
|    n_updates       | 1991641  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 975      |
|    ep_rew_mean     | 876      |
| time/              |          |
|    episodes        | 284      |
|    fps             | 39       |
|    time_elapsed    | 4926     |
|    total_timesteps | 195581   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 6.54     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.86     |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1995278  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 986      |
|    ep_rew_mean     | 886      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 39       |
|    time_elapsed    | 5014     |
|    total_timesteps | 199638   |
| train/             |          |
|    actor_loss      | -65.3    |
|    critic_loss     | 3.2      |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 4.5      |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1999335  |
---------------------------------
Eval num_timesteps=200000, episode_reward=739.25 +/- 0.00
Episode length: 811.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 811      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -0.552   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 1999697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 292      |
|    fps             | 39       |
|    time_elapsed    | 5138     |
|    total_timesteps | 204553   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 2.78     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -0.522   |
|    learning_rate   | 9.8e-05  |
|    n_updates       | 2004250  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 906      |
| time/              |          |
|    episodes        | 296      |
|    fps             | 39       |
|    time_elapsed    | 5234     |
|    total_timesteps | 208995   |
| train/             |          |
|    actor_loss      | -66.9    |
|    critic_loss     | 2.19     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -5.28    |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2008692  |
---------------------------------
Eval num_timesteps=210000, episode_reward=975.00 +/- 0.00
Episode length: 1065.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.06e+03 |
|    mean_reward     | 975      |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 2.5      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 4.6      |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2009697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    episodes        | 300      |
|    fps             | 39       |
|    time_elapsed    | 5347     |
|    total_timesteps | 213176   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 3.26     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -0.438   |
|    learning_rate   | 9.79e-05 |
|    n_updates       | 2012873  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 996      |
|    ep_rew_mean     | 899      |
| time/              |          |
|    episodes        | 304      |
|    fps             | 39       |
|    time_elapsed    | 5412     |
|    total_timesteps | 216045   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 3.66     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 2.42     |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2015742  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 991      |
|    ep_rew_mean     | 895      |
| time/              |          |
|    episodes        | 308      |
|    fps             | 39       |
|    time_elapsed    | 5487     |
|    total_timesteps | 219447   |
| train/             |          |
|    actor_loss      | -63.7    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2019144  |
---------------------------------
Eval num_timesteps=220000, episode_reward=928.32 +/- 0.00
Episode length: 1027.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 928      |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -64.8    |
|    critic_loss     | 2.48     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -5.66    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2019697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 992      |
|    ep_rew_mean     | 895      |
| time/              |          |
|    episodes        | 312      |
|    fps             | 39       |
|    time_elapsed    | 5616     |
|    total_timesteps | 224504   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 6.59     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.198    |
|    learning_rate   | 9.78e-05 |
|    n_updates       | 2024201  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 904      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 40       |
|    time_elapsed    | 5708     |
|    total_timesteps | 228840   |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.643    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2028537  |
---------------------------------
Eval num_timesteps=230000, episode_reward=929.87 +/- 0.00
Episode length: 1013.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 930      |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.3      |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | 2.32     |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2029697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 905      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 40       |
|    time_elapsed    | 5852     |
|    total_timesteps | 234671   |
| train/             |          |
|    actor_loss      | -65.8    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -3.37    |
|    learning_rate   | 9.77e-05 |
|    n_updates       | 2034368  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 40       |
|    time_elapsed    | 5950     |
|    total_timesteps | 239266   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 2.92     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.64    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2038963  |
---------------------------------
Eval num_timesteps=240000, episode_reward=1273.37 +/- 0.00
Episode length: 1390.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 1.27e+03 |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -64.4    |
|    critic_loss     | 3.38     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -4.07    |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2039697  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 919      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 40       |
|    time_elapsed    | 6082     |
|    total_timesteps | 244187   |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 3.52     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | -0.0815  |
|    learning_rate   | 9.76e-05 |
|    n_updates       | 2043884  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 929      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 40       |
|    time_elapsed    | 6180     |
|    total_timesteps | 248852   |
| train/             |          |
|    actor_loss      | -66.2    |
|    critic_loss     | 3.21     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -0.826   |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2048549  |
---------------------------------
Eval num_timesteps=250000, episode_reward=1064.57 +/- 0.00
Episode length: 1200.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 7.48     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.971    |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2049697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 929      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 40       |
|    time_elapsed    | 6319     |
|    total_timesteps | 254281   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 3.92     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 4.66     |
|    learning_rate   | 9.75e-05 |
|    n_updates       | 2053978  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 928      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 40       |
|    time_elapsed    | 6403     |
|    total_timesteps | 258240   |
| train/             |          |
|    actor_loss      | -66      |
|    critic_loss     | 3.63     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 2.7      |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2057937  |
---------------------------------
Eval num_timesteps=260000, episode_reward=1100.64 +/- 0.00
Episode length: 1211.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 6.37     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.605   |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2059697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 926      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 40       |
|    time_elapsed    | 6531     |
|    total_timesteps | 263128   |
| train/             |          |
|    actor_loss      | -65.7    |
|    critic_loss     | 3.17     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -0.0981  |
|    learning_rate   | 9.74e-05 |
|    n_updates       | 2062825  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 927      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 40       |
|    time_elapsed    | 6630     |
|    total_timesteps | 267858   |
| train/             |          |
|    actor_loss      | -66.3    |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -4.99    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2067555  |
---------------------------------
Eval num_timesteps=270000, episode_reward=982.29 +/- 0.00
Episode length: 1076.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 982      |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2069697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 936      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 40       |
|    time_elapsed    | 6739     |
|    total_timesteps | 271727   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.27     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 9.73e-05 |
|    n_updates       | 2071424  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 946      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 40       |
|    time_elapsed    | 6830     |
|    total_timesteps | 276110   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.63     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2075807  |
---------------------------------
Eval num_timesteps=280000, episode_reward=1134.14 +/- 0.00
Episode length: 1232.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.23e+03 |
|    mean_reward     | 1.13e+03 |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 3.23     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -4.73    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2079697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 944      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 40       |
|    time_elapsed    | 6956     |
|    total_timesteps | 281037   |
| train/             |          |
|    actor_loss      | -66.1    |
|    critic_loss     | 5.01     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -5.06    |
|    learning_rate   | 9.72e-05 |
|    n_updates       | 2080734  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 945      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 40       |
|    time_elapsed    | 7061     |
|    total_timesteps | 286011   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 2.99     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -0.983   |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2085708  |
---------------------------------
Eval num_timesteps=290000, episode_reward=872.66 +/- 0.00
Episode length: 973.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 973      |
|    mean_reward     | 873      |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.931    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2089697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 40       |
|    time_elapsed    | 7185     |
|    total_timesteps | 291035   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.923    |
|    learning_rate   | 9.71e-05 |
|    n_updates       | 2090732  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 951      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 40       |
|    time_elapsed    | 7273     |
|    total_timesteps | 295219   |
| train/             |          |
|    actor_loss      | -63.2    |
|    critic_loss     | 4.01     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 3.13     |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2094916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 954      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 40       |
|    time_elapsed    | 7362     |
|    total_timesteps | 299349   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -4.09    |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2099046  |
---------------------------------
Eval num_timesteps=300000, episode_reward=1198.15 +/- 0.00
Episode length: 1310.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.31e+03 |
|    mean_reward     | 1.2e+03  |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -63.9    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 1.39     |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2099697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 957      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 40       |
|    time_elapsed    | 7490     |
|    total_timesteps | 304259   |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -3.74    |
|    learning_rate   | 9.7e-05  |
|    n_updates       | 2103956  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 958      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 40       |
|    time_elapsed    | 7572     |
|    total_timesteps | 308098   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2107795  |
---------------------------------
Eval num_timesteps=310000, episode_reward=993.20 +/- 0.00
Episode length: 1096.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.1e+03  |
|    mean_reward     | 993      |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 2.53     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 5.72     |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2109697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 956      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 40       |
|    time_elapsed    | 7692     |
|    total_timesteps | 312689   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 2.95     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -0.174   |
|    learning_rate   | 9.69e-05 |
|    n_updates       | 2112386  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 950      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 40       |
|    time_elapsed    | 7778     |
|    total_timesteps | 316625   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -1.46    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2116322  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 40       |
|    time_elapsed    | 7852     |
|    total_timesteps | 319979   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.82     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2119676  |
---------------------------------
Eval num_timesteps=320000, episode_reward=1106.29 +/- 0.00
Episode length: 1211.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.11e+03 |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 3.91     |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2119697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 40       |
|    time_elapsed    | 7961     |
|    total_timesteps | 323963   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 3.65     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -2.54    |
|    learning_rate   | 9.68e-05 |
|    n_updates       | 2123660  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 949      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 40       |
|    time_elapsed    | 8050     |
|    total_timesteps | 328104   |
| train/             |          |
|    actor_loss      | -63.6    |
|    critic_loss     | 4.5      |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -0.471   |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2127801  |
---------------------------------
Eval num_timesteps=330000, episode_reward=915.43 +/- 0.00
Episode length: 1013.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 915      |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 3.06     |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2129697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.05e+03 |
|    ep_rew_mean     | 951      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 40       |
|    time_elapsed    | 8155     |
|    total_timesteps | 331880   |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 7.33     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.751   |
|    learning_rate   | 9.67e-05 |
|    n_updates       | 2131577  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 40       |
|    time_elapsed    | 8228     |
|    total_timesteps | 335130   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 2.44     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2134827  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.04e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 40       |
|    time_elapsed    | 8323     |
|    total_timesteps | 339498   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 3.15     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -2.5     |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2139195  |
---------------------------------
Eval num_timesteps=340000, episode_reward=833.12 +/- 0.00
Episode length: 922.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 922      |
|    mean_reward     | 833      |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 3.14     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.29    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2139697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.03e+03 |
|    ep_rew_mean     | 929      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 40       |
|    time_elapsed    | 8435     |
|    total_timesteps | 343688   |
| train/             |          |
|    actor_loss      | -64.9    |
|    critic_loss     | 2.76     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -4.35    |
|    learning_rate   | 9.66e-05 |
|    n_updates       | 2143385  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 913      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 40       |
|    time_elapsed    | 8500     |
|    total_timesteps | 346589   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.47     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 3.15     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2146286  |
---------------------------------
Eval num_timesteps=350000, episode_reward=1156.15 +/- 0.00
Episode length: 1251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.25e+03 |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.67     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | 0.96     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2149697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 909      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 40       |
|    time_elapsed    | 8617     |
|    total_timesteps | 350860   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 3.07     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 5.74     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2150557  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 995      |
|    ep_rew_mean     | 896      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 40       |
|    time_elapsed    | 8688     |
|    total_timesteps | 354118   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.62     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 1.89     |
|    learning_rate   | 9.65e-05 |
|    n_updates       | 2153815  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 902      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 40       |
|    time_elapsed    | 8792     |
|    total_timesteps | 359081   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 5.36     |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2158778  |
---------------------------------
Eval num_timesteps=360000, episode_reward=1388.93 +/- 0.00
Episode length: 1526.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.53e+03 |
|    mean_reward     | 1.39e+03 |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 8.14     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 0.114    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2159697  |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 907      |
| time/              |          |
|    episodes        | 440      |
|    fps             | 40       |
|    time_elapsed    | 8933     |
|    total_timesteps | 364573   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | 0.822    |
|    learning_rate   | 9.64e-05 |
|    n_updates       | 2164270  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 909      |
| time/              |          |
|    episodes        | 444      |
|    fps             | 40       |
|    time_elapsed    | 9026     |
|    total_timesteps | 368878   |
| train/             |          |
|    actor_loss      | -65      |
|    critic_loss     | 3.35     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -3.3     |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2168575  |
---------------------------------
Eval num_timesteps=370000, episode_reward=1084.59 +/- 0.00
Episode length: 1203.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | -65.9    |
|    critic_loss     | 3.03     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -3.31    |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2169697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 911      |
| time/              |          |
|    episodes        | 448      |
|    fps             | 40       |
|    time_elapsed    | 9176     |
|    total_timesteps | 374920   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -0.726   |
|    learning_rate   | 9.63e-05 |
|    n_updates       | 2174617  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 915      |
| time/              |          |
|    episodes        | 452      |
|    fps             | 40       |
|    time_elapsed    | 9260     |
|    total_timesteps | 378827   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2178524  |
---------------------------------
Eval num_timesteps=380000, episode_reward=741.18 +/- 0.00
Episode length: 829.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 829      |
|    mean_reward     | 741      |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 2        |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -4.58    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2179697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 913      |
| time/              |          |
|    episodes        | 456      |
|    fps             | 40       |
|    time_elapsed    | 9373     |
|    total_timesteps | 383096   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -2.65    |
|    learning_rate   | 9.62e-05 |
|    n_updates       | 2182793  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 904      |
| time/              |          |
|    episodes        | 460      |
|    fps             | 40       |
|    time_elapsed    | 9454     |
|    total_timesteps | 386759   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.67     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 6.14     |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2186456  |
---------------------------------
Eval num_timesteps=390000, episode_reward=1086.79 +/- 0.00
Episode length: 1205.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.09e+03 |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 3.53     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2189697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 898      |
| time/              |          |
|    episodes        | 464      |
|    fps             | 40       |
|    time_elapsed    | 9575     |
|    total_timesteps | 391148   |
| train/             |          |
|    actor_loss      | -64.2    |
|    critic_loss     | 2.96     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -5.31    |
|    learning_rate   | 9.61e-05 |
|    n_updates       | 2190845  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 898      |
| time/              |          |
|    episodes        | 468      |
|    fps             | 40       |
|    time_elapsed    | 9674     |
|    total_timesteps | 395794   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 2.64     |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2195491  |
---------------------------------
Eval num_timesteps=400000, episode_reward=1280.66 +/- 0.00
Episode length: 1390.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 1.28e+03 |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2199697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 998      |
|    ep_rew_mean     | 898      |
| time/              |          |
|    episodes        | 472      |
|    fps             | 40       |
|    time_elapsed    | 9790     |
|    total_timesteps | 400000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 996      |
|    ep_rew_mean     | 897      |
| time/              |          |
|    episodes        | 476      |
|    fps             | 40       |
|    time_elapsed    | 9876     |
|    total_timesteps | 403954   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 5.95     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 1.42     |
|    learning_rate   | 9.6e-05  |
|    n_updates       | 2203651  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 900      |
| time/              |          |
|    episodes        | 480      |
|    fps             | 40       |
|    time_elapsed    | 9971     |
|    total_timesteps | 408492   |
| train/             |          |
|    actor_loss      | -66.4    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2208189  |
---------------------------------
Eval num_timesteps=410000, episode_reward=1103.48 +/- 0.00
Episode length: 1210.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.21e+03 |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | -62.6    |
|    critic_loss     | 2.68     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 0.936    |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2209697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 904      |
| time/              |          |
|    episodes        | 484      |
|    fps             | 40       |
|    time_elapsed    | 10098    |
|    total_timesteps | 413152   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -2.51    |
|    learning_rate   | 9.59e-05 |
|    n_updates       | 2212849  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 913      |
| time/              |          |
|    episodes        | 488      |
|    fps             | 40       |
|    time_elapsed    | 10198    |
|    total_timesteps | 417823   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.628   |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2217520  |
---------------------------------
Eval num_timesteps=420000, episode_reward=1159.22 +/- 0.00
Episode length: 1261.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.26e+03 |
|    mean_reward     | 1.16e+03 |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 3.29     |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2219697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    episodes        | 492      |
|    fps             | 40       |
|    time_elapsed    | 10336    |
|    total_timesteps | 423138   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 3.5      |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 9.58e-05 |
|    n_updates       | 2222835  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 917      |
| time/              |          |
|    episodes        | 496      |
|    fps             | 40       |
|    time_elapsed    | 10408    |
|    total_timesteps | 426384   |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2226081  |
---------------------------------
Eval num_timesteps=430000, episode_reward=1373.68 +/- 0.00
Episode length: 1494.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.49e+03 |
|    mean_reward     | 1.37e+03 |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.99     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2229697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.02e+03 |
|    ep_rew_mean     | 916      |
| time/              |          |
|    episodes        | 500      |
|    fps             | 40       |
|    time_elapsed    | 10535    |
|    total_timesteps | 431072   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 5.49     |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2230769  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 915      |
| time/              |          |
|    episodes        | 504      |
|    fps             | 40       |
|    time_elapsed    | 10621    |
|    total_timesteps | 434940   |
| train/             |          |
|    actor_loss      | -64.5    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.894   |
|    learning_rate   | 9.57e-05 |
|    n_updates       | 2234637  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 910      |
| time/              |          |
|    episodes        | 508      |
|    fps             | 40       |
|    time_elapsed    | 10693    |
|    total_timesteps | 438173   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.19     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -5.06    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2237870  |
---------------------------------
Eval num_timesteps=440000, episode_reward=448.21 +/- 0.00
Episode length: 508.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 508      |
|    mean_reward     | 448      |
| time/              |          |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -64.6    |
|    critic_loss     | 2.09     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -3.29    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2239697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.01e+03 |
|    ep_rew_mean     | 907      |
| time/              |          |
|    episodes        | 512      |
|    fps             | 40       |
|    time_elapsed    | 10784    |
|    total_timesteps | 441332   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.62     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 2.68     |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2241029  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 990      |
|    ep_rew_mean     | 893      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 40       |
|    time_elapsed    | 10850    |
|    total_timesteps | 444201   |
| train/             |          |
|    actor_loss      | -65.6    |
|    critic_loss     | 2.88     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -3.02    |
|    learning_rate   | 9.56e-05 |
|    n_updates       | 2243898  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 972      |
|    ep_rew_mean     | 877      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 40       |
|    time_elapsed    | 10898    |
|    total_timesteps | 446125   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 3.76     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -4.48    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2245822  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 970      |
|    ep_rew_mean     | 875      |
| time/              |          |
|    episodes        | 524      |
|    fps             | 40       |
|    time_elapsed    | 10959    |
|    total_timesteps | 448773   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.49    |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2248470  |
---------------------------------
Eval num_timesteps=450000, episode_reward=677.12 +/- 0.00
Episode length: 753.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 753      |
|    mean_reward     | 677      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 4.37     |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2249697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 959      |
|    ep_rew_mean     | 865      |
| time/              |          |
|    episodes        | 528      |
|    fps             | 40       |
|    time_elapsed    | 11053    |
|    total_timesteps | 451959   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 3.18     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 2.36     |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2251656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 956      |
|    ep_rew_mean     | 862      |
| time/              |          |
|    episodes        | 532      |
|    fps             | 40       |
|    time_elapsed    | 11120    |
|    total_timesteps | 454853   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 3.35     |
|    learning_rate   | 9.55e-05 |
|    n_updates       | 2254550  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 940      |
|    ep_rew_mean     | 847      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 40       |
|    time_elapsed    | 11197    |
|    total_timesteps | 458297   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.25     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.595   |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2257994  |
---------------------------------
Eval num_timesteps=460000, episode_reward=933.51 +/- 0.00
Episode length: 1034.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.03e+03 |
|    mean_reward     | 934      |
| time/              |          |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 6.85     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 8.73     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2259697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 923      |
|    ep_rew_mean     | 831      |
| time/              |          |
|    episodes        | 540      |
|    fps             | 40       |
|    time_elapsed    | 11294    |
|    total_timesteps | 461526   |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 5.9      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -2.72    |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2261223  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 909      |
|    ep_rew_mean     | 818      |
| time/              |          |
|    episodes        | 544      |
|    fps             | 40       |
|    time_elapsed    | 11359    |
|    total_timesteps | 464361   |
| train/             |          |
|    actor_loss      | -63.1    |
|    critic_loss     | 2.8      |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -2.7     |
|    learning_rate   | 9.54e-05 |
|    n_updates       | 2264058  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 808      |
| time/              |          |
|    episodes        | 548      |
|    fps             | 40       |
|    time_elapsed    | 11446    |
|    total_timesteps | 468316   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 3        |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2268013  |
---------------------------------
Eval num_timesteps=470000, episode_reward=734.63 +/- 0.00
Episode length: 825.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 825      |
|    mean_reward     | 735      |
| time/              |          |
|    total_timesteps | 470000   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 0.923    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2269697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 802      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 40       |
|    time_elapsed    | 11542    |
|    total_timesteps | 471612   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 6.27     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 0.728    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2271309  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 882      |
|    ep_rew_mean     | 793      |
| time/              |          |
|    episodes        | 556      |
|    fps             | 40       |
|    time_elapsed    | 11612    |
|    total_timesteps | 474703   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.96     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 0.953    |
|    learning_rate   | 9.53e-05 |
|    n_updates       | 2274400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 877      |
|    ep_rew_mean     | 788      |
| time/              |          |
|    episodes        | 560      |
|    fps             | 40       |
|    time_elapsed    | 11685    |
|    total_timesteps | 477893   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -1.24    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2277590  |
---------------------------------
Eval num_timesteps=480000, episode_reward=964.50 +/- 0.00
Episode length: 1076.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.08e+03 |
|    mean_reward     | 965      |
| time/              |          |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2279697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 866      |
|    ep_rew_mean     | 778      |
| time/              |          |
|    episodes        | 564      |
|    fps             | 40       |
|    time_elapsed    | 11792    |
|    total_timesteps | 481701   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 3.03     |
|    learning_rate   | 9.52e-05 |
|    n_updates       | 2281398  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 767      |
| time/              |          |
|    episodes        | 568      |
|    fps             | 40       |
|    time_elapsed    | 11870    |
|    total_timesteps | 485184   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2284881  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 757      |
| time/              |          |
|    episodes        | 572      |
|    fps             | 40       |
|    time_elapsed    | 11941    |
|    total_timesteps | 488290   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 4.82     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2287987  |
---------------------------------
Eval num_timesteps=490000, episode_reward=646.27 +/- 0.00
Episode length: 722.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 722      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 490000   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.51     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -0.0931  |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2289697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 576      |
|    fps             | 40       |
|    time_elapsed    | 12036    |
|    total_timesteps | 491684   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.4      |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -0.0404  |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2291381  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 817      |
|    ep_rew_mean     | 732      |
| time/              |          |
|    episodes        | 580      |
|    fps             | 40       |
|    time_elapsed    | 12108    |
|    total_timesteps | 494827   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.4      |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 9.51e-05 |
|    n_updates       | 2294524  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 584      |
|    fps             | 40       |
|    time_elapsed    | 12171    |
|    total_timesteps | 497595   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 6.83     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2297292  |
---------------------------------
Eval num_timesteps=500000, episode_reward=663.62 +/- 0.00
Episode length: 735.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 735      |
|    mean_reward     | 664      |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 4.33     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2299697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 782      |
|    ep_rew_mean     | 699      |
| time/              |          |
|    episodes        | 588      |
|    fps             | 40       |
|    time_elapsed    | 12261    |
|    total_timesteps | 500580   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.97     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2300277  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 684      |
| time/              |          |
|    episodes        | 592      |
|    fps             | 40       |
|    time_elapsed    | 12327    |
|    total_timesteps | 503447   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.1      |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -4.81    |
|    learning_rate   | 9.5e-05  |
|    n_updates       | 2303144  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 760      |
|    ep_rew_mean     | 679      |
| time/              |          |
|    episodes        | 596      |
|    fps             | 40       |
|    time_elapsed    | 12390    |
|    total_timesteps | 506139   |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 5.55     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | 1.59     |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2305836  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 742      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 600      |
|    fps             | 40       |
|    time_elapsed    | 12442    |
|    total_timesteps | 508266   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -4.81    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2307963  |
---------------------------------
Eval num_timesteps=510000, episode_reward=669.46 +/- 0.00
Episode length: 737.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 737      |
|    mean_reward     | 669      |
| time/              |          |
|    total_timesteps | 510000   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2309697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 729      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 604      |
|    fps             | 40       |
|    time_elapsed    | 12525    |
|    total_timesteps | 510884   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 2.9      |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2310581  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 723      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 608      |
|    fps             | 40       |
|    time_elapsed    | 12586    |
|    total_timesteps | 513586   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.09     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -4.43    |
|    learning_rate   | 9.49e-05 |
|    n_updates       | 2313283  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 724      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 612      |
|    fps             | 40       |
|    time_elapsed    | 12653    |
|    total_timesteps | 516563   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 1.58     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2316260  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 616      |
|    fps             | 40       |
|    time_elapsed    | 12723    |
|    total_timesteps | 519656   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2319353  |
---------------------------------
Eval num_timesteps=520000, episode_reward=889.39 +/- 0.00
Episode length: 996.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 996      |
|    mean_reward     | 889      |
| time/              |          |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -2.09    |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2319697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 620      |
|    fps             | 40       |
|    time_elapsed    | 12829    |
|    total_timesteps | 523362   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 4.42     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 9.48e-05 |
|    n_updates       | 2323059  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 624      |
|    fps             | 40       |
|    time_elapsed    | 12905    |
|    total_timesteps | 526848   |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 3.44     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -0.617   |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2326545  |
---------------------------------
Eval num_timesteps=530000, episode_reward=857.11 +/- 0.00
Episode length: 945.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 945      |
|    mean_reward     | 857      |
| time/              |          |
|    total_timesteps | 530000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 2.38     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -4.97    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2329697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 628      |
|    fps             | 40       |
|    time_elapsed    | 13017    |
|    total_timesteps | 530945   |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 3.3      |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2330642  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 761      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 632      |
|    fps             | 40       |
|    time_elapsed    | 13088    |
|    total_timesteps | 534105   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -2.11    |
|    learning_rate   | 9.47e-05 |
|    n_updates       | 2333802  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 636      |
|    fps             | 40       |
|    time_elapsed    | 13148    |
|    total_timesteps | 536767   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -6.32    |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2336464  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 640      |
|    fps             | 40       |
|    time_elapsed    | 13209    |
|    total_timesteps | 539297   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 2.73     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -2.25    |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2338994  |
---------------------------------
Eval num_timesteps=540000, episode_reward=729.10 +/- 0.00
Episode length: 821.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 821      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 4.67     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -4.89    |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2339697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 746      |
|    ep_rew_mean     | 668      |
| time/              |          |
|    episodes        | 644      |
|    fps             | 40       |
|    time_elapsed    | 13289    |
|    total_timesteps | 541855   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 1.05     |
|    learning_rate   | 9.46e-05 |
|    n_updates       | 2341552  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 648      |
|    fps             | 40       |
|    time_elapsed    | 13363    |
|    total_timesteps | 545161   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 4.75     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 3.51     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2344858  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 652      |
|    fps             | 40       |
|    time_elapsed    | 13433    |
|    total_timesteps | 548287   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -1.4     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2347984  |
---------------------------------
Eval num_timesteps=550000, episode_reward=848.90 +/- 0.00
Episode length: 943.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 943      |
|    mean_reward     | 849      |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -4.48    |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2349697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 661      |
| time/              |          |
|    episodes        | 656      |
|    fps             | 40       |
|    time_elapsed    | 13526    |
|    total_timesteps | 551479   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 4.62     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 2.19     |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2351176  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 660      |
|    fps             | 40       |
|    time_elapsed    | 13603    |
|    total_timesteps | 554920   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 9.45e-05 |
|    n_updates       | 2354617  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 668      |
| time/              |          |
|    episodes        | 664      |
|    fps             | 40       |
|    time_elapsed    | 13683    |
|    total_timesteps | 558474   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -0.124   |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2358171  |
---------------------------------
Eval num_timesteps=560000, episode_reward=1055.93 +/- 0.00
Episode length: 1169.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.17e+03 |
|    mean_reward     | 1.06e+03 |
| time/              |          |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 3.52     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -2.07    |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2359697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 668      |
|    fps             | 40       |
|    time_elapsed    | 13795    |
|    total_timesteps | 562623   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -0.172   |
|    learning_rate   | 9.44e-05 |
|    n_updates       | 2362320  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 40       |
|    time_elapsed    | 13868    |
|    total_timesteps | 565751   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.79     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -2.95    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2365448  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 676      |
|    fps             | 40       |
|    time_elapsed    | 13940    |
|    total_timesteps | 568920   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.646   |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2368617  |
---------------------------------
Eval num_timesteps=570000, episode_reward=648.30 +/- 0.00
Episode length: 735.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 735      |
|    mean_reward     | 648      |
| time/              |          |
|    total_timesteps | 570000   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.39     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.65    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2369697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 672      |
| time/              |          |
|    episodes        | 680      |
|    fps             | 40       |
|    time_elapsed    | 14042    |
|    total_timesteps | 572590   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 5.31     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 0.596    |
|    learning_rate   | 9.43e-05 |
|    n_updates       | 2372287  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 684      |
|    fps             | 40       |
|    time_elapsed    | 14113    |
|    total_timesteps | 575746   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 0.889    |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2375443  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 685      |
| time/              |          |
|    episodes        | 688      |
|    fps             | 40       |
|    time_elapsed    | 14195    |
|    total_timesteps | 579413   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -4.65    |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2379110  |
---------------------------------
Eval num_timesteps=580000, episode_reward=836.24 +/- 0.00
Episode length: 923.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 923      |
|    mean_reward     | 836      |
| time/              |          |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 3.89     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2379697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 777      |
|    ep_rew_mean     | 698      |
| time/              |          |
|    episodes        | 692      |
|    fps             | 40       |
|    time_elapsed    | 14318    |
|    total_timesteps | 584177   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 5.34     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -2.48    |
|    learning_rate   | 9.42e-05 |
|    n_updates       | 2383874  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 709      |
| time/              |          |
|    episodes        | 696      |
|    fps             | 40       |
|    time_elapsed    | 14406    |
|    total_timesteps | 588112   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2387809  |
---------------------------------
Eval num_timesteps=590000, episode_reward=857.65 +/- 0.00
Episode length: 946.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 946      |
|    mean_reward     | 858      |
| time/              |          |
|    total_timesteps | 590000   |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 6.17     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 0.954    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2389697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 799      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 700      |
|    fps             | 40       |
|    time_elapsed    | 14512    |
|    total_timesteps | 591964   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.05     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 0.405    |
|    learning_rate   | 9.41e-05 |
|    n_updates       | 2391661  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 812      |
|    ep_rew_mean     | 730      |
| time/              |          |
|    episodes        | 704      |
|    fps             | 40       |
|    time_elapsed    | 14595    |
|    total_timesteps | 595841   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -0.3     |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2395538  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 736      |
| time/              |          |
|    episodes        | 708      |
|    fps             | 40       |
|    time_elapsed    | 14671    |
|    total_timesteps | 599179   |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -0.297   |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2398876  |
---------------------------------
Eval num_timesteps=600000, episode_reward=825.18 +/- 0.00
Episode length: 924.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 924      |
|    mean_reward     | 825      |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.63     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2399697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 826      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 712      |
|    fps             | 40       |
|    time_elapsed    | 14789    |
|    total_timesteps | 603672   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 2.93     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 0.946    |
|    learning_rate   | 9.4e-05  |
|    n_updates       | 2403369  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 748      |
| time/              |          |
|    episodes        | 716      |
|    fps             | 40       |
|    time_elapsed    | 14874    |
|    total_timesteps | 607550   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 6.01     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | 4.73     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2407247  |
---------------------------------
Eval num_timesteps=610000, episode_reward=1225.66 +/- 0.00
Episode length: 1387.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.39e+03 |
|    mean_reward     | 1.23e+03 |
| time/              |          |
|    total_timesteps | 610000   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 2.64     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2409697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 835      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 720      |
|    fps             | 40       |
|    time_elapsed    | 14992    |
|    total_timesteps | 611751   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.1     |
|    learning_rate   | 9.39e-05 |
|    n_updates       | 2411448  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 724      |
|    fps             | 40       |
|    time_elapsed    | 15075    |
|    total_timesteps | 615560   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.5      |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 3.33     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2415257  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 728      |
|    fps             | 40       |
|    time_elapsed    | 15152    |
|    total_timesteps | 619011   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | -7.32    |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2418708  |
---------------------------------
Eval num_timesteps=620000, episode_reward=911.33 +/- 0.00
Episode length: 1015.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 911      |
| time/              |          |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 1.35     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2419697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 732      |
|    fps             | 40       |
|    time_elapsed    | 15263    |
|    total_timesteps | 622961   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.1      |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 9.38e-05 |
|    n_updates       | 2422658  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 736      |
|    fps             | 40       |
|    time_elapsed    | 15336    |
|    total_timesteps | 626254   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 1.25     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2425951  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 740      |
|    fps             | 40       |
|    time_elapsed    | 15403    |
|    total_timesteps | 629245   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -2.45    |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2428942  |
---------------------------------
Eval num_timesteps=630000, episode_reward=1084.65 +/- 0.00
Episode length: 1185.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.18e+03 |
|    mean_reward     | 1.08e+03 |
| time/              |          |
|    total_timesteps | 630000   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 2.23     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2429697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 744      |
|    fps             | 40       |
|    time_elapsed    | 15491    |
|    total_timesteps | 631959   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 3.88     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2431656  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 748      |
|    fps             | 40       |
|    time_elapsed    | 15548    |
|    total_timesteps | 634417   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 0.69     |
|    learning_rate   | 9.37e-05 |
|    n_updates       | 2434114  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 752      |
|    fps             | 40       |
|    time_elapsed    | 15636    |
|    total_timesteps | 638409   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 0.915    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2438106  |
---------------------------------
Eval num_timesteps=640000, episode_reward=955.95 +/- 0.00
Episode length: 1061.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.06e+03 |
|    mean_reward     | 956      |
| time/              |          |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 0.71     |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2439697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 766      |
| time/              |          |
|    episodes        | 756      |
|    fps             | 40       |
|    time_elapsed    | 15755    |
|    total_timesteps | 642804   |
| train/             |          |
|    actor_loss      | -64      |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | -4.62    |
|    learning_rate   | 9.36e-05 |
|    n_updates       | 2442501  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 849      |
|    ep_rew_mean     | 763      |
| time/              |          |
|    episodes        | 760      |
|    fps             | 40       |
|    time_elapsed    | 15823    |
|    total_timesteps | 645842   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | 1.16     |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2445539  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 846      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 764      |
|    fps             | 40       |
|    time_elapsed    | 15897    |
|    total_timesteps | 649112   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 3.28     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -3.27    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2448809  |
---------------------------------
Eval num_timesteps=650000, episode_reward=662.50 +/- 0.00
Episode length: 734.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 734      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 4.84     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 0.671    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2449697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 768      |
|    fps             | 40       |
|    time_elapsed    | 15994    |
|    total_timesteps | 652389   |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 5.37     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 0.911    |
|    learning_rate   | 9.35e-05 |
|    n_updates       | 2452086  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 758      |
| time/              |          |
|    episodes        | 772      |
|    fps             | 40       |
|    time_elapsed    | 16060    |
|    total_timesteps | 655313   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | 1.34     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2455010  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 759      |
| time/              |          |
|    episodes        | 776      |
|    fps             | 40       |
|    time_elapsed    | 16133    |
|    total_timesteps | 658538   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2458235  |
---------------------------------
Eval num_timesteps=660000, episode_reward=743.91 +/- 0.00
Episode length: 843.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 843      |
|    mean_reward     | 744      |
| time/              |          |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2459697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 758      |
| time/              |          |
|    episodes        | 780      |
|    fps             | 40       |
|    time_elapsed    | 16241    |
|    total_timesteps | 662441   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 3.22     |
|    learning_rate   | 9.34e-05 |
|    n_updates       | 2462138  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 784      |
|    fps             | 40       |
|    time_elapsed    | 16303    |
|    total_timesteps | 665154   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 3.22     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2464851  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 788      |
|    fps             | 40       |
|    time_elapsed    | 16374    |
|    total_timesteps | 668330   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 0.377    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2468027  |
---------------------------------
Eval num_timesteps=670000, episode_reward=858.87 +/- 0.00
Episode length: 938.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 938      |
|    mean_reward     | 859      |
| time/              |          |
|    total_timesteps | 670000   |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -3.07    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2469697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 826      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 792      |
|    fps             | 40       |
|    time_elapsed    | 16475    |
|    total_timesteps | 671900   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.9      |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -3.97    |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2471597  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 733      |
| time/              |          |
|    episodes        | 796      |
|    fps             | 40       |
|    time_elapsed    | 16540    |
|    total_timesteps | 674709   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 3.45     |
|    learning_rate   | 9.33e-05 |
|    n_updates       | 2474406  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 728      |
| time/              |          |
|    episodes        | 800      |
|    fps             | 40       |
|    time_elapsed    | 16600    |
|    total_timesteps | 677352   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2477049  |
---------------------------------
Eval num_timesteps=680000, episode_reward=676.98 +/- 0.00
Episode length: 739.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 739      |
|    mean_reward     | 677      |
| time/              |          |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 3        |
|    ent_coef        | 0.0122   |
|    ent_coef_loss   | -1.59    |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2479697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 717      |
| time/              |          |
|    episodes        | 804      |
|    fps             | 40       |
|    time_elapsed    | 16695    |
|    total_timesteps | 680527   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2480224  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 710      |
| time/              |          |
|    episodes        | 808      |
|    fps             | 40       |
|    time_elapsed    | 16754    |
|    total_timesteps | 683056   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 0.609    |
|    learning_rate   | 9.32e-05 |
|    n_updates       | 2482753  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 701      |
| time/              |          |
|    episodes        | 812      |
|    fps             | 40       |
|    time_elapsed    | 16816    |
|    total_timesteps | 685693   |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | 0.835    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2485390  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 689      |
| time/              |          |
|    episodes        | 816      |
|    fps             | 40       |
|    time_elapsed    | 16873    |
|    total_timesteps | 688146   |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 8.41     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 6.46     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2487843  |
---------------------------------
Eval num_timesteps=690000, episode_reward=488.08 +/- 0.00
Episode length: 535.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 535      |
|    mean_reward     | 488      |
| time/              |          |
|    total_timesteps | 690000   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 4.11     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 1.91     |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2489697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 820      |
|    fps             | 40       |
|    time_elapsed    | 16968    |
|    total_timesteps | 691407   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 7.78     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 0.563    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2491104  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 824      |
|    fps             | 40       |
|    time_elapsed    | 17020    |
|    total_timesteps | 693588   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.51     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 9.31e-05 |
|    n_updates       | 2493285  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 659      |
| time/              |          |
|    episodes        | 828      |
|    fps             | 40       |
|    time_elapsed    | 17080    |
|    total_timesteps | 696197   |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 8.24     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | 3.37     |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2495894  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 832      |
|    fps             | 40       |
|    time_elapsed    | 17130    |
|    total_timesteps | 698259   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.73     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -6.47    |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2497956  |
---------------------------------
Eval num_timesteps=700000, episode_reward=613.82 +/- 0.00
Episode length: 671.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | 614      |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 2.89     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -0.601   |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2499697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 706      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 836      |
|    fps             | 40       |
|    time_elapsed    | 17209    |
|    total_timesteps | 700601   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.175    |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2500298  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 700      |
|    ep_rew_mean     | 632      |
| time/              |          |
|    episodes        | 840      |
|    fps             | 40       |
|    time_elapsed    | 17269    |
|    total_timesteps | 703058   |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 8.02     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 4.47     |
|    learning_rate   | 9.3e-05  |
|    n_updates       | 2502755  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 706      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 844      |
|    fps             | 40       |
|    time_elapsed    | 17326    |
|    total_timesteps | 705587   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -3.5     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2505284  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 848      |
|    fps             | 40       |
|    time_elapsed    | 17396    |
|    total_timesteps | 708659   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2508356  |
---------------------------------
Eval num_timesteps=710000, episode_reward=527.82 +/- 0.00
Episode length: 588.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 588      |
|    mean_reward     | 528      |
| time/              |          |
|    total_timesteps | 710000   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 3.46     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.986    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2509697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 703      |
|    ep_rew_mean     | 634      |
| time/              |          |
|    episodes        | 852      |
|    fps             | 40       |
|    time_elapsed    | 17495    |
|    total_timesteps | 712140   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.05     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2511837  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 692      |
|    ep_rew_mean     | 624      |
| time/              |          |
|    episodes        | 856      |
|    fps             | 40       |
|    time_elapsed    | 17552    |
|    total_timesteps | 714613   |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.4      |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 5.55     |
|    learning_rate   | 9.29e-05 |
|    n_updates       | 2514310  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 860      |
|    fps             | 40       |
|    time_elapsed    | 17614    |
|    total_timesteps | 717255   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2516952  |
---------------------------------
Eval num_timesteps=720000, episode_reward=865.57 +/- 0.00
Episode length: 954.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 954      |
|    mean_reward     | 866      |
| time/              |          |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 6.03     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -3.44    |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2519697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 687      |
|    ep_rew_mean     | 620      |
| time/              |          |
|    episodes        | 864      |
|    fps             | 40       |
|    time_elapsed    | 17717    |
|    total_timesteps | 720816   |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 5.59     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 6.12     |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2520513  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 685      |
|    ep_rew_mean     | 618      |
| time/              |          |
|    episodes        | 868      |
|    fps             | 40       |
|    time_elapsed    | 17787    |
|    total_timesteps | 723856   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.46     |
|    ent_coef        | 0.0124   |
|    ent_coef_loss   | -0.319   |
|    learning_rate   | 9.28e-05 |
|    n_updates       | 2523553  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 681      |
|    ep_rew_mean     | 614      |
| time/              |          |
|    episodes        | 872      |
|    fps             | 40       |
|    time_elapsed    | 17843    |
|    total_timesteps | 726381   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 5.36     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -4       |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2526078  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 678      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 876      |
|    fps             | 40       |
|    time_elapsed    | 17911    |
|    total_timesteps | 729297   |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 0.176    |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2528994  |
---------------------------------
Eval num_timesteps=730000, episode_reward=856.73 +/- 0.00
Episode length: 956.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 956      |
|    mean_reward     | 857      |
| time/              |          |
|    total_timesteps | 730000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 4.38     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2529697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 671      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 880      |
|    fps             | 40       |
|    time_elapsed    | 18007    |
|    total_timesteps | 732570   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 3.01     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.07     |
|    learning_rate   | 9.27e-05 |
|    n_updates       | 2532267  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 670      |
|    ep_rew_mean     | 604      |
| time/              |          |
|    episodes        | 884      |
|    fps             | 40       |
|    time_elapsed    | 18067    |
|    total_timesteps | 735113   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 3.71     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -0.287   |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2534810  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 670      |
|    ep_rew_mean     | 605      |
| time/              |          |
|    episodes        | 888      |
|    fps             | 40       |
|    time_elapsed    | 18138    |
|    total_timesteps | 738363   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 4.4      |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 2.84     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2538060  |
---------------------------------
Eval num_timesteps=740000, episode_reward=1095.47 +/- 0.00
Episode length: 1203.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.2e+03  |
|    mean_reward     | 1.1e+03  |
| time/              |          |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 0.865    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2539697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 662      |
|    ep_rew_mean     | 596      |
| time/              |          |
|    episodes        | 892      |
|    fps             | 40       |
|    time_elapsed    | 18232    |
|    total_timesteps | 741380   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | -3.27    |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2541077  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 666      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 896      |
|    fps             | 40       |
|    time_elapsed    | 18306    |
|    total_timesteps | 744614   |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 8.66     |
|    ent_coef        | 0.0117   |
|    ent_coef_loss   | 2.59     |
|    learning_rate   | 9.26e-05 |
|    n_updates       | 2544311  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | 601      |
| time/              |          |
|    episodes        | 900      |
|    fps             | 40       |
|    time_elapsed    | 18370    |
|    total_timesteps | 747369   |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 3.59     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2547066  |
---------------------------------
Eval num_timesteps=750000, episode_reward=879.95 +/- 0.00
Episode length: 985.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 985      |
|    mean_reward     | 880      |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0118   |
|    ent_coef_loss   | -0.674   |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2549697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 603      |
| time/              |          |
|    episodes        | 904      |
|    fps             | 40       |
|    time_elapsed    | 18478    |
|    total_timesteps | 751172   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -3.55    |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2550869  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 680      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 908      |
|    fps             | 40       |
|    time_elapsed    | 18560    |
|    total_timesteps | 754863   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 3.56     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 9.25e-05 |
|    n_updates       | 2554560  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 681      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 912      |
|    fps             | 40       |
|    time_elapsed    | 18623    |
|    total_timesteps | 757573   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -1.26    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2557270  |
---------------------------------
Eval num_timesteps=760000, episode_reward=760.98 +/- 0.00
Episode length: 827.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 827      |
|    mean_reward     | 761      |
| time/              |          |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.53     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2559697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 683      |
|    ep_rew_mean     | 615      |
| time/              |          |
|    episodes        | 916      |
|    fps             | 40       |
|    time_elapsed    | 18720    |
|    total_timesteps | 760903   |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 3.47     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 0.298    |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2560600  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 690      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 920      |
|    fps             | 40       |
|    time_elapsed    | 18796    |
|    total_timesteps | 764298   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.8      |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 6.59     |
|    learning_rate   | 9.24e-05 |
|    n_updates       | 2563995  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 707      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 924      |
|    fps             | 40       |
|    time_elapsed    | 18881    |
|    total_timesteps | 768232   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 1.46     |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2567929  |
---------------------------------
Eval num_timesteps=770000, episode_reward=938.84 +/- 0.00
Episode length: 1037.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.04e+03 |
|    mean_reward     | 939      |
| time/              |          |
|    total_timesteps | 770000   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -0.607   |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2569697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 716      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 928      |
|    fps             | 40       |
|    time_elapsed    | 18982    |
|    total_timesteps | 771764   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 2.36     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 9.23e-05 |
|    n_updates       | 2571461  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 932      |
|    fps             | 40       |
|    time_elapsed    | 19064    |
|    total_timesteps | 775495   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 7.84     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | 0.693    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2575192  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 936      |
|    fps             | 40       |
|    time_elapsed    | 19149    |
|    total_timesteps | 779355   |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.22     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | -2.85    |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2579052  |
---------------------------------
Eval num_timesteps=780000, episode_reward=929.67 +/- 0.00
Episode length: 1024.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.02e+03 |
|    mean_reward     | 930      |
| time/              |          |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 3.98     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 1.75     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2579697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 689      |
| time/              |          |
|    episodes        | 940      |
|    fps             | 40       |
|    time_elapsed    | 19274    |
|    total_timesteps | 784034   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 9.22e-05 |
|    n_updates       | 2583731  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 776      |
|    ep_rew_mean     | 699      |
| time/              |          |
|    episodes        | 944      |
|    fps             | 40       |
|    time_elapsed    | 19352    |
|    total_timesteps | 787579   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 4.75     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2587276  |
---------------------------------
Eval num_timesteps=790000, episode_reward=855.98 +/- 0.00
Episode length: 949.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 949      |
|    mean_reward     | 856      |
| time/              |          |
|    total_timesteps | 790000   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 5.43     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.35     |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2589697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | 706      |
| time/              |          |
|    episodes        | 948      |
|    fps             | 40       |
|    time_elapsed    | 19467    |
|    total_timesteps | 791701   |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 2.74     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.962    |
|    learning_rate   | 9.21e-05 |
|    n_updates       | 2591398  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 714      |
| time/              |          |
|    episodes        | 952      |
|    fps             | 40       |
|    time_elapsed    | 19552    |
|    total_timesteps | 795596   |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 4.92     |
|    ent_coef        | 0.00952  |
|    ent_coef_loss   | -2.05    |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2595293  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 810      |
|    ep_rew_mean     | 730      |
| time/              |          |
|    episodes        | 956      |
|    fps             | 40       |
|    time_elapsed    | 19643    |
|    total_timesteps | 799859   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 5.14     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -0.742   |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2599556  |
---------------------------------
Eval num_timesteps=800000, episode_reward=801.86 +/- 0.00
Episode length: 895.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 895      |
|    mean_reward     | 802      |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.26     |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2599697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 960      |
|    fps             | 40       |
|    time_elapsed    | 19758    |
|    total_timesteps | 804032   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -4.31    |
|    learning_rate   | 9.2e-05  |
|    n_updates       | 2603729  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 964      |
|    fps             | 40       |
|    time_elapsed    | 19842    |
|    total_timesteps | 807954   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.58     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | 0.214    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2607651  |
---------------------------------
Eval num_timesteps=810000, episode_reward=724.40 +/- 0.00
Episode length: 801.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 801      |
|    mean_reward     | 724      |
| time/              |          |
|    total_timesteps | 810000   |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.00992  |
|    ent_coef_loss   | -4.93    |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2609697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 968      |
|    fps             | 40       |
|    time_elapsed    | 19947    |
|    total_timesteps | 811725   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 4.12     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 6.35     |
|    learning_rate   | 9.19e-05 |
|    n_updates       | 2611422  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 853      |
|    ep_rew_mean     | 768      |
| time/              |          |
|    episodes        | 972      |
|    fps             | 40       |
|    time_elapsed    | 20034    |
|    total_timesteps | 815699   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 3.85     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | 0.898    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2615396  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 859      |
|    ep_rew_mean     | 773      |
| time/              |          |
|    episodes        | 976      |
|    fps             | 40       |
|    time_elapsed    | 20110    |
|    total_timesteps | 819235   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 7.25     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 3.25     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2618932  |
---------------------------------
Eval num_timesteps=820000, episode_reward=844.35 +/- 0.00
Episode length: 937.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 937      |
|    mean_reward     | 844      |
| time/              |          |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 5.79     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -3.85    |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2619697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 874      |
|    ep_rew_mean     | 786      |
| time/              |          |
|    episodes        | 980      |
|    fps             | 40       |
|    time_elapsed    | 20237    |
|    total_timesteps | 824083   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 2.16     |
|    learning_rate   | 9.18e-05 |
|    n_updates       | 2623780  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 886      |
|    ep_rew_mean     | 798      |
| time/              |          |
|    episodes        | 984      |
|    fps             | 40       |
|    time_elapsed    | 20322    |
|    total_timesteps | 827884   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.61     |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2627581  |
---------------------------------
Eval num_timesteps=830000, episode_reward=971.30 +/- 0.00
Episode length: 1123.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.12e+03 |
|    mean_reward     | 971      |
| time/              |          |
|    total_timesteps | 830000   |
| train/             |          |
|    actor_loss      | -63.4    |
|    critic_loss     | 3.34     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -1.44    |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2629697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 892      |
|    ep_rew_mean     | 802      |
| time/              |          |
|    episodes        | 988      |
|    fps             | 40       |
|    time_elapsed    | 20432    |
|    total_timesteps | 831939   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -0.998   |
|    learning_rate   | 9.17e-05 |
|    n_updates       | 2631636  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 904      |
|    ep_rew_mean     | 813      |
| time/              |          |
|    episodes        | 992      |
|    fps             | 40       |
|    time_elapsed    | 20515    |
|    total_timesteps | 835681   |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.4      |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2635378  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 820      |
| time/              |          |
|    episodes        | 996      |
|    fps             | 40       |
|    time_elapsed    | 20601    |
|    total_timesteps | 839655   |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.24     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 3.3      |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2639352  |
---------------------------------
Eval num_timesteps=840000, episode_reward=899.15 +/- 0.00
Episode length: 1005.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 899      |
| time/              |          |
|    total_timesteps | 840000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 3.86     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -0.822   |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2639697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 926      |
|    ep_rew_mean     | 832      |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 40       |
|    time_elapsed    | 20722    |
|    total_timesteps | 844174   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 3.31     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 0.739    |
|    learning_rate   | 9.16e-05 |
|    n_updates       | 2643871  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 941      |
|    ep_rew_mean     | 845      |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 40       |
|    time_elapsed    | 20814    |
|    total_timesteps | 848427   |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -0.199   |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2648124  |
---------------------------------
Eval num_timesteps=850000, episode_reward=739.06 +/- 0.00
Episode length: 814.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 814      |
|    mean_reward     | 739      |
| time/              |          |
|    total_timesteps | 850000   |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -0.0751  |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2649697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 942      |
|    ep_rew_mean     | 847      |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 40       |
|    time_elapsed    | 20928    |
|    total_timesteps | 852758   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.38     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -1.17    |
|    learning_rate   | 9.15e-05 |
|    n_updates       | 2652455  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 948      |
|    ep_rew_mean     | 851      |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 40       |
|    time_elapsed    | 21001    |
|    total_timesteps | 855975   |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 5.77     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2655672  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 950      |
|    ep_rew_mean     | 854      |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 40       |
|    time_elapsed    | 21069    |
|    total_timesteps | 858901   |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.8      |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -0.831   |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2658598  |
---------------------------------
Eval num_timesteps=860000, episode_reward=793.54 +/- 0.00
Episode length: 890.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 890      |
|    mean_reward     | 794      |
| time/              |          |
|    total_timesteps | 860000   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 4.43     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | 0.328    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2659697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 951      |
|    ep_rew_mean     | 854      |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 40       |
|    time_elapsed    | 21171    |
|    total_timesteps | 862490   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 4.46     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 0.812    |
|    learning_rate   | 9.14e-05 |
|    n_updates       | 2662187  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 947      |
|    ep_rew_mean     | 850      |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 40       |
|    time_elapsed    | 21249    |
|    total_timesteps | 866051   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.34     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -0.174   |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2665748  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 949      |
|    ep_rew_mean     | 852      |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 40       |
|    time_elapsed    | 21330    |
|    total_timesteps | 869683   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 4.55     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | 3.5      |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2669380  |
---------------------------------
Eval num_timesteps=870000, episode_reward=781.52 +/- 0.00
Episode length: 874.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 874      |
|    mean_reward     | 782      |
| time/              |          |
|    total_timesteps | 870000   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 2.98     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 2.21     |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2669697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 944      |
|    ep_rew_mean     | 847      |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 40       |
|    time_elapsed    | 21431    |
|    total_timesteps | 873237   |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.07     |
|    ent_coef        | 0.00922  |
|    ent_coef_loss   | -5.36    |
|    learning_rate   | 9.13e-05 |
|    n_updates       | 2672934  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 943      |
|    ep_rew_mean     | 846      |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 40       |
|    time_elapsed    | 21514    |
|    total_timesteps | 877054   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 9.35     |
|    ent_coef        | 0.00948  |
|    ent_coef_loss   | 1.62     |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2676751  |
---------------------------------
Eval num_timesteps=880000, episode_reward=814.93 +/- 0.00
Episode length: 917.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 917      |
|    mean_reward     | 815      |
| time/              |          |
|    total_timesteps | 880000   |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 6.02     |
|    ent_coef        | 0.00998  |
|    ent_coef_loss   | -0.285   |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2679697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 934      |
|    ep_rew_mean     | 838      |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 40       |
|    time_elapsed    | 21621    |
|    total_timesteps | 880864   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2680561  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 930      |
|    ep_rew_mean     | 834      |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 40       |
|    time_elapsed    | 21691    |
|    total_timesteps | 883993   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 3.36     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -4.27    |
|    learning_rate   | 9.12e-05 |
|    n_updates       | 2683690  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 924      |
|    ep_rew_mean     | 828      |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 40       |
|    time_elapsed    | 21765    |
|    total_timesteps | 887296   |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.00983  |
|    ent_coef_loss   | 0.884    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2686993  |
---------------------------------
Eval num_timesteps=890000, episode_reward=761.00 +/- 0.00
Episode length: 857.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 857      |
|    mean_reward     | 761      |
| time/              |          |
|    total_timesteps | 890000   |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -1.77    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2689697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 912      |
|    ep_rew_mean     | 817      |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 40       |
|    time_elapsed    | 21862    |
|    total_timesteps | 890620   |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 7.51     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2690317  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 899      |
|    ep_rew_mean     | 805      |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 40       |
|    time_elapsed    | 21929    |
|    total_timesteps | 893532   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.00968  |
|    ent_coef_loss   | -0.0711  |
|    learning_rate   | 9.11e-05 |
|    n_updates       | 2693229  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 890      |
|    ep_rew_mean     | 796      |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 40       |
|    time_elapsed    | 22001    |
|    total_timesteps | 896665   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 5.21     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -3.84    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2696362  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 876      |
|    ep_rew_mean     | 783      |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 40       |
|    time_elapsed    | 22059    |
|    total_timesteps | 899148   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 3.43     |
|    ent_coef        | 0.0102   |
|    ent_coef_loss   | -6.2     |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2698845  |
---------------------------------
Eval num_timesteps=900000, episode_reward=692.64 +/- 0.00
Episode length: 791.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 791      |
|    mean_reward     | 693      |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -64.3    |
|    critic_loss     | 4.68     |
|    ent_coef        | 0.00991  |
|    ent_coef_loss   | -5.68    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2699697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 864      |
|    ep_rew_mean     | 772      |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 40       |
|    time_elapsed    | 22157    |
|    total_timesteps | 902569   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 9.1e-05  |
|    n_updates       | 2702266  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 40       |
|    time_elapsed    | 22222    |
|    total_timesteps | 905368   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 2.87     |
|    ent_coef        | 0.01     |
|    ent_coef_loss   | -0.13    |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2705065  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 848      |
|    ep_rew_mean     | 757      |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 40       |
|    time_elapsed    | 22291    |
|    total_timesteps | 908422   |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 4.19     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 3.23     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2708119  |
---------------------------------
Eval num_timesteps=910000, episode_reward=723.05 +/- 0.00
Episode length: 803.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 803      |
|    mean_reward     | 723      |
| time/              |          |
|    total_timesteps | 910000   |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | -0.45    |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2709697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 747      |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 40       |
|    time_elapsed    | 22380    |
|    total_timesteps | 911450   |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 2.91     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -3.88    |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2711147  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 40       |
|    time_elapsed    | 22455    |
|    total_timesteps | 914873   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.84     |
|    learning_rate   | 9.09e-05 |
|    n_updates       | 2714570  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 731      |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 40       |
|    time_elapsed    | 22512    |
|    total_timesteps | 917325   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2717022  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 40       |
|    time_elapsed    | 22568    |
|    total_timesteps | 919611   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.06     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2719308  |
---------------------------------
Eval num_timesteps=920000, episode_reward=743.41 +/- 0.00
Episode length: 831.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 831      |
|    mean_reward     | 743      |
| time/              |          |
|    total_timesteps | 920000   |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 2.77     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -3.48    |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2719697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 794      |
|    ep_rew_mean     | 708      |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 40       |
|    time_elapsed    | 22662    |
|    total_timesteps | 922868   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.00987  |
|    ent_coef_loss   | 1.47     |
|    learning_rate   | 9.08e-05 |
|    n_updates       | 2722565  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 780      |
|    ep_rew_mean     | 695      |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 40       |
|    time_elapsed    | 22725    |
|    total_timesteps | 925629   |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 5.05     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -1.71    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2725326  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 767      |
|    ep_rew_mean     | 684      |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 40       |
|    time_elapsed    | 22793    |
|    total_timesteps | 928610   |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 4.09     |
|    ent_coef        | 0.00983  |
|    ent_coef_loss   | 1.09     |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2728307  |
---------------------------------
Eval num_timesteps=930000, episode_reward=631.20 +/- 0.00
Episode length: 702.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | 631      |
| time/              |          |
|    total_timesteps | 930000   |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.00999  |
|    ent_coef_loss   | 0.264    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2729697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 760      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 40       |
|    time_elapsed    | 22895    |
|    total_timesteps | 932372   |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 3.75     |
|    ent_coef        | 0.00986  |
|    ent_coef_loss   | 0.482    |
|    learning_rate   | 9.07e-05 |
|    n_updates       | 2732069  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 675      |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 40       |
|    time_elapsed    | 22964    |
|    total_timesteps | 935363   |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 3.77     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -1.02    |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2735060  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 761      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 40       |
|    time_elapsed    | 23037    |
|    total_timesteps | 938569   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2738266  |
---------------------------------
Eval num_timesteps=940000, episode_reward=741.87 +/- 0.00
Episode length: 823.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 823      |
|    mean_reward     | 742      |
| time/              |          |
|    total_timesteps | 940000   |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 3.54     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 4.02     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2739697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 40       |
|    time_elapsed    | 23141    |
|    total_timesteps | 942288   |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 7.77     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | 2.65     |
|    learning_rate   | 9.06e-05 |
|    n_updates       | 2741985  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 753      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 40       |
|    time_elapsed    | 23211    |
|    total_timesteps | 945423   |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -1.11    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2745120  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 40       |
|    time_elapsed    | 23275    |
|    total_timesteps | 948119   |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 3.97     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -1.1     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2747816  |
---------------------------------
Eval num_timesteps=950000, episode_reward=723.08 +/- 0.00
Episode length: 803.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 803      |
|    mean_reward     | 723      |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -4.63    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2749697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 40       |
|    time_elapsed    | 23371    |
|    total_timesteps | 951435   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.78     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 0.842    |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2751132  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 729      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 40       |
|    time_elapsed    | 23434    |
|    total_timesteps | 954258   |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 6.41     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 9.05e-05 |
|    n_updates       | 2753955  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 726      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 40       |
|    time_elapsed    | 23501    |
|    total_timesteps | 957133   |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 3.49     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -3.93    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2756830  |
---------------------------------
Eval num_timesteps=960000, episode_reward=677.22 +/- 0.00
Episode length: 762.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 762      |
|    mean_reward     | 677      |
| time/              |          |
|    total_timesteps | 960000   |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 7.86     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -1.62    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2759697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 40       |
|    time_elapsed    | 23605    |
|    total_timesteps | 960924   |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2760621  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 724      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 40       |
|    time_elapsed    | 23670    |
|    total_timesteps | 963847   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.85     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | 0.842    |
|    learning_rate   | 9.04e-05 |
|    n_updates       | 2763544  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 40       |
|    time_elapsed    | 23738    |
|    total_timesteps | 966924   |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 3.88     |
|    ent_coef        | 0.0101   |
|    ent_coef_loss   | -4.93    |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2766621  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 40       |
|    time_elapsed    | 23803    |
|    total_timesteps | 969732   |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 4.23     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2769429  |
---------------------------------
Eval num_timesteps=970000, episode_reward=769.90 +/- 0.00
Episode length: 863.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 863      |
|    mean_reward     | 770      |
| time/              |          |
|    total_timesteps | 970000   |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 4.31     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -2.61    |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2769697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 730      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 40       |
|    time_elapsed    | 23907    |
|    total_timesteps | 973388   |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 4.58     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.607   |
|    learning_rate   | 9.03e-05 |
|    n_updates       | 2773085  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 659      |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 40       |
|    time_elapsed    | 23982    |
|    total_timesteps | 976878   |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 4.2      |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 3        |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2776575  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 40       |
|    time_elapsed    | 24052    |
|    total_timesteps | 979952   |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 2.04     |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2779649  |
---------------------------------
Eval num_timesteps=980000, episode_reward=678.91 +/- 0.00
Episode length: 753.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 753      |
|    mean_reward     | 679      |
| time/              |          |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | -0.923   |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2779697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 751      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 40       |
|    time_elapsed    | 24152    |
|    total_timesteps | 983445   |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.93     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | -0.986   |
|    learning_rate   | 9.02e-05 |
|    n_updates       | 2783142  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 40       |
|    time_elapsed    | 24234    |
|    total_timesteps | 987074   |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.0107   |
|    ent_coef_loss   | -3.65    |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2786771  |
---------------------------------
Eval num_timesteps=990000, episode_reward=785.34 +/- 0.00
Episode length: 866.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 866      |
|    mean_reward     | 785      |
| time/              |          |
|    total_timesteps | 990000   |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0104   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2789697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 759      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 40       |
|    time_elapsed    | 24340    |
|    total_timesteps | 990635   |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 5.35     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 8.04     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2790332  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 756      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 40       |
|    time_elapsed    | 24423    |
|    total_timesteps | 993790   |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 3.42     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | 0.13     |
|    learning_rate   | 9.01e-05 |
|    n_updates       | 2793487  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 765      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 40       |
|    time_elapsed    | 24499    |
|    total_timesteps | 997113   |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0105   |
|    ent_coef_loss   | -5.86    |
|    learning_rate   | 9e-05    |
|    n_updates       | 2796810  |
---------------------------------
Eval num_timesteps=1000000, episode_reward=723.85 +/- 0.00
Episode length: 809.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 809      |
|    mean_reward     | 724      |
| time/              |          |
|    total_timesteps | 1000000  |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 6.94     |
|    ent_coef        | 0.0106   |
|    ent_coef_loss   | 2.13     |
|    learning_rate   | 9e-05    |
|    n_updates       | 2799697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 695      |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 40       |
|    time_elapsed    | 24603    |
|    total_timesteps | 1000916  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 0.697    |
|    learning_rate   | 9e-05    |
|    n_updates       | 2800613  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 785      |
|    ep_rew_mean     | 701      |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 40       |
|    time_elapsed    | 24682    |
|    total_timesteps | 1004434  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.68     |
|    ent_coef        | 0.0108   |
|    ent_coef_loss   | 0.601    |
|    learning_rate   | 9e-05    |
|    n_updates       | 2804131  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 789      |
|    ep_rew_mean     | 704      |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 40       |
|    time_elapsed    | 24752    |
|    total_timesteps | 1007602  |
| train/             |          |
|    actor_loss      | -58.7    |
|    critic_loss     | 3.84     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -0.897   |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2807299  |
---------------------------------
Eval num_timesteps=1010000, episode_reward=820.50 +/- 0.00
Episode length: 917.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 917      |
|    mean_reward     | 821      |
| time/              |          |
|    total_timesteps | 1010000  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 3.95     |
|    ent_coef        | 0.0109   |
|    ent_coef_loss   | 1.15     |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2809697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 791      |
|    ep_rew_mean     | 706      |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 40       |
|    time_elapsed    | 24856    |
|    total_timesteps | 1011422  |
| train/             |          |
|    actor_loss      | -62.5    |
|    critic_loss     | 4.63     |
|    ent_coef        | 0.011    |
|    ent_coef_loss   | -4.64    |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2811119  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 793      |
|    ep_rew_mean     | 708      |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 40       |
|    time_elapsed    | 24933    |
|    total_timesteps | 1014856  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 4.14     |
|    ent_coef        | 0.0103   |
|    ent_coef_loss   | -2.47    |
|    learning_rate   | 8.99e-05 |
|    n_updates       | 2814553  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 804      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 40       |
|    time_elapsed    | 25021    |
|    total_timesteps | 1018936  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 8.07     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 5.57     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2818633  |
---------------------------------
Eval num_timesteps=1020000, episode_reward=757.21 +/- 0.00
Episode length: 843.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 843      |
|    mean_reward     | 757      |
| time/              |          |
|    total_timesteps | 1020000  |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 3.81     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | 2.49     |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2819697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 40       |
|    time_elapsed    | 25118    |
|    total_timesteps | 1022414  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 4.86     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | 0.141    |
|    learning_rate   | 8.98e-05 |
|    n_updates       | 2822111  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 802      |
|    ep_rew_mean     | 716      |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 40       |
|    time_elapsed    | 25180    |
|    total_timesteps | 1025108  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 2.85     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | -1.84    |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2824805  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 714      |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 40       |
|    time_elapsed    | 25249    |
|    total_timesteps | 1028079  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0112   |
|    ent_coef_loss   | 3.37     |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2827776  |
---------------------------------
Eval num_timesteps=1030000, episode_reward=811.49 +/- 0.00
Episode length: 913.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 913      |
|    mean_reward     | 811      |
| time/              |          |
|    total_timesteps | 1030000  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -2.6     |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2829697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 806      |
|    ep_rew_mean     | 719      |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 40       |
|    time_elapsed    | 25350    |
|    total_timesteps | 1031657  |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 5.44     |
|    ent_coef        | 0.0116   |
|    ent_coef_loss   | -2.29    |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2831354  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 40       |
|    time_elapsed    | 25417    |
|    total_timesteps | 1034705  |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 3.72     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 8.97e-05 |
|    n_updates       | 2834402  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 812      |
|    ep_rew_mean     | 725      |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 40       |
|    time_elapsed    | 25488    |
|    total_timesteps | 1037864  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 2.98     |
|    ent_coef        | 0.0111   |
|    ent_coef_loss   | -2.36    |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2837561  |
---------------------------------
Eval num_timesteps=1040000, episode_reward=915.87 +/- 0.00
Episode length: 1014.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 916      |
| time/              |          |
|    total_timesteps | 1040000  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 4.48     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2839697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 815      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 40       |
|    time_elapsed    | 25594    |
|    total_timesteps | 1041617  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 4.03     |
|    ent_coef        | 0.0115   |
|    ent_coef_loss   | -4.1     |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2841314  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 727      |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 40       |
|    time_elapsed    | 25666    |
|    total_timesteps | 1044883  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 5.42     |
|    ent_coef        | 0.0113   |
|    ent_coef_loss   | 0.893    |
|    learning_rate   | 8.96e-05 |
|    n_updates       | 2844580  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 816      |
|    ep_rew_mean     | 728      |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 40       |
|    time_elapsed    | 25740    |
|    total_timesteps | 1048017  |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.87     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 0.529    |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2847714  |
---------------------------------
Eval num_timesteps=1050000, episode_reward=861.74 +/- 0.00
Episode length: 963.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 963      |
|    mean_reward     | 862      |
| time/              |          |
|    total_timesteps | 1050000  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 19.6     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | 2.09     |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2849697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 730      |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 40       |
|    time_elapsed    | 25843    |
|    total_timesteps | 1051677  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 3.64     |
|    ent_coef        | 0.0126   |
|    ent_coef_loss   | 1.4      |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2851374  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 820      |
|    ep_rew_mean     | 731      |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 40       |
|    time_elapsed    | 25910    |
|    total_timesteps | 1054614  |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 4.04     |
|    ent_coef        | 0.012    |
|    ent_coef_loss   | -5.65    |
|    learning_rate   | 8.95e-05 |
|    n_updates       | 2854311  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 819      |
|    ep_rew_mean     | 731      |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 40       |
|    time_elapsed    | 25984    |
|    total_timesteps | 1057970  |
| train/             |          |
|    actor_loss      | -59.8    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0114   |
|    ent_coef_loss   | -2.08    |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2857667  |
---------------------------------
Eval num_timesteps=1060000, episode_reward=708.08 +/- 0.00
Episode length: 799.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 799      |
|    mean_reward     | 708      |
| time/              |          |
|    total_timesteps | 1060000  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 5.49     |
|    ent_coef        | 0.0121   |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2859697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 726      |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 40       |
|    time_elapsed    | 26084    |
|    total_timesteps | 1061509  |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 7.29     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | 7.37     |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2861206  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 814      |
|    ep_rew_mean     | 726      |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 40       |
|    time_elapsed    | 26153    |
|    total_timesteps | 1064527  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 3.94     |
|    ent_coef        | 0.0123   |
|    ent_coef_loss   | 0.0102   |
|    learning_rate   | 8.94e-05 |
|    n_updates       | 2864224  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 724      |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 40       |
|    time_elapsed    | 26225    |
|    total_timesteps | 1067731  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0119   |
|    ent_coef_loss   | 2.79     |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2867428  |
---------------------------------
Eval num_timesteps=1070000, episode_reward=623.02 +/- 0.00
Episode length: 691.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 691      |
|    mean_reward     | 623      |
| time/              |          |
|    total_timesteps | 1070000  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 6.31     |
|    ent_coef        | 0.0125   |
|    ent_coef_loss   | -5.07    |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2869697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 40       |
|    time_elapsed    | 26316    |
|    total_timesteps | 1070792  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 5.06     |
|    ent_coef        | 0.0127   |
|    ent_coef_loss   | 0.128    |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2870489  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 713      |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 40       |
|    time_elapsed    | 26379    |
|    total_timesteps | 1073530  |
| train/             |          |
|    actor_loss      | -61.8    |
|    critic_loss     | 5.3      |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 8.93e-05 |
|    n_updates       | 2873227  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 797      |
|    ep_rew_mean     | 709      |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 40       |
|    time_elapsed    | 26443    |
|    total_timesteps | 1076336  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 4.35     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2876033  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 792      |
|    ep_rew_mean     | 705      |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 40       |
|    time_elapsed    | 26507    |
|    total_timesteps | 1079136  |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0132   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2878833  |
---------------------------------
Eval num_timesteps=1080000, episode_reward=751.78 +/- 0.00
Episode length: 826.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 826      |
|    mean_reward     | 752      |
| time/              |          |
|    total_timesteps | 1080000  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 8.73     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | 1.23     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2879697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 785      |
|    ep_rew_mean     | 698      |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 40       |
|    time_elapsed    | 26602    |
|    total_timesteps | 1082250  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.45     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 8.92e-05 |
|    n_updates       | 2881947  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 779      |
|    ep_rew_mean     | 692      |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 40       |
|    time_elapsed    | 26668    |
|    total_timesteps | 1085130  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 5.27     |
|    ent_coef        | 0.0129   |
|    ent_coef_loss   | -1.08    |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2884827  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 775      |
|    ep_rew_mean     | 688      |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 40       |
|    time_elapsed    | 26732    |
|    total_timesteps | 1087911  |
| train/             |          |
|    actor_loss      | -62.7    |
|    critic_loss     | 5.61     |
|    ent_coef        | 0.0128   |
|    ent_coef_loss   | -4.47    |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2887608  |
---------------------------------
Eval num_timesteps=1090000, episode_reward=600.56 +/- 0.00
Episode length: 688.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 688      |
|    mean_reward     | 601      |
| time/              |          |
|    total_timesteps | 1090000  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.013    |
|    ent_coef_loss   | -2.66    |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2889697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 771      |
|    ep_rew_mean     | 684      |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 40       |
|    time_elapsed    | 26817    |
|    total_timesteps | 1090679  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 5.1      |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | -5.56    |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2890376  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 766      |
|    ep_rew_mean     | 680      |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 40       |
|    time_elapsed    | 26885    |
|    total_timesteps | 1093666  |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 5.67     |
|    ent_coef        | 0.0131   |
|    ent_coef_loss   | 0.152    |
|    learning_rate   | 8.91e-05 |
|    n_updates       | 2893363  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 751      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 40       |
|    time_elapsed    | 26945    |
|    total_timesteps | 1096241  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.39     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2895938  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 40       |
|    time_elapsed    | 27008    |
|    total_timesteps | 1098979  |
| train/             |          |
|    actor_loss      | -63.3    |
|    critic_loss     | 5.25     |
|    ent_coef        | 0.0133   |
|    ent_coef_loss   | -0.0188  |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2898676  |
---------------------------------
Eval num_timesteps=1100000, episode_reward=607.33 +/- 0.00
Episode length: 695.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 695      |
|    mean_reward     | 607      |
| time/              |          |
|    total_timesteps | 1100000  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0134   |
|    ent_coef_loss   | -0.854   |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2899697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 40       |
|    time_elapsed    | 27103    |
|    total_timesteps | 1102277  |
| train/             |          |
|    actor_loss      | -61.1    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 8.9e-05  |
|    n_updates       | 2901974  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 662      |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 40       |
|    time_elapsed    | 27172    |
|    total_timesteps | 1105223  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 3.68     |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | 2.88     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2904920  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 40       |
|    time_elapsed    | 27236    |
|    total_timesteps | 1107952  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.0137   |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2907649  |
---------------------------------
Eval num_timesteps=1110000, episode_reward=605.74 +/- 0.00
Episode length: 686.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 686      |
|    mean_reward     | 606      |
| time/              |          |
|    total_timesteps | 1110000  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 4.17     |
|    ent_coef        | 0.0135   |
|    ent_coef_loss   | 0.523    |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2909697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 656      |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 40       |
|    time_elapsed    | 27336    |
|    total_timesteps | 1111535  |
| train/             |          |
|    actor_loss      | -62      |
|    critic_loss     | 4.81     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 2.36     |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2911232  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 654      |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 40       |
|    time_elapsed    | 27404    |
|    total_timesteps | 1114475  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | -0.867   |
|    learning_rate   | 8.89e-05 |
|    n_updates       | 2914172  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 654      |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 40       |
|    time_elapsed    | 27478    |
|    total_timesteps | 1117685  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 7.23     |
|    ent_coef        | 0.0136   |
|    ent_coef_loss   | 2.61     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2917382  |
---------------------------------
Eval num_timesteps=1120000, episode_reward=589.04 +/- 0.00
Episode length: 662.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 662      |
|    mean_reward     | 589      |
| time/              |          |
|    total_timesteps | 1120000  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 3.48     |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2919697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 735      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 40       |
|    time_elapsed    | 27567    |
|    total_timesteps | 1120690  |
| train/             |          |
|    actor_loss      | -63.8    |
|    critic_loss     | 4.77     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.0162   |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2920387  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 734      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 40       |
|    time_elapsed    | 27636    |
|    total_timesteps | 1123715  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -2.59    |
|    learning_rate   | 8.88e-05 |
|    n_updates       | 2923412  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 731      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 40       |
|    time_elapsed    | 27707    |
|    total_timesteps | 1126810  |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2926507  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 730      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 40       |
|    time_elapsed    | 27772    |
|    total_timesteps | 1129621  |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 0.712    |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2929318  |
---------------------------------
Eval num_timesteps=1130000, episode_reward=626.87 +/- 0.00
Episode length: 700.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 1130000  |
| train/             |          |
|    actor_loss      | -63.5    |
|    critic_loss     | 4.25     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -2.95    |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2929697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 40       |
|    time_elapsed    | 27865    |
|    total_timesteps | 1132812  |
| train/             |          |
|    actor_loss      | -60.5    |
|    critic_loss     | 6.13     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.127    |
|    learning_rate   | 8.87e-05 |
|    n_updates       | 2932509  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 726      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 40       |
|    time_elapsed    | 27938    |
|    total_timesteps | 1135972  |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 5.23     |
|    ent_coef        | 0.0138   |
|    ent_coef_loss   | -3.91    |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2935669  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 40       |
|    time_elapsed    | 28010    |
|    total_timesteps | 1139075  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 6        |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 1.54     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2938772  |
---------------------------------
Eval num_timesteps=1140000, episode_reward=643.15 +/- 0.00
Episode length: 726.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 726      |
|    mean_reward     | 643      |
| time/              |          |
|    total_timesteps | 1140000  |
| train/             |          |
|    actor_loss      | -61      |
|    critic_loss     | 7.52     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.3      |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2939697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 637      |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 40       |
|    time_elapsed    | 28098    |
|    total_timesteps | 1141911  |
| train/             |          |
|    actor_loss      | -62.9    |
|    critic_loss     | 5.91     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.3     |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2941608  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 635      |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 40       |
|    time_elapsed    | 28162    |
|    total_timesteps | 1144700  |
| train/             |          |
|    actor_loss      | -62.8    |
|    critic_loss     | 6.5      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -4.56    |
|    learning_rate   | 8.86e-05 |
|    n_updates       | 2944397  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 40       |
|    time_elapsed    | 28227    |
|    total_timesteps | 1147487  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 6.66     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.884    |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2947184  |
---------------------------------
Eval num_timesteps=1150000, episode_reward=627.22 +/- 0.00
Episode length: 698.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 698      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 1150000  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 5.09     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 1.73     |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2949697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 638      |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 40       |
|    time_elapsed    | 28322    |
|    total_timesteps | 1150755  |
| train/             |          |
|    actor_loss      | -61.9    |
|    critic_loss     | 5.61     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.348   |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2950452  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 723      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 40       |
|    time_elapsed    | 28389    |
|    total_timesteps | 1153712  |
| train/             |          |
|    actor_loss      | -61.5    |
|    critic_loss     | 3.41     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.208    |
|    learning_rate   | 8.85e-05 |
|    n_updates       | 2953409  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 638      |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 40       |
|    time_elapsed    | 28455    |
|    total_timesteps | 1156559  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.34    |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2956256  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 40       |
|    time_elapsed    | 28528    |
|    total_timesteps | 1159795  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 3.39     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -0.137   |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2959492  |
---------------------------------
Eval num_timesteps=1160000, episode_reward=627.14 +/- 0.00
Episode length: 713.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 713      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 1160000  |
| train/             |          |
|    actor_loss      | -61.7    |
|    critic_loss     | 7.56     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -0.101   |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2959697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 724      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 40       |
|    time_elapsed    | 28614    |
|    total_timesteps | 1162588  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 4.74     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.56    |
|    learning_rate   | 8.84e-05 |
|    n_updates       | 2962285  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 40       |
|    time_elapsed    | 28684    |
|    total_timesteps | 1165676  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.796   |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2965373  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 726      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 40       |
|    time_elapsed    | 28751    |
|    total_timesteps | 1168516  |
| train/             |          |
|    actor_loss      | -59      |
|    critic_loss     | 6.71     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 2.94     |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2968213  |
---------------------------------
Eval num_timesteps=1170000, episode_reward=684.77 +/- 0.00
Episode length: 769.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 769      |
|    mean_reward     | 685      |
| time/              |          |
|    total_timesteps | 1170000  |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 0.618    |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2969697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 729      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 40       |
|    time_elapsed    | 28841    |
|    total_timesteps | 1171536  |
| train/             |          |
|    actor_loss      | -61.6    |
|    critic_loss     | 5.26     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.95    |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2971233  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 40       |
|    time_elapsed    | 28910    |
|    total_timesteps | 1174545  |
| train/             |          |
|    actor_loss      | -58.9    |
|    critic_loss     | 6.94     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 2.7      |
|    learning_rate   | 8.83e-05 |
|    n_updates       | 2974242  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 734      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 40       |
|    time_elapsed    | 28981    |
|    total_timesteps | 1177744  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2977441  |
---------------------------------
Eval num_timesteps=1180000, episode_reward=629.98 +/- 0.00
Episode length: 716.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 716      |
|    mean_reward     | 630      |
| time/              |          |
|    total_timesteps | 1180000  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 5.08     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.221    |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2979697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 735      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 40       |
|    time_elapsed    | 29085    |
|    total_timesteps | 1181521  |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 6.47     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2981218  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 653      |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 40       |
|    time_elapsed    | 29151    |
|    total_timesteps | 1184356  |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 4.59     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.91     |
|    learning_rate   | 8.82e-05 |
|    n_updates       | 2984053  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 653      |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 40       |
|    time_elapsed    | 29217    |
|    total_timesteps | 1187215  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.51     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -0.491   |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2986912  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 735      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 40       |
|    time_elapsed    | 29280    |
|    total_timesteps | 1189990  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 3.67     |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2989687  |
---------------------------------
Eval num_timesteps=1190000, episode_reward=673.92 +/- 0.00
Episode length: 778.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 778      |
|    mean_reward     | 674      |
| time/              |          |
|    total_timesteps | 1190000  |
| train/             |          |
|    actor_loss      | -62.2    |
|    critic_loss     | 7.24     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2989697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 731      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 40       |
|    time_elapsed    | 29367    |
|    total_timesteps | 1192813  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 5.11     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.27     |
|    learning_rate   | 8.81e-05 |
|    n_updates       | 2992510  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 730      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 40       |
|    time_elapsed    | 29433    |
|    total_timesteps | 1195599  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 5.15     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2995296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 40       |
|    time_elapsed    | 29498    |
|    total_timesteps | 1198367  |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 5.19     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 1.4      |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2998064  |
---------------------------------
Eval num_timesteps=1200000, episode_reward=644.79 +/- 0.00
Episode length: 752.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 752      |
|    mean_reward     | 645      |
| time/              |          |
|    total_timesteps | 1200000  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 3.61     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.126    |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 2999697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 40       |
|    time_elapsed    | 29588    |
|    total_timesteps | 1201399  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 4.72     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 3001096  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 726      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 40       |
|    time_elapsed    | 29656    |
|    total_timesteps | 1204309  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 6.03     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.534    |
|    learning_rate   | 8.8e-05  |
|    n_updates       | 3004006  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 40       |
|    time_elapsed    | 29733    |
|    total_timesteps | 1207761  |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.06     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 3007458  |
---------------------------------
Eval num_timesteps=1210000, episode_reward=696.34 +/- 0.00
Episode length: 788.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 788      |
|    mean_reward     | 696      |
| time/              |          |
|    total_timesteps | 1210000  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 8.37     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 0.17     |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 3009697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 40       |
|    time_elapsed    | 29820    |
|    total_timesteps | 1210691  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 3.33     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.45    |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 3010388  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 725      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 40       |
|    time_elapsed    | 29884    |
|    total_timesteps | 1213491  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 4.24     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 8.79e-05 |
|    n_updates       | 3013188  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 731      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 40       |
|    time_elapsed    | 29954    |
|    total_timesteps | 1216596  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.71     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 3016293  |
---------------------------------
Eval num_timesteps=1220000, episode_reward=792.51 +/- 0.00
Episode length: 893.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 893      |
|    mean_reward     | 793      |
| time/              |          |
|    total_timesteps | 1220000  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 4.26     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -2.74    |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 3019697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 654      |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 40       |
|    time_elapsed    | 30068    |
|    total_timesteps | 1220773  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 7.47     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 3.49     |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 3020470  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 40       |
|    time_elapsed    | 30145    |
|    total_timesteps | 1224291  |
| train/             |          |
|    actor_loss      | -59.5    |
|    critic_loss     | 9.74     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 8.78e-05 |
|    n_updates       | 3023988  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 742      |
|    ep_rew_mean     | 659      |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 40       |
|    time_elapsed    | 30211    |
|    total_timesteps | 1227171  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 7.22     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.3     |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 3026868  |
---------------------------------
Eval num_timesteps=1230000, episode_reward=742.01 +/- 0.00
Episode length: 829.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 829      |
|    mean_reward     | 742      |
| time/              |          |
|    total_timesteps | 1230000  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 4.56     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.827    |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 3029697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 40       |
|    time_elapsed    | 30314    |
|    total_timesteps | 1230891  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6        |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 2.3      |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 3030588  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 758      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 40       |
|    time_elapsed    | 30398    |
|    total_timesteps | 1234799  |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 5.65     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 8.77e-05 |
|    n_updates       | 3034496  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 761      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 40       |
|    time_elapsed    | 30476    |
|    total_timesteps | 1238384  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 18.3     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.37    |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 3038081  |
---------------------------------
Eval num_timesteps=1240000, episode_reward=603.53 +/- 0.00
Episode length: 672.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 672      |
|    mean_reward     | 604      |
| time/              |          |
|    total_timesteps | 1240000  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 4.44     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.28    |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 3039697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 40       |
|    time_elapsed    | 30588    |
|    total_timesteps | 1242489  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 5.22     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.604    |
|    learning_rate   | 8.76e-05 |
|    n_updates       | 3042186  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 771      |
|    ep_rew_mean     | 685      |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 40       |
|    time_elapsed    | 30666    |
|    total_timesteps | 1245907  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 6.83     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.885    |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 3045604  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 773      |
|    ep_rew_mean     | 687      |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 40       |
|    time_elapsed    | 30733    |
|    total_timesteps | 1248900  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 7.96     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -1.39    |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 3048597  |
---------------------------------
Eval num_timesteps=1250000, episode_reward=720.58 +/- 0.00
Episode length: 804.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 804      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 1250000  |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 4.88     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 3049697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 777      |
|    ep_rew_mean     | 691      |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 40       |
|    time_elapsed    | 30835    |
|    total_timesteps | 1252462  |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 7.81     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 8.75e-05 |
|    n_updates       | 3052159  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 778      |
|    ep_rew_mean     | 692      |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 40       |
|    time_elapsed    | 30906    |
|    total_timesteps | 1255565  |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 3.38     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.99    |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 3055262  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 784      |
|    ep_rew_mean     | 697      |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 40       |
|    time_elapsed    | 30990    |
|    total_timesteps | 1259404  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 4.66     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.562    |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 3059101  |
---------------------------------
Eval num_timesteps=1260000, episode_reward=740.85 +/- 0.00
Episode length: 822.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 822      |
|    mean_reward     | 741      |
| time/              |          |
|    total_timesteps | 1260000  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 3059697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 790      |
|    ep_rew_mean     | 703      |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 40       |
|    time_elapsed    | 31105    |
|    total_timesteps | 1263665  |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.68     |
|    learning_rate   | 8.74e-05 |
|    n_updates       | 3063362  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 795      |
|    ep_rew_mean     | 707      |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 40       |
|    time_elapsed    | 31182    |
|    total_timesteps | 1267019  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 7.07     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -3.17    |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 3066716  |
---------------------------------
Eval num_timesteps=1270000, episode_reward=892.28 +/- 0.00
Episode length: 999.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 999      |
|    mean_reward     | 892      |
| time/              |          |
|    total_timesteps | 1270000  |
| train/             |          |
|    actor_loss      | -60.9    |
|    critic_loss     | 5.62     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | -0.0274  |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 3069697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 712      |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 40       |
|    time_elapsed    | 31288    |
|    total_timesteps | 1270882  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 0.917    |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 3070579  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 717      |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 40       |
|    time_elapsed    | 31364    |
|    total_timesteps | 1274216  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 7.86     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 4.13     |
|    learning_rate   | 8.73e-05 |
|    n_updates       | 3073913  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 811      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 40       |
|    time_elapsed    | 31441    |
|    total_timesteps | 1277559  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 0.103    |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 3077256  |
---------------------------------
Eval num_timesteps=1280000, episode_reward=783.12 +/- 0.00
Episode length: 885.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 885      |
|    mean_reward     | 783      |
| time/              |          |
|    total_timesteps | 1280000  |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 6.47     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.258    |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 3079697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 813      |
|    ep_rew_mean     | 724      |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 40       |
|    time_elapsed    | 31537    |
|    total_timesteps | 1280894  |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 8.05     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | 3.23     |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 3080591  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 821      |
|    ep_rew_mean     | 732      |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 40       |
|    time_elapsed    | 31621    |
|    total_timesteps | 1284513  |
| train/             |          |
|    actor_loss      | -57.7    |
|    critic_loss     | 8.31     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 1.99     |
|    learning_rate   | 8.72e-05 |
|    n_updates       | 3084210  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 40       |
|    time_elapsed    | 31706    |
|    total_timesteps | 1288287  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.92     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.227   |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 3087984  |
---------------------------------
Eval num_timesteps=1290000, episode_reward=791.03 +/- 0.00
Episode length: 892.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 892      |
|    mean_reward     | 791      |
| time/              |          |
|    total_timesteps | 1290000  |
| train/             |          |
|    actor_loss      | -60.4    |
|    critic_loss     | 4.9      |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -3.02    |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 3089697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 746      |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 40       |
|    time_elapsed    | 31816    |
|    total_timesteps | 1292383  |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 7.27     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.13     |
|    learning_rate   | 8.71e-05 |
|    n_updates       | 3092080  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 748      |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 40       |
|    time_elapsed    | 31897    |
|    total_timesteps | 1295976  |
| train/             |          |
|    actor_loss      | -59.7    |
|    critic_loss     | 5.54     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -0.918   |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 3095673  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 845      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 40       |
|    time_elapsed    | 31974    |
|    total_timesteps | 1299424  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 6.36     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 4.02     |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 3099121  |
---------------------------------
Eval num_timesteps=1300000, episode_reward=884.85 +/- 0.00
Episode length: 1006.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1.01e+03 |
|    mean_reward     | 885      |
| time/              |          |
|    total_timesteps | 1300000  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 5.56     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.0753   |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 3099697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 40       |
|    time_elapsed    | 32086    |
|    total_timesteps | 1303497  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 7.11     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.31    |
|    learning_rate   | 8.7e-05  |
|    n_updates       | 3103194  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 852      |
|    ep_rew_mean     | 761      |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 40       |
|    time_elapsed    | 32157    |
|    total_timesteps | 1306549  |
| train/             |          |
|    actor_loss      | -62.4    |
|    critic_loss     | 5        |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -2.78    |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 3106246  |
---------------------------------
Eval num_timesteps=1310000, episode_reward=839.98 +/- 0.00
Episode length: 946.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 946      |
|    mean_reward     | 840      |
| time/              |          |
|    total_timesteps | 1310000  |
| train/             |          |
|    actor_loss      | -56.3    |
|    critic_loss     | 7.35     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 0.516    |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 3109697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 763      |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 40       |
|    time_elapsed    | 32274    |
|    total_timesteps | 1310952  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 3.91     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -1.68    |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 3110649  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 850      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 40       |
|    time_elapsed    | 32345    |
|    total_timesteps | 1314035  |
| train/             |          |
|    actor_loss      | -61.3    |
|    critic_loss     | 4.29     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -5.44    |
|    learning_rate   | 8.69e-05 |
|    n_updates       | 3113732  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 854      |
|    ep_rew_mean     | 763      |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 40       |
|    time_elapsed    | 32418    |
|    total_timesteps | 1317281  |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 2.35     |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 3116978  |
---------------------------------
Eval num_timesteps=1320000, episode_reward=885.15 +/- 0.00
Episode length: 991.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 991      |
|    mean_reward     | 885      |
| time/              |          |
|    total_timesteps | 1320000  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 7.07     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.322    |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 3119697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 850      |
|    ep_rew_mean     | 760      |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 40       |
|    time_elapsed    | 32521    |
|    total_timesteps | 1320848  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 5.65     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.36     |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 3120545  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 846      |
|    ep_rew_mean     | 757      |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 40       |
|    time_elapsed    | 32600    |
|    total_timesteps | 1324343  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 8.17     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.236   |
|    learning_rate   | 8.68e-05 |
|    n_updates       | 3124040  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 752      |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 40       |
|    time_elapsed    | 32669    |
|    total_timesteps | 1327408  |
| train/             |          |
|    actor_loss      | -60.8    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -1.28    |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 3127105  |
---------------------------------
Eval num_timesteps=1330000, episode_reward=798.30 +/- 0.00
Episode length: 909.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 909      |
|    mean_reward     | 798      |
| time/              |          |
|    total_timesteps | 1330000  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 4.91     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 3129697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 839      |
|    ep_rew_mean     | 750      |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 40       |
|    time_elapsed    | 32765    |
|    total_timesteps | 1330633  |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -1.89    |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 3130330  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 40       |
|    time_elapsed    | 32841    |
|    total_timesteps | 1333945  |
| train/             |          |
|    actor_loss      | -60      |
|    critic_loss     | 8.1      |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.5     |
|    learning_rate   | 8.67e-05 |
|    n_updates       | 3133642  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 40       |
|    time_elapsed    | 32917    |
|    total_timesteps | 1337326  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.03     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.05    |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 3137023  |
---------------------------------
Eval num_timesteps=1340000, episode_reward=872.39 +/- 0.00
Episode length: 973.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 973      |
|    mean_reward     | 872      |
| time/              |          |
|    total_timesteps | 1340000  |
| train/             |          |
|    actor_loss      | -61.4    |
|    critic_loss     | 8.35     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 3139697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 40       |
|    time_elapsed    | 33035    |
|    total_timesteps | 1341681  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 9.16     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.99     |
|    learning_rate   | 8.66e-05 |
|    n_updates       | 3141378  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 847      |
|    ep_rew_mean     | 758      |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 40       |
|    time_elapsed    | 33114    |
|    total_timesteps | 1345121  |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 9.27     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | -0.154   |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 3144818  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 40       |
|    time_elapsed    | 33192    |
|    total_timesteps | 1348578  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 6.54     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -4.44    |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 3148275  |
---------------------------------
Eval num_timesteps=1350000, episode_reward=902.28 +/- 0.00
Episode length: 1004.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 902      |
| time/              |          |
|    total_timesteps | 1350000  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 7.85     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.921    |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 3149697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 40       |
|    time_elapsed    | 33308    |
|    total_timesteps | 1352814  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 8.72     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.583   |
|    learning_rate   | 8.65e-05 |
|    n_updates       | 3152511  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 844      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 40       |
|    time_elapsed    | 33384    |
|    total_timesteps | 1356182  |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 6.9      |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 3155879  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 40       |
|    time_elapsed    | 33457    |
|    total_timesteps | 1359430  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 6.51     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.36     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 3159127  |
---------------------------------
Eval num_timesteps=1360000, episode_reward=757.82 +/- 0.00
Episode length: 856.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 856      |
|    mean_reward     | 758      |
| time/              |          |
|    total_timesteps | 1360000  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 6.36     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 3159697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 842      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 40       |
|    time_elapsed    | 33562    |
|    total_timesteps | 1363230  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 0.457    |
|    learning_rate   | 8.64e-05 |
|    n_updates       | 3162927  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 40       |
|    time_elapsed    | 33636    |
|    total_timesteps | 1366502  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 3166199  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 756      |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 40       |
|    time_elapsed    | 33709    |
|    total_timesteps | 1369720  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 5.2      |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -5.12    |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 3169417  |
---------------------------------
Eval num_timesteps=1370000, episode_reward=698.15 +/- 0.00
Episode length: 779.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 779      |
|    mean_reward     | 698      |
| time/              |          |
|    total_timesteps | 1370000  |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 5.64     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.151   |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 3169697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 40       |
|    time_elapsed    | 33809    |
|    total_timesteps | 1373288  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 6.39     |
|    learning_rate   | 8.63e-05 |
|    n_updates       | 3172985  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 743      |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 40       |
|    time_elapsed    | 33873    |
|    total_timesteps | 1376058  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.47     |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 3175755  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 830      |
|    ep_rew_mean     | 744      |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 40       |
|    time_elapsed    | 33953    |
|    total_timesteps | 1379608  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -4.36    |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 3179305  |
---------------------------------
Eval num_timesteps=1380000, episode_reward=237.25 +/- 0.00
Episode length: 271.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 271      |
|    mean_reward     | 237      |
| time/              |          |
|    total_timesteps | 1380000  |
| train/             |          |
|    actor_loss      | -61.2    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.645   |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 3179697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 827      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 40       |
|    time_elapsed    | 34050    |
|    total_timesteps | 1383266  |
| train/             |          |
|    actor_loss      | -60.1    |
|    critic_loss     | 7.31     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -3.36    |
|    learning_rate   | 8.62e-05 |
|    n_updates       | 3182963  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 829      |
|    ep_rew_mean     | 742      |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 40       |
|    time_elapsed    | 34133    |
|    total_timesteps | 1386908  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 3186605  |
---------------------------------
Eval num_timesteps=1390000, episode_reward=864.31 +/- 0.00
Episode length: 964.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 964      |
|    mean_reward     | 864      |
| time/              |          |
|    total_timesteps | 1390000  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 8.45     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 3189697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 831      |
|    ep_rew_mean     | 744      |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 40       |
|    time_elapsed    | 34246    |
|    total_timesteps | 1391011  |
| train/             |          |
|    actor_loss      | -60.6    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.78    |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 3190708  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 746      |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 40       |
|    time_elapsed    | 34322    |
|    total_timesteps | 1394361  |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 7.35     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 4.47     |
|    learning_rate   | 8.61e-05 |
|    n_updates       | 3194058  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 40       |
|    time_elapsed    | 34401    |
|    total_timesteps | 1397892  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 5.16     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -0.99    |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 3197589  |
---------------------------------
Eval num_timesteps=1400000, episode_reward=754.03 +/- 0.00
Episode length: 841.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 841      |
|    mean_reward     | 754      |
| time/              |          |
|    total_timesteps | 1400000  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 8.69     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.8      |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 3199697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 836      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 40       |
|    time_elapsed    | 34506    |
|    total_timesteps | 1401684  |
| train/             |          |
|    actor_loss      | -63      |
|    critic_loss     | 6.25     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | 2.11     |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 3201381  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 749      |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 40       |
|    time_elapsed    | 34582    |
|    total_timesteps | 1404994  |
| train/             |          |
|    actor_loss      | -58.1    |
|    critic_loss     | 6.86     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.81    |
|    learning_rate   | 8.6e-05  |
|    n_updates       | 3204691  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 40       |
|    time_elapsed    | 34662    |
|    total_timesteps | 1408524  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.41     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 3208221  |
---------------------------------
Eval num_timesteps=1410000, episode_reward=804.18 +/- 0.00
Episode length: 898.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 898      |
|    mean_reward     | 804      |
| time/              |          |
|    total_timesteps | 1410000  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 9.19     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.69     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 3209697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 838      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 40       |
|    time_elapsed    | 34760    |
|    total_timesteps | 1411882  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 5.92     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 2.64     |
|    learning_rate   | 8.59e-05 |
|    n_updates       | 3211579  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 752      |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 40       |
|    time_elapsed    | 34831    |
|    total_timesteps | 1415064  |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 4.61     |
|    ent_coef        | 0.0153   |
|    ent_coef_loss   | -2.57    |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 3214761  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 754      |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 40       |
|    time_elapsed    | 34904    |
|    total_timesteps | 1418256  |
| train/             |          |
|    actor_loss      | -59.6    |
|    critic_loss     | 6.36     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 3217953  |
---------------------------------
Eval num_timesteps=1420000, episode_reward=646.36 +/- 0.00
Episode length: 717.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 717      |
|    mean_reward     | 646      |
| time/              |          |
|    total_timesteps | 1420000  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 7.07     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -1.53    |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 3219697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 841      |
|    ep_rew_mean     | 753      |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 40       |
|    time_elapsed    | 35001    |
|    total_timesteps | 1421595  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 13.2     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 8.58e-05 |
|    n_updates       | 3221292  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 843      |
|    ep_rew_mean     | 755      |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 40       |
|    time_elapsed    | 35079    |
|    total_timesteps | 1425131  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 3224828  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 840      |
|    ep_rew_mean     | 751      |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 40       |
|    time_elapsed    | 35152    |
|    total_timesteps | 1428283  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 6.94     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 4.15     |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 3227980  |
---------------------------------
Eval num_timesteps=1430000, episode_reward=750.57 +/- 0.00
Episode length: 834.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 834      |
|    mean_reward     | 751      |
| time/              |          |
|    total_timesteps | 1430000  |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 14.4     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 3229697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 834      |
|    ep_rew_mean     | 747      |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 40       |
|    time_elapsed    | 35246    |
|    total_timesteps | 1431339  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 6.85     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -4.43    |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 3231036  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 833      |
|    ep_rew_mean     | 745      |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 40       |
|    time_elapsed    | 35318    |
|    total_timesteps | 1434671  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 5.13     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.691   |
|    learning_rate   | 8.57e-05 |
|    n_updates       | 3234368  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 828      |
|    ep_rew_mean     | 741      |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 40       |
|    time_elapsed    | 35393    |
|    total_timesteps | 1437999  |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 9.58     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.115    |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 3237696  |
---------------------------------
Eval num_timesteps=1440000, episode_reward=841.39 +/- 0.00
Episode length: 936.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 936      |
|    mean_reward     | 841      |
| time/              |          |
|    total_timesteps | 1440000  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 8.07     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -2.78    |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 3239697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 825      |
|    ep_rew_mean     | 739      |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 40       |
|    time_elapsed    | 35495    |
|    total_timesteps | 1441563  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 8.88     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.571    |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 3241260  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 824      |
|    ep_rew_mean     | 738      |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 40       |
|    time_elapsed    | 35565    |
|    total_timesteps | 1444687  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 7.87     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.392    |
|    learning_rate   | 8.56e-05 |
|    n_updates       | 3244384  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 816      |
|    ep_rew_mean     | 731      |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 40       |
|    time_elapsed    | 35623    |
|    total_timesteps | 1447105  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -0.126   |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 3246802  |
---------------------------------
Eval num_timesteps=1450000, episode_reward=701.44 +/- 0.00
Episode length: 781.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 781      |
|    mean_reward     | 701      |
| time/              |          |
|    total_timesteps | 1450000  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.96     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.19     |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 3249697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 813      |
|    ep_rew_mean     | 728      |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 40       |
|    time_elapsed    | 35728    |
|    total_timesteps | 1450800  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 7.69     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 3250497  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 808      |
|    ep_rew_mean     | 723      |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 40       |
|    time_elapsed    | 35789    |
|    total_timesteps | 1453478  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 7.89     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 0.901    |
|    learning_rate   | 8.55e-05 |
|    n_updates       | 3253175  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 721      |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 40       |
|    time_elapsed    | 35857    |
|    total_timesteps | 1456494  |
| train/             |          |
|    actor_loss      | -58.6    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -2.84    |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 3256191  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 809      |
|    ep_rew_mean     | 725      |
| time/              |          |
|    episodes        | 1752     |
|    fps             | 40       |
|    time_elapsed    | 35930    |
|    total_timesteps | 1459686  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.242    |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 3259383  |
---------------------------------
Eval num_timesteps=1460000, episode_reward=511.38 +/- 0.00
Episode length: 562.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 562      |
|    mean_reward     | 511      |
| time/              |          |
|    total_timesteps | 1460000  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 7.64     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 3259697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 805      |
|    ep_rew_mean     | 722      |
| time/              |          |
|    episodes        | 1756     |
|    fps             | 40       |
|    time_elapsed    | 36027    |
|    total_timesteps | 1463127  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.91     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.529   |
|    learning_rate   | 8.54e-05 |
|    n_updates       | 3262824  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 800      |
|    ep_rew_mean     | 718      |
| time/              |          |
|    episodes        | 1760     |
|    fps             | 40       |
|    time_elapsed    | 36091    |
|    total_timesteps | 1465898  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 7.31     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.72     |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 3265595  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 794      |
|    ep_rew_mean     | 713      |
| time/              |          |
|    episodes        | 1764     |
|    fps             | 40       |
|    time_elapsed    | 36161    |
|    total_timesteps | 1468990  |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 6.38     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 3268687  |
---------------------------------
Eval num_timesteps=1470000, episode_reward=773.93 +/- 0.00
Episode length: 860.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 860      |
|    mean_reward     | 774      |
| time/              |          |
|    total_timesteps | 1470000  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 6.17     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 3269697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 786      |
|    ep_rew_mean     | 706      |
| time/              |          |
|    episodes        | 1768     |
|    fps             | 40       |
|    time_elapsed    | 36255    |
|    total_timesteps | 1472078  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 6.64     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 2.31     |
|    learning_rate   | 8.53e-05 |
|    n_updates       | 3271775  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 782      |
|    ep_rew_mean     | 702      |
| time/              |          |
|    episodes        | 1772     |
|    fps             | 40       |
|    time_elapsed    | 36322    |
|    total_timesteps | 1475031  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 8.34     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.49    |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 3274728  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 772      |
|    ep_rew_mean     | 694      |
| time/              |          |
|    episodes        | 1776     |
|    fps             | 40       |
|    time_elapsed    | 36381    |
|    total_timesteps | 1477580  |
| train/             |          |
|    actor_loss      | -60.2    |
|    critic_loss     | 4.76     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.3      |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 3277277  |
---------------------------------
Eval num_timesteps=1480000, episode_reward=848.10 +/- 0.00
Episode length: 950.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 950      |
|    mean_reward     | 848      |
| time/              |          |
|    total_timesteps | 1480000  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 3.83     |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 3279697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 768      |
|    ep_rew_mean     | 690      |
| time/              |          |
|    episodes        | 1780     |
|    fps             | 40       |
|    time_elapsed    | 36479    |
|    total_timesteps | 1480851  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 7.01     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.866    |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 3280548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 764      |
|    ep_rew_mean     | 686      |
| time/              |          |
|    episodes        | 1784     |
|    fps             | 40       |
|    time_elapsed    | 36544    |
|    total_timesteps | 1483712  |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 9.12     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.161    |
|    learning_rate   | 8.52e-05 |
|    n_updates       | 3283409  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 757      |
|    ep_rew_mean     | 680      |
| time/              |          |
|    episodes        | 1788     |
|    fps             | 40       |
|    time_elapsed    | 36610    |
|    total_timesteps | 1486577  |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 0.231    |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 3286274  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 754      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 1792     |
|    fps             | 40       |
|    time_elapsed    | 36676    |
|    total_timesteps | 1489507  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 8.3      |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | 1.74     |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 3289204  |
---------------------------------
Eval num_timesteps=1490000, episode_reward=756.59 +/- 0.00
Episode length: 840.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 840      |
|    mean_reward     | 757      |
| time/              |          |
|    total_timesteps | 1490000  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.93    |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 3289697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 1796     |
|    fps             | 40       |
|    time_elapsed    | 36769    |
|    total_timesteps | 1492695  |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 8.95     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.107    |
|    learning_rate   | 8.51e-05 |
|    n_updates       | 3292392  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 1800     |
|    fps             | 40       |
|    time_elapsed    | 36839    |
|    total_timesteps | 1495696  |
| train/             |          |
|    actor_loss      | -59.3    |
|    critic_loss     | 8.26     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.15    |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 3295393  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 1804     |
|    fps             | 40       |
|    time_elapsed    | 36907    |
|    total_timesteps | 1498733  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 7.21     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 3298430  |
---------------------------------
Eval num_timesteps=1500000, episode_reward=764.78 +/- 0.00
Episode length: 857.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 857      |
|    mean_reward     | 765      |
| time/              |          |
|    total_timesteps | 1500000  |
| train/             |          |
|    actor_loss      | -59.4    |
|    critic_loss     | 9.32     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 2.97     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 3299697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 745      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 1808     |
|    fps             | 40       |
|    time_elapsed    | 37014    |
|    total_timesteps | 1502615  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 9.61     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 3.83     |
|    learning_rate   | 8.5e-05  |
|    n_updates       | 3302312  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 742      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 1812     |
|    fps             | 40       |
|    time_elapsed    | 37082    |
|    total_timesteps | 1505516  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 11.5     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 5.49     |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 3305213  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 742      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 1816     |
|    fps             | 40       |
|    time_elapsed    | 37148    |
|    total_timesteps | 1508369  |
| train/             |          |
|    actor_loss      | -60.3    |
|    critic_loss     | 6.61     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | -2.24    |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 3308066  |
---------------------------------
Eval num_timesteps=1510000, episode_reward=758.92 +/- 0.00
Episode length: 849.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 849      |
|    mean_reward     | 759      |
| time/              |          |
|    total_timesteps | 1510000  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 6.81     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.0456   |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 3309697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 658      |
| time/              |          |
|    episodes        | 1820     |
|    fps             | 40       |
|    time_elapsed    | 37236    |
|    total_timesteps | 1511130  |
| train/             |          |
|    actor_loss      | -60.7    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 3310827  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 726      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 1824     |
|    fps             | 40       |
|    time_elapsed    | 37296    |
|    total_timesteps | 1513740  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 6.19     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -3.05    |
|    learning_rate   | 8.49e-05 |
|    n_updates       | 3313437  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 1828     |
|    fps             | 40       |
|    time_elapsed    | 37358    |
|    total_timesteps | 1516378  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 36.8     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.88    |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 3316075  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 1832     |
|    fps             | 40       |
|    time_elapsed    | 37425    |
|    total_timesteps | 1519343  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.0152   |
|    ent_coef_loss   | 0.0768   |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 3319040  |
---------------------------------
Eval num_timesteps=1520000, episode_reward=703.07 +/- 0.00
Episode length: 781.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 781      |
|    mean_reward     | 703      |
| time/              |          |
|    total_timesteps | 1520000  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.12     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.43    |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 3319697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 1836     |
|    fps             | 40       |
|    time_elapsed    | 37511    |
|    total_timesteps | 1522149  |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 9.25     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 4.33     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 3321846  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 1840     |
|    fps             | 40       |
|    time_elapsed    | 37571    |
|    total_timesteps | 1524560  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 8.42     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 5.61     |
|    learning_rate   | 8.48e-05 |
|    n_updates       | 3324257  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 1844     |
|    fps             | 40       |
|    time_elapsed    | 37636    |
|    total_timesteps | 1527278  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 13.6     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.406    |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 3326975  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 1848     |
|    fps             | 40       |
|    time_elapsed    | 37693    |
|    total_timesteps | 1529730  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 5.38     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -2.25    |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 3329427  |
---------------------------------
Eval num_timesteps=1530000, episode_reward=663.16 +/- 0.00
Episode length: 747.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 747      |
|    mean_reward     | 663      |
| time/              |          |
|    total_timesteps | 1530000  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 5.52     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.4      |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 3329697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 708      |
|    ep_rew_mean     | 636      |
| time/              |          |
|    episodes        | 1852     |
|    fps             | 40       |
|    time_elapsed    | 37784    |
|    total_timesteps | 1532820  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 7        |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 8.47e-05 |
|    n_updates       | 3332517  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 701      |
|    ep_rew_mean     | 630      |
| time/              |          |
|    episodes        | 1856     |
|    fps             | 40       |
|    time_elapsed    | 37843    |
|    total_timesteps | 1535272  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 5.99     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 3334969  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 699      |
|    ep_rew_mean     | 628      |
| time/              |          |
|    episodes        | 1860     |
|    fps             | 40       |
|    time_elapsed    | 37905    |
|    total_timesteps | 1537873  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 8.78     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.522    |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 3337570  |
---------------------------------
Eval num_timesteps=1540000, episode_reward=633.34 +/- 0.00
Episode length: 720.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 720      |
|    mean_reward     | 633      |
| time/              |          |
|    total_timesteps | 1540000  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 8.95     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -0.656   |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 3339697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 695      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 1864     |
|    fps             | 40       |
|    time_elapsed    | 37989    |
|    total_timesteps | 1540616  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 7.22     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -3.63    |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 3340313  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 693      |
|    ep_rew_mean     | 623      |
| time/              |          |
|    episodes        | 1868     |
|    fps             | 40       |
|    time_elapsed    | 38051    |
|    total_timesteps | 1543292  |
| train/             |          |
|    actor_loss      | -57.4    |
|    critic_loss     | 6.05     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.683   |
|    learning_rate   | 8.46e-05 |
|    n_updates       | 3342989  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 691      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 1872     |
|    fps             | 40       |
|    time_elapsed    | 38114    |
|    total_timesteps | 1545979  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 7.71     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 3345676  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 691      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 1876     |
|    fps             | 40       |
|    time_elapsed    | 38177    |
|    total_timesteps | 1548614  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 6.72     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -3.06    |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 3348311  |
---------------------------------
Eval num_timesteps=1550000, episode_reward=698.63 +/- 0.00
Episode length: 776.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 776      |
|    mean_reward     | 699      |
| time/              |          |
|    total_timesteps | 1550000  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 7.44     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 2.52     |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 3349697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 619      |
| time/              |          |
|    episodes        | 1880     |
|    fps             | 40       |
|    time_elapsed    | 38272    |
|    total_timesteps | 1551921  |
| train/             |          |
|    actor_loss      | -57.6    |
|    critic_loss     | 9.39     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.61    |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 3351618  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 688      |
|    ep_rew_mean     | 619      |
| time/              |          |
|    episodes        | 1884     |
|    fps             | 40       |
|    time_elapsed    | 38339    |
|    total_timesteps | 1554782  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 7.69     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.22    |
|    learning_rate   | 8.45e-05 |
|    n_updates       | 3354479  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 686      |
|    ep_rew_mean     | 616      |
| time/              |          |
|    episodes        | 1888     |
|    fps             | 40       |
|    time_elapsed    | 38402    |
|    total_timesteps | 1557407  |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 7.43     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -1.09    |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 3357104  |
---------------------------------
Eval num_timesteps=1560000, episode_reward=719.03 +/- 0.00
Episode length: 802.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 719      |
| time/              |          |
|    total_timesteps | 1560000  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 6.39     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.0252  |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 3359697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 681      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 1892     |
|    fps             | 40       |
|    time_elapsed    | 38494    |
|    total_timesteps | 1560574  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 8.49     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 1.12     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 3360271  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 681      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 1896     |
|    fps             | 40       |
|    time_elapsed    | 38558    |
|    total_timesteps | 1563292  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 7.57     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 4.09     |
|    learning_rate   | 8.44e-05 |
|    n_updates       | 3362989  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 678      |
|    ep_rew_mean     | 609      |
| time/              |          |
|    episodes        | 1900     |
|    fps             | 40       |
|    time_elapsed    | 38621    |
|    total_timesteps | 1565925  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.26     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 3365622  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 674      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 1904     |
|    fps             | 40       |
|    time_elapsed    | 38683    |
|    total_timesteps | 1568570  |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 11.3     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 1.68     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 3368267  |
---------------------------------
Eval num_timesteps=1570000, episode_reward=620.17 +/- 0.00
Episode length: 687.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 687      |
|    mean_reward     | 620      |
| time/              |          |
|    total_timesteps | 1570000  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 7.98     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -2.4     |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 3369697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 667      |
|    ep_rew_mean     | 599      |
| time/              |          |
|    episodes        | 1908     |
|    fps             | 40       |
|    time_elapsed    | 38774    |
|    total_timesteps | 1571611  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 6.7      |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.0815  |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 3371308  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 665      |
|    ep_rew_mean     | 598      |
| time/              |          |
|    episodes        | 1912     |
|    fps             | 40       |
|    time_elapsed    | 38840    |
|    total_timesteps | 1574378  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 9.42     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -2.54    |
|    learning_rate   | 8.43e-05 |
|    n_updates       | 3374075  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 593      |
| time/              |          |
|    episodes        | 1916     |
|    fps             | 40       |
|    time_elapsed    | 38896    |
|    total_timesteps | 1576670  |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 7.5      |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 2.74     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 3376367  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 594      |
| time/              |          |
|    episodes        | 1920     |
|    fps             | 40       |
|    time_elapsed    | 38957    |
|    total_timesteps | 1579223  |
| train/             |          |
|    actor_loss      | -57.5    |
|    critic_loss     | 5.76     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 3378920  |
---------------------------------
Eval num_timesteps=1580000, episode_reward=709.90 +/- 0.00
Episode length: 796.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 796      |
|    mean_reward     | 710      |
| time/              |          |
|    total_timesteps | 1580000  |
| train/             |          |
|    actor_loss      | -57.1    |
|    critic_loss     | 6.85     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -0.381   |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 3379697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 662      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 1924     |
|    fps             | 40       |
|    time_elapsed    | 39046    |
|    total_timesteps | 1582031  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 9.68     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 3381728  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 594      |
| time/              |          |
|    episodes        | 1928     |
|    fps             | 40       |
|    time_elapsed    | 39105    |
|    total_timesteps | 1584532  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 4.89     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.462    |
|    learning_rate   | 8.42e-05 |
|    n_updates       | 3384229  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 658      |
|    ep_rew_mean     | 591      |
| time/              |          |
|    episodes        | 1932     |
|    fps             | 40       |
|    time_elapsed    | 39168    |
|    total_timesteps | 1587179  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 9.06     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.57     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 3386876  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 657      |
|    ep_rew_mean     | 591      |
| time/              |          |
|    episodes        | 1936     |
|    fps             | 40       |
|    time_elapsed    | 39230    |
|    total_timesteps | 1589835  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 5.71     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 1.41     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 3389532  |
---------------------------------
Eval num_timesteps=1590000, episode_reward=850.75 +/- 0.00
Episode length: 944.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 944      |
|    mean_reward     | 851      |
| time/              |          |
|    total_timesteps | 1590000  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 7.4      |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 0.497    |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 3389697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 658      |
|    ep_rew_mean     | 592      |
| time/              |          |
|    episodes        | 1940     |
|    fps             | 40       |
|    time_elapsed    | 39316    |
|    total_timesteps | 1592485  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 7.98     |
|    ent_coef        | 0.0139   |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 8.41e-05 |
|    n_updates       | 3392182  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 657      |
|    ep_rew_mean     | 591      |
| time/              |          |
|    episodes        | 1944     |
|    fps             | 40       |
|    time_elapsed    | 39378    |
|    total_timesteps | 1595069  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 6.82     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 1.88     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 3394766  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 593      |
| time/              |          |
|    episodes        | 1948     |
|    fps             | 40       |
|    time_elapsed    | 39442    |
|    total_timesteps | 1597806  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 5.94     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 3397503  |
---------------------------------
Eval num_timesteps=1600000, episode_reward=760.15 +/- 0.00
Episode length: 843.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 843      |
|    mean_reward     | 760      |
| time/              |          |
|    total_timesteps | 1600000  |
| train/             |          |
|    actor_loss      | -59.1    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.98    |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 3399697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 656      |
|    ep_rew_mean     | 590      |
| time/              |          |
|    episodes        | 1952     |
|    fps             | 40       |
|    time_elapsed    | 39529    |
|    total_timesteps | 1600685  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 7.36     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | 0.81     |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 3400382  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 656      |
|    ep_rew_mean     | 591      |
| time/              |          |
|    episodes        | 1956     |
|    fps             | 40       |
|    time_elapsed    | 39590    |
|    total_timesteps | 1603180  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 7.94     |
|    ent_coef        | 0.014    |
|    ent_coef_loss   | -1.32    |
|    learning_rate   | 8.4e-05  |
|    n_updates       | 3402877  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 655      |
|    ep_rew_mean     | 590      |
| time/              |          |
|    episodes        | 1960     |
|    fps             | 40       |
|    time_elapsed    | 39649    |
|    total_timesteps | 1605665  |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 8.29     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 3.78     |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 3405362  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 654      |
|    ep_rew_mean     | 589      |
| time/              |          |
|    episodes        | 1964     |
|    fps             | 40       |
|    time_elapsed    | 39710    |
|    total_timesteps | 1608231  |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 7.82     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 3407928  |
---------------------------------
Eval num_timesteps=1610000, episode_reward=502.81 +/- 0.00
Episode length: 554.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 554      |
|    mean_reward     | 503      |
| time/              |          |
|    total_timesteps | 1610000  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 8.53     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | 0.00758  |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 3409697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 653      |
|    ep_rew_mean     | 588      |
| time/              |          |
|    episodes        | 1968     |
|    fps             | 40       |
|    time_elapsed    | 39799    |
|    total_timesteps | 1611298  |
| train/             |          |
|    actor_loss      | -57.9    |
|    critic_loss     | 5.66     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -3.19    |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 3410995  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 652      |
|    ep_rew_mean     | 587      |
| time/              |          |
|    episodes        | 1972     |
|    fps             | 40       |
|    time_elapsed    | 39861    |
|    total_timesteps | 1613881  |
| train/             |          |
|    actor_loss      | -57      |
|    critic_loss     | 7.51     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.647    |
|    learning_rate   | 8.39e-05 |
|    n_updates       | 3413578  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 653      |
|    ep_rew_mean     | 588      |
| time/              |          |
|    episodes        | 1976     |
|    fps             | 40       |
|    time_elapsed    | 39924    |
|    total_timesteps | 1616632  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 6.06     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 3416329  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 649      |
|    ep_rew_mean     | 585      |
| time/              |          |
|    episodes        | 1980     |
|    fps             | 40       |
|    time_elapsed    | 39978    |
|    total_timesteps | 1618924  |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 5.79     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 4.96     |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 3418621  |
---------------------------------
Eval num_timesteps=1620000, episode_reward=621.44 +/- 0.00
Episode length: 689.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 689      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 1620000  |
| train/             |          |
|    actor_loss      | -58.8    |
|    critic_loss     | 7.19     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.933    |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 3419697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 643      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 1984     |
|    fps             | 40       |
|    time_elapsed    | 40066    |
|    total_timesteps | 1621740  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 9.31     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -0.916   |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 3421437  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 641      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 1988     |
|    fps             | 40       |
|    time_elapsed    | 40123    |
|    total_timesteps | 1624123  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 6.96     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -0.91    |
|    learning_rate   | 8.38e-05 |
|    n_updates       | 3423820  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 641      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 1992     |
|    fps             | 40       |
|    time_elapsed    | 40183    |
|    total_timesteps | 1626599  |
| train/             |          |
|    actor_loss      | -56.4    |
|    critic_loss     | 5.97     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | -1.94    |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 3426296  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 643      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 1996     |
|    fps             | 40       |
|    time_elapsed    | 40248    |
|    total_timesteps | 1629447  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 8.03     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.03     |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 3429144  |
---------------------------------
Eval num_timesteps=1630000, episode_reward=621.79 +/- 0.00
Episode length: 684.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 684      |
|    mean_reward     | 622      |
| time/              |          |
|    total_timesteps | 1630000  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 5.83     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.184   |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 3429697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 641      |
|    ep_rew_mean     | 578      |
| time/              |          |
|    episodes        | 2000     |
|    fps             | 40       |
|    time_elapsed    | 40339    |
|    total_timesteps | 1632504  |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 4.6      |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 3432201  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 640      |
|    ep_rew_mean     | 577      |
| time/              |          |
|    episodes        | 2004     |
|    fps             | 40       |
|    time_elapsed    | 40398    |
|    total_timesteps | 1634972  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.32    |
|    learning_rate   | 8.37e-05 |
|    n_updates       | 3434669  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 635      |
|    ep_rew_mean     | 573      |
| time/              |          |
|    episodes        | 2008     |
|    fps             | 40       |
|    time_elapsed    | 40455    |
|    total_timesteps | 1637395  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 6.2      |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 3.62     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 3437092  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 631      |
|    ep_rew_mean     | 570      |
| time/              |          |
|    episodes        | 2012     |
|    fps             | 40       |
|    time_elapsed    | 40510    |
|    total_timesteps | 1639715  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.1     |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 3439412  |
---------------------------------
Eval num_timesteps=1640000, episode_reward=710.63 +/- 0.00
Episode length: 802.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 711      |
| time/              |          |
|    total_timesteps | 1640000  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 4.92     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.252    |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 3439697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 633      |
|    ep_rew_mean     | 572      |
| time/              |          |
|    episodes        | 2016     |
|    fps             | 40       |
|    time_elapsed    | 40598    |
|    total_timesteps | 1642546  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 4.49     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 3442243  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 632      |
|    ep_rew_mean     | 571      |
| time/              |          |
|    episodes        | 2020     |
|    fps             | 40       |
|    time_elapsed    | 40656    |
|    total_timesteps | 1645001  |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 5.88     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -1.99    |
|    learning_rate   | 8.36e-05 |
|    n_updates       | 3444698  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 628      |
|    ep_rew_mean     | 567      |
| time/              |          |
|    episodes        | 2024     |
|    fps             | 40       |
|    time_elapsed    | 40711    |
|    total_timesteps | 1647309  |
| train/             |          |
|    actor_loss      | -55.9    |
|    critic_loss     | 8.13     |
|    ent_coef        | 0.0144   |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 3447006  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 630      |
|    ep_rew_mean     | 568      |
| time/              |          |
|    episodes        | 2028     |
|    fps             | 40       |
|    time_elapsed    | 40773    |
|    total_timesteps | 1649930  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 24.9     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 5.99     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 3449627  |
---------------------------------
Eval num_timesteps=1650000, episode_reward=670.59 +/- 0.00
Episode length: 745.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 745      |
|    mean_reward     | 671      |
| time/              |          |
|    total_timesteps | 1650000  |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 7.66     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.67     |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 3449697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 626      |
|    ep_rew_mean     | 565      |
| time/              |          |
|    episodes        | 2032     |
|    fps             | 40       |
|    time_elapsed    | 40850    |
|    total_timesteps | 1652274  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 6.78     |
|    ent_coef        | 0.0143   |
|    ent_coef_loss   | -2.69    |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 3451971  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 623      |
|    ep_rew_mean     | 562      |
| time/              |          |
|    episodes        | 2036     |
|    fps             | 40       |
|    time_elapsed    | 40906    |
|    total_timesteps | 1654605  |
| train/             |          |
|    actor_loss      | -59.9    |
|    critic_loss     | 5.85     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | -3.47    |
|    learning_rate   | 8.35e-05 |
|    n_updates       | 3454302  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 622      |
|    ep_rew_mean     | 562      |
| time/              |          |
|    episodes        | 2040     |
|    fps             | 40       |
|    time_elapsed    | 40962    |
|    total_timesteps | 1657022  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 9.38     |
|    ent_coef        | 0.0141   |
|    ent_coef_loss   | 2.03     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 3456719  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 621      |
|    ep_rew_mean     | 561      |
| time/              |          |
|    episodes        | 2044     |
|    fps             | 40       |
|    time_elapsed    | 41021    |
|    total_timesteps | 1659518  |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 5.42     |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | -0.561   |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 3459215  |
---------------------------------
Eval num_timesteps=1660000, episode_reward=608.39 +/- 0.00
Episode length: 667.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 667      |
|    mean_reward     | 608      |
| time/              |          |
|    total_timesteps | 1660000  |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 7        |
|    ent_coef        | 0.0142   |
|    ent_coef_loss   | 0.948    |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 3459697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 618      |
|    ep_rew_mean     | 558      |
| time/              |          |
|    episodes        | 2048     |
|    fps             | 40       |
|    time_elapsed    | 41109    |
|    total_timesteps | 1662405  |
| train/             |          |
|    actor_loss      | -58      |
|    critic_loss     | 4.65     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 3462102  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 615      |
|    ep_rew_mean     | 555      |
| time/              |          |
|    episodes        | 2052     |
|    fps             | 40       |
|    time_elapsed    | 41163    |
|    total_timesteps | 1664570  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 6.72     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 3.78     |
|    learning_rate   | 8.34e-05 |
|    n_updates       | 3464267  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 610      |
|    ep_rew_mean     | 552      |
| time/              |          |
|    episodes        | 2056     |
|    fps             | 40       |
|    time_elapsed    | 41212    |
|    total_timesteps | 1666625  |
| train/             |          |
|    actor_loss      | -56.9    |
|    critic_loss     | 7.58     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.98    |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 3466322  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 611      |
|    ep_rew_mean     | 552      |
| time/              |          |
|    episodes        | 2060     |
|    fps             | 40       |
|    time_elapsed    | 41274    |
|    total_timesteps | 1669212  |
| train/             |          |
|    actor_loss      | -59.2    |
|    critic_loss     | 9.15     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.76    |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 3468909  |
---------------------------------
Eval num_timesteps=1670000, episode_reward=647.51 +/- 0.00
Episode length: 717.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 717      |
|    mean_reward     | 648      |
| time/              |          |
|    total_timesteps | 1670000  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 6.74     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -1.04    |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 3469697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 613      |
|    ep_rew_mean     | 554      |
| time/              |          |
|    episodes        | 2064     |
|    fps             | 40       |
|    time_elapsed    | 41359    |
|    total_timesteps | 1672017  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 6.39     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.113   |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 3471714  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 610      |
|    ep_rew_mean     | 551      |
| time/              |          |
|    episodes        | 2068     |
|    fps             | 40       |
|    time_elapsed    | 41415    |
|    total_timesteps | 1674314  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.798   |
|    learning_rate   | 8.33e-05 |
|    n_updates       | 3474011  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 607      |
|    ep_rew_mean     | 549      |
| time/              |          |
|    episodes        | 2072     |
|    fps             | 40       |
|    time_elapsed    | 41469    |
|    total_timesteps | 1676607  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 7.7      |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | 0.291    |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 3476304  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 602      |
|    ep_rew_mean     | 544      |
| time/              |          |
|    episodes        | 2076     |
|    fps             | 40       |
|    time_elapsed    | 41522    |
|    total_timesteps | 1678793  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.27    |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 3478490  |
---------------------------------
Eval num_timesteps=1680000, episode_reward=525.51 +/- 0.00
Episode length: 577.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 1680000  |
| train/             |          |
|    actor_loss      | -55.5    |
|    critic_loss     | 8.93     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2       |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 3479697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 604      |
|    ep_rew_mean     | 546      |
| time/              |          |
|    episodes        | 2080     |
|    fps             | 40       |
|    time_elapsed    | 41604    |
|    total_timesteps | 1681473  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 10.3     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 0.446    |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 3481170  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 603      |
|    ep_rew_mean     | 545      |
| time/              |          |
|    episodes        | 2084     |
|    fps             | 40       |
|    time_elapsed    | 41657    |
|    total_timesteps | 1683654  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 9.45     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -2.82    |
|    learning_rate   | 8.32e-05 |
|    n_updates       | 3483351  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 604      |
|    ep_rew_mean     | 546      |
| time/              |          |
|    episodes        | 2088     |
|    fps             | 40       |
|    time_elapsed    | 41715    |
|    total_timesteps | 1686130  |
| train/             |          |
|    actor_loss      | -55.3    |
|    critic_loss     | 5.4      |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -4.33    |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 3485827  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 603      |
|    ep_rew_mean     | 544      |
| time/              |          |
|    episodes        | 2092     |
|    fps             | 40       |
|    time_elapsed    | 41771    |
|    total_timesteps | 1688439  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 6.55     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 0.14     |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 3488136  |
---------------------------------
Eval num_timesteps=1690000, episode_reward=522.26 +/- 0.00
Episode length: 577.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 577      |
|    mean_reward     | 522      |
| time/              |          |
|    total_timesteps | 1690000  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 5.68     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -1.42    |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 3489697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 599      |
|    ep_rew_mean     | 541      |
| time/              |          |
|    episodes        | 2096     |
|    fps             | 40       |
|    time_elapsed    | 41855    |
|    total_timesteps | 1691172  |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 6.67     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 0.783    |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 3490869  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 596      |
|    ep_rew_mean     | 539      |
| time/              |          |
|    episodes        | 2100     |
|    fps             | 40       |
|    time_elapsed    | 41909    |
|    total_timesteps | 1693433  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 9.45     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | 3.6      |
|    learning_rate   | 8.31e-05 |
|    n_updates       | 3493130  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 594      |
|    ep_rew_mean     | 537      |
| time/              |          |
|    episodes        | 2104     |
|    fps             | 40       |
|    time_elapsed    | 41963    |
|    total_timesteps | 1695681  |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 8.96     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 6.36     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 3495378  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 594      |
|    ep_rew_mean     | 537      |
| time/              |          |
|    episodes        | 2108     |
|    fps             | 40       |
|    time_elapsed    | 42020    |
|    total_timesteps | 1698063  |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 8.19     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -3.6     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 3497760  |
---------------------------------
Eval num_timesteps=1700000, episode_reward=491.59 +/- 0.00
Episode length: 544.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 544      |
|    mean_reward     | 492      |
| time/              |          |
|    total_timesteps | 1700000  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 6.93     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 3499697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 593      |
|    ep_rew_mean     | 536      |
| time/              |          |
|    episodes        | 2112     |
|    fps             | 40       |
|    time_elapsed    | 42099    |
|    total_timesteps | 1700576  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 3.05     |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 3500273  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 592      |
|    ep_rew_mean     | 535      |
| time/              |          |
|    episodes        | 2116     |
|    fps             | 40       |
|    time_elapsed    | 42156    |
|    total_timesteps | 1703041  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 8.33     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -3.04    |
|    learning_rate   | 8.3e-05  |
|    n_updates       | 3502738  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 589      |
|    ep_rew_mean     | 532      |
| time/              |          |
|    episodes        | 2120     |
|    fps             | 40       |
|    time_elapsed    | 42208    |
|    total_timesteps | 1705140  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 6.51     |
|    ent_coef        | 0.0145   |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 3504837  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 586      |
|    ep_rew_mean     | 530      |
| time/              |          |
|    episodes        | 2124     |
|    fps             | 40       |
|    time_elapsed    | 42259    |
|    total_timesteps | 1707149  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 5.57     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -2.8     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 3506846  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 582      |
|    ep_rew_mean     | 527      |
| time/              |          |
|    episodes        | 2128     |
|    fps             | 40       |
|    time_elapsed    | 42314    |
|    total_timesteps | 1709446  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 7.74     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 0.547    |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 3509143  |
---------------------------------
Eval num_timesteps=1710000, episode_reward=526.39 +/- 0.00
Episode length: 581.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 581      |
|    mean_reward     | 526      |
| time/              |          |
|    total_timesteps | 1710000  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 7.16     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.64     |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 3509697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 588      |
|    ep_rew_mean     | 532      |
| time/              |          |
|    episodes        | 2132     |
|    fps             | 40       |
|    time_elapsed    | 42409    |
|    total_timesteps | 1712846  |
| train/             |          |
|    actor_loss      | -58.2    |
|    critic_loss     | 5.55     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.16    |
|    learning_rate   | 8.29e-05 |
|    n_updates       | 3512543  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 590      |
|    ep_rew_mean     | 533      |
| time/              |          |
|    episodes        | 2136     |
|    fps             | 40       |
|    time_elapsed    | 42469    |
|    total_timesteps | 1715336  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 6.46     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.938   |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 3515033  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 588      |
|    ep_rew_mean     | 532      |
| time/              |          |
|    episodes        | 2140     |
|    fps             | 40       |
|    time_elapsed    | 42525    |
|    total_timesteps | 1717634  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 6.44     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 3.58     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 3517331  |
---------------------------------
Eval num_timesteps=1720000, episode_reward=524.66 +/- 0.00
Episode length: 575.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 575      |
|    mean_reward     | 525      |
| time/              |          |
|    total_timesteps | 1720000  |
| train/             |          |
|    actor_loss      | -57.2    |
|    critic_loss     | 7.65     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -0.677   |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 3519697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 590      |
|    ep_rew_mean     | 534      |
| time/              |          |
|    episodes        | 2144     |
|    fps             | 40       |
|    time_elapsed    | 42616    |
|    total_timesteps | 1720677  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 13.4     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 3.51     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 3520374  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 592      |
|    ep_rew_mean     | 536      |
| time/              |          |
|    episodes        | 2148     |
|    fps             | 40       |
|    time_elapsed    | 42675    |
|    total_timesteps | 1723305  |
| train/             |          |
|    actor_loss      | -58.5    |
|    critic_loss     | 6.74     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -2.1     |
|    learning_rate   | 8.28e-05 |
|    n_updates       | 3523002  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 595      |
|    ep_rew_mean     | 538      |
| time/              |          |
|    episodes        | 2152     |
|    fps             | 40       |
|    time_elapsed    | 42734    |
|    total_timesteps | 1725742  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 6.55     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.78    |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 3525439  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 602      |
|    ep_rew_mean     | 544      |
| time/              |          |
|    episodes        | 2156     |
|    fps             | 40       |
|    time_elapsed    | 42798    |
|    total_timesteps | 1728484  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 10.6     |
|    ent_coef        | 0.0149   |
|    ent_coef_loss   | -2.14    |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 3528181  |
---------------------------------
Eval num_timesteps=1730000, episode_reward=634.09 +/- 0.00
Episode length: 700.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 700      |
|    mean_reward     | 634      |
| time/              |          |
|    total_timesteps | 1730000  |
| train/             |          |
|    actor_loss      | -53.2    |
|    critic_loss     | 10.7     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 0.902    |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 3529697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 598      |
|    ep_rew_mean     | 541      |
| time/              |          |
|    episodes        | 2160     |
|    fps             | 40       |
|    time_elapsed    | 42882    |
|    total_timesteps | 1731156  |
| train/             |          |
|    actor_loss      | -56.1    |
|    critic_loss     | 8.93     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 1.07     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 3530853  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 596      |
|    ep_rew_mean     | 539      |
| time/              |          |
|    episodes        | 2164     |
|    fps             | 40       |
|    time_elapsed    | 42942    |
|    total_timesteps | 1733713  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 4.92     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.33     |
|    learning_rate   | 8.27e-05 |
|    n_updates       | 3533410  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 602      |
|    ep_rew_mean     | 544      |
| time/              |          |
|    episodes        | 2168     |
|    fps             | 40       |
|    time_elapsed    | 43007    |
|    total_timesteps | 1736523  |
| train/             |          |
|    actor_loss      | -56.8    |
|    critic_loss     | 8.12     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -2.28    |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 3536220  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 604      |
|    ep_rew_mean     | 546      |
| time/              |          |
|    episodes        | 2172     |
|    fps             | 40       |
|    time_elapsed    | 43067    |
|    total_timesteps | 1739042  |
| train/             |          |
|    actor_loss      | -58.4    |
|    critic_loss     | 9.33     |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | -1.27    |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 3538739  |
---------------------------------
Eval num_timesteps=1740000, episode_reward=633.03 +/- 0.00
Episode length: 702.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 702      |
|    mean_reward     | 633      |
| time/              |          |
|    total_timesteps | 1740000  |
| train/             |          |
|    actor_loss      | -55.7    |
|    critic_loss     | 6.55     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.14     |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 3539697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 609      |
|    ep_rew_mean     | 551      |
| time/              |          |
|    episodes        | 2176     |
|    fps             | 40       |
|    time_elapsed    | 43158    |
|    total_timesteps | 1742135  |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 5.71     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.691   |
|    learning_rate   | 8.26e-05 |
|    n_updates       | 3541832  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 612      |
|    ep_rew_mean     | 554      |
| time/              |          |
|    episodes        | 2180     |
|    fps             | 40       |
|    time_elapsed    | 43224    |
|    total_timesteps | 1745019  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 9.6      |
|    ent_coef        | 0.0146   |
|    ent_coef_loss   | 3.06     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 3544716  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 619      |
|    ep_rew_mean     | 560      |
| time/              |          |
|    episodes        | 2184     |
|    fps             | 40       |
|    time_elapsed    | 43290    |
|    total_timesteps | 1747871  |
| train/             |          |
|    actor_loss      | -55.6    |
|    critic_loss     | 7.57     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | 1.49     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 3547568  |
---------------------------------
Eval num_timesteps=1750000, episode_reward=668.29 +/- 0.00
Episode length: 738.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 738      |
|    mean_reward     | 668      |
| time/              |          |
|    total_timesteps | 1750000  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 7.11     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | -0.126   |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 3549697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 622      |
|    ep_rew_mean     | 562      |
| time/              |          |
|    episodes        | 2188     |
|    fps             | 40       |
|    time_elapsed    | 43381    |
|    total_timesteps | 1750857  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 7.72     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 0.801    |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 3550554  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 628      |
|    ep_rew_mean     | 568      |
| time/              |          |
|    episodes        | 2192     |
|    fps             | 40       |
|    time_elapsed    | 43448    |
|    total_timesteps | 1753824  |
| train/             |          |
|    actor_loss      | -49.6    |
|    critic_loss     | 8.47     |
|    ent_coef        | 0.0148   |
|    ent_coef_loss   | 2.45     |
|    learning_rate   | 8.25e-05 |
|    n_updates       | 3553521  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 633      |
|    ep_rew_mean     | 573      |
| time/              |          |
|    episodes        | 2196     |
|    fps             | 40       |
|    time_elapsed    | 43517    |
|    total_timesteps | 1756798  |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 7.51     |
|    ent_coef        | 0.0147   |
|    ent_coef_loss   | -0.381   |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 3556495  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 637      |
|    ep_rew_mean     | 576      |
| time/              |          |
|    episodes        | 2200     |
|    fps             | 40       |
|    time_elapsed    | 43580    |
|    total_timesteps | 1759423  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 8.71     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | 1.43     |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 3559120  |
---------------------------------
Eval num_timesteps=1760000, episode_reward=669.04 +/- 0.00
Episode length: 738.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 738      |
|    mean_reward     | 669      |
| time/              |          |
|    total_timesteps | 1760000  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -1.64    |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 3559697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 641      |
|    ep_rew_mean     | 580      |
| time/              |          |
|    episodes        | 2204     |
|    fps             | 40       |
|    time_elapsed    | 43674    |
|    total_timesteps | 1762696  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 7.15     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.72    |
|    learning_rate   | 8.24e-05 |
|    n_updates       | 3562393  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 645      |
|    ep_rew_mean     | 584      |
| time/              |          |
|    episodes        | 2208     |
|    fps             | 40       |
|    time_elapsed    | 43738    |
|    total_timesteps | 1765474  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 5.73     |
|    ent_coef        | 0.015    |
|    ent_coef_loss   | -3.86    |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 3565171  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 648      |
|    ep_rew_mean     | 586      |
| time/              |          |
|    episodes        | 2212     |
|    fps             | 40       |
|    time_elapsed    | 43796    |
|    total_timesteps | 1767966  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 8.38     |
|    ent_coef        | 0.0151   |
|    ent_coef_loss   | 0.865    |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 3567663  |
---------------------------------
Eval num_timesteps=1770000, episode_reward=519.29 +/- 0.00
Episode length: 571.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 571      |
|    mean_reward     | 519      |
| time/              |          |
|    total_timesteps | 1770000  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 6.79     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | -2.42    |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 3569697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 647      |
|    ep_rew_mean     | 586      |
| time/              |          |
|    episodes        | 2216     |
|    fps             | 40       |
|    time_elapsed    | 43879    |
|    total_timesteps | 1770564  |
| train/             |          |
|    actor_loss      | -56.5    |
|    critic_loss     | 7.08     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 0.0639   |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 3570261  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 649      |
|    ep_rew_mean     | 587      |
| time/              |          |
|    episodes        | 2220     |
|    fps             | 40       |
|    time_elapsed    | 43934    |
|    total_timesteps | 1772810  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 7.24     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 5.79     |
|    learning_rate   | 8.23e-05 |
|    n_updates       | 3572507  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 658      |
|    ep_rew_mean     | 595      |
| time/              |          |
|    episodes        | 2224     |
|    fps             | 40       |
|    time_elapsed    | 44000    |
|    total_timesteps | 1775693  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 5.84     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -0.455   |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 3575390  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 598      |
| time/              |          |
|    episodes        | 2228     |
|    fps             | 40       |
|    time_elapsed    | 44061    |
|    total_timesteps | 1778331  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 7.46     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 0.14     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 3578028  |
---------------------------------
Eval num_timesteps=1780000, episode_reward=518.03 +/- 0.00
Episode length: 568.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 568      |
|    mean_reward     | 518      |
| time/              |          |
|    total_timesteps | 1780000  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 9.86     |
|    ent_coef        | 0.0154   |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 3579697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 597      |
| time/              |          |
|    episodes        | 2232     |
|    fps             | 40       |
|    time_elapsed    | 44155    |
|    total_timesteps | 1781481  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 6.49     |
|    ent_coef        | 0.0156   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 3581178  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 598      |
| time/              |          |
|    episodes        | 2236     |
|    fps             | 40       |
|    time_elapsed    | 44216    |
|    total_timesteps | 1784051  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 6.09     |
|    ent_coef        | 0.0155   |
|    ent_coef_loss   | 1.4      |
|    learning_rate   | 8.22e-05 |
|    n_updates       | 3583748  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 663      |
|    ep_rew_mean     | 600      |
| time/              |          |
|    episodes        | 2240     |
|    fps             | 40       |
|    time_elapsed    | 44275    |
|    total_timesteps | 1786579  |
| train/             |          |
|    actor_loss      | -57.3    |
|    critic_loss     | 8.34     |
|    ent_coef        | 0.0157   |
|    ent_coef_loss   | -5.17    |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 3586276  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 661      |
|    ep_rew_mean     | 598      |
| time/              |          |
|    episodes        | 2244     |
|    fps             | 40       |
|    time_elapsed    | 44332    |
|    total_timesteps | 1788986  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 9.42     |
|    ent_coef        | 0.0158   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 3588683  |
---------------------------------
Eval num_timesteps=1790000, episode_reward=680.17 +/- 0.00
Episode length: 745.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 745      |
|    mean_reward     | 680      |
| time/              |          |
|    total_timesteps | 1790000  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 7.54     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 3589697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 660      |
|    ep_rew_mean     | 597      |
| time/              |          |
|    episodes        | 2248     |
|    fps             | 40       |
|    time_elapsed    | 44420    |
|    total_timesteps | 1791851  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 7.55     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.69    |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 3591548  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 664      |
|    ep_rew_mean     | 601      |
| time/              |          |
|    episodes        | 2252     |
|    fps             | 40       |
|    time_elapsed    | 44486    |
|    total_timesteps | 1794675  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 7.36     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -2.25    |
|    learning_rate   | 8.21e-05 |
|    n_updates       | 3594372  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 663      |
|    ep_rew_mean     | 601      |
| time/              |          |
|    episodes        | 2256     |
|    fps             | 40       |
|    time_elapsed    | 44549    |
|    total_timesteps | 1797398  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 7.17     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 3597095  |
---------------------------------
Eval num_timesteps=1800000, episode_reward=682.72 +/- 0.00
Episode length: 756.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 756      |
|    mean_reward     | 683      |
| time/              |          |
|    total_timesteps | 1800000  |
| train/             |          |
|    actor_loss      | -53.1    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -1.91    |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 3599697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 669      |
|    ep_rew_mean     | 606      |
| time/              |          |
|    episodes        | 2260     |
|    fps             | 40       |
|    time_elapsed    | 44644    |
|    total_timesteps | 1800704  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | -1.83    |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 3600401  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 671      |
|    ep_rew_mean     | 608      |
| time/              |          |
|    episodes        | 2264     |
|    fps             | 40       |
|    time_elapsed    | 44708    |
|    total_timesteps | 1803432  |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 6.95     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | 0.91     |
|    learning_rate   | 8.2e-05  |
|    n_updates       | 3603129  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 672      |
|    ep_rew_mean     | 609      |
| time/              |          |
|    episodes        | 2268     |
|    fps             | 40       |
|    time_elapsed    | 44775    |
|    total_timesteps | 1806369  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 7.45     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | -0.23    |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 3606066  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 675      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 2272     |
|    fps             | 40       |
|    time_elapsed    | 44839    |
|    total_timesteps | 1809156  |
| train/             |          |
|    actor_loss      | -49.8    |
|    critic_loss     | 8.52     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 1.51     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 3608853  |
---------------------------------
Eval num_timesteps=1810000, episode_reward=702.83 +/- 0.00
Episode length: 774.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 774      |
|    mean_reward     | 703      |
| time/              |          |
|    total_timesteps | 1810000  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 6        |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.949   |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 3609697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 677      |
|    ep_rew_mean     | 613      |
| time/              |          |
|    episodes        | 2276     |
|    fps             | 40       |
|    time_elapsed    | 44930    |
|    total_timesteps | 1812242  |
| train/             |          |
|    actor_loss      | -48.4    |
|    critic_loss     | 12       |
|    ent_coef        | 0.0159   |
|    ent_coef_loss   | 3.86     |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 3611939  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 675      |
|    ep_rew_mean     | 611      |
| time/              |          |
|    episodes        | 2280     |
|    fps             | 40       |
|    time_elapsed    | 44993    |
|    total_timesteps | 1814954  |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 7.44     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -2.55    |
|    learning_rate   | 8.19e-05 |
|    n_updates       | 3614651  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 676      |
|    ep_rew_mean     | 612      |
| time/              |          |
|    episodes        | 2284     |
|    fps             | 40       |
|    time_elapsed    | 45059    |
|    total_timesteps | 1817858  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 5.98     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 4.82     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 3617555  |
---------------------------------
Eval num_timesteps=1820000, episode_reward=864.63 +/- 0.00
Episode length: 950.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 950      |
|    mean_reward     | 865      |
| time/              |          |
|    total_timesteps | 1820000  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 7.81     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | -0.721   |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 3619697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 679      |
|    ep_rew_mean     | 615      |
| time/              |          |
|    episodes        | 2288     |
|    fps             | 40       |
|    time_elapsed    | 45163    |
|    total_timesteps | 1821542  |
| train/             |          |
|    actor_loss      | -49.8    |
|    critic_loss     | 8.85     |
|    ent_coef        | 0.016    |
|    ent_coef_loss   | 5.28     |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 3621239  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 679      |
|    ep_rew_mean     | 615      |
| time/              |          |
|    episodes        | 2292     |
|    fps             | 40       |
|    time_elapsed    | 45231    |
|    total_timesteps | 1824512  |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 6.07     |
|    ent_coef        | 0.0161   |
|    ent_coef_loss   | -0.335   |
|    learning_rate   | 8.18e-05 |
|    n_updates       | 3624209  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 681      |
|    ep_rew_mean     | 617      |
| time/              |          |
|    episodes        | 2296     |
|    fps             | 40       |
|    time_elapsed    | 45302    |
|    total_timesteps | 1827721  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 8.15     |
|    ent_coef        | 0.0162   |
|    ent_coef_loss   | -1.07    |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 3627418  |
---------------------------------
Eval num_timesteps=1830000, episode_reward=730.98 +/- 0.00
Episode length: 802.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 731      |
| time/              |          |
|    total_timesteps | 1830000  |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 6.69     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -1.15    |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 3629697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 685      |
|    ep_rew_mean     | 621      |
| time/              |          |
|    episodes        | 2300     |
|    fps             | 40       |
|    time_elapsed    | 45393    |
|    total_timesteps | 1830811  |
| train/             |          |
|    actor_loss      | -53.5    |
|    critic_loss     | 6.12     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 1.11     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 3630508  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 689      |
|    ep_rew_mean     | 625      |
| time/              |          |
|    episodes        | 2304     |
|    fps             | 40       |
|    time_elapsed    | 45465    |
|    total_timesteps | 1833909  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 1.04     |
|    learning_rate   | 8.17e-05 |
|    n_updates       | 3633606  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 691      |
|    ep_rew_mean     | 627      |
| time/              |          |
|    episodes        | 2308     |
|    fps             | 40       |
|    time_elapsed    | 45535    |
|    total_timesteps | 1836941  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 6.4      |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | -1.18    |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 3636638  |
---------------------------------
Eval num_timesteps=1840000, episode_reward=732.20 +/- 0.00
Episode length: 806.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 806      |
|    mean_reward     | 732      |
| time/              |          |
|    total_timesteps | 1840000  |
| train/             |          |
|    actor_loss      | -49.3    |
|    critic_loss     | 6.6      |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | -0.562   |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 3639697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 698      |
|    ep_rew_mean     | 633      |
| time/              |          |
|    episodes        | 2312     |
|    fps             | 40       |
|    time_elapsed    | 45638    |
|    total_timesteps | 1840735  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 6.81     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 2.54     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 3640432  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 639      |
| time/              |          |
|    episodes        | 2316     |
|    fps             | 40       |
|    time_elapsed    | 45708    |
|    total_timesteps | 1843804  |
| train/             |          |
|    actor_loss      | -55      |
|    critic_loss     | 6.37     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 4.12     |
|    learning_rate   | 8.16e-05 |
|    n_updates       | 3643501  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2320     |
|    fps             | 40       |
|    time_elapsed    | 45775    |
|    total_timesteps | 1846676  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 7.28     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 5.02     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 3646373  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 2324     |
|    fps             | 40       |
|    time_elapsed    | 45842    |
|    total_timesteps | 1849666  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 6.6      |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 0.476    |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 3649363  |
---------------------------------
Eval num_timesteps=1850000, episode_reward=725.14 +/- 0.00
Episode length: 802.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 802      |
|    mean_reward     | 725      |
| time/              |          |
|    total_timesteps | 1850000  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 7.53     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 5.98     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 3649697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 714      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 2328     |
|    fps             | 40       |
|    time_elapsed    | 45936    |
|    total_timesteps | 1852867  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 8.48     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 2.16     |
|    learning_rate   | 8.15e-05 |
|    n_updates       | 3652564  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2332     |
|    fps             | 40       |
|    time_elapsed    | 46003    |
|    total_timesteps | 1855703  |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 4.28     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -0.67    |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 3655400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 718      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 2336     |
|    fps             | 40       |
|    time_elapsed    | 46069    |
|    total_timesteps | 1858587  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 8.88     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 4.76     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 3658284  |
---------------------------------
Eval num_timesteps=1860000, episode_reward=864.65 +/- 0.00
Episode length: 953.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 953      |
|    mean_reward     | 865      |
| time/              |          |
|    total_timesteps | 1860000  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 8.81     |
|    ent_coef        | 0.0164   |
|    ent_coef_loss   | 2.76     |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 3659697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 723      |
|    ep_rew_mean     | 655      |
| time/              |          |
|    episodes        | 2340     |
|    fps             | 40       |
|    time_elapsed    | 46174    |
|    total_timesteps | 1862385  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 8.49     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | -0.599   |
|    learning_rate   | 8.14e-05 |
|    n_updates       | 3662082  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 2344     |
|    fps             | 40       |
|    time_elapsed    | 46242    |
|    total_timesteps | 1865318  |
| train/             |          |
|    actor_loss      | -51.5    |
|    critic_loss     | 9        |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 0.98     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 3665015  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 2348     |
|    fps             | 40       |
|    time_elapsed    | 46301    |
|    total_timesteps | 1867871  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 7.02     |
|    ent_coef        | 0.0165   |
|    ent_coef_loss   | 0.476    |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 3667568  |
---------------------------------
Eval num_timesteps=1870000, episode_reward=627.70 +/- 0.00
Episode length: 685.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 685      |
|    mean_reward     | 628      |
| time/              |          |
|    total_timesteps | 1870000  |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 5.47     |
|    ent_coef        | 0.0163   |
|    ent_coef_loss   | 2.43     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 3669697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 729      |
|    ep_rew_mean     | 661      |
| time/              |          |
|    episodes        | 2352     |
|    fps             | 40       |
|    time_elapsed    | 46399    |
|    total_timesteps | 1871315  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 6.75     |
|    ent_coef        | 0.0166   |
|    ent_coef_loss   | 4.02     |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 3671012  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 2356     |
|    fps             | 40       |
|    time_elapsed    | 46466    |
|    total_timesteps | 1874341  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 8.33     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -2.18    |
|    learning_rate   | 8.13e-05 |
|    n_updates       | 3674038  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 734      |
|    ep_rew_mean     | 666      |
| time/              |          |
|    episodes        | 2360     |
|    fps             | 40       |
|    time_elapsed    | 46537    |
|    total_timesteps | 1877403  |
| train/             |          |
|    actor_loss      | -53.2    |
|    critic_loss     | 6.31     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -1.35    |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 3677100  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 2364     |
|    fps             | 40       |
|    time_elapsed    | 46606    |
|    total_timesteps | 1879941  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 8.52     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 1.02     |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 3679638  |
---------------------------------
Eval num_timesteps=1880000, episode_reward=631.21 +/- 0.00
Episode length: 692.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 692      |
|    mean_reward     | 631      |
| time/              |          |
|    total_timesteps | 1880000  |
| train/             |          |
|    actor_loss      | -54.3    |
|    critic_loss     | 7.54     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -3.14    |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 3679697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 2368     |
|    fps             | 40       |
|    time_elapsed    | 46700    |
|    total_timesteps | 1882990  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 6.11     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -0.913   |
|    learning_rate   | 8.12e-05 |
|    n_updates       | 3682687  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 668      |
| time/              |          |
|    episodes        | 2372     |
|    fps             | 40       |
|    time_elapsed    | 46772    |
|    total_timesteps | 1886100  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 6.91     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 5.07     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 3685797  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 737      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 2376     |
|    fps             | 40       |
|    time_elapsed    | 46840    |
|    total_timesteps | 1889084  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 8        |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 0.0888   |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 3688781  |
---------------------------------
Eval num_timesteps=1890000, episode_reward=685.75 +/- 0.00
Episode length: 760.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 760      |
|    mean_reward     | 686      |
| time/              |          |
|    total_timesteps | 1890000  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 8.62     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 2.48     |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 3689697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 2380     |
|    fps             | 40       |
|    time_elapsed    | 46935    |
|    total_timesteps | 1892257  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 6.37     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | -0.36    |
|    learning_rate   | 8.11e-05 |
|    n_updates       | 3691954  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 2384     |
|    fps             | 40       |
|    time_elapsed    | 47006    |
|    total_timesteps | 1895158  |
| train/             |          |
|    actor_loss      | -57.8    |
|    critic_loss     | 6.55     |
|    ent_coef        | 0.0169   |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 3694855  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 2388     |
|    fps             | 40       |
|    time_elapsed    | 47081    |
|    total_timesteps | 1898053  |
| train/             |          |
|    actor_loss      | -56.7    |
|    critic_loss     | 5.93     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 2.71     |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 3697750  |
---------------------------------
Eval num_timesteps=1900000, episode_reward=659.49 +/- 0.00
Episode length: 726.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 726      |
|    mean_reward     | 659      |
| time/              |          |
|    total_timesteps | 1900000  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 9.87     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | -0.657   |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 3699697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 2392     |
|    fps             | 40       |
|    time_elapsed    | 47202    |
|    total_timesteps | 1901516  |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 8.17     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 0.174    |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 3701213  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 668      |
| time/              |          |
|    episodes        | 2396     |
|    fps             | 40       |
|    time_elapsed    | 47284    |
|    total_timesteps | 1904528  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 7.55     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | 0.665    |
|    learning_rate   | 8.1e-05  |
|    n_updates       | 3704225  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 2400     |
|    fps             | 40       |
|    time_elapsed    | 47365    |
|    total_timesteps | 1907487  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 6.2      |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 3707184  |
---------------------------------
Eval num_timesteps=1910000, episode_reward=725.46 +/- 0.00
Episode length: 804.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 804      |
|    mean_reward     | 725      |
| time/              |          |
|    total_timesteps | 1910000  |
| train/             |          |
|    actor_loss      | -52.3    |
|    critic_loss     | 9.67     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 0.378    |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 3709697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 735      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 2404     |
|    fps             | 40       |
|    time_elapsed    | 47478    |
|    total_timesteps | 1910801  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 7.56     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 1.1      |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 3710498  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 733      |
|    ep_rew_mean     | 665      |
| time/              |          |
|    episodes        | 2408     |
|    fps             | 40       |
|    time_elapsed    | 47555    |
|    total_timesteps | 1913634  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 9.34     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.331    |
|    learning_rate   | 8.09e-05 |
|    n_updates       | 3713331  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 731      |
|    ep_rew_mean     | 663      |
| time/              |          |
|    episodes        | 2412     |
|    fps             | 40       |
|    time_elapsed    | 47636    |
|    total_timesteps | 1916617  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 8.35     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 2.87     |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 3716314  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 732      |
|    ep_rew_mean     | 664      |
| time/              |          |
|    episodes        | 2416     |
|    fps             | 40       |
|    time_elapsed    | 47723    |
|    total_timesteps | 1919796  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 6.75     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.403   |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 3719493  |
---------------------------------
Eval num_timesteps=1920000, episode_reward=682.61 +/- 0.00
Episode length: 759.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 759      |
|    mean_reward     | 683      |
| time/              |          |
|    total_timesteps | 1920000  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 6.34     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -2.43    |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 3719697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 2420     |
|    fps             | 40       |
|    time_elapsed    | 47833    |
|    total_timesteps | 1923219  |
| train/             |          |
|    actor_loss      | -50.5    |
|    critic_loss     | 6.76     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.0601  |
|    learning_rate   | 8.08e-05 |
|    n_updates       | 3722916  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 736      |
|    ep_rew_mean     | 667      |
| time/              |          |
|    episodes        | 2424     |
|    fps             | 40       |
|    time_elapsed    | 47914    |
|    total_timesteps | 1926275  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 8.07     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.28    |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 3725972  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 2428     |
|    fps             | 40       |
|    time_elapsed    | 47995    |
|    total_timesteps | 1929333  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 8.3      |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | 3.85     |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 3729030  |
---------------------------------
Eval num_timesteps=1930000, episode_reward=737.43 +/- 0.00
Episode length: 812.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 812      |
|    mean_reward     | 737      |
| time/              |          |
|    total_timesteps | 1930000  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 7.59     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 1.37     |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 3729697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 740      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 2432     |
|    fps             | 40       |
|    time_elapsed    | 48112    |
|    total_timesteps | 1932970  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 6.96     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 2.02     |
|    learning_rate   | 8.07e-05 |
|    n_updates       | 3732667  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 2436     |
|    fps             | 40       |
|    time_elapsed    | 48195    |
|    total_timesteps | 1936176  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 6.3      |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 0.812    |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 3735873  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 743      |
|    ep_rew_mean     | 673      |
| time/              |          |
|    episodes        | 2440     |
|    fps             | 40       |
|    time_elapsed    | 48276    |
|    total_timesteps | 1939130  |
| train/             |          |
|    actor_loss      | -54.7    |
|    critic_loss     | 4.99     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -5.6     |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 3738827  |
---------------------------------
Eval num_timesteps=1940000, episode_reward=728.92 +/- 0.00
Episode length: 811.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 811      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 1940000  |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 12.2     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -0.954   |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 3739697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 744      |
|    ep_rew_mean     | 674      |
| time/              |          |
|    episodes        | 2444     |
|    fps             | 40       |
|    time_elapsed    | 48384    |
|    total_timesteps | 1942287  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 7.91     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -0.914   |
|    learning_rate   | 8.06e-05 |
|    n_updates       | 3741984  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 746      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 2448     |
|    fps             | 40       |
|    time_elapsed    | 48456    |
|    total_timesteps | 1945063  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 6.41     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -1.24    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 3744760  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 746      |
|    ep_rew_mean     | 676      |
| time/              |          |
|    episodes        | 2452     |
|    fps             | 40       |
|    time_elapsed    | 48533    |
|    total_timesteps | 1947947  |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 0.452    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 3747644  |
---------------------------------
Eval num_timesteps=1950000, episode_reward=720.52 +/- 0.00
Episode length: 794.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 794      |
|    mean_reward     | 721      |
| time/              |          |
|    total_timesteps | 1950000  |
| train/             |          |
|    actor_loss      | -48.2    |
|    critic_loss     | 8.81     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.92     |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 3749697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 2456     |
|    fps             | 40       |
|    time_elapsed    | 48649    |
|    total_timesteps | 1951596  |
| train/             |          |
|    actor_loss      | -54.5    |
|    critic_loss     | 6.72     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 3751293  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 747      |
|    ep_rew_mean     | 677      |
| time/              |          |
|    episodes        | 2460     |
|    fps             | 40       |
|    time_elapsed    | 48730    |
|    total_timesteps | 1954638  |
| train/             |          |
|    actor_loss      | -55.8    |
|    critic_loss     | 6.47     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -2.37    |
|    learning_rate   | 8.05e-05 |
|    n_updates       | 3754335  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 751      |
|    ep_rew_mean     | 681      |
| time/              |          |
|    episodes        | 2464     |
|    fps             | 40       |
|    time_elapsed    | 48806    |
|    total_timesteps | 1957589  |
| train/             |          |
|    actor_loss      | -53.8    |
|    critic_loss     | 7.91     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 0.255    |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 3757286  |
---------------------------------
Eval num_timesteps=1960000, episode_reward=737.02 +/- 0.00
Episode length: 810.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 810      |
|    mean_reward     | 737      |
| time/              |          |
|    total_timesteps | 1960000  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -0.0676  |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 3759697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 752      |
|    ep_rew_mean     | 682      |
| time/              |          |
|    episodes        | 2468     |
|    fps             | 40       |
|    time_elapsed    | 48932    |
|    total_timesteps | 1961525  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 9.42     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | -1.01    |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 3761222  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 680      |
| time/              |          |
|    episodes        | 2472     |
|    fps             | 40       |
|    time_elapsed    | 49007    |
|    total_timesteps | 1964407  |
| train/             |          |
|    actor_loss      | -56.2    |
|    critic_loss     | 5.39     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -2.71    |
|    learning_rate   | 8.04e-05 |
|    n_updates       | 3764104  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 750      |
|    ep_rew_mean     | 680      |
| time/              |          |
|    episodes        | 2476     |
|    fps             | 40       |
|    time_elapsed    | 49085    |
|    total_timesteps | 1967414  |
| train/             |          |
|    actor_loss      | -55.2    |
|    critic_loss     | 6.57     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -4.33    |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 3767111  |
---------------------------------
Eval num_timesteps=1970000, episode_reward=619.78 +/- 0.00
Episode length: 682.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 682      |
|    mean_reward     | 620      |
| time/              |          |
|    total_timesteps | 1970000  |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 5.62     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 3769697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 2480     |
|    fps             | 40       |
|    time_elapsed    | 49195    |
|    total_timesteps | 1970703  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 5.79     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -0.535   |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 3770400  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 2484     |
|    fps             | 40       |
|    time_elapsed    | 49275    |
|    total_timesteps | 1973546  |
| train/             |          |
|    actor_loss      | -51.8    |
|    critic_loss     | 10.7     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | -0.167   |
|    learning_rate   | 8.03e-05 |
|    n_updates       | 3773243  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 749      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 2488     |
|    fps             | 40       |
|    time_elapsed    | 49355    |
|    total_timesteps | 1976486  |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 7.73     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 0.411    |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 3776183  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 748      |
|    ep_rew_mean     | 678      |
| time/              |          |
|    episodes        | 2492     |
|    fps             | 40       |
|    time_elapsed    | 49436    |
|    total_timesteps | 1979463  |
| train/             |          |
|    actor_loss      | -50.7    |
|    critic_loss     | 6.16     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 2.93     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 3779160  |
---------------------------------
Eval num_timesteps=1980000, episode_reward=728.88 +/- 0.00
Episode length: 815.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 815      |
|    mean_reward     | 729      |
| time/              |          |
|    total_timesteps | 1980000  |
| train/             |          |
|    actor_loss      | -49.9    |
|    critic_loss     | 8.03     |
|    ent_coef        | 0.0177   |
|    ent_coef_loss   | 1.29     |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 3779697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 742      |
|    ep_rew_mean     | 672      |
| time/              |          |
|    episodes        | 2496     |
|    fps             | 40       |
|    time_elapsed    | 49538    |
|    total_timesteps | 1982373  |
| train/             |          |
|    actor_loss      | -50.2    |
|    critic_loss     | 6.16     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -0.317   |
|    learning_rate   | 8.02e-05 |
|    n_updates       | 3782070  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 741      |
|    ep_rew_mean     | 671      |
| time/              |          |
|    episodes        | 2500     |
|    fps             | 40       |
|    time_elapsed    | 49614    |
|    total_timesteps | 1985220  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 6.74     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | 0.0975   |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 3784917  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 2504     |
|    fps             | 40       |
|    time_elapsed    | 49689    |
|    total_timesteps | 1988114  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 5.85     |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -1.73    |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 3787811  |
---------------------------------
Eval num_timesteps=1990000, episode_reward=620.89 +/- 0.00
Episode length: 682.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 682      |
|    mean_reward     | 621      |
| time/              |          |
|    total_timesteps | 1990000  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 7.14     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 2.08     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 3789697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 739      |
|    ep_rew_mean     | 670      |
| time/              |          |
|    episodes        | 2508     |
|    fps             | 39       |
|    time_elapsed    | 49800    |
|    total_timesteps | 1991432  |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 8.77     |
|    ent_coef        | 0.017    |
|    ent_coef_loss   | 3.05     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 3791129  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 738      |
|    ep_rew_mean     | 669      |
| time/              |          |
|    episodes        | 2512     |
|    fps             | 39       |
|    time_elapsed    | 49877    |
|    total_timesteps | 1994339  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 14       |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 5.44     |
|    learning_rate   | 8.01e-05 |
|    n_updates       | 3794036  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 2516     |
|    fps             | 39       |
|    time_elapsed    | 49938    |
|    total_timesteps | 1996532  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 9.79     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 2.34     |
|    learning_rate   | 8e-05    |
|    n_updates       | 3796229  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 728      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 2520     |
|    fps             | 39       |
|    time_elapsed    | 50025    |
|    total_timesteps | 1999720  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 6.14     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | -0.178   |
|    learning_rate   | 8e-05    |
|    n_updates       | 3799417  |
---------------------------------
Eval num_timesteps=2000000, episode_reward=735.65 +/- 0.00
Episode length: 817.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 817      |
|    mean_reward     | 736      |
| time/              |          |
|    total_timesteps | 2000000  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 6.75     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 4.97     |
|    learning_rate   | 8e-05    |
|    n_updates       | 3799697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 727      |
|    ep_rew_mean     | 660      |
| time/              |          |
|    episodes        | 2524     |
|    fps             | 39       |
|    time_elapsed    | 50139    |
|    total_timesteps | 2002982  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 5.1      |
|    ent_coef        | 0.0167   |
|    ent_coef_loss   | -6.41    |
|    learning_rate   | 8e-05    |
|    n_updates       | 3802679  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 718      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 2528     |
|    fps             | 39       |
|    time_elapsed    | 50198    |
|    total_timesteps | 2005098  |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 11.6     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -1.25    |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 3804795  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 2532     |
|    fps             | 39       |
|    time_elapsed    | 50280    |
|    total_timesteps | 2008173  |
| train/             |          |
|    actor_loss      | -50.1    |
|    critic_loss     | 8.27     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 4.4      |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 3807870  |
---------------------------------
Eval num_timesteps=2010000, episode_reward=718.58 +/- 0.00
Episode length: 793.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 793      |
|    mean_reward     | 719      |
| time/              |          |
|    total_timesteps | 2010000  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 4.74     |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | 2.5      |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 3809697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2536     |
|    fps             | 39       |
|    time_elapsed    | 50393    |
|    total_timesteps | 2011544  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 13.2     |
|    ent_coef        | 0.0172   |
|    ent_coef_loss   | 3.83     |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 3811241  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 718      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 2540     |
|    fps             | 39       |
|    time_elapsed    | 50477    |
|    total_timesteps | 2014654  |
| train/             |          |
|    actor_loss      | -49.2    |
|    critic_loss     | 9.13     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | 2.1      |
|    learning_rate   | 7.99e-05 |
|    n_updates       | 3814351  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2544     |
|    fps             | 39       |
|    time_elapsed    | 50553    |
|    total_timesteps | 2017533  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 7.37     |
|    ent_coef        | 0.0168   |
|    ent_coef_loss   | -2.88    |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 3817230  |
---------------------------------
Eval num_timesteps=2020000, episode_reward=719.58 +/- 0.00
Episode length: 783.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 783      |
|    mean_reward     | 720      |
| time/              |          |
|    total_timesteps | 2020000  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 6.29     |
|    ent_coef        | 0.0171   |
|    ent_coef_loss   | 0.916    |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 3819697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2548     |
|    fps             | 39       |
|    time_elapsed    | 50664    |
|    total_timesteps | 2020746  |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 10.5     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -3.59    |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 3820443  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 716      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2552     |
|    fps             | 39       |
|    time_elapsed    | 50739    |
|    total_timesteps | 2023496  |
| train/             |          |
|    actor_loss      | -52.9    |
|    critic_loss     | 4.95     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | -2.38    |
|    learning_rate   | 7.98e-05 |
|    n_updates       | 3823193  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 2556     |
|    fps             | 39       |
|    time_elapsed    | 50809    |
|    total_timesteps | 2026290  |
| train/             |          |
|    actor_loss      | -53.3    |
|    critic_loss     | 6.61     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -0.626   |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 3825987  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2560     |
|    fps             | 39       |
|    time_elapsed    | 50887    |
|    total_timesteps | 2029169  |
| train/             |          |
|    actor_loss      | -52      |
|    critic_loss     | 6.1      |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 0.0776   |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 3828866  |
---------------------------------
Eval num_timesteps=2030000, episode_reward=713.85 +/- 0.00
Episode length: 795.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 795      |
|    mean_reward     | 714      |
| time/              |          |
|    total_timesteps | 2030000  |
| train/             |          |
|    actor_loss      | -56.6    |
|    critic_loss     | 5.44     |
|    ent_coef        | 0.0176   |
|    ent_coef_loss   | -2.21    |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 3829697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2564     |
|    fps             | 39       |
|    time_elapsed    | 50998    |
|    total_timesteps | 2032267  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | 1.52     |
|    learning_rate   | 7.97e-05 |
|    n_updates       | 3831964  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2568     |
|    fps             | 39       |
|    time_elapsed    | 51082    |
|    total_timesteps | 2035348  |
| train/             |          |
|    actor_loss      | -46.7    |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0178   |
|    ent_coef_loss   | 4.83     |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 3835045  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2572     |
|    fps             | 39       |
|    time_elapsed    | 51160    |
|    total_timesteps | 2038317  |
| train/             |          |
|    actor_loss      | -49      |
|    critic_loss     | 7.02     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.19     |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 3838014  |
---------------------------------
Eval num_timesteps=2040000, episode_reward=643.61 +/- 0.00
Episode length: 708.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 708      |
|    mean_reward     | 644      |
| time/              |          |
|    total_timesteps | 2040000  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 7.23     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -3.54    |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 3839697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2576     |
|    fps             | 39       |
|    time_elapsed    | 51269    |
|    total_timesteps | 2041393  |
| train/             |          |
|    actor_loss      | -48.5    |
|    critic_loss     | 7.12     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -1.58    |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 3841090  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 2580     |
|    fps             | 39       |
|    time_elapsed    | 51352    |
|    total_timesteps | 2044467  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 5.89     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -0.78    |
|    learning_rate   | 7.96e-05 |
|    n_updates       | 3844164  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2584     |
|    fps             | 39       |
|    time_elapsed    | 51425    |
|    total_timesteps | 2047192  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 8.17     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -2.9     |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 3846889  |
---------------------------------
Eval num_timesteps=2050000, episode_reward=718.47 +/- 0.00
Episode length: 799.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 799      |
|    mean_reward     | 718      |
| time/              |          |
|    total_timesteps | 2050000  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 6.77     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | -5.11    |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 3849697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2588     |
|    fps             | 39       |
|    time_elapsed    | 51543    |
|    total_timesteps | 2050793  |
| train/             |          |
|    actor_loss      | -51.9    |
|    critic_loss     | 7.62     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.71     |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 3850490  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2592     |
|    fps             | 39       |
|    time_elapsed    | 51621    |
|    total_timesteps | 2053638  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 5.26     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -1.86    |
|    learning_rate   | 7.95e-05 |
|    n_updates       | 3853335  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2596     |
|    fps             | 39       |
|    time_elapsed    | 51703    |
|    total_timesteps | 2056600  |
| train/             |          |
|    actor_loss      | -50.3    |
|    critic_loss     | 6.06     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | -0.634   |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 3856297  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 2600     |
|    fps             | 39       |
|    time_elapsed    | 51785    |
|    total_timesteps | 2059600  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 5.93     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -1.66    |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 3859297  |
---------------------------------
Eval num_timesteps=2060000, episode_reward=715.23 +/- 0.00
Episode length: 779.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 779      |
|    mean_reward     | 715      |
| time/              |          |
|    total_timesteps | 2060000  |
| train/             |          |
|    actor_loss      | -47.6    |
|    critic_loss     | 7.34     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | 6.24     |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 3859697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2604     |
|    fps             | 39       |
|    time_elapsed    | 51894    |
|    total_timesteps | 2062717  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 5.8      |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -0.199   |
|    learning_rate   | 7.94e-05 |
|    n_updates       | 3862414  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 716      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2608     |
|    fps             | 39       |
|    time_elapsed    | 51974    |
|    total_timesteps | 2065582  |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 8.35     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 1.38     |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 3865279  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 714      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2612     |
|    fps             | 39       |
|    time_elapsed    | 52046    |
|    total_timesteps | 2068325  |
| train/             |          |
|    actor_loss      | -54.4    |
|    critic_loss     | 5.78     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | -6.6     |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 3868022  |
---------------------------------
Eval num_timesteps=2070000, episode_reward=616.81 +/- 0.00
Episode length: 671.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 671      |
|    mean_reward     | 617      |
| time/              |          |
|    total_timesteps | 2070000  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | 2.12     |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 3869697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 653      |
| time/              |          |
|    episodes        | 2616     |
|    fps             | 39       |
|    time_elapsed    | 52150    |
|    total_timesteps | 2071317  |
| train/             |          |
|    actor_loss      | -52.4    |
|    critic_loss     | 7.69     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -0.385   |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 3871014  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 717      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 2620     |
|    fps             | 39       |
|    time_elapsed    | 52230    |
|    total_timesteps | 2074306  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 5.74     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 0.396    |
|    learning_rate   | 7.93e-05 |
|    n_updates       | 3874003  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2624     |
|    fps             | 39       |
|    time_elapsed    | 52308    |
|    total_timesteps | 2077124  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 7.62     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 1.28     |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 3876821  |
---------------------------------
Eval num_timesteps=2080000, episode_reward=635.95 +/- 0.00
Episode length: 694.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 694      |
|    mean_reward     | 636      |
| time/              |          |
|    total_timesteps | 2080000  |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 6.08     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | 0.208    |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 3879697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 724      |
|    ep_rew_mean     | 658      |
| time/              |          |
|    episodes        | 2628     |
|    fps             | 39       |
|    time_elapsed    | 52429    |
|    total_timesteps | 2080801  |
| train/             |          |
|    actor_loss      | -51.7    |
|    critic_loss     | 6.33     |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | 3.63     |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 3880498  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 656      |
| time/              |          |
|    episodes        | 2632     |
|    fps             | 39       |
|    time_elapsed    | 52504    |
|    total_timesteps | 2083648  |
| train/             |          |
|    actor_loss      | -54      |
|    critic_loss     | 6.7      |
|    ent_coef        | 0.0192   |
|    ent_coef_loss   | -1.92    |
|    learning_rate   | 7.92e-05 |
|    n_updates       | 3883345  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 655      |
| time/              |          |
|    episodes        | 2636     |
|    fps             | 39       |
|    time_elapsed    | 52581    |
|    total_timesteps | 2086510  |
| train/             |          |
|    actor_loss      | -51.1    |
|    critic_loss     | 7.92     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 2.6      |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 3886207  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 719      |
|    ep_rew_mean     | 654      |
| time/              |          |
|    episodes        | 2640     |
|    fps             | 39       |
|    time_elapsed    | 52661    |
|    total_timesteps | 2089476  |
| train/             |          |
|    actor_loss      | -48.5    |
|    critic_loss     | 4.87     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 0.861    |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 3889173  |
---------------------------------
Eval num_timesteps=2090000, episode_reward=683.74 +/- 0.00
Episode length: 755.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 755      |
|    mean_reward     | 684      |
| time/              |          |
|    total_timesteps | 2090000  |
| train/             |          |
|    actor_loss      | -53.4    |
|    critic_loss     | 8.95     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -1.51    |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 3889697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 654      |
| time/              |          |
|    episodes        | 2644     |
|    fps             | 39       |
|    time_elapsed    | 52784    |
|    total_timesteps | 2092980  |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -2.23    |
|    learning_rate   | 7.91e-05 |
|    n_updates       | 3892677  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 721      |
|    ep_rew_mean     | 656      |
| time/              |          |
|    episodes        | 2648     |
|    fps             | 39       |
|    time_elapsed    | 52864    |
|    total_timesteps | 2095891  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 7.2      |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | 2.05     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 3895588  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 723      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 2652     |
|    fps             | 39       |
|    time_elapsed    | 52945    |
|    total_timesteps | 2098849  |
| train/             |          |
|    actor_loss      | -53.9    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 0.483    |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 3898546  |
---------------------------------
Eval num_timesteps=2100000, episode_reward=623.83 +/- 0.00
Episode length: 681.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 681      |
|    mean_reward     | 624      |
| time/              |          |
|    total_timesteps | 2100000  |
| train/             |          |
|    actor_loss      | -55.4    |
|    critic_loss     | 10.5     |
|    ent_coef        | 0.0181   |
|    ent_coef_loss   | -2.01    |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 3899697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 722      |
|    ep_rew_mean     | 657      |
| time/              |          |
|    episodes        | 2656     |
|    fps             | 39       |
|    time_elapsed    | 53051    |
|    total_timesteps | 2101940  |
| train/             |          |
|    actor_loss      | -48.7    |
|    critic_loss     | 7.26     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 3.14     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 3901637  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 650      |
| time/              |          |
|    episodes        | 2660     |
|    fps             | 39       |
|    time_elapsed    | 53115    |
|    total_timesteps | 2104094  |
| train/             |          |
|    actor_loss      | -52.2    |
|    critic_loss     | 6.93     |
|    ent_coef        | 0.018    |
|    ent_coef_loss   | 1.67     |
|    learning_rate   | 7.9e-05  |
|    n_updates       | 3903791  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 713      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 2664     |
|    fps             | 39       |
|    time_elapsed    | 53195    |
|    total_timesteps | 2106837  |
| train/             |          |
|    actor_loss      | -47.4    |
|    critic_loss     | 8.96     |
|    ent_coef        | 0.0179   |
|    ent_coef_loss   | 1.18     |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 3906534  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 2668     |
|    fps             | 39       |
|    time_elapsed    | 53274    |
|    total_timesteps | 2109592  |
| train/             |          |
|    actor_loss      | -50.8    |
|    critic_loss     | 7.9      |
|    ent_coef        | 0.0175   |
|    ent_coef_loss   | -0.502   |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 3909289  |
---------------------------------
Eval num_timesteps=2110000, episode_reward=648.08 +/- 0.00
Episode length: 709.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 709      |
|    mean_reward     | 648      |
| time/              |          |
|    total_timesteps | 2110000  |
| train/             |          |
|    actor_loss      | -51.4    |
|    critic_loss     | 7.39     |
|    ent_coef        | 0.0174   |
|    ent_coef_loss   | -1.74    |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 3909697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 708      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2672     |
|    fps             | 39       |
|    time_elapsed    | 53395    |
|    total_timesteps | 2112807  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 5.17     |
|    ent_coef        | 0.0173   |
|    ent_coef_loss   | -0.785   |
|    learning_rate   | 7.89e-05 |
|    n_updates       | 3912504  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2676     |
|    fps             | 39       |
|    time_elapsed    | 53479    |
|    total_timesteps | 2115664  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 6.36     |
|    ent_coef        | 0.0184   |
|    ent_coef_loss   | -3.54    |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 3915361  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 707      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 2680     |
|    fps             | 39       |
|    time_elapsed    | 53555    |
|    total_timesteps | 2118551  |
| train/             |          |
|    actor_loss      | -51.6    |
|    critic_loss     | 11.7     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 3.2      |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 3918248  |
---------------------------------
Eval num_timesteps=2120000, episode_reward=726.56 +/- 0.00
Episode length: 813.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 813      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 2120000  |
| train/             |          |
|    actor_loss      | -54.8    |
|    critic_loss     | 10.1     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | 0.823    |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 3919697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2684     |
|    fps             | 39       |
|    time_elapsed    | 53672    |
|    total_timesteps | 2121590  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 7.54     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | 2.73     |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 3921287  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2688     |
|    fps             | 39       |
|    time_elapsed    | 53757    |
|    total_timesteps | 2124516  |
| train/             |          |
|    actor_loss      | -51.3    |
|    critic_loss     | 8.68     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 1.3      |
|    learning_rate   | 7.88e-05 |
|    n_updates       | 3924213  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 644      |
| time/              |          |
|    episodes        | 2692     |
|    fps             | 39       |
|    time_elapsed    | 53835    |
|    total_timesteps | 2127270  |
| train/             |          |
|    actor_loss      | -50.9    |
|    critic_loss     | 7.1      |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -0.0398  |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 3926967  |
---------------------------------
Eval num_timesteps=2130000, episode_reward=665.84 +/- 0.00
Episode length: 732.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 732      |
|    mean_reward     | 666      |
| time/              |          |
|    total_timesteps | 2130000  |
| train/             |          |
|    actor_loss      | -50      |
|    critic_loss     | 7.67     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | -2.26    |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 3929697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 2696     |
|    fps             | 39       |
|    time_elapsed    | 53952    |
|    total_timesteps | 2130553  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 9.29     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 4.27     |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 3930250  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 704      |
|    ep_rew_mean     | 640      |
| time/              |          |
|    episodes        | 2700     |
|    fps             | 39       |
|    time_elapsed    | 54035    |
|    total_timesteps | 2133415  |
| train/             |          |
|    actor_loss      | -52      |
|    critic_loss     | 6.77     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 0.743    |
|    learning_rate   | 7.87e-05 |
|    n_updates       | 3933112  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 641      |
| time/              |          |
|    episodes        | 2704     |
|    fps             | 39       |
|    time_elapsed    | 54121    |
|    total_timesteps | 2136253  |
| train/             |          |
|    actor_loss      | -52.6    |
|    critic_loss     | 7.38     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | 0.711    |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 3935950  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 2708     |
|    fps             | 39       |
|    time_elapsed    | 54202    |
|    total_timesteps | 2139151  |
| train/             |          |
|    actor_loss      | -53.7    |
|    critic_loss     | 8.03     |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | -0.807   |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 3938848  |
---------------------------------
Eval num_timesteps=2140000, episode_reward=726.60 +/- 0.00
Episode length: 804.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 804      |
|    mean_reward     | 727      |
| time/              |          |
|    total_timesteps | 2140000  |
| train/             |          |
|    actor_loss      | -52.5    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0185   |
|    ent_coef_loss   | 2.15     |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 3939697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 705      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 2712     |
|    fps             | 39       |
|    time_elapsed    | 54313    |
|    total_timesteps | 2142055  |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 11       |
|    ent_coef        | 0.0183   |
|    ent_coef_loss   | 4.78     |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 3941752  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 706      |
|    ep_rew_mean     | 642      |
| time/              |          |
|    episodes        | 2716     |
|    fps             | 39       |
|    time_elapsed    | 54391    |
|    total_timesteps | 2144774  |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 8        |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | 0.824    |
|    learning_rate   | 7.86e-05 |
|    n_updates       | 3944471  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 707      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 2720     |
|    fps             | 39       |
|    time_elapsed    | 54467    |
|    total_timesteps | 2147879  |
| train/             |          |
|    actor_loss      | -49.8    |
|    critic_loss     | 8.83     |
|    ent_coef        | 0.0191   |
|    ent_coef_loss   | 0.559    |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 3947576  |
---------------------------------
Eval num_timesteps=2150000, episode_reward=626.76 +/- 0.00
Episode length: 683.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 683      |
|    mean_reward     | 627      |
| time/              |          |
|    total_timesteps | 2150000  |
| train/             |          |
|    actor_loss      | -49.4    |
|    critic_loss     | 9        |
|    ent_coef        | 0.0192   |
|    ent_coef_loss   | 2.42     |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 3949697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2724     |
|    fps             | 39       |
|    time_elapsed    | 54574    |
|    total_timesteps | 2151505  |
| train/             |          |
|    actor_loss      | -50.8    |
|    critic_loss     | 9.97     |
|    ent_coef        | 0.0195   |
|    ent_coef_loss   | 1.69     |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 3951202  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 710      |
|    ep_rew_mean     | 646      |
| time/              |          |
|    episodes        | 2728     |
|    fps             | 39       |
|    time_elapsed    | 54660    |
|    total_timesteps | 2154605  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 6.9      |
|    ent_coef        | 0.0196   |
|    ent_coef_loss   | -2.35    |
|    learning_rate   | 7.85e-05 |
|    n_updates       | 3954302  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 712      |
|    ep_rew_mean     | 648      |
| time/              |          |
|    episodes        | 2732     |
|    fps             | 39       |
|    time_elapsed    | 54744    |
|    total_timesteps | 2157610  |
| train/             |          |
|    actor_loss      | -54.2    |
|    critic_loss     | 7.48     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | -3.01    |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 3957307  |
---------------------------------
Eval num_timesteps=2160000, episode_reward=638.64 +/- 0.00
Episode length: 706.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 706      |
|    mean_reward     | 639      |
| time/              |          |
|    total_timesteps | 2160000  |
| train/             |          |
|    actor_loss      | -55.1    |
|    critic_loss     | 4.75     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -4.28    |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 3959697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 713      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2736     |
|    fps             | 39       |
|    time_elapsed    | 54854    |
|    total_timesteps | 2160705  |
| train/             |          |
|    actor_loss      | -56      |
|    critic_loss     | 7.59     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | 0.248    |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 3960402  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 2740     |
|    fps             | 39       |
|    time_elapsed    | 54934    |
|    total_timesteps | 2163459  |
| train/             |          |
|    actor_loss      | -47.5    |
|    critic_loss     | 10.7     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | 4.43     |
|    learning_rate   | 7.84e-05 |
|    n_updates       | 3963156  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 711      |
|    ep_rew_mean     | 647      |
| time/              |          |
|    episodes        | 2744     |
|    fps             | 39       |
|    time_elapsed    | 55019    |
|    total_timesteps | 2166412  |
| train/             |          |
|    actor_loss      | -54.6    |
|    critic_loss     | 8.85     |
|    ent_coef        | 0.0188   |
|    ent_coef_loss   | -4.43    |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 3966109  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 709      |
|    ep_rew_mean     | 645      |
| time/              |          |
|    episodes        | 2748     |
|    fps             | 39       |
|    time_elapsed    | 55094    |
|    total_timesteps | 2169136  |
| train/             |          |
|    actor_loss      | -48.5    |
|    critic_loss     | 10.8     |
|    ent_coef        | 0.0187   |
|    ent_coef_loss   | 0.707    |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 3968833  |
---------------------------------
Eval num_timesteps=2170000, episode_reward=678.45 +/- 0.00
Episode length: 748.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 748      |
|    mean_reward     | 678      |
| time/              |          |
|    total_timesteps | 2170000  |
| train/             |          |
|    actor_loss      | -52.1    |
|    critic_loss     | 5.28     |
|    ent_coef        | 0.0186   |
|    ent_coef_loss   | -4.05    |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 3969697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 707      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 2752     |
|    fps             | 39       |
|    time_elapsed    | 55207    |
|    total_timesteps | 2172120  |
| train/             |          |
|    actor_loss      | -52.8    |
|    critic_loss     | 8.71     |
|    ent_coef        | 0.019    |
|    ent_coef_loss   | -1.31    |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 3971817  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 707      |
|    ep_rew_mean     | 643      |
| time/              |          |
|    episodes        | 2756     |
|    fps             | 39       |
|    time_elapsed    | 55286    |
|    total_timesteps | 2174859  |
| train/             |          |
|    actor_loss      | -51.2    |
|    critic_loss     | 11.4     |
|    ent_coef        | 0.0189   |
|    ent_coef_loss   | 1.44     |
|    learning_rate   | 7.83e-05 |
|    n_updates       | 3974556  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 713      |
|    ep_rew_mean     | 649      |
| time/              |          |
|    episodes        | 2760     |
|    fps             | 39       |
|    total_timesteps | 2177614  |
| train/             |          |
|    actor_loss      | -52.7    |
|    critic_loss     | 7.02     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 1.01     |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 3977311  |
---------------------------------
Eval num_timesteps=2180000, episode_reward=659.59 +/- 0.00
Episode length: 725.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 725      |
|    mean_reward     | 660      |
| time/              |          |
|    total_timesteps | 2180000  |
| train/             |          |
|    actor_loss      | -48.6    |
|    critic_loss     | 8.69     |
|    ent_coef        | 0.0194   |
|    ent_coef_loss   | 1.79     |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 3979697  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 715      |
|    ep_rew_mean     | 651      |
| time/              |          |
|    episodes        | 2764     |
|    fps             | 39       |
|    time_elapsed    | 55480    |
|    total_timesteps | 2180804  |
| train/             |          |
|    actor_loss      | -51      |
|    critic_loss     | 7.69     |
|    ent_coef        | 0.0192   |
|    ent_coef_loss   | -2.62    |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 3980501  |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 716      |
|    ep_rew_mean     | 652      |
| time/              |          |
|    episodes        | 2768     |
|    fps             | 39       |
|    time_elapsed    | 55564    |
|    total_timesteps | 2183724  |
| train/             |          |
|    actor_loss      | -53      |
|    critic_loss     | 10.4     |
|    ent_coef        | 0.0198   |
|    ent_coef_loss   | -3.75    |
|    learning_rate   | 7.82e-05 |
|    n_updates       | 3983421  |
